{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from ivyspt.input_processing import split_surfaces, IVSurfaceDataset\n",
    "from ivyspt.ivyspt import IvySPT\n",
    "from ivyspt.market_sensitivity import MarketSensitivityAnalysis\n",
    "from ivyspt.convergence_ntk import ConvergenceNTK\n",
    "from ivyspt.loss_flatness import OptimalLossFlatness\n",
    "\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "RANDOM_STATE = 0\n",
    "N_JOBS = 8\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_data = pd.read_csv('data/pre_train_data.csv', parse_dates=True, index_col=[0, 1], date_format=\"ISO8601\")\n",
    "fine_tune_data = pd.read_csv('data/fine_tune_data.csv', parse_dates=True, index_col=[0, 1], date_format=\"ISO8601\")\n",
    "pre_train_surfaces_train, pre_train_surfaces_validation, pre_train_surfaces_test = split_surfaces(\n",
    "    pre_train_data,\n",
    "    toy_sample=True,\n",
    "    max_points=20,\n",
    "    max_surfaces=5,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "fine_tune_surfaces_train, fine_tune_surfaces_validation, fine_tune_surfaces_test = split_surfaces(\n",
    "    fine_tune_data,\n",
    "    toy_sample=True,\n",
    "    max_points=20,\n",
    "    max_surfaces=5,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'Input Preprocessing' : {\n",
    "        'Mask Proportions' : [0.1, 0.3, 0.5, 0.7],\n",
    "        'Number of Query Points' : 1,\n",
    "        'Batch Size' : 5\n",
    "    },\n",
    "    'Surface Embedding' : {\n",
    "        'Embedding Dimension' : 64,\n",
    "    },\n",
    "    'Surface Encoding' : {\n",
    "        'Number of Heads' : 4,\n",
    "        'FFN Hidden Dimension' : 256,\n",
    "        'Attention Dropout' : 0.,\n",
    "        'Gate Dropout' : 0.,\n",
    "        'FFN Dropout' : 0.,\n",
    "        'Number of Blocks' : 4,\n",
    "        'External Feature Dimension' : 5,\n",
    "        'Weight Initializer Std.' : 0.02,\n",
    "        'Linear Bias Initializer' : 0.0,\n",
    "        'Gate Bias Inititalizer' : 10.0\n",
    "    },\n",
    "    'Adaptive Loss Weights' : {\n",
    "        'Asymmetry' : 1.5,\n",
    "    },\n",
    "    'Trainer' : {\n",
    "        'Pre-Train' : {\n",
    "            'Number of Epochs' : 20,\n",
    "            'Warmup Ratio' : 0.15,\n",
    "            'Peak Learning Rate' : 1e-3,\n",
    "            'Minimal Learning Rate' : 1e-5,\n",
    "            'Gradient Clipping' : 1,\n",
    "            'Adam Betas' : (0.9, 0.999),\n",
    "            'Adam Epsilon' : 1e-8,\n",
    "            'Adam Weight Decay' : 0.01,\n",
    "            'Layer-Wise Decay' : None,\n",
    "        },\n",
    "        'Fine-Tune' : {\n",
    "            'Number of Epochs' : 10,\n",
    "            'Warmup Ratio' : 0.1,\n",
    "            'Peak Learning Rate' : 1e-3,\n",
    "            'Minimal Learning Rate' : 1e-6,\n",
    "            'Gradient Clipping' : 0,\n",
    "            'Adam Betas' : (0.9, 0.999),\n",
    "            'Adam Epsilon' : 1e-8,\n",
    "            'Adam Weight Decay' : 0.01,\n",
    "            'Layer-Wise Decay' : 0.9,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_dataset_train = IVSurfaceDataset(\n",
    "    pre_train_surfaces_train, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "pre_train_data_loader_train = DataLoader(\n",
    "    pre_train_dataset_train, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "pre_train_dataset_validation = IVSurfaceDataset(\n",
    "    pre_train_surfaces_validation, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "pre_train_data_loader_validation = DataLoader(\n",
    "    pre_train_dataset_validation, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "pre_train_dataset_test = IVSurfaceDataset(\n",
    "    pre_train_surfaces_test, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "pre_train_data_loader_test = DataLoader(\n",
    "    pre_train_dataset_test, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_dataset_train = IVSurfaceDataset(\n",
    "    fine_tune_surfaces_train, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "fine_tune_data_loader_train = DataLoader(\n",
    "    fine_tune_dataset_train, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "fine_tune_dataset_validation = IVSurfaceDataset(\n",
    "    fine_tune_surfaces_validation, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "fine_tune_data_loader_validation = DataLoader(\n",
    "    fine_tune_dataset_validation, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "fine_tune_dataset_test = IVSurfaceDataset(\n",
    "    fine_tune_surfaces_test, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "fine_tune_data_loader_test = DataLoader(\n",
    "    fine_tune_dataset_test, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_STATE)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "model_pre_train = IvySPT(\n",
    "    hyperparameters['Surface Embedding']['Embedding Dimension'], \n",
    "    hyperparameters['Surface Encoding']['Number of Blocks'],\n",
    "    hyperparameters['Surface Encoding']['Number of Heads'], \n",
    "    hyperparameters['Surface Encoding']['FFN Hidden Dimension'],\n",
    "    hyperparameters['Surface Encoding']['Attention Dropout'], \n",
    "    hyperparameters['Surface Encoding']['Gate Dropout'],\n",
    "    hyperparameters['Surface Encoding']['FFN Dropout'],\n",
    "    hyperparameters['Surface Encoding']['External Feature Dimension'],\n",
    "    hyperparameters['Surface Encoding']['Weight Initializer Std.'],\n",
    "    hyperparameters['Surface Encoding']['Linear Bias Initializer'],\n",
    "    hyperparameters['Surface Encoding']['Gate Bias Inititalizer']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market Return</th>\n",
       "      <th>Market Volatility</th>\n",
       "      <th>Treasury Rate</th>\n",
       "      <th>TV Mean</th>\n",
       "      <th>TV Std.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.300791e-09</td>\n",
       "      <td>-3.680444e-09</td>\n",
       "      <td>2.708491e-09</td>\n",
       "      <td>5.486312e-09</td>\n",
       "      <td>-4.387399e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.579360e-09</td>\n",
       "      <td>-3.936594e-09</td>\n",
       "      <td>3.121626e-09</td>\n",
       "      <td>4.651789e-09</td>\n",
       "      <td>1.302495e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.198960e-09</td>\n",
       "      <td>-3.705896e-09</td>\n",
       "      <td>2.707650e-09</td>\n",
       "      <td>5.172908e-09</td>\n",
       "      <td>2.300866e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.730379e-09</td>\n",
       "      <td>-3.505497e-09</td>\n",
       "      <td>3.177272e-09</td>\n",
       "      <td>4.927850e-09</td>\n",
       "      <td>1.728902e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.275354e-09</td>\n",
       "      <td>-3.869429e-09</td>\n",
       "      <td>2.777071e-09</td>\n",
       "      <td>5.058292e-09</td>\n",
       "      <td>1.998642e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.591125e-09</td>\n",
       "      <td>-4.460486e-09</td>\n",
       "      <td>2.974249e-09</td>\n",
       "      <td>4.820414e-09</td>\n",
       "      <td>8.651481e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.276457e-09</td>\n",
       "      <td>-3.803585e-09</td>\n",
       "      <td>2.642152e-09</td>\n",
       "      <td>5.224385e-09</td>\n",
       "      <td>5.882288e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.370255e-09</td>\n",
       "      <td>-4.226236e-09</td>\n",
       "      <td>2.977057e-09</td>\n",
       "      <td>4.424542e-09</td>\n",
       "      <td>1.443153e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.623057e-09</td>\n",
       "      <td>-4.194531e-09</td>\n",
       "      <td>3.131289e-09</td>\n",
       "      <td>5.033720e-09</td>\n",
       "      <td>1.005484e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.498242e-09</td>\n",
       "      <td>-4.028611e-09</td>\n",
       "      <td>2.708284e-09</td>\n",
       "      <td>5.168156e-09</td>\n",
       "      <td>1.271045e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.162341e-09</td>\n",
       "      <td>-3.722076e-09</td>\n",
       "      <td>2.767284e-09</td>\n",
       "      <td>5.166901e-09</td>\n",
       "      <td>2.648704e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.217397e-09</td>\n",
       "      <td>-3.754704e-09</td>\n",
       "      <td>2.625876e-09</td>\n",
       "      <td>5.213025e-09</td>\n",
       "      <td>2.108802e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.134839e-09</td>\n",
       "      <td>-3.702566e-09</td>\n",
       "      <td>2.911202e-09</td>\n",
       "      <td>5.132959e-09</td>\n",
       "      <td>4.018643e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.783211e-09</td>\n",
       "      <td>-3.896091e-09</td>\n",
       "      <td>3.143658e-09</td>\n",
       "      <td>4.679438e-09</td>\n",
       "      <td>1.222028e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.077676e-09</td>\n",
       "      <td>-3.638685e-09</td>\n",
       "      <td>2.888408e-09</td>\n",
       "      <td>5.177080e-09</td>\n",
       "      <td>3.477055e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.302502e-09</td>\n",
       "      <td>-3.882480e-09</td>\n",
       "      <td>2.659207e-09</td>\n",
       "      <td>5.189575e-09</td>\n",
       "      <td>1.587746e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.281256e-09</td>\n",
       "      <td>-3.765960e-09</td>\n",
       "      <td>2.739750e-09</td>\n",
       "      <td>5.159666e-09</td>\n",
       "      <td>3.975739e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.551342e-09</td>\n",
       "      <td>-4.173927e-09</td>\n",
       "      <td>3.117541e-09</td>\n",
       "      <td>4.413026e-09</td>\n",
       "      <td>1.061587e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.378328e-09</td>\n",
       "      <td>-3.812715e-09</td>\n",
       "      <td>2.739252e-09</td>\n",
       "      <td>5.196930e-09</td>\n",
       "      <td>1.716905e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.910452e-09</td>\n",
       "      <td>-3.553851e-09</td>\n",
       "      <td>2.464173e-09</td>\n",
       "      <td>5.026434e-09</td>\n",
       "      <td>4.802929e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.985473e-09</td>\n",
       "      <td>-3.956584e-09</td>\n",
       "      <td>3.127789e-09</td>\n",
       "      <td>4.965620e-09</td>\n",
       "      <td>9.704622e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.146330e-09</td>\n",
       "      <td>-3.695459e-09</td>\n",
       "      <td>2.780607e-09</td>\n",
       "      <td>5.219258e-09</td>\n",
       "      <td>1.015268e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.226194e-09</td>\n",
       "      <td>-3.876110e-09</td>\n",
       "      <td>2.647094e-09</td>\n",
       "      <td>5.177245e-09</td>\n",
       "      <td>2.059831e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.160272e-09</td>\n",
       "      <td>-3.841796e-09</td>\n",
       "      <td>2.867157e-09</td>\n",
       "      <td>5.163764e-09</td>\n",
       "      <td>3.453592e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>5.132379e-09</td>\n",
       "      <td>-3.645700e-09</td>\n",
       "      <td>2.611333e-09</td>\n",
       "      <td>5.423044e-09</td>\n",
       "      <td>2.834585e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.438382e-09</td>\n",
       "      <td>-4.073581e-09</td>\n",
       "      <td>2.678258e-09</td>\n",
       "      <td>5.158994e-09</td>\n",
       "      <td>1.713218e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.117072e-09</td>\n",
       "      <td>-3.665687e-09</td>\n",
       "      <td>2.631336e-09</td>\n",
       "      <td>5.177718e-09</td>\n",
       "      <td>3.249334e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.329726e-09</td>\n",
       "      <td>-3.895556e-09</td>\n",
       "      <td>2.749378e-09</td>\n",
       "      <td>5.120810e-09</td>\n",
       "      <td>1.609170e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4.873032e-09</td>\n",
       "      <td>-3.484613e-09</td>\n",
       "      <td>2.626345e-09</td>\n",
       "      <td>5.159429e-09</td>\n",
       "      <td>4.378594e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.319765e-09</td>\n",
       "      <td>-3.987369e-09</td>\n",
       "      <td>2.733721e-09</td>\n",
       "      <td>5.165276e-09</td>\n",
       "      <td>2.669281e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>5.368133e-09</td>\n",
       "      <td>-3.885371e-09</td>\n",
       "      <td>2.639297e-09</td>\n",
       "      <td>5.214736e-09</td>\n",
       "      <td>7.084486e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4.810016e-09</td>\n",
       "      <td>-4.017290e-09</td>\n",
       "      <td>2.888717e-09</td>\n",
       "      <td>4.610379e-09</td>\n",
       "      <td>1.628697e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.140465e-09</td>\n",
       "      <td>-4.113072e-09</td>\n",
       "      <td>3.151572e-09</td>\n",
       "      <td>4.822340e-09</td>\n",
       "      <td>1.166759e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.926003e-09</td>\n",
       "      <td>-4.330190e-09</td>\n",
       "      <td>3.000760e-09</td>\n",
       "      <td>4.553103e-09</td>\n",
       "      <td>1.174708e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.865692e-09</td>\n",
       "      <td>-4.037194e-09</td>\n",
       "      <td>3.146458e-09</td>\n",
       "      <td>4.718652e-09</td>\n",
       "      <td>1.235327e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.802371e-09</td>\n",
       "      <td>-4.119808e-09</td>\n",
       "      <td>2.804392e-09</td>\n",
       "      <td>5.228622e-09</td>\n",
       "      <td>-7.031917e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.046338e-09</td>\n",
       "      <td>-3.712145e-09</td>\n",
       "      <td>2.880576e-09</td>\n",
       "      <td>5.197706e-09</td>\n",
       "      <td>3.699503e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.431527e-09</td>\n",
       "      <td>-4.105815e-09</td>\n",
       "      <td>2.743730e-09</td>\n",
       "      <td>5.119098e-09</td>\n",
       "      <td>2.292235e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.775052e-09</td>\n",
       "      <td>-3.588490e-09</td>\n",
       "      <td>2.847807e-09</td>\n",
       "      <td>5.024517e-09</td>\n",
       "      <td>6.594699e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.634767e-09</td>\n",
       "      <td>-4.328085e-09</td>\n",
       "      <td>3.117469e-09</td>\n",
       "      <td>5.035752e-09</td>\n",
       "      <td>1.006301e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.988689e-09</td>\n",
       "      <td>-4.449674e-09</td>\n",
       "      <td>3.013478e-09</td>\n",
       "      <td>4.933057e-09</td>\n",
       "      <td>7.242638e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.282565e-09</td>\n",
       "      <td>-3.790499e-09</td>\n",
       "      <td>2.683466e-09</td>\n",
       "      <td>5.138652e-09</td>\n",
       "      <td>4.550348e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.260438e-09</td>\n",
       "      <td>-3.817169e-09</td>\n",
       "      <td>2.672686e-09</td>\n",
       "      <td>5.215288e-09</td>\n",
       "      <td>1.084208e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.172365e-09</td>\n",
       "      <td>-3.652702e-09</td>\n",
       "      <td>2.584429e-09</td>\n",
       "      <td>5.225302e-09</td>\n",
       "      <td>1.263483e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.100583e-09</td>\n",
       "      <td>-3.614625e-09</td>\n",
       "      <td>2.792067e-09</td>\n",
       "      <td>5.403011e-09</td>\n",
       "      <td>1.395723e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.681089e-09</td>\n",
       "      <td>-4.080542e-09</td>\n",
       "      <td>3.077955e-09</td>\n",
       "      <td>4.988707e-09</td>\n",
       "      <td>9.486488e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.368492e-09</td>\n",
       "      <td>-4.294153e-09</td>\n",
       "      <td>3.095967e-09</td>\n",
       "      <td>4.978425e-09</td>\n",
       "      <td>1.097370e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.414947e-09</td>\n",
       "      <td>-3.939486e-09</td>\n",
       "      <td>2.708285e-09</td>\n",
       "      <td>5.176275e-09</td>\n",
       "      <td>9.987824e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.694765e-09</td>\n",
       "      <td>-4.254479e-09</td>\n",
       "      <td>3.154483e-09</td>\n",
       "      <td>5.001473e-09</td>\n",
       "      <td>1.035286e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>4.904020e-09</td>\n",
       "      <td>-3.422762e-09</td>\n",
       "      <td>2.833085e-09</td>\n",
       "      <td>5.131117e-09</td>\n",
       "      <td>2.841412e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Market Return  Market Volatility  Treasury Rate       TV Mean  \\\n",
       "0    5.300791e-09      -3.680444e-09   2.708491e-09  5.486312e-09   \n",
       "1    4.579360e-09      -3.936594e-09   3.121626e-09  4.651789e-09   \n",
       "2    5.198960e-09      -3.705896e-09   2.707650e-09  5.172908e-09   \n",
       "3    4.730379e-09      -3.505497e-09   3.177272e-09  4.927850e-09   \n",
       "4    5.275354e-09      -3.869429e-09   2.777071e-09  5.058292e-09   \n",
       "5    5.591125e-09      -4.460486e-09   2.974249e-09  4.820414e-09   \n",
       "6    5.276457e-09      -3.803585e-09   2.642152e-09  5.224385e-09   \n",
       "7    4.370255e-09      -4.226236e-09   2.977057e-09  4.424542e-09   \n",
       "8    5.623057e-09      -4.194531e-09   3.131289e-09  5.033720e-09   \n",
       "9    5.498242e-09      -4.028611e-09   2.708284e-09  5.168156e-09   \n",
       "10   5.162341e-09      -3.722076e-09   2.767284e-09  5.166901e-09   \n",
       "11   5.217397e-09      -3.754704e-09   2.625876e-09  5.213025e-09   \n",
       "12   5.134839e-09      -3.702566e-09   2.911202e-09  5.132959e-09   \n",
       "13   4.783211e-09      -3.896091e-09   3.143658e-09  4.679438e-09   \n",
       "14   5.077676e-09      -3.638685e-09   2.888408e-09  5.177080e-09   \n",
       "15   5.302502e-09      -3.882480e-09   2.659207e-09  5.189575e-09   \n",
       "16   5.281256e-09      -3.765960e-09   2.739750e-09  5.159666e-09   \n",
       "17   4.551342e-09      -4.173927e-09   3.117541e-09  4.413026e-09   \n",
       "18   5.378328e-09      -3.812715e-09   2.739252e-09  5.196930e-09   \n",
       "19   4.910452e-09      -3.553851e-09   2.464173e-09  5.026434e-09   \n",
       "20   4.985473e-09      -3.956584e-09   3.127789e-09  4.965620e-09   \n",
       "21   5.146330e-09      -3.695459e-09   2.780607e-09  5.219258e-09   \n",
       "22   5.226194e-09      -3.876110e-09   2.647094e-09  5.177245e-09   \n",
       "23   5.160272e-09      -3.841796e-09   2.867157e-09  5.163764e-09   \n",
       "24   5.132379e-09      -3.645700e-09   2.611333e-09  5.423044e-09   \n",
       "25   5.438382e-09      -4.073581e-09   2.678258e-09  5.158994e-09   \n",
       "26   5.117072e-09      -3.665687e-09   2.631336e-09  5.177718e-09   \n",
       "27   5.329726e-09      -3.895556e-09   2.749378e-09  5.120810e-09   \n",
       "28   4.873032e-09      -3.484613e-09   2.626345e-09  5.159429e-09   \n",
       "29   5.319765e-09      -3.987369e-09   2.733721e-09  5.165276e-09   \n",
       "30   5.368133e-09      -3.885371e-09   2.639297e-09  5.214736e-09   \n",
       "31   4.810016e-09      -4.017290e-09   2.888717e-09  4.610379e-09   \n",
       "32   5.140465e-09      -4.113072e-09   3.151572e-09  4.822340e-09   \n",
       "33   4.926003e-09      -4.330190e-09   3.000760e-09  4.553103e-09   \n",
       "34   4.865692e-09      -4.037194e-09   3.146458e-09  4.718652e-09   \n",
       "35   5.802371e-09      -4.119808e-09   2.804392e-09  5.228622e-09   \n",
       "36   5.046338e-09      -3.712145e-09   2.880576e-09  5.197706e-09   \n",
       "37   5.431527e-09      -4.105815e-09   2.743730e-09  5.119098e-09   \n",
       "38   4.775052e-09      -3.588490e-09   2.847807e-09  5.024517e-09   \n",
       "39   5.634767e-09      -4.328085e-09   3.117469e-09  5.035752e-09   \n",
       "40   5.988689e-09      -4.449674e-09   3.013478e-09  4.933057e-09   \n",
       "41   5.282565e-09      -3.790499e-09   2.683466e-09  5.138652e-09   \n",
       "42   5.260438e-09      -3.817169e-09   2.672686e-09  5.215288e-09   \n",
       "43   5.172365e-09      -3.652702e-09   2.584429e-09  5.225302e-09   \n",
       "44   5.100583e-09      -3.614625e-09   2.792067e-09  5.403011e-09   \n",
       "45   5.681089e-09      -4.080542e-09   3.077955e-09  4.988707e-09   \n",
       "46   5.368492e-09      -4.294153e-09   3.095967e-09  4.978425e-09   \n",
       "47   5.414947e-09      -3.939486e-09   2.708285e-09  5.176275e-09   \n",
       "48   5.694765e-09      -4.254479e-09   3.154483e-09  5.001473e-09   \n",
       "49   4.904020e-09      -3.422762e-09   2.833085e-09  5.131117e-09   \n",
       "\n",
       "         TV Std.  \n",
       "0  -4.387399e-11  \n",
       "1   1.302495e-09  \n",
       "2   2.300866e-10  \n",
       "3   1.728902e-10  \n",
       "4   1.998642e-10  \n",
       "5   8.651481e-10  \n",
       "6   5.882288e-11  \n",
       "7   1.443153e-09  \n",
       "8   1.005484e-09  \n",
       "9   1.271045e-10  \n",
       "10  2.648704e-10  \n",
       "11  2.108802e-10  \n",
       "12  4.018643e-10  \n",
       "13  1.222028e-09  \n",
       "14  3.477055e-10  \n",
       "15  1.587746e-10  \n",
       "16  3.975739e-11  \n",
       "17  1.061587e-09  \n",
       "18  1.716905e-10  \n",
       "19  4.802929e-10  \n",
       "20  9.704622e-10  \n",
       "21  1.015268e-10  \n",
       "22  2.059831e-10  \n",
       "23  3.453592e-10  \n",
       "24  2.834585e-10  \n",
       "25  1.713218e-10  \n",
       "26  3.249334e-10  \n",
       "27  1.609170e-10  \n",
       "28  4.378594e-10  \n",
       "29  2.669281e-10  \n",
       "30  7.084486e-11  \n",
       "31  1.628697e-09  \n",
       "32  1.166759e-09  \n",
       "33  1.174708e-09  \n",
       "34  1.235327e-09  \n",
       "35 -7.031917e-11  \n",
       "36  3.699503e-10  \n",
       "37  2.292235e-10  \n",
       "38  6.594699e-10  \n",
       "39  1.006301e-09  \n",
       "40  7.242638e-10  \n",
       "41  4.550348e-11  \n",
       "42  1.084208e-10  \n",
       "43  1.263483e-10  \n",
       "44  1.395723e-10  \n",
       "45  9.486488e-10  \n",
       "46  1.097370e-09  \n",
       "47  9.987824e-11  \n",
       "48  1.035286e-09  \n",
       "49  2.841412e-10  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MarketSensitivityAnalysis(model_pre_train, pre_train_data_loader_validation, device).compute_sensitivity()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.5917e-04,  9.1110e-03,  1.0178e-02,  2.5670e-02,  1.1351e-02,\n",
       "           1.9972e-02, -2.6299e-02, -3.0845e-02, -3.9019e-02, -4.3398e-02,\n",
       "          -5.7609e-02, -1.2017e-02, -4.2323e-02, -8.4755e-03, -3.6993e-02,\n",
       "          -2.4207e-02, -6.0259e-02, -4.5890e-02, -4.0323e-02, -5.0224e-03,\n",
       "          -2.8772e-02, -3.9266e-02, -4.4171e-02,  1.2904e-02, -2.2278e-02,\n",
       "          -2.0048e-02, -3.4520e-02, -7.5087e-03, -9.0928e-03,  1.7408e-02,\n",
       "          -1.2067e-02, -1.6023e-02, -3.0639e-02,  2.2428e-04, -2.6769e-02,\n",
       "           5.5081e-03, -9.9355e-03,  6.4645e-03, -5.0180e-03,  1.3802e-02,\n",
       "          -1.2159e-02,  2.2248e-02, -1.2435e-02,  1.4962e-02,  2.4553e-03,\n",
       "           4.9902e-02, -2.1854e-02, -1.0599e-03, -6.1956e-03,  3.8186e-02,\n",
       "           2.3587e-02,  3.3872e-02,  1.0321e-02,  3.1012e-02,  2.5622e-02,\n",
       "           3.4977e-02,  1.7726e-02,  5.7327e-02,  5.0149e-02,  1.0153e-01,\n",
       "           1.3832e-02,  4.3278e-02,  6.9490e-02,  5.9584e-02,  1.8566e-02],\n",
       "         [-3.0192e-03, -2.9315e-02, -1.6901e-02, -4.2564e-03, -1.4900e-03,\n",
       "          -1.8516e-04, -1.0230e-03,  2.3655e-03,  1.6236e-03,  1.5833e-03,\n",
       "          -2.5121e-04,  1.0617e-03,  1.1487e-03,  1.8484e-04, -3.4750e-05,\n",
       "           7.2970e-04,  1.3727e-03,  1.2623e-03,  8.3506e-04,  7.2870e-04,\n",
       "           1.1502e-03,  1.6072e-03,  1.5041e-03,  8.5782e-04,  1.9567e-03,\n",
       "           1.7403e-03,  1.9958e-03,  1.7370e-03,  2.1090e-03,  1.4694e-03,\n",
       "           1.9883e-03,  2.3851e-03,  2.6672e-03,  2.1768e-03,  2.8715e-03,\n",
       "           2.1192e-03,  2.2957e-03,  2.1639e-03,  2.2321e-03,  1.6923e-03,\n",
       "           2.0940e-03,  1.4858e-03,  2.1225e-03,  1.2114e-03,  1.5446e-03,\n",
       "           3.6422e-04,  1.7663e-03,  1.1298e-03,  1.1178e-03, -1.0948e-05,\n",
       "           5.2662e-05, -1.2898e-04,  2.8928e-04, -2.5660e-04, -1.9809e-04,\n",
       "          -3.0756e-04,  6.6456e-05, -1.1601e-03, -9.4110e-04, -1.9767e-03,\n",
       "          -7.3654e-05, -1.0865e-03, -1.2543e-03, -9.9099e-04,  0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]),\n",
       " tensor([[5.4053e-02, 1.1470e-01, 2.0071e-01, 2.3628e-01, 2.6886e-01, 3.1320e-01,\n",
       "          3.1597e-01, 3.2197e-01, 3.2768e-01, 3.3525e-01, 3.7011e-01, 3.7803e-01,\n",
       "          4.2043e-01, 4.2446e-01, 4.3101e-01, 5.1179e-01, 5.6076e-01, 6.0045e-01,\n",
       "          6.3211e-01, 6.3938e-01, 6.5605e-01, 7.2186e-01, 7.4073e-01, 7.8668e-01,\n",
       "          7.9807e-01, 8.2738e-01, 8.8782e-01, 9.8424e-01, 1.0759e+00, 1.1051e+00,\n",
       "          1.1497e+00, 1.1548e+00, 1.1633e+00, 1.2251e+00, 1.4504e+00, 1.4577e+00,\n",
       "          1.4750e+00, 1.4819e+00, 1.5423e+00, 1.5983e+00, 1.8367e+00, 2.0000e+00,\n",
       "          2.0807e+00, 2.1029e+00, 2.1256e+00, 2.1323e+00, 2.2107e+00, 2.2479e+00,\n",
       "          2.3189e+00, 2.3568e+00, 2.3771e+00, 2.4195e+00, 2.4325e+00, 3.0875e+00,\n",
       "          3.1973e+00, 3.4357e+00, 3.6534e+00, 4.0366e+00, 4.1345e+00, 4.4666e+00,\n",
       "          4.5827e+00, 5.8180e+00, 6.2288e+00, 8.4729e+00, 2.0503e+01],\n",
       "         [0.0000e+00, 3.9931e-03, 5.2845e-03, 5.6069e-03, 7.0565e-03, 7.0905e-03,\n",
       "          8.1409e-03, 8.5533e-03, 9.2039e-03, 9.2449e-03, 9.4484e-03, 9.7178e-03,\n",
       "          1.2130e-02, 1.2877e-02, 1.3902e-02, 1.5767e-02, 1.6427e-02, 1.6539e-02,\n",
       "          1.8077e-02, 2.0171e-02, 2.2208e-02, 2.4031e-02, 2.6051e-02, 2.9391e-02,\n",
       "          3.1968e-02, 3.2323e-02, 3.2754e-02, 3.4671e-02, 3.7612e-02, 3.8185e-02,\n",
       "          3.9752e-02, 3.9913e-02, 4.0865e-02, 4.2920e-02, 4.4692e-02, 4.7205e-02,\n",
       "          4.7360e-02, 5.0674e-02, 5.4831e-02, 5.5478e-02, 5.7935e-02, 5.9439e-02,\n",
       "          6.4710e-02, 6.7553e-02, 6.7718e-02, 7.4712e-02, 7.7629e-02, 7.8554e-02,\n",
       "          8.0868e-02, 8.1253e-02, 8.2270e-02, 8.5108e-02, 8.5617e-02, 8.9486e-02,\n",
       "          9.4988e-02, 9.5088e-02, 1.0295e-01, 1.0367e-01, 1.3206e-01, 1.4993e-01,\n",
       "          1.5664e-01, 1.7009e-01, 3.7378e-01, 5.0177e+00, 1.4349e+01],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OptimalLossFlatness(model_pre_train, pre_train_data_loader_validation, device).calculate_flatness()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.1202e-05, -4.7568e-05, -4.2913e-05, -3.6620e-05, -2.3285e-05,\n",
       "        -1.7199e-05, -1.3334e-05, -7.6005e-06, -6.1810e-06,  1.7723e-06,\n",
       "         5.0658e-06,  1.0935e-05,  1.6904e-05,  1.9331e-05,  2.7516e-05,\n",
       "         3.3941e-05,  4.5298e-05,  5.1175e-05,  5.4233e-05,  5.7227e-05,\n",
       "         6.2577e-05,  7.9743e-05,  9.3287e-05,  1.3859e-04,  1.8095e-04,\n",
       "         2.0091e-04,  2.3962e-04,  3.0984e-04,  4.5091e-04,  5.9554e-04,\n",
       "         8.3025e-04,  9.7705e-04,  2.0120e-03,  3.7965e-03,  4.4103e-03,\n",
       "         9.8362e-03,  4.6224e-02,  5.0096e-02,  9.1300e-02,  1.6152e-01,\n",
       "         4.2422e-01,  7.7977e-01,  1.6154e+00,  2.0385e+00,  4.5672e+00,\n",
       "         6.2726e+00,  2.4490e+01,  5.2211e+01,  6.2503e+02,  2.5357e+03])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvergenceNTK(model_pre_train, pre_train_data_loader_validation, device).calculate_ntk_eigenvalues()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
