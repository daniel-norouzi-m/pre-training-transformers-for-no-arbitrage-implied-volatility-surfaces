{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "RANDOM_STATE = 0\n",
    "N_JOBS = 8\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    'Input Preprocessing' : {\n",
    "        'Mask Proportions' : [0.1, 0.2, 0.4, 0.8],\n",
    "        'Batch Size' : 4\n",
    "    },\n",
    "    'Input Embedding' : {\n",
    "        'Surface Embedding' : {\n",
    "            'Grid Dimension' : 3,\n",
    "            'Channels Dimension' : 8,\n",
    "        },\n",
    "        'Pre-Encoder' : {\n",
    "            'Branch Channels Dimension' : 4,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'Surface Encoding' : {\n",
    "        'Encoder' : {\n",
    "            'Number of Heads' : 4,\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "            'External Feature Dimension' : 3,\n",
    "        }\n",
    "    },\n",
    "    'Query Embedding' : {\n",
    "        'Pre-Decoder' : {\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'Surface Decoding' : {\n",
    "        'Decoder' : {\n",
    "            'Number of Heads' : 4,\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'No-Arbitrage' : {\n",
    "        'Butterfly' : 1,\n",
    "        'Calendar' : 1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Log Moneyness</th>\n",
       "      <th>Time to Maturity</th>\n",
       "      <th>Implied Volatility</th>\n",
       "      <th>Market Return</th>\n",
       "      <th>Market Volatility</th>\n",
       "      <th>Treasury Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.316688</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.316688</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.304266</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.304266</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.291996</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-06-28</th>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.427518</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.434898</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.434898</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.442224</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2402</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.442224</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574326 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Log Moneyness  Time to Maturity  Implied Volatility  \\\n",
       "Datetime   Symbol                                                        \n",
       "2013-01-02 AAPL        -0.316688          0.007937              0.3726   \n",
       "           AAPL        -0.316688          0.007937              0.6095   \n",
       "           AAPL        -0.304266          0.007937              0.3726   \n",
       "           AAPL        -0.304266          0.007937              0.6095   \n",
       "           AAPL        -0.291996          0.007937              0.3726   \n",
       "...                          ...               ...                 ...   \n",
       "2013-06-28 GOOGL        0.427518          2.253968              0.2430   \n",
       "           GOOGL        0.434898          2.253968              0.2383   \n",
       "           GOOGL        0.434898          2.253968              0.2426   \n",
       "           GOOGL        0.442224          2.253968              0.2402   \n",
       "           GOOGL        0.442224          2.253968              0.2433   \n",
       "\n",
       "                   Market Return  Market Volatility  Treasury Rate  \n",
       "Datetime   Symbol                                                   \n",
       "2013-01-02 AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "...                          ...                ...            ...  \n",
       "2013-06-28 GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "\n",
       "[574326 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_googl_data = pd.read_csv('volatility_surface_AAPL_GOOGL_2013_01_2013_06.csv', parse_dates=True, index_col=[0, 1], date_format=\"ISO8601\")\n",
    "aapl_googl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': Timestamp('2013-01-02 00:00:00'),\n",
       " 'Symbol': 'AAPL',\n",
       " 'Market Features': {'Market Return': 0.0250861159586972,\n",
       "  'Market Volatility': 14.68000030517578,\n",
       "  'Treasury Rate': 0.0549999997019767},\n",
       " 'Surface': {'Log Moneyness': array([-0.31668849, -0.31668849, -0.30426597, ...,  0.63882295,\n",
       "          0.6483924 ,  0.6483924 ]),\n",
       "  'Time to Maturity': array([0.00793651, 0.00793651, 0.00793651, ..., 2.95634921, 2.95634921,\n",
       "         2.95634921]),\n",
       "  'Implied Volatility': array([0.3726, 0.6095, 0.3726, ..., 0.3387, 0.3342, 0.3389])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def implied_volatility_surfaces(options_market_data):\n",
    "    # Group the data by Datetime and Symbol\n",
    "    grouped_data = options_market_data.groupby(level=['Datetime', 'Symbol'])\n",
    "\n",
    "    surfaces = []\n",
    "    for (date, symbol), surface in grouped_data:\n",
    "        surface_dict = {\n",
    "            'Datetime': date,\n",
    "            'Symbol': symbol,\n",
    "            'Market Features': {\n",
    "                'Market Return': surface['Market Return'].values[0],\n",
    "                'Market Volatility': surface['Market Volatility'].values[0],\n",
    "                'Treasury Rate': surface['Treasury Rate'].values[0],\n",
    "            },\n",
    "            'Surface': {\n",
    "                'Log Moneyness': surface['Log Moneyness'].values,\n",
    "                'Time to Maturity': surface['Time to Maturity'].values,\n",
    "                'Implied Volatility': surface['Implied Volatility'].values,\n",
    "            }\n",
    "        }\n",
    "        surfaces.append(surface_dict)\n",
    "\n",
    "    return surfaces\n",
    "\n",
    "surfaces = implied_volatility_surfaces(aapl_googl_data)\n",
    "surfaces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': [Timestamp('2013-06-10 00:00:00'),\n",
       "  Timestamp('2013-01-28 00:00:00'),\n",
       "  Timestamp('2013-05-20 00:00:00'),\n",
       "  Timestamp('2013-03-07 00:00:00')],\n",
       " 'Symbol': ['AAPL', 'AAPL', 'GOOGL', 'AAPL'],\n",
       " 'Market Features': {'Market Return': tensor([-0.0003, -0.0019, -0.0007,  0.0018]),\n",
       "  'Market Volatility': tensor([15.4400, 13.5700, 13.0200, 13.0600]),\n",
       "  'Treasury Rate': tensor([0.0400, 0.0600, 0.0350, 0.0900])},\n",
       " 'Input Surface': {'Log Moneyness': [tensor([0.4524, 0.4597, 0.4668, 0.4739, 0.4739, 0.4880, 0.4950, 0.4950, 0.5019,\n",
       "           0.5019, 0.5088, 0.5088, 0.5156, 0.5156, 0.5224, 0.5224, 0.5291, 0.5358,\n",
       "           0.5358, 0.5425, 0.5491, 0.5556, 0.5556, 0.5621, 0.5621, 0.5686, 0.5686,\n",
       "           0.5750, 0.5750, 0.5814, 0.5814, 0.5878, 0.5878, 0.5941, 0.6004, 0.6004,\n",
       "           0.6066, 0.6066, 0.6128, 0.6128, 0.6189, 0.6251, 0.6251, 0.6311, 0.6372,\n",
       "           0.6372, 0.6432, 0.6492, 0.6492, 0.6551, 0.6551, 0.6610, 0.6610, 0.6669,\n",
       "           0.6669, 0.6727, 0.6727, 0.6785, 0.6785, 0.6842, 0.6842, 0.6900, 0.6900,\n",
       "           0.6957, 0.6957, 0.0138, 0.0138, 0.0250, 0.0250, 0.0360, 0.0360, 0.0470,\n",
       "           0.0578, 0.0578, 0.0685, 0.0685, 0.0791, 0.0791, 0.0895, 0.0999, 0.0999,\n",
       "           0.1102, 0.1203, 0.1203, 0.1304, 0.1304, 0.1403, 0.1403, 0.1502, 0.1599,\n",
       "           0.1599, 0.1696, 0.1696, 0.1791, 0.1791, 0.1886, 0.1886, 0.1980, 0.1980,\n",
       "           0.2073, 0.2073, 0.2165, 0.2257, 0.2257, 0.2347, 0.2347, 0.2437, 0.2437,\n",
       "           0.2526, 0.2526, 0.2614, 0.2614, 0.2701, 0.2701, 0.2788, 0.2874, 0.2874,\n",
       "           0.2959, 0.2959, 0.3043, 0.3043, 0.3127, 0.3210, 0.3292, 0.3374, 0.3455,\n",
       "           0.3535, 0.3535, 0.3615, 0.3615, 0.3694, 0.3694, 0.3772, 0.3772, 0.3850,\n",
       "           0.3850, 0.3927, 0.3927, 0.4080, 0.4155, 0.4155, 0.4230, 0.4305, 0.4378,\n",
       "           0.4378, 0.4452, 0.4452, 0.4524, 0.4524, 0.4597, 0.4597, 0.4668, 0.4739,\n",
       "           0.4739, 0.4810, 0.4810, 0.4880, 0.5019, 0.5088, 0.5088, 0.5156, 0.5156,\n",
       "           0.5224, 0.5224, 0.5291, 0.5291, 0.5358, 0.5425, 0.5491, 0.5491, 0.5556,\n",
       "           0.5556, 0.5621, 0.5686, 0.5750, 0.5814, 0.5814, 0.5878, 0.5878, 0.5941,\n",
       "           0.5941, 0.6004, 0.6066, 0.6066, 0.6128, 0.6189, 0.6251, 0.6251, 0.6311,\n",
       "           0.6311, 0.6372, 0.6372, 0.6432, 0.6492, 0.6492, 0.6551, 0.6551, 0.6610,\n",
       "           0.6610, 0.6669, 0.6727, 0.6785, 0.6785, 0.6842, 0.6842, 0.6900, 0.6900,\n",
       "           0.6957, 0.7013, 0.7013, 0.7070, 0.7126, 0.7126, 0.7181, 0.7237, 0.7237,\n",
       "           0.7401, 0.7401, 0.7455, 0.7455, 0.7509, 0.7509, 0.7563, 0.7563, 0.7669,\n",
       "           0.7669, 0.7775, 0.7775, 0.7827, 0.7827, 0.7879, 0.7879, 0.7930, 0.7930,\n",
       "           0.7982, 0.7982, 0.8033, 0.8084, 0.8135, 0.8135, 0.8185, 0.8235, 0.8335,\n",
       "           0.8433, 0.8433, 0.8531, 0.8531, 0.8627, 0.8627, 0.8723, 0.8723, 0.0470,\n",
       "           0.0470, 0.0578, 0.0685, 0.0791, 0.0791, 0.0895, 0.0895, 0.0999, 0.1102,\n",
       "           0.1102, 0.1203, 0.1304, 0.1304, 0.1403, 0.1403, 0.1502, 0.1502, 0.1599,\n",
       "           0.1696, 0.1696, 0.1791, 0.1791, 0.1886, 0.1886, 0.1980, 0.1980, 0.2073,\n",
       "           0.2073, 0.2165, 0.2165, 0.2257, 0.2347, 0.2347, 0.2437, 0.2437, 0.2526,\n",
       "           0.2526, 0.2614, 0.2701, 0.2701, 0.2788, 0.2788, 0.2959, 0.3043, 0.3043,\n",
       "           0.3210, 0.3210, 0.3374, 0.3374, 0.3455, 0.3455, 0.3535, 0.3535, 0.3615,\n",
       "           0.3615, 0.3694, 0.3694, 0.3772, 0.3772, 0.3850, 0.3927, 0.3927, 0.4004,\n",
       "           0.4004, 0.4080, 0.4155, 0.4155, 0.4230]),\n",
       "   tensor([-2.5094e-01, -5.2914e-01, -5.2914e-01, -5.1045e-01, -4.9210e-01,\n",
       "           -4.7408e-01, -4.7408e-01, -4.5638e-01, -4.3899e-01, -4.2189e-01,\n",
       "           -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.7230e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01, -3.2504e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01, -2.7992e-01,\n",
       "           -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.3675e-01, -2.3675e-01,\n",
       "           -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.2914e-01,\n",
       "           -5.1045e-01, -5.1045e-01, -4.9210e-01, -4.9210e-01, -4.7408e-01,\n",
       "           -4.7408e-01, -4.5638e-01, -4.3899e-01, -4.3899e-01, -4.2189e-01,\n",
       "           -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.7230e-01, -3.5630e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01,\n",
       "           -3.2504e-01, -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01,\n",
       "           -2.7992e-01, -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01,\n",
       "           -2.0897e-01, -5.6761e-01, -5.6761e-01, -5.4819e-01, -5.4819e-01,\n",
       "           -5.2914e-01, -5.2914e-01, -5.1045e-01, -5.1045e-01, -4.9210e-01,\n",
       "           -4.9210e-01, -4.7408e-01, -4.7408e-01, -4.5638e-01, -4.5638e-01,\n",
       "           -4.3899e-01, -4.3899e-01, -4.2189e-01, -4.2189e-01, -4.0509e-01,\n",
       "           -4.0509e-01, -3.8856e-01, -3.8856e-01, -3.7230e-01, -3.5630e-01,\n",
       "           -3.4055e-01, -3.4055e-01, -3.2504e-01, -3.0978e-01, -2.9474e-01,\n",
       "           -2.9474e-01, -2.7992e-01, -2.7992e-01, -2.6533e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.0897e-01, -1.9537e-01,\n",
       "           -1.9537e-01, -1.8194e-01, -1.8194e-01, -1.6870e-01, -1.6870e-01,\n",
       "           -5.6761e-01, -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01,\n",
       "           -5.2914e-01, -5.1045e-01, -4.9210e-01, -4.9210e-01, -4.7408e-01,\n",
       "           -4.7408e-01, -4.5638e-01, -4.5638e-01, -4.3899e-01, -4.3899e-01,\n",
       "           -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.5630e-01, -3.5630e-01, -3.4055e-01, -3.2504e-01, -3.0978e-01,\n",
       "           -3.0978e-01, -2.9474e-01, -2.7992e-01, -2.6533e-01, -2.6533e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.0897e-01, -2.0897e-01,\n",
       "           -1.9537e-01, -1.9537e-01, -1.8194e-01, -1.6870e-01, -1.5563e-01,\n",
       "           -1.4272e-01, -1.4272e-01, -1.2998e-01, -1.2998e-01, -5.6761e-01,\n",
       "           -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.1045e-01,\n",
       "           -5.1045e-01, -4.9210e-01, -4.9210e-01, -4.7408e-01, -4.3899e-01,\n",
       "           -4.2189e-01, -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01,\n",
       "           -3.8856e-01, -3.7230e-01, -3.7230e-01, -3.5630e-01, -3.5630e-01,\n",
       "           -3.4055e-01, -3.4055e-01, -3.2504e-01, -3.2504e-01, -3.0978e-01,\n",
       "           -2.9474e-01, -2.9474e-01, -2.7992e-01, -2.6533e-01, -2.6533e-01,\n",
       "           -2.5094e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01, -2.0897e-01,\n",
       "           -1.9537e-01, -1.9537e-01, -1.8194e-01, -1.8194e-01, -1.5563e-01,\n",
       "           -1.5563e-01, -1.4272e-01, -1.4272e-01, -1.2998e-01, -1.1741e-01,\n",
       "           -1.0498e-01, -9.2713e-02, -9.2713e-02, -5.6761e-01, -5.6761e-01,\n",
       "           -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.1045e-01, -5.1045e-01,\n",
       "           -4.9210e-01, -4.7408e-01, -4.5638e-01, -4.5638e-01, -4.3899e-01,\n",
       "           -4.3899e-01, -4.2189e-01, -4.0509e-01, -3.8856e-01, -3.8856e-01,\n",
       "           -3.7230e-01, -3.7230e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01, -2.7992e-01,\n",
       "           -2.7992e-01, -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01, -1.9537e-01,\n",
       "           -1.9537e-01, -1.8194e-01, -1.8194e-01, -1.6870e-01, -1.5563e-01,\n",
       "           -1.5563e-01, -1.4272e-01, -1.2998e-01, -1.2998e-01, -1.1741e-01,\n",
       "           -1.0498e-01, -1.0498e-01, -9.2713e-02, -9.2713e-02, -8.0591e-02,\n",
       "           -6.8615e-02, -5.6781e-02, -5.6761e-01, -5.6761e-01, -5.4819e-01,\n",
       "           -5.4819e-01, -5.2914e-01, -5.1045e-01, -5.1045e-01, -4.9210e-01,\n",
       "           -4.7408e-01, -4.7408e-01, -4.5638e-01, -4.3899e-01, -4.3899e-01,\n",
       "           -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.7230e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01, -3.2504e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01,\n",
       "           -2.7992e-01, -2.7992e-01, -2.6533e-01, -2.5094e-01, -2.3675e-01,\n",
       "           -2.3675e-01, -2.2277e-01, -2.0897e-01, -2.0897e-01, -1.9537e-01,\n",
       "           -1.8194e-01, -1.6870e-01, -1.6870e-01, -1.5563e-01, -1.5563e-01,\n",
       "           -1.4272e-01, -1.4272e-01, -1.2998e-01, -1.2998e-01, -1.1741e-01,\n",
       "           -1.0498e-01, -1.0498e-01, -9.2713e-02, -9.2713e-02, -8.0591e-02,\n",
       "           -6.8615e-02, -5.6781e-02, -4.5085e-02, -4.5085e-02, -3.3524e-02,\n",
       "           -3.3524e-02, -2.2095e-02, -1.0795e-02, -1.0795e-02,  3.7784e-04,\n",
       "            1.1428e-02,  1.1428e-02,  2.2357e-02,  2.2357e-02,  3.3168e-02,\n",
       "            3.3168e-02, -7.3823e-01, -7.3823e-01, -7.1524e-01, -6.9277e-01,\n",
       "           -6.9277e-01, -6.7079e-01, -6.7079e-01, -6.4928e-01, -6.2823e-01,\n",
       "           -6.2823e-01, -6.0761e-01, -6.0761e-01, -5.8741e-01, -5.8741e-01,\n",
       "           -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.2914e-01,\n",
       "           -5.1045e-01, -4.9210e-01, -4.7408e-01, -4.7408e-01, -4.5638e-01,\n",
       "           -4.5638e-01, -4.3899e-01, -4.3899e-01, -4.2189e-01, -4.0509e-01,\n",
       "           -3.8856e-01, -3.7230e-01, -3.5630e-01, -3.5630e-01, -3.4055e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01, -2.7992e-01,\n",
       "           -2.7992e-01, -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01,\n",
       "           -2.0897e-01, -1.9537e-01, -1.8194e-01, -1.6870e-01, -1.6870e-01,\n",
       "           -1.5563e-01, -1.5563e-01, -1.4272e-01, -1.4272e-01, -1.2998e-01,\n",
       "           -1.2998e-01, -1.1741e-01, -1.1741e-01, -1.0498e-01, -1.0498e-01,\n",
       "           -9.2713e-02, -9.2713e-02, -8.0591e-02, -8.0591e-02, -6.8615e-02,\n",
       "           -6.8615e-02, -5.6781e-02, -5.6781e-02, -4.5085e-02, -3.3524e-02,\n",
       "           -3.3524e-02]),\n",
       "   tensor([-0.0549, -0.0433, -0.0433, -0.0376, -0.0319, -0.0262, -0.0206, -0.0150,\n",
       "           -0.0094, -0.0094, -0.0039, -0.0039,  0.0016,  0.0016,  0.0071,  0.0071,\n",
       "            0.0125,  0.0125,  0.0180,  0.0180,  0.0234,  0.0287,  0.0287,  0.0341,\n",
       "            0.0394,  0.0446,  0.0446,  0.0499,  0.0499,  0.0551,  0.0551,  0.0603,\n",
       "            0.0603,  0.0655,  0.0655,  0.0706,  0.0706,  0.0757,  0.0757,  0.0808,\n",
       "            0.0859,  0.0859,  0.0909,  0.0909,  0.0959,  0.0959,  0.1059,  0.1157,\n",
       "            0.1157,  0.1255,  0.1255,  0.1351,  0.1447,  0.1447,  0.1542,  0.1542,\n",
       "            0.1636,  0.1729,  0.1729,  0.1821,  0.1821,  0.1912,  0.1912,  0.2003,\n",
       "            0.2003,  0.2093,  0.2093,  0.2181,  0.2181,  0.2270,  0.2270,  0.2357,\n",
       "            0.2357,  0.2443,  0.2443,  0.2529,  0.2529,  0.2614,  0.2614,  0.2699,\n",
       "            0.2699,  0.2782,  0.2782, -0.3196, -0.3196, -0.3120, -0.3046, -0.3046,\n",
       "           -0.2971, -0.2971, -0.2897, -0.2824, -0.2824, -0.2751, -0.2751, -0.2679,\n",
       "           -0.2679, -0.2607, -0.2536, -0.2536, -0.2466, -0.2466, -0.2395, -0.2326,\n",
       "           -0.2326, -0.2257, -0.2257, -0.2188, -0.2188, -0.2120, -0.2120, -0.2052,\n",
       "           -0.2052, -0.1984, -0.1984, -0.1918, -0.1918, -0.1851, -0.1785, -0.1785,\n",
       "           -0.1720, -0.1720, -0.1654, -0.1654, -0.1590, -0.1525, -0.1525, -0.1461,\n",
       "           -0.1461, -0.1398, -0.1335, -0.1272, -0.1210, -0.1210, -0.1148, -0.1086,\n",
       "           -0.1025, -0.1025, -0.0964, -0.0904, -0.0844, -0.0844, -0.0784, -0.0784,\n",
       "           -0.0725, -0.0666, -0.0666, -0.0607, -0.0607, -0.0549, -0.0491, -0.0491,\n",
       "           -0.0433, -0.0433, -0.0376, -0.0376, -0.0319, -0.0262, -0.0206, -0.0150,\n",
       "           -0.0094, -0.0039, -0.0039,  0.0016,  0.0016,  0.0071,  0.0071,  0.0125,\n",
       "            0.0125,  0.0180,  0.0180,  0.0234,  0.0234,  0.0287,  0.0341,  0.0341,\n",
       "            0.0394,  0.0394,  0.0446,  0.0551,  0.0603,  0.0603,  0.0655,  0.0655,\n",
       "            0.0706,  0.0706,  0.0757,  0.0757,  0.0808,  0.0859,  0.0909,  0.0909,\n",
       "            0.0959,  0.1009,  0.1059,  0.1059,  0.1108,  0.1108,  0.1157,  0.1255,\n",
       "            0.1351,  0.1351,  0.1447,  0.1447,  0.1542,  0.1636,  0.1636,  0.1729,\n",
       "            0.1729,  0.1821,  0.1912,  0.1912,  0.2003,  0.2093,  0.2093,  0.2181,\n",
       "            0.2181,  0.2270,  0.2270,  0.2443,  0.2443,  0.2529,  0.2529,  0.2614,\n",
       "            0.2614,  0.2782, -0.3272, -0.3272, -0.3196, -0.3196, -0.3120, -0.3120,\n",
       "           -0.3046, -0.3046, -0.2971, -0.2897, -0.2824, -0.2824, -0.2751, -0.2679,\n",
       "           -0.2679, -0.2607, -0.2607, -0.2536, -0.2466, -0.2395, -0.2395, -0.2326,\n",
       "           -0.2257, -0.2257, -0.2188, -0.2188, -0.2120, -0.2052, -0.2052, -0.1984,\n",
       "           -0.1918, -0.1851, -0.1851, -0.1785, -0.1785, -0.1720, -0.1654, -0.1654,\n",
       "           -0.1590, -0.1590, -0.1525, -0.1525, -0.1461, -0.1461, -0.1398, -0.1398,\n",
       "           -0.1335, -0.1272, -0.1210, -0.1210, -0.1148, -0.1148, -0.1086, -0.1025,\n",
       "           -0.0964, -0.0964, -0.0904, -0.0904, -0.0844, -0.0844, -0.0784, -0.0784,\n",
       "           -0.0725, -0.0725, -0.0666, -0.0607, -0.0549, -0.0549, -0.0491, -0.0491,\n",
       "           -0.0433, -0.0433, -0.0376, -0.0319, -0.0262, -0.0262, -0.0206, -0.0206,\n",
       "           -0.0150, -0.0150, -0.0094, -0.0039, -0.0039,  0.0016,  0.0016,  0.0071,\n",
       "            0.0071,  0.0125,  0.0125,  0.0180,  0.0180,  0.0234,  0.0234,  0.0287,\n",
       "            0.0287,  0.0341,  0.0394,  0.0446,  0.0446,  0.0499,  0.0499,  0.0551,\n",
       "            0.0603,  0.0655,  0.0655,  0.0706,  0.0757,  0.0757,  0.0808,  0.0808,\n",
       "            0.0909,  0.0909,  0.0959,  0.1059,  0.1059,  0.1157,  0.1255,  0.1255,\n",
       "            0.1351,  0.1351,  0.1447,  0.1542,  0.1542,  0.1636,  0.1636,  0.1729,\n",
       "            0.1729,  0.1821,  0.1912,  0.1912,  0.2003,  0.2093,  0.2181,  0.2270,\n",
       "            0.2270,  0.2443,  0.2443,  0.2529,  0.2614,  0.2699,  0.2699,  0.2782]),\n",
       "   tensor([-0.6945, -0.6715, -0.6490, -0.6271, -0.6271, -0.6055, -0.6055, -0.5845,\n",
       "           -0.5437, -0.5437, -0.5045, -0.4667, -0.4303, -0.4303, -0.3953, -0.3953,\n",
       "           -0.3614, -0.3614, -0.3286, -0.3286, -0.2968, -0.2660, -0.2660, -0.2362,\n",
       "           -0.2072, -0.1790, -0.1790, -0.1516, -0.1516, -0.0990, -0.0990, -0.0737,\n",
       "           -0.0737, -0.0490, -0.0490, -0.0249, -0.0249, -0.0013,  0.0216,  0.0216,\n",
       "            0.0441,  0.0441,  0.0661,  0.0661,  0.0876,  0.1087,  0.1087,  0.1293,\n",
       "            0.1293,  0.1495,  0.1495])],\n",
       "  'Time to Maturity': [tensor([0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421]),\n",
       "   tensor([0.0159, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
       "           0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
       "           0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
       "           0.0754, 0.0754, 0.0754, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087]),\n",
       "   tensor([0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643]),\n",
       "   tensor([2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024])],\n",
       "  'Implied Volatility': [tensor([0.3229, 0.3229, 0.3229, 0.3229, 0.2849, 0.3124, 0.3069, 0.2849, 0.3091,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124,\n",
       "           0.2849, 0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124,\n",
       "           0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.2718, 0.2748, 0.2716, 0.2743, 0.2711, 0.2737, 0.2707,\n",
       "           0.2703, 0.2732, 0.2702, 0.2727, 0.2698, 0.2723, 0.2727, 0.2690, 0.2725,\n",
       "           0.2686, 0.2682, 0.2725, 0.2678, 0.2728, 0.2679, 0.2731, 0.2733, 0.2673,\n",
       "           0.2728, 0.2671, 0.2741, 0.2675, 0.2740, 0.2677, 0.2746, 0.2683, 0.2736,\n",
       "           0.2683, 0.2765, 0.2685, 0.2687, 0.2779, 0.2691, 0.2785, 0.2690, 0.2798,\n",
       "           0.2698, 0.2794, 0.2702, 0.2821, 0.2717, 0.2804, 0.2721, 0.2733, 0.2824,\n",
       "           0.2738, 0.2876, 0.2745, 0.2879, 0.2901, 0.2760, 0.2937, 0.2965, 0.2775,\n",
       "           0.2782, 0.3004, 0.2794, 0.2990, 0.2804, 0.3029, 0.2818, 0.3037, 0.2827,\n",
       "           0.3085, 0.2857, 0.3088, 0.2875, 0.2885, 0.3089, 0.2892, 0.3089, 0.2918,\n",
       "           0.3089, 0.2932, 0.3089, 0.2943, 0.3089, 0.2964, 0.3089, 0.2965, 0.2998,\n",
       "           0.3089, 0.3015, 0.3089, 0.3042, 0.3089, 0.3091, 0.3089, 0.3096, 0.3089,\n",
       "           0.3127, 0.3089, 0.3116, 0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3116, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.2797,\n",
       "           0.2829, 0.2824, 0.2786, 0.2784, 0.2819, 0.2780, 0.2817, 0.2818, 0.2776,\n",
       "           0.2817, 0.2816, 0.2770, 0.2811, 0.2771, 0.2814, 0.2765, 0.2808, 0.2811,\n",
       "           0.2764, 0.2811, 0.2763, 0.2814, 0.2762, 0.2819, 0.2763, 0.2819, 0.2772,\n",
       "           0.2824, 0.2767, 0.2824, 0.2767, 0.2765, 0.2817, 0.2764, 0.2824, 0.2765,\n",
       "           0.2841, 0.2772, 0.2777, 0.2852, 0.2783, 0.2858, 0.2779, 0.2783, 0.2871,\n",
       "           0.2791, 0.2882, 0.2807, 0.2927, 0.2812, 0.2968, 0.2818, 0.2938, 0.2823,\n",
       "           0.2938, 0.2829, 0.2975, 0.2839, 0.2978, 0.3004, 0.2849, 0.3000, 0.2853,\n",
       "           0.2980, 0.2856, 0.2870, 0.2999, 0.2999]),\n",
       "   tensor([0.4101, 0.7247, 0.3801, 0.3801, 0.7247, 0.7247, 0.3801, 0.3801, 0.3801,\n",
       "           0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.3801, 0.7247,\n",
       "           0.3801, 0.7247, 0.3801, 0.3801, 0.7247, 0.3801, 0.7247, 0.7247, 0.3801,\n",
       "           0.7104, 0.6707, 0.3801, 0.5372, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.5191, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3855, 0.3962, 0.3481, 0.3055, 0.3962, 0.3481,\n",
       "           0.3962, 0.3347, 0.3962, 0.3481, 0.3962, 0.3493, 0.3909, 0.3374, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355,\n",
       "           0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3355, 0.3632, 0.3632, 0.3355, 0.3355, 0.3355,\n",
       "           0.3632, 0.3355, 0.3570, 0.3318, 0.3277, 0.3231, 0.3379, 0.3194, 0.3372,\n",
       "           0.3129, 0.3226, 0.3094, 0.3147, 0.3068, 0.3101, 0.3040, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.3484, 0.3484,\n",
       "           0.4352, 0.3484, 0.3429, 0.4122, 0.3953, 0.3444, 0.3835, 0.3753, 0.3739,\n",
       "           0.3358, 0.3570, 0.3293, 0.3245, 0.3413, 0.3237, 0.3356, 0.3221, 0.3173,\n",
       "           0.3161, 0.3231, 0.3221, 0.3128, 0.3187, 0.3110, 0.4089, 0.3532, 0.4089,\n",
       "           0.3532, 0.3532, 0.4089, 0.3306, 0.4089, 0.3532, 0.3439, 0.4089, 0.4089,\n",
       "           0.3356, 0.4089, 0.3532, 0.4089, 0.3407, 0.3976, 0.3439, 0.3822, 0.3405,\n",
       "           0.3716, 0.3346, 0.3633, 0.3286, 0.3605, 0.3439, 0.3254, 0.3225, 0.3393,\n",
       "           0.3182, 0.3260, 0.3226, 0.3096, 0.3162, 0.3071, 0.3090, 0.3064, 0.3063,\n",
       "           0.3047, 0.3030, 0.2998, 0.3005, 0.2977, 0.2965, 0.2965, 0.2912, 0.2891,\n",
       "           0.2916, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3792, 0.3370, 0.3370,\n",
       "           0.3792, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3396, 0.3792, 0.3317,\n",
       "           0.3690, 0.3352, 0.3646, 0.3534, 0.3273, 0.3442, 0.3353, 0.3286, 0.3150,\n",
       "           0.3222, 0.3121, 0.3166, 0.3108, 0.3126, 0.3070, 0.3071, 0.3081, 0.3051,\n",
       "           0.3024, 0.2994, 0.3020, 0.2969, 0.2969, 0.2973, 0.2949, 0.2960, 0.2921,\n",
       "           0.2897, 0.2912, 0.2858, 0.2854, 0.2883, 0.2834, 0.2882, 0.2870, 0.2810,\n",
       "           0.2792, 0.4797, 0.3385, 0.4674, 0.3353, 0.4503, 0.4401, 0.3400, 0.4230,\n",
       "           0.4074, 0.3331, 0.3976, 0.3877, 0.3264, 0.3230, 0.3690, 0.3173, 0.3187,\n",
       "           0.3479, 0.3088, 0.3357, 0.3313, 0.3114, 0.3227, 0.3064, 0.3177, 0.3004,\n",
       "           0.3160, 0.3030, 0.3108, 0.3012, 0.3054, 0.2979, 0.3003, 0.2969, 0.2962,\n",
       "           0.2937, 0.2944, 0.2927, 0.2910, 0.2922, 0.2887, 0.2859, 0.2885, 0.2833,\n",
       "           0.2873, 0.2841, 0.2864, 0.2803, 0.2793, 0.2844, 0.2800, 0.2844, 0.2784,\n",
       "           0.2795, 0.2819, 0.2738, 0.2798, 0.2748, 0.2798, 0.2702, 0.2723, 0.2790,\n",
       "           0.2723, 0.2720, 0.2796, 0.2711, 0.2788, 0.2671, 0.2767, 0.3372, 0.3342,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3342, 0.3372,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3358, 0.3372, 0.3280, 0.3294,\n",
       "           0.3196, 0.3372, 0.3249, 0.3372, 0.3230, 0.3372, 0.3163, 0.3372, 0.3153,\n",
       "           0.3432, 0.3371, 0.3294, 0.3124, 0.3232, 0.3027, 0.3059, 0.3133, 0.3030,\n",
       "           0.3111, 0.3025, 0.3034, 0.2974, 0.3012, 0.2988, 0.2992, 0.2993, 0.2988,\n",
       "           0.2975, 0.2953, 0.2959, 0.2926, 0.2927, 0.2848, 0.2920, 0.2854, 0.2931,\n",
       "           0.2836, 0.2914, 0.2810, 0.2895, 0.2774, 0.2888, 0.2811, 0.2896, 0.2795,\n",
       "           0.2870, 0.2785, 0.2880, 0.2794, 0.2853, 0.2798, 0.2858, 0.2784, 0.2745,\n",
       "           0.2848]),\n",
       "   tensor([0.2326, 0.2317, 0.2282, 0.2274, 0.2262, 0.2286, 0.2275, 0.2275, 0.2253,\n",
       "           0.2231, 0.2252, 0.2221, 0.2242, 0.2214, 0.2234, 0.2208, 0.2237, 0.2205,\n",
       "           0.2228, 0.2202, 0.2189, 0.2221, 0.2196, 0.2191, 0.2213, 0.2206, 0.2165,\n",
       "           0.2205, 0.2173, 0.2197, 0.2155, 0.2196, 0.2158, 0.2193, 0.2160, 0.2197,\n",
       "           0.2146, 0.2190, 0.2151, 0.2186, 0.2185, 0.2146, 0.2190, 0.2126, 0.2185,\n",
       "           0.2138, 0.2143, 0.2194, 0.2124, 0.2191, 0.2165, 0.2191, 0.2195, 0.2172,\n",
       "           0.2204, 0.2174, 0.2188, 0.2225, 0.2123, 0.2231, 0.2166, 0.2241, 0.2156,\n",
       "           0.2246, 0.2205, 0.2279, 0.2139, 0.2274, 0.2198, 0.2342, 0.2137, 0.2299,\n",
       "           0.2137, 0.2315, 0.2137, 0.2330, 0.2137, 0.2343, 0.2118, 0.2344, 0.2137,\n",
       "           0.2403, 0.2137, 0.2851, 0.2756, 0.2723, 0.2813, 0.2715, 0.2803, 0.2693,\n",
       "           0.2780, 0.2765, 0.2693, 0.2769, 0.2686, 0.2743, 0.2650, 0.2631, 0.2702,\n",
       "           0.2635, 0.2691, 0.2620, 0.2671, 0.2661, 0.2596, 0.2626, 0.2575, 0.2631,\n",
       "           0.2605, 0.2620, 0.2561, 0.2587, 0.2552, 0.2597, 0.2544, 0.2574, 0.2528,\n",
       "           0.2525, 0.2541, 0.2505, 0.2537, 0.2489, 0.2523, 0.2479, 0.2518, 0.2509,\n",
       "           0.2470, 0.2495, 0.2457, 0.2441, 0.2480, 0.2421, 0.2461, 0.2412, 0.2426,\n",
       "           0.2400, 0.2426, 0.2386, 0.2373, 0.2405, 0.2399, 0.2363, 0.2391, 0.2347,\n",
       "           0.2343, 0.2371, 0.2337, 0.2367, 0.2335, 0.2322, 0.2346, 0.2308, 0.2326,\n",
       "           0.2310, 0.2327, 0.2294, 0.2290, 0.2307, 0.2303, 0.2287, 0.2286, 0.2274,\n",
       "           0.2257, 0.2274, 0.2252, 0.2272, 0.2258, 0.2262, 0.2241, 0.2263, 0.2237,\n",
       "           0.2248, 0.2233, 0.2247, 0.2241, 0.2232, 0.2236, 0.2233, 0.2210, 0.2212,\n",
       "           0.2228, 0.2210, 0.2228, 0.2207, 0.2222, 0.2199, 0.2216, 0.2200, 0.2227,\n",
       "           0.2214, 0.2224, 0.2200, 0.2225, 0.2187, 0.2213, 0.2184, 0.2222, 0.2184,\n",
       "           0.2183, 0.2221, 0.2227, 0.2177, 0.2217, 0.2180, 0.2215, 0.2215, 0.2196,\n",
       "           0.2218, 0.2205, 0.2209, 0.2231, 0.2218, 0.2229, 0.2236, 0.2226, 0.2259,\n",
       "           0.2230, 0.2268, 0.2239, 0.2280, 0.2259, 0.2283, 0.2255, 0.2265, 0.2251,\n",
       "           0.2313, 0.2810, 0.2642, 0.2789, 0.2642, 0.2775, 0.2642, 0.2761, 0.2642,\n",
       "           0.2745, 0.2731, 0.2712, 0.2642, 0.2700, 0.2692, 0.2605, 0.2646, 0.2607,\n",
       "           0.2646, 0.2567, 0.2628, 0.2558, 0.2533, 0.2591, 0.2552, 0.2589, 0.2534,\n",
       "           0.2562, 0.2553, 0.2502, 0.2548, 0.2519, 0.2500, 0.2468, 0.2513, 0.2460,\n",
       "           0.2483, 0.2477, 0.2438, 0.2491, 0.2424, 0.2468, 0.2421, 0.2451, 0.2413,\n",
       "           0.2436, 0.2401, 0.2389, 0.2422, 0.2416, 0.2369, 0.2402, 0.2358, 0.2394,\n",
       "           0.2343, 0.2371, 0.2335, 0.2375, 0.2324, 0.2365, 0.2320, 0.2356, 0.2305,\n",
       "           0.2351, 0.2304, 0.2321, 0.2333, 0.2310, 0.2283, 0.2297, 0.2277, 0.2306,\n",
       "           0.2271, 0.2265, 0.2257, 0.2275, 0.2251, 0.2274, 0.2246, 0.2256, 0.2238,\n",
       "           0.2232, 0.2258, 0.2227, 0.2252, 0.2221, 0.2240, 0.2219, 0.2241, 0.2213,\n",
       "           0.2231, 0.2207, 0.2233, 0.2203, 0.2222, 0.2198, 0.2197, 0.2214, 0.2222,\n",
       "           0.2181, 0.2218, 0.2184, 0.2181, 0.2174, 0.2210, 0.2172, 0.2167, 0.2203,\n",
       "           0.2181, 0.2200, 0.2174, 0.2199, 0.2166, 0.2194, 0.2190, 0.2164, 0.2192,\n",
       "           0.2183, 0.2150, 0.2183, 0.2152, 0.2189, 0.2186, 0.2172, 0.2180, 0.2156,\n",
       "           0.2182, 0.2162, 0.2179, 0.2191, 0.2163, 0.2195, 0.2188, 0.2174, 0.2206,\n",
       "           0.2193, 0.2218, 0.2173, 0.2220, 0.2211, 0.2226, 0.2208, 0.2229]),\n",
       "   tensor([0.3600, 0.3587, 0.3557, 0.4459, 0.3539, 0.4343, 0.3496, 0.3521, 0.4066,\n",
       "           0.3464, 0.3444, 0.3424, 0.3633, 0.3404, 0.3564, 0.3388, 0.3491, 0.3375,\n",
       "           0.3425, 0.3351, 0.3372, 0.3307, 0.3313, 0.3277, 0.3263, 0.3217, 0.3271,\n",
       "           0.3212, 0.3253, 0.3166, 0.3235, 0.3180, 0.3231, 0.3128, 0.3222, 0.3124,\n",
       "           0.3200, 0.3197, 0.3105, 0.3187, 0.3090, 0.3170, 0.3088, 0.3177, 0.3164,\n",
       "           0.3044, 0.3156, 0.3043, 0.3150, 0.3042, 0.3148])]},\n",
       " 'Query Points': {'Log Moneyness': [tensor([0.4004, 0.7347, 0.4810, 0.6727, 0.7070, 0.4080, 0.4668, 0.2874, 0.4810,\n",
       "           0.3292, 0.5425, 0.6432, 0.5019, 0.2614, 0.1203, 0.2257, 0.4597, 0.3210,\n",
       "           0.4452, 0.5358, 0.4524, 0.6004, 0.6669, 0.7292, 0.4004, 0.7181, 0.6432,\n",
       "           0.1599, 0.7722, 0.4230, 0.7292, 0.5750, 0.3127, 0.0895, 0.0685, 0.8185,\n",
       "           0.3127, 0.4950, 0.3455, 0.4668, 0.3292, 0.0470, 0.8335, 0.8235, 0.5491,\n",
       "           0.1502, 0.6128, 0.6189, 0.5941, 0.6311, 0.8084, 0.4880, 0.5425, 0.6189,\n",
       "           0.4880, 0.7722, 0.4080, 0.0999, 0.3850, 0.7616, 0.8033, 0.4230, 0.2165,\n",
       "           0.5291, 0.1102, 0.4452, 0.2959, 0.5686, 0.0578, 0.3374, 0.2788, 0.6957,\n",
       "           0.3127, 0.5621, 0.4305, 0.7347, 0.3292, 0.4950, 0.7616, 0.2874],\n",
       "          requires_grad=True),\n",
       "   tensor([-1.8194e-01, -4.2189e-01, -3.0978e-01, -1.8194e-01, -3.2504e-01,\n",
       "           -2.7992e-01, -2.2277e-01, -3.5630e-01, -1.1741e-01, -2.3675e-01,\n",
       "           -2.7992e-01, -4.9210e-01, -1.6870e-01, -2.2095e-02, -1.2998e-01,\n",
       "            3.7784e-04, -4.7408e-01, -3.2504e-01, -2.0897e-01, -3.0978e-01,\n",
       "           -2.3675e-01, -2.5094e-01, -5.2914e-01, -2.5094e-01, -4.5638e-01,\n",
       "           -8.0591e-02, -2.3675e-01, -1.6870e-01, -1.6870e-01, -6.8615e-02,\n",
       "           -1.4272e-01, -5.1045e-01, -5.4819e-01, -1.1741e-01, -4.9210e-01,\n",
       "           -3.7230e-01, -1.6870e-01, -1.5563e-01, -5.2914e-01, -3.2504e-01,\n",
       "           -3.4055e-01, -4.5085e-02, -3.7230e-01, -2.7992e-01, -4.3899e-01,\n",
       "           -3.5630e-01, -1.0498e-01, -1.1741e-01, -5.6761e-01, -4.5638e-01,\n",
       "           -2.5094e-01, -3.5630e-01, -2.7992e-01, -1.9537e-01, -3.7230e-01,\n",
       "           -3.0978e-01, -4.5638e-01, -3.4055e-01, -5.6781e-02, -4.3899e-01,\n",
       "           -6.4928e-01, -5.1045e-01, -3.2504e-01, -4.5638e-01, -3.8856e-01,\n",
       "           -5.1045e-01, -4.5638e-01, -3.8856e-01, -2.5094e-01, -5.6761e-01,\n",
       "           -2.5094e-01, -3.5630e-01, -3.8856e-01, -2.9474e-01, -5.6781e-02,\n",
       "           -2.5094e-01, -2.5094e-01, -4.2189e-01, -3.8856e-01, -7.1524e-01,\n",
       "           -1.8194e-01, -3.0978e-01, -4.2189e-01, -4.9210e-01, -4.0509e-01,\n",
       "           -4.2189e-01, -4.9210e-01, -4.2189e-01, -2.2277e-01, -5.2914e-01,\n",
       "           -2.6533e-01, -5.4819e-01, -6.8615e-02, -2.0897e-01, -4.0509e-01,\n",
       "           -1.9537e-01, -4.7408e-01, -3.0978e-01, -3.0978e-01, -2.2277e-01,\n",
       "           -8.0591e-02, -2.6533e-01], requires_grad=True),\n",
       "   tensor([-0.0376, -0.2536,  0.0808,  0.1542, -0.0666, -0.2971,  0.2357,  0.0341,\n",
       "           -0.0262,  0.1447, -0.0319, -0.1335,  0.2699,  0.0808, -0.1272, -0.1148,\n",
       "            0.2357, -0.2751,  0.0499,  0.2003, -0.2326,  0.1636,  0.1255, -0.0491,\n",
       "            0.2782,  0.2003,  0.0959, -0.1590,  0.0341,  0.2357, -0.1398,  0.2357,\n",
       "            0.0394,  0.2782, -0.0262, -0.0964,  0.2614, -0.1272, -0.0607,  0.0859,\n",
       "            0.1821, -0.1086,  0.2529, -0.2466, -0.0549,  0.1009,  0.0394,  0.0499,\n",
       "           -0.3120,  0.0959, -0.0725, -0.1086,  0.0859,  0.2699, -0.1918,  0.0287,\n",
       "           -0.1720, -0.0319, -0.2395,  0.0234,  0.0603,  0.0859,  0.0446,  0.2093,\n",
       "           -0.0094, -0.2607,  0.2181,  0.1157,  0.1821,  0.1157, -0.0094, -0.1335,\n",
       "           -0.0904, -0.0206, -0.0491,  0.0551, -0.0150, -0.0549, -0.0376, -0.1851,\n",
       "            0.0706, -0.2897, -0.0206, -0.2120,  0.0551, -0.0319, -0.1025,  0.1351,\n",
       "           -0.0150, -0.2897,  0.1059, -0.1984], requires_grad=True),\n",
       "   tensor([-0.2362, -0.5045,  0.0876, -0.2072, -0.4667, -0.6715, -0.2968, -0.5845,\n",
       "           -0.1250, -0.6490, -0.6945, -0.0013, -0.1250], requires_grad=True)],\n",
       "  'Time to Maturity': [tensor([0.8810, 0.8810, 0.5198, 0.8810, 0.8810, 0.8810, 0.5198, 1.2421, 0.5198,\n",
       "           1.2421, 0.8810, 0.5198, 0.8810, 1.2421, 1.2421, 1.2421, 0.5198, 0.8810,\n",
       "           0.5198, 0.8810, 0.5198, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           1.2421, 0.8810, 1.2421, 0.8810, 0.8810, 0.8810, 0.8810, 1.2421, 0.8810,\n",
       "           1.2421, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.5198,\n",
       "           0.8810, 0.8810, 0.8810, 0.5198, 0.5198, 0.8810, 0.8810, 0.5198, 0.5198,\n",
       "           0.5198, 0.8810, 1.2421, 1.2421, 1.2421, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.5198, 0.8810, 0.5198, 1.2421, 0.8810, 1.2421, 0.8810, 0.8810, 0.8810,\n",
       "           1.2421, 0.8810, 0.8810, 0.8810, 1.2421, 0.8810, 0.8810, 1.2421],\n",
       "          requires_grad=True),\n",
       "   tensor([0.4365, 0.6865, 0.3254, 1.0476, 1.4087, 0.0754, 0.3254, 0.3254, 1.0476,\n",
       "           0.5754, 0.1865, 1.4087, 0.5754, 1.0476, 0.5754, 1.0476, 0.5754, 0.4365,\n",
       "           0.3254, 0.6865, 0.5754, 0.4365, 0.6865, 0.0754, 0.5754, 1.0476, 0.6865,\n",
       "           0.5754, 0.4365, 0.6865, 0.6865, 0.4365, 0.0754, 0.6865, 0.6865, 0.4365,\n",
       "           0.6865, 0.4365, 1.0476, 0.3254, 0.4365, 1.4087, 1.4087, 0.5754, 0.5754,\n",
       "           0.6865, 0.5754, 0.5754, 1.4087, 1.0476, 0.5754, 0.0754, 0.4365, 1.4087,\n",
       "           0.3254, 1.4087, 0.5754, 1.4087, 0.6865, 0.0754, 1.4087, 1.4087, 0.6865,\n",
       "           0.0754, 1.0476, 0.0754, 0.1865, 0.4365, 0.3254, 0.1865, 1.0476, 1.0476,\n",
       "           0.1865, 0.4365, 1.0476, 0.0159, 0.4365, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           0.5754, 0.4365, 0.0754, 0.6865, 0.0754, 1.0476, 1.0476, 0.4365, 0.5754,\n",
       "           0.3254, 0.0754, 1.0476, 0.6865, 1.4087, 1.0476, 0.6865, 0.0754, 0.1865,\n",
       "           1.0476, 0.6865, 1.0476], requires_grad=True),\n",
       "   tensor([0.9643, 0.9643, 0.8532, 0.8532, 0.9643, 0.9643, 0.9643, 0.9643, 0.4921,\n",
       "           0.9643, 0.9643, 0.9643, 0.8532, 0.4921, 0.8532, 0.8532, 0.8532, 0.9643,\n",
       "           0.8532, 0.8532, 0.9643, 0.4921, 0.8532, 0.4921, 0.9643, 0.9643, 0.8532,\n",
       "           0.8532, 0.4921, 0.8532, 0.8532, 0.9643, 0.4921, 0.8532, 0.8532, 0.8532,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.8532, 0.9643, 0.9643, 0.4921,\n",
       "           0.8532, 0.9643, 0.8532, 0.8532, 0.9643, 0.8532, 0.9643, 0.9643, 0.8532,\n",
       "           0.9643, 0.8532, 0.9643, 0.4921, 0.8532, 0.4921, 0.9643, 0.8532, 0.8532,\n",
       "           0.9643, 0.8532, 0.8532, 0.9643, 0.8532, 0.8532, 0.9643, 0.9643, 0.8532,\n",
       "           0.8532, 0.8532, 0.4921, 0.8532, 0.8532, 0.8532, 0.4921, 0.8532, 0.9643,\n",
       "           0.8532, 0.4921, 0.9643, 0.9643, 0.8532, 0.9643, 0.4921, 0.4921, 0.9643,\n",
       "           0.4921, 0.9643], requires_grad=True),\n",
       "   tensor([2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024], requires_grad=True)],\n",
       "  'Implied Volatility': [tensor([0.3085, 0.3116, 0.2849, 0.3116, 0.3116, 0.3089, 0.2849, 0.2774, 0.3124,\n",
       "           0.2800, 0.3116, 0.2849, 0.3057, 0.2848, 0.2772, 0.2829, 0.2849, 0.2911,\n",
       "           0.3229, 0.3116, 0.2849, 0.3089, 0.3116, 0.3089, 0.2856, 0.3116, 0.3089,\n",
       "           0.2765, 0.3089, 0.2872, 0.3116, 0.3116, 0.2740, 0.2688, 0.2822, 0.3089,\n",
       "           0.2895, 0.3048, 0.2942, 0.3089, 0.2760, 0.2733, 0.3116, 0.3116, 0.2849,\n",
       "           0.2672, 0.3089, 0.3089, 0.2849, 0.2849, 0.3116, 0.3089, 0.3124, 0.3124,\n",
       "           0.2849, 0.3116, 0.3009, 0.2779, 0.2837, 0.3089, 0.3089, 0.3089, 0.2765,\n",
       "           0.3124, 0.2727, 0.2849, 0.2890, 0.3116, 0.2792, 0.2772, 0.2854, 0.3116,\n",
       "           0.2788, 0.3089, 0.2902, 0.3089, 0.2902, 0.3089, 0.3116, 0.2866]),\n",
       "   tensor([0.3331, 0.3792, 0.3632, 0.2953, 0.3212, 0.3801, 0.3153, 0.3355, 0.2859,\n",
       "           0.3278, 0.3962, 0.3372, 0.3044, 0.2785, 0.2967, 0.2794, 0.4089, 0.3464,\n",
       "           0.3263, 0.3174, 0.3109, 0.3256, 0.3792, 0.3801, 0.3532, 0.2837, 0.3050,\n",
       "           0.3021, 0.3295, 0.2847, 0.2945, 0.3484, 0.3801, 0.2892, 0.3792, 0.4487,\n",
       "           0.2964, 0.3143, 0.3435, 0.3632, 0.4214, 0.2859, 0.3126, 0.3410, 0.3496,\n",
       "           0.3274, 0.2932, 0.2939, 0.3360, 0.3296, 0.3172, 0.7247, 0.3365, 0.2949,\n",
       "           0.3632, 0.3165, 0.4089, 0.3026, 0.2834, 0.7247, 0.3342, 0.3372, 0.3232,\n",
       "           0.7247, 0.3554, 0.7247, 0.3481, 0.4610, 0.3592, 0.3962, 0.3043, 0.3103,\n",
       "           0.3481, 0.3401, 0.2750, 0.4484, 0.3654, 0.3168, 0.3152, 0.3372, 0.2934,\n",
       "           0.3235, 0.3484, 0.3801, 0.3792, 0.7247, 0.3363, 0.3754, 0.3477, 0.4089,\n",
       "           0.3396, 0.7247, 0.2817, 0.3015, 0.3372, 0.2935, 0.3370, 0.7247, 0.3962,\n",
       "           0.2948, 0.2819, 0.2994]),\n",
       "   tensor([0.2287, 0.2577, 0.2192, 0.2196, 0.2295, 0.2642, 0.2217, 0.2220, 0.2258,\n",
       "           0.2151, 0.2285, 0.2442, 0.2301, 0.2175, 0.2465, 0.2403, 0.2238, 0.2579,\n",
       "           0.2217, 0.2225, 0.2597, 0.2207, 0.2183, 0.2325, 0.2231, 0.2173, 0.2193,\n",
       "           0.2479, 0.2217, 0.2272, 0.2469, 0.2193, 0.2180, 0.2287, 0.2292, 0.2414,\n",
       "           0.2187, 0.2380, 0.2288, 0.2198, 0.2165, 0.2437, 0.2198, 0.2647, 0.2302,\n",
       "           0.2212, 0.2195, 0.2228, 0.2852, 0.2166, 0.2381, 0.2352, 0.2176, 0.2267,\n",
       "           0.2480, 0.2230, 0.2453, 0.2294, 0.2602, 0.2212, 0.2211, 0.2197, 0.2235,\n",
       "           0.2171, 0.2268, 0.2723, 0.2201, 0.2220, 0.2248, 0.2146, 0.2256, 0.2426,\n",
       "           0.2374, 0.2289, 0.2297, 0.2226, 0.2281, 0.2358, 0.2310, 0.2570, 0.2204,\n",
       "           0.2698, 0.2250, 0.2524, 0.2214, 0.2318, 0.2384, 0.2171, 0.2238, 0.2642,\n",
       "           0.2185, 0.2492]),\n",
       "   tensor([0.3301, 0.3884, 0.3060, 0.3280, 0.3755, 0.4660, 0.3333, 0.4248, 0.3245,\n",
       "           0.4548, 0.4785, 0.3126, 0.3192])]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "class IVSurfaceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data, \n",
    "        proportion, \n",
    "        random_state=0\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.proportion = proportion\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        surface_data = self.data[idx]\n",
    "        \n",
    "        # Extract the surface coordinates and volatilities\n",
    "        points_coordinates = np.stack([\n",
    "            surface_data['Surface']['Log Moneyness'], \n",
    "            surface_data['Surface']['Time to Maturity']\n",
    "        ], axis=1)\n",
    "        points_volatilities = surface_data['Surface']['Implied Volatility']\n",
    "\n",
    "        # Perform clustering\n",
    "        n_clusters = int(np.ceil(1 / self.proportion))\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('kmeans', KMeans(n_clusters=n_clusters, random_state=self.random_state, n_init='auto'))\n",
    "        ])\n",
    "        labels = pipeline.fit_predict(points_coordinates)\n",
    "\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        cluster_indices = np.where(labels == rng.integers(n_clusters))[0]\n",
    "        num_to_mask = int(np.ceil(len(cluster_indices) * self.proportion))\n",
    "        masked_indices = rng.choice(cluster_indices, size=num_to_mask, replace=False)\n",
    "        \n",
    "        unmasked_indices = np.setdiff1d(cluster_indices, masked_indices)\n",
    "\n",
    "\n",
    "        data_item = {\n",
    "            'Datetime': surface_data['Datetime'],\n",
    "            'Symbol': surface_data['Symbol'],\n",
    "            'Market Features': {\n",
    "                'Market Return': torch.tensor(surface_data['Market Features']['Market Return'], dtype=torch.float32),\n",
    "                'Market Volatility': torch.tensor(surface_data['Market Features']['Market Volatility'], dtype=torch.float32),\n",
    "                'Treasury Rate': torch.tensor(surface_data['Market Features']['Treasury Rate'], dtype=torch.float32),\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': torch.tensor(points_coordinates[unmasked_indices, 0], dtype=torch.float32),\n",
    "                'Time to Maturity': torch.tensor(points_coordinates[unmasked_indices, 1], dtype=torch.float32),\n",
    "                'Implied Volatility': torch.tensor(points_volatilities[unmasked_indices], dtype=torch.float32)\n",
    "            },\n",
    "            'Query Points': {\n",
    "                'Log Moneyness': torch.tensor(points_coordinates[masked_indices, 0], dtype=torch.float32),\n",
    "                'Time to Maturity': torch.tensor(points_coordinates[masked_indices, 1], dtype=torch.float32),\n",
    "                'Implied Volatility': torch.tensor(points_volatilities[masked_indices], dtype=torch.float32)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return data_item\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        batched_data = {\n",
    "            'Datetime': [item['Datetime'] for item in batch],\n",
    "            'Symbol': [item['Symbol'] for item in batch],\n",
    "            'Market Features': {\n",
    "                'Market Return': default_collate([item['Market Features']['Market Return'] for item in batch]),\n",
    "                'Market Volatility': default_collate([item['Market Features']['Market Volatility'] for item in batch]),\n",
    "                'Treasury Rate': default_collate([item['Market Features']['Treasury Rate'] for item in batch]),\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': [item['Input Surface']['Log Moneyness'].clone().detach() for item in batch],\n",
    "                'Time to Maturity': [item['Input Surface']['Time to Maturity'].clone().detach() for item in batch],\n",
    "                'Implied Volatility': [item['Input Surface']['Implied Volatility'].clone().detach() for item in batch],\n",
    "            },\n",
    "            'Query Points': {\n",
    "                'Log Moneyness': [item['Query Points']['Log Moneyness'].clone().detach().requires_grad_(True) for item in batch],\n",
    "                'Time to Maturity': [item['Query Points']['Time to Maturity'].clone().detach().requires_grad_(True) for item in batch],\n",
    "                'Implied Volatility': [item['Query Points']['Implied Volatility'].clone().detach() for item in batch],\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return batched_data\n",
    "\n",
    "\n",
    "# Assuming surfaces is the output from the implied_volatility_surfaces function\n",
    "proportion = 0.2  # example proportion\n",
    "dataset = IVSurfaceDataset(surfaces, proportion)\n",
    "data_loader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=HYPERPARAMETERS['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "\n",
    "# Fetch one batch from the DataLoader\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': [Timestamp('2013-06-10 00:00:00'),\n",
       "  Timestamp('2013-01-28 00:00:00'),\n",
       "  Timestamp('2013-05-20 00:00:00'),\n",
       "  Timestamp('2013-03-07 00:00:00')],\n",
       " 'Symbol': ['AAPL', 'AAPL', 'GOOGL', 'AAPL'],\n",
       " 'Market Features': {'Market Return': tensor([-0.0216, -0.4603, -0.1269,  0.6087], grad_fn=<SqueezeBackward1>),\n",
       "  'Market Volatility': tensor([ 1.6897, -0.2052, -0.7625, -0.7220], grad_fn=<SqueezeBackward1>),\n",
       "  'Treasury Rate': tensor([-0.7439,  0.1717, -0.9728,  1.5450], grad_fn=<SqueezeBackward1>)},\n",
       " 'Input Surface': {'Log Moneyness': [tensor([1.2476, 1.2676, 1.2873, 1.3070, 1.3070, 1.3458, 1.3650, 1.3650, 1.3841,\n",
       "           1.3841, 1.4030, 1.4030, 1.4219, 1.4219, 1.4406, 1.4406, 1.4591, 1.4776,\n",
       "           1.4776, 1.4959, 1.5141, 1.5322, 1.5322, 1.5501, 1.5501, 1.5680, 1.5680,\n",
       "           1.5857, 1.5857, 1.6033, 1.6033, 1.6209, 1.6209, 1.6383, 1.6555, 1.6555,\n",
       "           1.6727, 1.6727, 1.6898, 1.6898, 1.7068, 1.7236, 1.7236, 1.7404, 1.7571,\n",
       "           1.7571, 1.7736, 1.7901, 1.7901, 1.8064, 1.8064, 1.8227, 1.8227, 1.8389,\n",
       "           1.8389, 1.8550, 1.8550, 1.8710, 1.8710, 1.8869, 1.8869, 1.9027, 1.9027,\n",
       "           1.9184, 1.9184, 0.0381, 0.0381, 0.0690, 0.0690, 0.0994, 0.0994, 0.1296,\n",
       "           0.1594, 0.1594, 0.1889, 0.1889, 0.2180, 0.2180, 0.2469, 0.2755, 0.2755,\n",
       "           0.3038, 0.3318, 0.3318, 0.3595, 0.3595, 0.3869, 0.3869, 0.4141, 0.4410,\n",
       "           0.4410, 0.4676, 0.4676, 0.4940, 0.4940, 0.5202, 0.5202, 0.5461, 0.5461,\n",
       "           0.5717, 0.5717, 0.5971, 0.6223, 0.6223, 0.6473, 0.6473, 0.6720, 0.6720,\n",
       "           0.6965, 0.6965, 0.7208, 0.7208, 0.7449, 0.7449, 0.7688, 0.7924, 0.7924,\n",
       "           0.8159, 0.8159, 0.8392, 0.8392, 0.8622, 0.8851, 0.9078, 0.9303, 0.9527,\n",
       "           0.9748, 0.9748, 0.9968, 0.9968, 1.0186, 1.0186, 1.0402, 1.0402, 1.0617,\n",
       "           1.0617, 1.0830, 1.0830, 1.1251, 1.1459, 1.1459, 1.1665, 1.1870, 1.2074,\n",
       "           1.2074, 1.2276, 1.2276, 1.2476, 1.2476, 1.2676, 1.2676, 1.2873, 1.3070,\n",
       "           1.3070, 1.3264, 1.3264, 1.3458, 1.3841, 1.4030, 1.4030, 1.4219, 1.4219,\n",
       "           1.4406, 1.4406, 1.4591, 1.4591, 1.4776, 1.4959, 1.5141, 1.5141, 1.5322,\n",
       "           1.5322, 1.5501, 1.5680, 1.5857, 1.6033, 1.6033, 1.6209, 1.6209, 1.6383,\n",
       "           1.6383, 1.6555, 1.6727, 1.6727, 1.6898, 1.7068, 1.7236, 1.7236, 1.7404,\n",
       "           1.7404, 1.7571, 1.7571, 1.7736, 1.7901, 1.7901, 1.8064, 1.8064, 1.8227,\n",
       "           1.8227, 1.8389, 1.8550, 1.8710, 1.8710, 1.8869, 1.8869, 1.9027, 1.9027,\n",
       "           1.9184, 1.9340, 1.9340, 1.9495, 1.9650, 1.9650, 1.9803, 1.9956, 1.9956,\n",
       "           2.0409, 2.0409, 2.0559, 2.0559, 2.0708, 2.0708, 2.0855, 2.0855, 2.1149,\n",
       "           2.1149, 2.1439, 2.1439, 2.1583, 2.1583, 2.1726, 2.1726, 2.1869, 2.1869,\n",
       "           2.2011, 2.2011, 2.2152, 2.2292, 2.2432, 2.2432, 2.2570, 2.2709, 2.2983,\n",
       "           2.3255, 2.3255, 2.3524, 2.3524, 2.3790, 2.3790, 2.4054, 2.4054, 0.1296,\n",
       "           0.1296, 0.1594, 0.1889, 0.2180, 0.2180, 0.2469, 0.2469, 0.2755, 0.3038,\n",
       "           0.3038, 0.3318, 0.3595, 0.3595, 0.3869, 0.3869, 0.4141, 0.4141, 0.4410,\n",
       "           0.4676, 0.4676, 0.4940, 0.4940, 0.5202, 0.5202, 0.5461, 0.5461, 0.5717,\n",
       "           0.5717, 0.5971, 0.5971, 0.6223, 0.6473, 0.6473, 0.6720, 0.6720, 0.6965,\n",
       "           0.6965, 0.7208, 0.7449, 0.7449, 0.7688, 0.7688, 0.8159, 0.8392, 0.8392,\n",
       "           0.8851, 0.8851, 0.9303, 0.9303, 0.9527, 0.9527, 0.9748, 0.9748, 0.9968,\n",
       "           0.9968, 1.0186, 1.0186, 1.0402, 1.0402, 1.0617, 1.0830, 1.0830, 1.1041,\n",
       "           1.1041, 1.1251, 1.1459, 1.1459, 1.1665],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-6.9195e-01, -1.4591e+00, -1.4591e+00, -1.4076e+00, -1.3570e+00,\n",
       "           -1.3073e+00, -1.3073e+00, -1.2585e+00, -1.2105e+00, -1.1634e+00,\n",
       "           -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -1.0266e+00, -9.8249e-01, -9.3906e-01, -9.3906e-01, -8.9631e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01, -7.7189e-01,\n",
       "           -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.5284e-01, -6.5284e-01,\n",
       "           -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4591e+00,\n",
       "           -1.4076e+00, -1.4076e+00, -1.3570e+00, -1.3570e+00, -1.3073e+00,\n",
       "           -1.3073e+00, -1.2585e+00, -1.2105e+00, -1.2105e+00, -1.1634e+00,\n",
       "           -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -1.0266e+00, -9.8249e-01, -9.8249e-01, -9.3906e-01, -9.3906e-01,\n",
       "           -8.9631e-01, -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01,\n",
       "           -7.7189e-01, -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01,\n",
       "           -5.7623e-01, -1.5652e+00, -1.5652e+00, -1.5116e+00, -1.5116e+00,\n",
       "           -1.4591e+00, -1.4591e+00, -1.4076e+00, -1.4076e+00, -1.3570e+00,\n",
       "           -1.3570e+00, -1.3073e+00, -1.3073e+00, -1.2585e+00, -1.2585e+00,\n",
       "           -1.2105e+00, -1.2105e+00, -1.1634e+00, -1.1634e+00, -1.1170e+00,\n",
       "           -1.1170e+00, -1.0714e+00, -1.0714e+00, -1.0266e+00, -9.8249e-01,\n",
       "           -9.3906e-01, -9.3906e-01, -8.9631e-01, -8.5421e-01, -8.1274e-01,\n",
       "           -8.1274e-01, -7.7189e-01, -7.7189e-01, -7.3163e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -5.7623e-01, -5.3872e-01,\n",
       "           -5.3872e-01, -5.0170e-01, -5.0170e-01, -4.6518e-01, -4.6518e-01,\n",
       "           -1.5652e+00, -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00,\n",
       "           -1.4591e+00, -1.4076e+00, -1.3570e+00, -1.3570e+00, -1.3073e+00,\n",
       "           -1.3073e+00, -1.2585e+00, -1.2585e+00, -1.2105e+00, -1.2105e+00,\n",
       "           -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -9.8249e-01, -9.8249e-01, -9.3906e-01, -8.9631e-01, -8.5421e-01,\n",
       "           -8.5421e-01, -8.1274e-01, -7.7189e-01, -7.3163e-01, -7.3163e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -5.7623e-01, -5.7623e-01,\n",
       "           -5.3872e-01, -5.3872e-01, -5.0170e-01, -4.6518e-01, -4.2913e-01,\n",
       "           -3.9355e-01, -3.9355e-01, -3.5842e-01, -3.5842e-01, -1.5652e+00,\n",
       "           -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4076e+00,\n",
       "           -1.4076e+00, -1.3570e+00, -1.3570e+00, -1.3073e+00, -1.2105e+00,\n",
       "           -1.1634e+00, -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00,\n",
       "           -1.0714e+00, -1.0266e+00, -1.0266e+00, -9.8249e-01, -9.8249e-01,\n",
       "           -9.3906e-01, -9.3906e-01, -8.9631e-01, -8.9631e-01, -8.5421e-01,\n",
       "           -8.1274e-01, -8.1274e-01, -7.7189e-01, -7.3163e-01, -7.3163e-01,\n",
       "           -6.9195e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01, -5.7623e-01,\n",
       "           -5.3872e-01, -5.3872e-01, -5.0170e-01, -5.0170e-01, -4.2913e-01,\n",
       "           -4.2913e-01, -3.9355e-01, -3.9355e-01, -3.5842e-01, -3.2373e-01,\n",
       "           -2.8948e-01, -2.5564e-01, -2.5564e-01, -1.5652e+00, -1.5652e+00,\n",
       "           -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4076e+00, -1.4076e+00,\n",
       "           -1.3570e+00, -1.3073e+00, -1.2585e+00, -1.2585e+00, -1.2105e+00,\n",
       "           -1.2105e+00, -1.1634e+00, -1.1170e+00, -1.0714e+00, -1.0714e+00,\n",
       "           -1.0266e+00, -1.0266e+00, -9.8249e-01, -9.3906e-01, -9.3906e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01, -7.7189e-01,\n",
       "           -7.7189e-01, -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01, -5.3872e-01,\n",
       "           -5.3872e-01, -5.0170e-01, -5.0170e-01, -4.6518e-01, -4.2913e-01,\n",
       "           -4.2913e-01, -3.9355e-01, -3.5842e-01, -3.5842e-01, -3.2373e-01,\n",
       "           -2.8948e-01, -2.8948e-01, -2.5564e-01, -2.5564e-01, -2.2222e-01,\n",
       "           -1.8919e-01, -1.5656e-01, -1.5652e+00, -1.5652e+00, -1.5116e+00,\n",
       "           -1.5116e+00, -1.4591e+00, -1.4076e+00, -1.4076e+00, -1.3570e+00,\n",
       "           -1.3073e+00, -1.3073e+00, -1.2585e+00, -1.2105e+00, -1.2105e+00,\n",
       "           -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -1.0266e+00, -9.8249e-01, -9.3906e-01, -9.3906e-01, -8.9631e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01,\n",
       "           -7.7189e-01, -7.7189e-01, -7.3163e-01, -6.9195e-01, -6.5284e-01,\n",
       "           -6.5284e-01, -6.1427e-01, -5.7623e-01, -5.7623e-01, -5.3872e-01,\n",
       "           -5.0170e-01, -4.6518e-01, -4.6518e-01, -4.2913e-01, -4.2913e-01,\n",
       "           -3.9355e-01, -3.9355e-01, -3.5842e-01, -3.5842e-01, -3.2373e-01,\n",
       "           -2.8948e-01, -2.8948e-01, -2.5564e-01, -2.5564e-01, -2.2222e-01,\n",
       "           -1.8919e-01, -1.5656e-01, -1.2431e-01, -1.2431e-01, -9.2427e-02,\n",
       "           -9.2427e-02, -6.0912e-02, -2.9753e-02, -2.9753e-02,  1.0579e-03,\n",
       "            3.1528e-02,  3.1528e-02,  6.1666e-02,  6.1666e-02,  9.1477e-02,\n",
       "            9.1477e-02, -2.0357e+00, -2.0357e+00, -1.9723e+00, -1.9103e+00,\n",
       "           -1.9103e+00, -1.8497e+00, -1.8497e+00, -1.7904e+00, -1.7324e+00,\n",
       "           -1.7324e+00, -1.6755e+00, -1.6755e+00, -1.6198e+00, -1.6198e+00,\n",
       "           -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4591e+00,\n",
       "           -1.4076e+00, -1.3570e+00, -1.3073e+00, -1.3073e+00, -1.2585e+00,\n",
       "           -1.2585e+00, -1.2105e+00, -1.2105e+00, -1.1634e+00, -1.1170e+00,\n",
       "           -1.0714e+00, -1.0266e+00, -9.8249e-01, -9.8249e-01, -9.3906e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01, -7.7189e-01,\n",
       "           -7.7189e-01, -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01,\n",
       "           -5.7623e-01, -5.3872e-01, -5.0170e-01, -4.6518e-01, -4.6518e-01,\n",
       "           -4.2913e-01, -4.2913e-01, -3.9355e-01, -3.9355e-01, -3.5842e-01,\n",
       "           -3.5842e-01, -3.2373e-01, -3.2373e-01, -2.8948e-01, -2.8948e-01,\n",
       "           -2.5564e-01, -2.5564e-01, -2.2222e-01, -2.2222e-01, -1.8919e-01,\n",
       "           -1.8919e-01, -1.5656e-01, -1.5656e-01, -1.2431e-01, -9.2427e-02,\n",
       "           -9.2427e-02], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.1514, -0.1195, -0.1195, -0.1037, -0.0880, -0.0723, -0.0568, -0.0414,\n",
       "           -0.0260, -0.0260, -0.0107, -0.0107,  0.0045,  0.0045,  0.0196,  0.0196,\n",
       "            0.0346,  0.0346,  0.0496,  0.0496,  0.0644,  0.0792,  0.0792,  0.0939,\n",
       "            0.1085,  0.1231,  0.1231,  0.1376,  0.1376,  0.1520,  0.1520,  0.1663,\n",
       "            0.1663,  0.1805,  0.1805,  0.1947,  0.1947,  0.2088,  0.2088,  0.2229,\n",
       "            0.2368,  0.2368,  0.2507,  0.2507,  0.2645,  0.2645,  0.2920,  0.3191,\n",
       "            0.3191,  0.3460,  0.3460,  0.3727,  0.3991,  0.3991,  0.4252,  0.4252,\n",
       "            0.4511,  0.4768,  0.4768,  0.5022,  0.5022,  0.5274,  0.5274,  0.5523,\n",
       "            0.5523,  0.5770,  0.5770,  0.6016,  0.6016,  0.6259,  0.6259,  0.6499,\n",
       "            0.6499,  0.6738,  0.6738,  0.6975,  0.6975,  0.7210,  0.7210,  0.7442,\n",
       "            0.7442,  0.7673,  0.7673, -0.8813, -0.8813, -0.8605, -0.8398, -0.8398,\n",
       "           -0.8193, -0.8193, -0.7989, -0.7787, -0.7787, -0.7587, -0.7587, -0.7388,\n",
       "           -0.7388, -0.7190, -0.6994, -0.6994, -0.6799, -0.6799, -0.6605, -0.6413,\n",
       "           -0.6413, -0.6222, -0.6222, -0.6033, -0.6033, -0.5845, -0.5845, -0.5658,\n",
       "           -0.5658, -0.5472, -0.5472, -0.5288, -0.5288, -0.5104, -0.4922, -0.4922,\n",
       "           -0.4741, -0.4741, -0.4562, -0.4562, -0.4383, -0.4206, -0.4206, -0.4030,\n",
       "           -0.4030, -0.3855, -0.3681, -0.3508, -0.3336, -0.3336, -0.3165, -0.2996,\n",
       "           -0.2827, -0.2827, -0.2659, -0.2493, -0.2327, -0.2327, -0.2162, -0.2162,\n",
       "           -0.1999, -0.1836, -0.1836, -0.1674, -0.1674, -0.1514, -0.1354, -0.1354,\n",
       "           -0.1195, -0.1195, -0.1037, -0.1037, -0.0880, -0.0723, -0.0568, -0.0414,\n",
       "           -0.0260, -0.0107, -0.0107,  0.0045,  0.0045,  0.0196,  0.0196,  0.0346,\n",
       "            0.0346,  0.0496,  0.0496,  0.0644,  0.0644,  0.0792,  0.0939,  0.0939,\n",
       "            0.1085,  0.1085,  0.1231,  0.1520,  0.1663,  0.1663,  0.1805,  0.1805,\n",
       "            0.1947,  0.1947,  0.2088,  0.2088,  0.2229,  0.2368,  0.2507,  0.2507,\n",
       "            0.2645,  0.2783,  0.2920,  0.2920,  0.3056,  0.3056,  0.3191,  0.3460,\n",
       "            0.3727,  0.3727,  0.3991,  0.3991,  0.4252,  0.4511,  0.4511,  0.4768,\n",
       "            0.4768,  0.5022,  0.5274,  0.5274,  0.5523,  0.5770,  0.5770,  0.6016,\n",
       "            0.6016,  0.6259,  0.6259,  0.6738,  0.6738,  0.6975,  0.6975,  0.7210,\n",
       "            0.7210,  0.7673, -0.9022, -0.9022, -0.8813, -0.8813, -0.8605, -0.8605,\n",
       "           -0.8398, -0.8398, -0.8193, -0.7989, -0.7787, -0.7787, -0.7587, -0.7388,\n",
       "           -0.7388, -0.7190, -0.7190, -0.6994, -0.6799, -0.6605, -0.6605, -0.6413,\n",
       "           -0.6222, -0.6222, -0.6033, -0.6033, -0.5845, -0.5658, -0.5658, -0.5472,\n",
       "           -0.5288, -0.5104, -0.5104, -0.4922, -0.4922, -0.4741, -0.4562, -0.4562,\n",
       "           -0.4383, -0.4383, -0.4206, -0.4206, -0.4030, -0.4030, -0.3855, -0.3855,\n",
       "           -0.3681, -0.3508, -0.3336, -0.3336, -0.3165, -0.3165, -0.2996, -0.2827,\n",
       "           -0.2659, -0.2659, -0.2493, -0.2493, -0.2327, -0.2327, -0.2162, -0.2162,\n",
       "           -0.1999, -0.1999, -0.1836, -0.1674, -0.1514, -0.1514, -0.1354, -0.1354,\n",
       "           -0.1195, -0.1195, -0.1037, -0.0880, -0.0723, -0.0723, -0.0568, -0.0568,\n",
       "           -0.0414, -0.0414, -0.0260, -0.0107, -0.0107,  0.0045,  0.0045,  0.0196,\n",
       "            0.0196,  0.0346,  0.0346,  0.0496,  0.0496,  0.0644,  0.0644,  0.0792,\n",
       "            0.0792,  0.0939,  0.1085,  0.1231,  0.1231,  0.1376,  0.1376,  0.1520,\n",
       "            0.1663,  0.1805,  0.1805,  0.1947,  0.2088,  0.2088,  0.2229,  0.2229,\n",
       "            0.2507,  0.2507,  0.2645,  0.2920,  0.2920,  0.3191,  0.3460,  0.3460,\n",
       "            0.3727,  0.3727,  0.3991,  0.4252,  0.4252,  0.4511,  0.4511,  0.4768,\n",
       "            0.4768,  0.5022,  0.5274,  0.5274,  0.5523,  0.5770,  0.6016,  0.6259,\n",
       "            0.6259,  0.6738,  0.6738,  0.6975,  0.7210,  0.7442,  0.7442,  0.7673],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-1.9151, -1.8517, -1.7897, -1.7291, -1.7291, -1.6698, -1.6698, -1.6118,\n",
       "           -1.4992, -1.4992, -1.3910, -1.2870, -1.1867, -1.1867, -1.0899, -1.0899,\n",
       "           -0.9964, -0.9964, -0.9060, -0.9060, -0.8185, -0.7336, -0.7336, -0.6513,\n",
       "           -0.5713, -0.4937, -0.4937, -0.4181, -0.4181, -0.2729, -0.2729, -0.2031,\n",
       "           -0.2031, -0.1350, -0.1350, -0.0686, -0.0686, -0.0037,  0.0597,  0.0597,\n",
       "            0.1217,  0.1217,  0.1823,  0.1823,  0.2416,  0.2996,  0.2996,  0.3565,\n",
       "            0.3565,  0.4122,  0.4122], grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Time to Maturity': [tensor([-0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-1.7154, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972,\n",
       "           -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972,\n",
       "           -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972,\n",
       "           -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174],\n",
       "          grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Implied Volatility': [tensor([0.3229, 0.3229, 0.3229, 0.3229, 0.2849, 0.3124, 0.3069, 0.2849, 0.3091,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124,\n",
       "           0.2849, 0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124,\n",
       "           0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.2718, 0.2748, 0.2716, 0.2743, 0.2711, 0.2737, 0.2707,\n",
       "           0.2703, 0.2732, 0.2702, 0.2727, 0.2698, 0.2723, 0.2727, 0.2690, 0.2725,\n",
       "           0.2686, 0.2682, 0.2725, 0.2678, 0.2728, 0.2679, 0.2731, 0.2733, 0.2673,\n",
       "           0.2728, 0.2671, 0.2741, 0.2675, 0.2740, 0.2677, 0.2746, 0.2683, 0.2736,\n",
       "           0.2683, 0.2765, 0.2685, 0.2687, 0.2779, 0.2691, 0.2785, 0.2690, 0.2798,\n",
       "           0.2698, 0.2794, 0.2702, 0.2821, 0.2717, 0.2804, 0.2721, 0.2733, 0.2824,\n",
       "           0.2738, 0.2876, 0.2745, 0.2879, 0.2901, 0.2760, 0.2937, 0.2965, 0.2775,\n",
       "           0.2782, 0.3004, 0.2794, 0.2990, 0.2804, 0.3029, 0.2818, 0.3037, 0.2827,\n",
       "           0.3085, 0.2857, 0.3088, 0.2875, 0.2885, 0.3089, 0.2892, 0.3089, 0.2918,\n",
       "           0.3089, 0.2932, 0.3089, 0.2943, 0.3089, 0.2964, 0.3089, 0.2965, 0.2998,\n",
       "           0.3089, 0.3015, 0.3089, 0.3042, 0.3089, 0.3091, 0.3089, 0.3096, 0.3089,\n",
       "           0.3127, 0.3089, 0.3116, 0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3116, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.2797,\n",
       "           0.2829, 0.2824, 0.2786, 0.2784, 0.2819, 0.2780, 0.2817, 0.2818, 0.2776,\n",
       "           0.2817, 0.2816, 0.2770, 0.2811, 0.2771, 0.2814, 0.2765, 0.2808, 0.2811,\n",
       "           0.2764, 0.2811, 0.2763, 0.2814, 0.2762, 0.2819, 0.2763, 0.2819, 0.2772,\n",
       "           0.2824, 0.2767, 0.2824, 0.2767, 0.2765, 0.2817, 0.2764, 0.2824, 0.2765,\n",
       "           0.2841, 0.2772, 0.2777, 0.2852, 0.2783, 0.2858, 0.2779, 0.2783, 0.2871,\n",
       "           0.2791, 0.2882, 0.2807, 0.2927, 0.2812, 0.2968, 0.2818, 0.2938, 0.2823,\n",
       "           0.2938, 0.2829, 0.2975, 0.2839, 0.2978, 0.3004, 0.2849, 0.3000, 0.2853,\n",
       "           0.2980, 0.2856, 0.2870, 0.2999, 0.2999]),\n",
       "   tensor([0.4101, 0.7247, 0.3801, 0.3801, 0.7247, 0.7247, 0.3801, 0.3801, 0.3801,\n",
       "           0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.3801, 0.7247,\n",
       "           0.3801, 0.7247, 0.3801, 0.3801, 0.7247, 0.3801, 0.7247, 0.7247, 0.3801,\n",
       "           0.7104, 0.6707, 0.3801, 0.5372, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.5191, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3855, 0.3962, 0.3481, 0.3055, 0.3962, 0.3481,\n",
       "           0.3962, 0.3347, 0.3962, 0.3481, 0.3962, 0.3493, 0.3909, 0.3374, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355,\n",
       "           0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3355, 0.3632, 0.3632, 0.3355, 0.3355, 0.3355,\n",
       "           0.3632, 0.3355, 0.3570, 0.3318, 0.3277, 0.3231, 0.3379, 0.3194, 0.3372,\n",
       "           0.3129, 0.3226, 0.3094, 0.3147, 0.3068, 0.3101, 0.3040, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.3484, 0.3484,\n",
       "           0.4352, 0.3484, 0.3429, 0.4122, 0.3953, 0.3444, 0.3835, 0.3753, 0.3739,\n",
       "           0.3358, 0.3570, 0.3293, 0.3245, 0.3413, 0.3237, 0.3356, 0.3221, 0.3173,\n",
       "           0.3161, 0.3231, 0.3221, 0.3128, 0.3187, 0.3110, 0.4089, 0.3532, 0.4089,\n",
       "           0.3532, 0.3532, 0.4089, 0.3306, 0.4089, 0.3532, 0.3439, 0.4089, 0.4089,\n",
       "           0.3356, 0.4089, 0.3532, 0.4089, 0.3407, 0.3976, 0.3439, 0.3822, 0.3405,\n",
       "           0.3716, 0.3346, 0.3633, 0.3286, 0.3605, 0.3439, 0.3254, 0.3225, 0.3393,\n",
       "           0.3182, 0.3260, 0.3226, 0.3096, 0.3162, 0.3071, 0.3090, 0.3064, 0.3063,\n",
       "           0.3047, 0.3030, 0.2998, 0.3005, 0.2977, 0.2965, 0.2965, 0.2912, 0.2891,\n",
       "           0.2916, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3792, 0.3370, 0.3370,\n",
       "           0.3792, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3396, 0.3792, 0.3317,\n",
       "           0.3690, 0.3352, 0.3646, 0.3534, 0.3273, 0.3442, 0.3353, 0.3286, 0.3150,\n",
       "           0.3222, 0.3121, 0.3166, 0.3108, 0.3126, 0.3070, 0.3071, 0.3081, 0.3051,\n",
       "           0.3024, 0.2994, 0.3020, 0.2969, 0.2969, 0.2973, 0.2949, 0.2960, 0.2921,\n",
       "           0.2897, 0.2912, 0.2858, 0.2854, 0.2883, 0.2834, 0.2882, 0.2870, 0.2810,\n",
       "           0.2792, 0.4797, 0.3385, 0.4674, 0.3353, 0.4503, 0.4401, 0.3400, 0.4230,\n",
       "           0.4074, 0.3331, 0.3976, 0.3877, 0.3264, 0.3230, 0.3690, 0.3173, 0.3187,\n",
       "           0.3479, 0.3088, 0.3357, 0.3313, 0.3114, 0.3227, 0.3064, 0.3177, 0.3004,\n",
       "           0.3160, 0.3030, 0.3108, 0.3012, 0.3054, 0.2979, 0.3003, 0.2969, 0.2962,\n",
       "           0.2937, 0.2944, 0.2927, 0.2910, 0.2922, 0.2887, 0.2859, 0.2885, 0.2833,\n",
       "           0.2873, 0.2841, 0.2864, 0.2803, 0.2793, 0.2844, 0.2800, 0.2844, 0.2784,\n",
       "           0.2795, 0.2819, 0.2738, 0.2798, 0.2748, 0.2798, 0.2702, 0.2723, 0.2790,\n",
       "           0.2723, 0.2720, 0.2796, 0.2711, 0.2788, 0.2671, 0.2767, 0.3372, 0.3342,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3342, 0.3372,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3358, 0.3372, 0.3280, 0.3294,\n",
       "           0.3196, 0.3372, 0.3249, 0.3372, 0.3230, 0.3372, 0.3163, 0.3372, 0.3153,\n",
       "           0.3432, 0.3371, 0.3294, 0.3124, 0.3232, 0.3027, 0.3059, 0.3133, 0.3030,\n",
       "           0.3111, 0.3025, 0.3034, 0.2974, 0.3012, 0.2988, 0.2992, 0.2993, 0.2988,\n",
       "           0.2975, 0.2953, 0.2959, 0.2926, 0.2927, 0.2848, 0.2920, 0.2854, 0.2931,\n",
       "           0.2836, 0.2914, 0.2810, 0.2895, 0.2774, 0.2888, 0.2811, 0.2896, 0.2795,\n",
       "           0.2870, 0.2785, 0.2880, 0.2794, 0.2853, 0.2798, 0.2858, 0.2784, 0.2745,\n",
       "           0.2848]),\n",
       "   tensor([0.2326, 0.2317, 0.2282, 0.2274, 0.2262, 0.2286, 0.2275, 0.2275, 0.2253,\n",
       "           0.2231, 0.2252, 0.2221, 0.2242, 0.2214, 0.2234, 0.2208, 0.2237, 0.2205,\n",
       "           0.2228, 0.2202, 0.2189, 0.2221, 0.2196, 0.2191, 0.2213, 0.2206, 0.2165,\n",
       "           0.2205, 0.2173, 0.2197, 0.2155, 0.2196, 0.2158, 0.2193, 0.2160, 0.2197,\n",
       "           0.2146, 0.2190, 0.2151, 0.2186, 0.2185, 0.2146, 0.2190, 0.2126, 0.2185,\n",
       "           0.2138, 0.2143, 0.2194, 0.2124, 0.2191, 0.2165, 0.2191, 0.2195, 0.2172,\n",
       "           0.2204, 0.2174, 0.2188, 0.2225, 0.2123, 0.2231, 0.2166, 0.2241, 0.2156,\n",
       "           0.2246, 0.2205, 0.2279, 0.2139, 0.2274, 0.2198, 0.2342, 0.2137, 0.2299,\n",
       "           0.2137, 0.2315, 0.2137, 0.2330, 0.2137, 0.2343, 0.2118, 0.2344, 0.2137,\n",
       "           0.2403, 0.2137, 0.2851, 0.2756, 0.2723, 0.2813, 0.2715, 0.2803, 0.2693,\n",
       "           0.2780, 0.2765, 0.2693, 0.2769, 0.2686, 0.2743, 0.2650, 0.2631, 0.2702,\n",
       "           0.2635, 0.2691, 0.2620, 0.2671, 0.2661, 0.2596, 0.2626, 0.2575, 0.2631,\n",
       "           0.2605, 0.2620, 0.2561, 0.2587, 0.2552, 0.2597, 0.2544, 0.2574, 0.2528,\n",
       "           0.2525, 0.2541, 0.2505, 0.2537, 0.2489, 0.2523, 0.2479, 0.2518, 0.2509,\n",
       "           0.2470, 0.2495, 0.2457, 0.2441, 0.2480, 0.2421, 0.2461, 0.2412, 0.2426,\n",
       "           0.2400, 0.2426, 0.2386, 0.2373, 0.2405, 0.2399, 0.2363, 0.2391, 0.2347,\n",
       "           0.2343, 0.2371, 0.2337, 0.2367, 0.2335, 0.2322, 0.2346, 0.2308, 0.2326,\n",
       "           0.2310, 0.2327, 0.2294, 0.2290, 0.2307, 0.2303, 0.2287, 0.2286, 0.2274,\n",
       "           0.2257, 0.2274, 0.2252, 0.2272, 0.2258, 0.2262, 0.2241, 0.2263, 0.2237,\n",
       "           0.2248, 0.2233, 0.2247, 0.2241, 0.2232, 0.2236, 0.2233, 0.2210, 0.2212,\n",
       "           0.2228, 0.2210, 0.2228, 0.2207, 0.2222, 0.2199, 0.2216, 0.2200, 0.2227,\n",
       "           0.2214, 0.2224, 0.2200, 0.2225, 0.2187, 0.2213, 0.2184, 0.2222, 0.2184,\n",
       "           0.2183, 0.2221, 0.2227, 0.2177, 0.2217, 0.2180, 0.2215, 0.2215, 0.2196,\n",
       "           0.2218, 0.2205, 0.2209, 0.2231, 0.2218, 0.2229, 0.2236, 0.2226, 0.2259,\n",
       "           0.2230, 0.2268, 0.2239, 0.2280, 0.2259, 0.2283, 0.2255, 0.2265, 0.2251,\n",
       "           0.2313, 0.2810, 0.2642, 0.2789, 0.2642, 0.2775, 0.2642, 0.2761, 0.2642,\n",
       "           0.2745, 0.2731, 0.2712, 0.2642, 0.2700, 0.2692, 0.2605, 0.2646, 0.2607,\n",
       "           0.2646, 0.2567, 0.2628, 0.2558, 0.2533, 0.2591, 0.2552, 0.2589, 0.2534,\n",
       "           0.2562, 0.2553, 0.2502, 0.2548, 0.2519, 0.2500, 0.2468, 0.2513, 0.2460,\n",
       "           0.2483, 0.2477, 0.2438, 0.2491, 0.2424, 0.2468, 0.2421, 0.2451, 0.2413,\n",
       "           0.2436, 0.2401, 0.2389, 0.2422, 0.2416, 0.2369, 0.2402, 0.2358, 0.2394,\n",
       "           0.2343, 0.2371, 0.2335, 0.2375, 0.2324, 0.2365, 0.2320, 0.2356, 0.2305,\n",
       "           0.2351, 0.2304, 0.2321, 0.2333, 0.2310, 0.2283, 0.2297, 0.2277, 0.2306,\n",
       "           0.2271, 0.2265, 0.2257, 0.2275, 0.2251, 0.2274, 0.2246, 0.2256, 0.2238,\n",
       "           0.2232, 0.2258, 0.2227, 0.2252, 0.2221, 0.2240, 0.2219, 0.2241, 0.2213,\n",
       "           0.2231, 0.2207, 0.2233, 0.2203, 0.2222, 0.2198, 0.2197, 0.2214, 0.2222,\n",
       "           0.2181, 0.2218, 0.2184, 0.2181, 0.2174, 0.2210, 0.2172, 0.2167, 0.2203,\n",
       "           0.2181, 0.2200, 0.2174, 0.2199, 0.2166, 0.2194, 0.2190, 0.2164, 0.2192,\n",
       "           0.2183, 0.2150, 0.2183, 0.2152, 0.2189, 0.2186, 0.2172, 0.2180, 0.2156,\n",
       "           0.2182, 0.2162, 0.2179, 0.2191, 0.2163, 0.2195, 0.2188, 0.2174, 0.2206,\n",
       "           0.2193, 0.2218, 0.2173, 0.2220, 0.2211, 0.2226, 0.2208, 0.2229]),\n",
       "   tensor([0.3600, 0.3587, 0.3557, 0.4459, 0.3539, 0.4343, 0.3496, 0.3521, 0.4066,\n",
       "           0.3464, 0.3444, 0.3424, 0.3633, 0.3404, 0.3564, 0.3388, 0.3491, 0.3375,\n",
       "           0.3425, 0.3351, 0.3372, 0.3307, 0.3313, 0.3277, 0.3263, 0.3217, 0.3271,\n",
       "           0.3212, 0.3253, 0.3166, 0.3235, 0.3180, 0.3231, 0.3128, 0.3222, 0.3124,\n",
       "           0.3200, 0.3197, 0.3105, 0.3187, 0.3090, 0.3170, 0.3088, 0.3177, 0.3164,\n",
       "           0.3044, 0.3156, 0.3043, 0.3150, 0.3042, 0.3148])]},\n",
       " 'Query Points': {'Log Moneyness': [tensor([1.1041, 2.0259, 1.3264, 1.8550, 1.9495, 1.1251, 1.2873, 0.7924, 1.3264,\n",
       "           0.9078, 1.4959, 1.7736, 1.3841, 0.7208, 0.3318, 0.6223, 1.2676, 0.8851,\n",
       "           1.2276, 1.4776, 1.2476, 1.6555, 1.8389, 2.0108, 1.1041, 1.9803, 1.7736,\n",
       "           0.4410, 2.1294, 1.1665, 2.0108, 1.5857, 0.8622, 0.2469, 0.1889, 2.2570,\n",
       "           0.8622, 1.3650, 0.9527, 1.2873, 0.9078, 0.1296, 2.2983, 2.2709, 1.5141,\n",
       "           0.4141, 1.6898, 1.7068, 1.6383, 1.7404, 2.2292, 1.3458, 1.4959, 1.7068,\n",
       "           1.3458, 2.1294, 1.1251, 0.2755, 1.0617, 2.1002, 2.2152, 1.1665, 0.5971,\n",
       "           1.4591, 0.3038, 1.2276, 0.8159, 1.5680, 0.1594, 0.9303, 0.7688, 1.9184,\n",
       "           0.8622, 1.5501, 1.1870, 2.0259, 0.9078, 1.3650, 2.1002, 0.7924],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-5.0170e-01, -1.1634e+00, -8.5421e-01, -5.0170e-01, -8.9631e-01,\n",
       "           -7.7189e-01, -6.1427e-01, -9.8249e-01, -3.2373e-01, -6.5284e-01,\n",
       "           -7.7189e-01, -1.3570e+00, -4.6518e-01, -6.0912e-02, -3.5842e-01,\n",
       "            1.0579e-03, -1.3073e+00, -8.9631e-01, -5.7623e-01, -8.5421e-01,\n",
       "           -6.5284e-01, -6.9195e-01, -1.4591e+00, -6.9195e-01, -1.2585e+00,\n",
       "           -2.2222e-01, -6.5284e-01, -4.6518e-01, -4.6518e-01, -1.8919e-01,\n",
       "           -3.9355e-01, -1.4076e+00, -1.5116e+00, -3.2373e-01, -1.3570e+00,\n",
       "           -1.0266e+00, -4.6518e-01, -4.2913e-01, -1.4591e+00, -8.9631e-01,\n",
       "           -9.3906e-01, -1.2431e-01, -1.0266e+00, -7.7189e-01, -1.2105e+00,\n",
       "           -9.8249e-01, -2.8948e-01, -3.2373e-01, -1.5652e+00, -1.2585e+00,\n",
       "           -6.9195e-01, -9.8249e-01, -7.7189e-01, -5.3872e-01, -1.0266e+00,\n",
       "           -8.5421e-01, -1.2585e+00, -9.3906e-01, -1.5656e-01, -1.2105e+00,\n",
       "           -1.7904e+00, -1.4076e+00, -8.9631e-01, -1.2585e+00, -1.0714e+00,\n",
       "           -1.4076e+00, -1.2585e+00, -1.0714e+00, -6.9195e-01, -1.5652e+00,\n",
       "           -6.9195e-01, -9.8249e-01, -1.0714e+00, -8.1274e-01, -1.5656e-01,\n",
       "           -6.9195e-01, -6.9195e-01, -1.1634e+00, -1.0714e+00, -1.9723e+00,\n",
       "           -5.0170e-01, -8.5421e-01, -1.1634e+00, -1.3570e+00, -1.1170e+00,\n",
       "           -1.1634e+00, -1.3570e+00, -1.1634e+00, -6.1427e-01, -1.4591e+00,\n",
       "           -7.3163e-01, -1.5116e+00, -1.8919e-01, -5.7623e-01, -1.1170e+00,\n",
       "           -5.3872e-01, -1.3073e+00, -8.5421e-01, -8.5421e-01, -6.1427e-01,\n",
       "           -2.2222e-01, -7.3163e-01], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.1037, -0.6994,  0.2229,  0.4252, -0.1836, -0.8193,  0.6499,  0.0939,\n",
       "           -0.0723,  0.3991, -0.0880, -0.3681,  0.7442,  0.2229, -0.3508, -0.3165,\n",
       "            0.6499, -0.7587,  0.1376,  0.5523, -0.6413,  0.4511,  0.3460, -0.1354,\n",
       "            0.7673,  0.5523,  0.2645, -0.4383,  0.0939,  0.6499, -0.3855,  0.6499,\n",
       "            0.1085,  0.7673, -0.0723, -0.2659,  0.7210, -0.3508, -0.1674,  0.2368,\n",
       "            0.5022, -0.2996,  0.6975, -0.6799, -0.1514,  0.2783,  0.1085,  0.1376,\n",
       "           -0.8605,  0.2645, -0.1999, -0.2996,  0.2368,  0.7442, -0.5288,  0.0792,\n",
       "           -0.4741, -0.0880, -0.6605,  0.0644,  0.1663,  0.2368,  0.1231,  0.5770,\n",
       "           -0.0260, -0.7190,  0.6016,  0.3191,  0.5022,  0.3191, -0.0260, -0.3681,\n",
       "           -0.2493, -0.0568, -0.1354,  0.1520, -0.0414, -0.1514, -0.1037, -0.5104,\n",
       "            0.1947, -0.7989, -0.0568, -0.5845,  0.1520, -0.0880, -0.2827,  0.3727,\n",
       "           -0.0414, -0.7989,  0.2920, -0.5472], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.6513, -1.3910,  0.2416, -0.5713, -1.2870, -1.8517, -0.8185, -1.6118,\n",
       "           -0.3446, -1.7897, -1.9151, -0.0037, -0.3446],\n",
       "          grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Time to Maturity': [tensor([ 0.0018,  0.0018, -0.7150,  0.0018,  0.0018,  0.0018, -0.7150,  0.7187,\n",
       "           -0.7150,  0.7187,  0.0018, -0.7150,  0.0018,  0.7187,  0.7187,  0.7187,\n",
       "           -0.7150,  0.0018, -0.7150,  0.0018, -0.7150,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.7187,  0.0018,  0.7187,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.7187,  0.0018,  0.7187,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018, -0.7150,  0.0018,  0.0018,  0.0018,\n",
       "           -0.7150, -0.7150,  0.0018,  0.0018, -0.7150, -0.7150, -0.7150,  0.0018,\n",
       "            0.7187,  0.7187,  0.7187,  0.0018,  0.0018,  0.0018,  0.0018, -0.7150,\n",
       "            0.0018, -0.7150,  0.7187,  0.0018,  0.7187,  0.0018,  0.0018,  0.0018,\n",
       "            0.7187,  0.0018,  0.0018,  0.0018,  0.7187,  0.0018,  0.0018,  0.7187],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.8804, -0.3841, -1.1010,  0.3327,  1.0495, -1.5972, -1.1010, -1.1010,\n",
       "            0.3327, -0.6047, -1.3767,  1.0495, -0.6047,  0.3327, -0.6047,  0.3327,\n",
       "           -0.6047, -0.8804, -1.1010, -0.3841, -0.6047, -0.8804, -0.3841, -1.5972,\n",
       "           -0.6047,  0.3327, -0.3841, -0.6047, -0.8804, -0.3841, -0.3841, -0.8804,\n",
       "           -1.5972, -0.3841, -0.3841, -0.8804, -0.3841, -0.8804,  0.3327, -1.1010,\n",
       "           -0.8804,  1.0495,  1.0495, -0.6047, -0.6047, -0.3841, -0.6047, -0.6047,\n",
       "            1.0495,  0.3327, -0.6047, -1.5972, -0.8804,  1.0495, -1.1010,  1.0495,\n",
       "           -0.6047,  1.0495, -0.3841, -1.5972,  1.0495,  1.0495, -0.3841, -1.5972,\n",
       "            0.3327, -1.5972, -1.3767, -0.8804, -1.1010, -1.3767,  0.3327,  0.3327,\n",
       "           -1.3767, -0.8804,  0.3327, -1.7154, -0.8804,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495, -0.6047, -0.8804, -1.5972, -0.3841, -1.5972,  0.3327,  0.3327,\n",
       "           -0.8804, -0.6047, -1.1010, -1.5972,  0.3327, -0.3841,  1.0495,  0.3327,\n",
       "           -0.3841, -1.5972, -1.3767,  0.3327, -0.3841,  0.3327],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([ 0.1673,  0.1673, -0.0533, -0.0533,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "           -0.7701,  0.1673,  0.1673,  0.1673, -0.0533, -0.7701, -0.0533, -0.0533,\n",
       "           -0.0533,  0.1673, -0.0533, -0.0533,  0.1673, -0.7701, -0.0533, -0.7701,\n",
       "            0.1673,  0.1673, -0.0533, -0.0533, -0.7701, -0.0533, -0.0533,  0.1673,\n",
       "           -0.7701, -0.0533, -0.0533, -0.0533,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673, -0.0533,  0.1673,  0.1673, -0.7701, -0.0533,  0.1673, -0.0533,\n",
       "           -0.0533,  0.1673, -0.0533,  0.1673,  0.1673, -0.0533,  0.1673, -0.0533,\n",
       "            0.1673, -0.7701, -0.0533, -0.7701,  0.1673, -0.0533, -0.0533,  0.1673,\n",
       "           -0.0533, -0.0533,  0.1673, -0.0533, -0.0533,  0.1673,  0.1673, -0.0533,\n",
       "           -0.0533, -0.0533, -0.7701, -0.0533, -0.0533, -0.0533, -0.7701, -0.0533,\n",
       "            0.1673, -0.0533, -0.7701,  0.1673,  0.1673, -0.0533,  0.1673, -0.7701,\n",
       "           -0.7701,  0.1673, -0.7701,  0.1673], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174], grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Implied Volatility': [tensor([0.3085, 0.3116, 0.2849, 0.3116, 0.3116, 0.3089, 0.2849, 0.2774, 0.3124,\n",
       "           0.2800, 0.3116, 0.2849, 0.3057, 0.2848, 0.2772, 0.2829, 0.2849, 0.2911,\n",
       "           0.3229, 0.3116, 0.2849, 0.3089, 0.3116, 0.3089, 0.2856, 0.3116, 0.3089,\n",
       "           0.2765, 0.3089, 0.2872, 0.3116, 0.3116, 0.2740, 0.2688, 0.2822, 0.3089,\n",
       "           0.2895, 0.3048, 0.2942, 0.3089, 0.2760, 0.2733, 0.3116, 0.3116, 0.2849,\n",
       "           0.2672, 0.3089, 0.3089, 0.2849, 0.2849, 0.3116, 0.3089, 0.3124, 0.3124,\n",
       "           0.2849, 0.3116, 0.3009, 0.2779, 0.2837, 0.3089, 0.3089, 0.3089, 0.2765,\n",
       "           0.3124, 0.2727, 0.2849, 0.2890, 0.3116, 0.2792, 0.2772, 0.2854, 0.3116,\n",
       "           0.2788, 0.3089, 0.2902, 0.3089, 0.2902, 0.3089, 0.3116, 0.2866]),\n",
       "   tensor([0.3331, 0.3792, 0.3632, 0.2953, 0.3212, 0.3801, 0.3153, 0.3355, 0.2859,\n",
       "           0.3278, 0.3962, 0.3372, 0.3044, 0.2785, 0.2967, 0.2794, 0.4089, 0.3464,\n",
       "           0.3263, 0.3174, 0.3109, 0.3256, 0.3792, 0.3801, 0.3532, 0.2837, 0.3050,\n",
       "           0.3021, 0.3295, 0.2847, 0.2945, 0.3484, 0.3801, 0.2892, 0.3792, 0.4487,\n",
       "           0.2964, 0.3143, 0.3435, 0.3632, 0.4214, 0.2859, 0.3126, 0.3410, 0.3496,\n",
       "           0.3274, 0.2932, 0.2939, 0.3360, 0.3296, 0.3172, 0.7247, 0.3365, 0.2949,\n",
       "           0.3632, 0.3165, 0.4089, 0.3026, 0.2834, 0.7247, 0.3342, 0.3372, 0.3232,\n",
       "           0.7247, 0.3554, 0.7247, 0.3481, 0.4610, 0.3592, 0.3962, 0.3043, 0.3103,\n",
       "           0.3481, 0.3401, 0.2750, 0.4484, 0.3654, 0.3168, 0.3152, 0.3372, 0.2934,\n",
       "           0.3235, 0.3484, 0.3801, 0.3792, 0.7247, 0.3363, 0.3754, 0.3477, 0.4089,\n",
       "           0.3396, 0.7247, 0.2817, 0.3015, 0.3372, 0.2935, 0.3370, 0.7247, 0.3962,\n",
       "           0.2948, 0.2819, 0.2994]),\n",
       "   tensor([0.2287, 0.2577, 0.2192, 0.2196, 0.2295, 0.2642, 0.2217, 0.2220, 0.2258,\n",
       "           0.2151, 0.2285, 0.2442, 0.2301, 0.2175, 0.2465, 0.2403, 0.2238, 0.2579,\n",
       "           0.2217, 0.2225, 0.2597, 0.2207, 0.2183, 0.2325, 0.2231, 0.2173, 0.2193,\n",
       "           0.2479, 0.2217, 0.2272, 0.2469, 0.2193, 0.2180, 0.2287, 0.2292, 0.2414,\n",
       "           0.2187, 0.2380, 0.2288, 0.2198, 0.2165, 0.2437, 0.2198, 0.2647, 0.2302,\n",
       "           0.2212, 0.2195, 0.2228, 0.2852, 0.2166, 0.2381, 0.2352, 0.2176, 0.2267,\n",
       "           0.2480, 0.2230, 0.2453, 0.2294, 0.2602, 0.2212, 0.2211, 0.2197, 0.2235,\n",
       "           0.2171, 0.2268, 0.2723, 0.2201, 0.2220, 0.2248, 0.2146, 0.2256, 0.2426,\n",
       "           0.2374, 0.2289, 0.2297, 0.2226, 0.2281, 0.2358, 0.2310, 0.2570, 0.2204,\n",
       "           0.2698, 0.2250, 0.2524, 0.2214, 0.2318, 0.2384, 0.2171, 0.2238, 0.2642,\n",
       "           0.2185, 0.2492]),\n",
       "   tensor([0.3301, 0.3884, 0.3060, 0.3280, 0.3755, 0.4660, 0.3333, 0.4248, 0.3245,\n",
       "           0.4548, 0.4785, 0.3126, 0.3192])]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "class SurfaceBatchNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_features=1, \n",
    "        momentum=0.1\n",
    "    ):\n",
    "        super(SurfaceBatchNorm, self).__init__()\n",
    "        self.log_moneyness_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.time_to_maturity_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.market_return_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.market_volatility_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.treasury_rate_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Concatenate all tensors from the Input Surface into one tensor for each feature\n",
    "        input_surface_log_moneyness = torch.cat([x for x in batch['Input Surface']['Log Moneyness']])\n",
    "        input_surface_time_to_maturity = torch.cat([x for x in batch['Input Surface']['Time to Maturity']])\n",
    "\n",
    "        # Concatenate Input Surface tensors with Query Points tensors\n",
    "        total_log_moneyness = torch.cat([input_surface_log_moneyness] + [x for x in batch['Query Points']['Log Moneyness']])\n",
    "        total_time_to_maturity = torch.cat([input_surface_time_to_maturity] + [x for x in batch['Query Points']['Time to Maturity']])\n",
    "\n",
    "        # Normalize Log Moneyness and Time to Maturity\n",
    "        norm_log_moneyness = self.log_moneyness_bn(total_log_moneyness.unsqueeze(1)).squeeze(1)\n",
    "        norm_time_to_maturity = self.time_to_maturity_bn(total_time_to_maturity.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Split the normalized results back to corresponding structures\n",
    "        input_surface_sizes = [len(x) for x in batch['Input Surface']['Log Moneyness']]\n",
    "        query_points_sizes = [len(x) for x in batch['Query Points']['Log Moneyness']]\n",
    "        total_input_size = sum(input_surface_sizes)\n",
    "\n",
    "        # Normalizing Market Features\n",
    "        market_features = batch['Market Features']\n",
    "        norm_market_return = self.market_return_bn(market_features['Market Return'].unsqueeze(1)).squeeze(1)\n",
    "        norm_market_volatility = self.market_volatility_bn(market_features['Market Volatility'].unsqueeze(1)).squeeze(1)\n",
    "        norm_treasury_rate = self.treasury_rate_bn(market_features['Treasury Rate'].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Reconstructing the batch with normalized data\n",
    "        output = {\n",
    "            'Datetime': batch['Datetime'],\n",
    "            'Symbol': batch['Symbol'],\n",
    "            'Market Features': {\n",
    "                'Market Return': norm_market_return,\n",
    "                'Market Volatility': norm_market_volatility,\n",
    "                'Treasury Rate': norm_treasury_rate\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': list(torch.split(norm_log_moneyness[:total_input_size], input_surface_sizes)),\n",
    "                'Time to Maturity': list(torch.split(norm_time_to_maturity[:total_input_size], input_surface_sizes)),\n",
    "                'Implied Volatility': batch['Input Surface']['Implied Volatility']\n",
    "            },\n",
    "            'Query Points': {\n",
    "                'Log Moneyness': list(torch.split(norm_log_moneyness[total_input_size:], query_points_sizes)),\n",
    "                'Time to Maturity': list(torch.split(norm_time_to_maturity[total_input_size:], query_points_sizes)),\n",
    "                'Implied Volatility': batch['Query Points']['Implied Volatility']\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Ensure requires_grad is True for query point values\n",
    "        for key in output['Query Points']:\n",
    "            if key != 'Implied Volatility':  # We only set requires_grad for Log Moneyness and Time to Maturity\n",
    "                for tensor in output['Query Points'][key]:\n",
    "                    tensor.requires_grad_()\n",
    "\n",
    "        return output\n",
    "\n",
    "# Usage\n",
    "surfacebatchnorm = SurfaceBatchNorm()\n",
    "processed_batch = surfacebatchnorm(batch)\n",
    "processed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Input Surface': [tensor([[ 1.2387,  0.6684,  0.2757,  ..., -0.4899, -0.6068, -0.6940],\n",
       "          [ 1.1609,  0.6920,  0.3154,  ..., -0.4901, -0.6148, -0.7079],\n",
       "          [ 1.0836,  0.7125,  0.3540,  ..., -0.4893, -0.6218, -0.7208],\n",
       "          ...,\n",
       "          [-0.5958, -0.7983, -0.3006,  ...,  0.3868,  0.4721,  0.5335],\n",
       "          [-0.5958, -0.7983, -0.3006,  ...,  0.3868,  0.4721,  0.5335],\n",
       "          [-0.5902, -0.7512, -0.2647,  ...,  0.3648,  0.4424,  0.4983]],\n",
       "         grad_fn=<NativeLayerNormBackward0>),\n",
       "  tensor([[ 2.2988,  0.7190,  0.0672,  ..., -0.6527, -0.7860, -0.8957],\n",
       "          [ 2.0635,  0.8940,  0.3154,  ..., -0.7051, -0.9214, -1.1002],\n",
       "          [ 2.0635,  0.8940,  0.3154,  ..., -0.7051, -0.9214, -1.1002],\n",
       "          ...,\n",
       "          [-1.3325, -1.1211, -0.7927,  ...,  0.7208,  1.1328,  1.4756],\n",
       "          [-1.3237, -1.1212, -0.7984,  ...,  0.7209,  1.1348,  1.4789],\n",
       "          [-1.3237, -1.1212, -0.7984,  ...,  0.7209,  1.1348,  1.4789]],\n",
       "         grad_fn=<NativeLayerNormBackward0>),\n",
       "  tensor([[-1.5019, -0.8998, -0.0232,  ...,  0.5193,  0.5641,  0.5946],\n",
       "          [-1.4987, -0.9411, -0.0587,  ...,  0.5378,  0.5900,  0.6259],\n",
       "          [-1.4987, -0.9411, -0.0587,  ...,  0.5378,  0.5900,  0.6259],\n",
       "          ...,\n",
       "          [-1.1865, -1.0851, -0.5273,  ...,  0.6414,  0.8113,  0.9372],\n",
       "          [-1.1865, -1.0851, -0.5273,  ...,  0.6414,  0.8113,  0.9372],\n",
       "          [-1.1544, -1.0890, -0.5465,  ...,  0.6410,  0.8162,  0.9462]],\n",
       "         grad_fn=<NativeLayerNormBackward0>),\n",
       "  tensor([[ 1.4606,  1.2417,  0.6781,  0.0894, -0.4136, -0.7821, -1.0413, -1.2328],\n",
       "          [ 1.5689,  1.1956,  0.6199,  0.0452, -0.4335, -0.7787, -1.0198, -1.1975],\n",
       "          [ 1.6575,  1.1522,  0.5693,  0.0076, -0.4491, -0.7737, -0.9990, -1.1648],\n",
       "          [ 1.7249,  1.1153,  0.5283, -0.0228, -0.4609, -0.7682, -0.9804, -1.1362],\n",
       "          [ 1.7249,  1.1153,  0.5283, -0.0228, -0.4609, -0.7682, -0.9804, -1.1362],\n",
       "          [ 1.7694,  1.0887,  0.4987, -0.0456, -0.4695, -0.7633, -0.9652, -1.1133],\n",
       "          [ 1.7694,  1.0887,  0.4987, -0.0456, -0.4695, -0.7633, -0.9652, -1.1133],\n",
       "          [ 1.7884,  1.0764,  0.4826, -0.0603, -0.4754, -0.7599, -0.9546, -1.0972],\n",
       "          [ 1.7322,  1.1088,  0.4988, -0.0631, -0.4791, -0.7591, -0.9496, -1.0889],\n",
       "          [ 1.7322,  1.1088,  0.4988, -0.0631, -0.4791, -0.7591, -0.9496, -1.0889],\n",
       "          [ 1.5232,  1.2154,  0.5799, -0.0287, -0.4684, -0.7604, -0.9582, -1.1028],\n",
       "          [ 1.2233,  1.3109,  0.6747,  0.0236, -0.4391, -0.7437, -0.9495, -1.1002],\n",
       "          [ 1.0064,  1.2907,  0.7083,  0.0577, -0.4012, -0.7020, -0.9054, -1.0545],\n",
       "          [ 1.0064,  1.2907,  0.7083,  0.0577, -0.4012, -0.7020, -0.9054, -1.0545],\n",
       "          [ 0.9109,  1.1442,  0.6631,  0.0647, -0.3586, -0.6364, -0.8247, -0.9632],\n",
       "          [ 0.9109,  1.1442,  0.6631,  0.0647, -0.3586, -0.6364, -0.8247, -0.9632],\n",
       "          [ 0.8172,  0.8935,  0.5506,  0.0589, -0.2951, -0.5293, -0.6889, -0.8069],\n",
       "          [ 0.8172,  0.8935,  0.5506,  0.0589, -0.2951, -0.5293, -0.6889, -0.8069],\n",
       "          [ 0.5827,  0.5413,  0.3744,  0.0543, -0.1880, -0.3516, -0.4645, -0.5486],\n",
       "          [ 0.5827,  0.5413,  0.3744,  0.0543, -0.1880, -0.3516, -0.4645, -0.5486],\n",
       "          [ 0.1344,  0.1039,  0.1424,  0.0558, -0.0301, -0.0934, -0.1390, -0.1739],\n",
       "          [-0.4047, -0.3188, -0.0934,  0.0571,  0.1369,  0.1822,  0.2105,  0.2302],\n",
       "          [-0.4047, -0.3188, -0.0934,  0.0571,  0.1369,  0.1822,  0.2105,  0.2302],\n",
       "          [-0.8168, -0.6219, -0.2729,  0.0495,  0.2570,  0.3884,  0.4762,  0.5404],\n",
       "          [-1.0487, -0.8105, -0.3934,  0.0323,  0.3236,  0.5140,  0.6435,  0.7392],\n",
       "          [-1.1599, -0.9291, -0.4767,  0.0091,  0.3558,  0.5876,  0.7472,  0.8661],\n",
       "          [-1.1599, -0.9291, -0.4767,  0.0091,  0.3558,  0.5876,  0.7472,  0.8661],\n",
       "          [-1.2087, -1.0064, -0.5373, -0.0167,  0.3690,  0.6321,  0.8153,  0.9526],\n",
       "          [-1.2087, -1.0064, -0.5373, -0.0167,  0.3690,  0.6321,  0.8153,  0.9526],\n",
       "          [-1.2367, -1.0874, -0.6175, -0.0682,  0.3683,  0.6780,  0.8981,  1.0653],\n",
       "          [-1.2367, -1.0874, -0.6175, -0.0682,  0.3683,  0.6780,  0.8981,  1.0653],\n",
       "          [-1.2403, -1.1048, -0.6437, -0.0922,  0.3613,  0.6894,  0.9251,  1.1052],\n",
       "          [-1.2403, -1.1048, -0.6437, -0.0922,  0.3613,  0.6894,  0.9251,  1.1052],\n",
       "          [-1.2449, -1.1116, -0.6629, -0.1142,  0.3521,  0.6964,  0.9464,  1.1386],\n",
       "          [-1.2449, -1.1116, -0.6629, -0.1142,  0.3521,  0.6964,  0.9464,  1.1386],\n",
       "          [-1.2531, -1.1101, -0.6758, -0.1339,  0.3419,  0.7003,  0.9635,  1.1671],\n",
       "          [-1.2531, -1.1101, -0.6758, -0.1339,  0.3419,  0.7003,  0.9635,  1.1671],\n",
       "          [-1.2653, -1.1025, -0.6834, -0.1511,  0.3313,  0.7021,  0.9774,  1.1916],\n",
       "          [-1.2801, -1.0910, -0.6870, -0.1662,  0.3204,  0.7021,  0.9887,  1.2131],\n",
       "          [-1.2801, -1.0910, -0.6870, -0.1662,  0.3204,  0.7021,  0.9887,  1.2131],\n",
       "          [-1.2950, -1.0775, -0.6880, -0.1798,  0.3093,  0.7007,  0.9980,  1.2323],\n",
       "          [-1.2950, -1.0775, -0.6880, -0.1798,  0.3093,  0.7007,  0.9980,  1.2323],\n",
       "          [-1.3080, -1.0639, -0.6878, -0.1923,  0.2980,  0.6983,  1.0059,  1.2498],\n",
       "          [-1.3080, -1.0639, -0.6878, -0.1923,  0.2980,  0.6983,  1.0059,  1.2498],\n",
       "          [-1.3177, -1.0510, -0.6870, -0.2043,  0.2864,  0.6951,  1.0126,  1.2660],\n",
       "          [-1.3236, -1.0396, -0.6864, -0.2159,  0.2745,  0.6911,  1.0184,  1.2814],\n",
       "          [-1.3236, -1.0396, -0.6864, -0.2159,  0.2745,  0.6911,  1.0184,  1.2814],\n",
       "          [-1.3258, -1.0298, -0.6860, -0.2273,  0.2625,  0.6866,  1.0236,  1.2962],\n",
       "          [-1.3258, -1.0298, -0.6860, -0.2273,  0.2625,  0.6866,  1.0236,  1.2962],\n",
       "          [-1.3247, -1.0214, -0.6860, -0.2385,  0.2503,  0.6816,  1.0283,  1.3105],\n",
       "          [-1.3247, -1.0214, -0.6860, -0.2385,  0.2503,  0.6816,  1.0283,  1.3105]],\n",
       "         grad_fn=<NativeLayerNormBackward0>)],\n",
       " 'Query Points': tensor([[-0.8168, -0.6219, -0.2729,  0.0495,  0.2570,  0.3884,  0.4762,  0.5404],\n",
       "         [ 1.5232,  1.2154,  0.5799, -0.0287, -0.4684, -0.7604, -0.9582, -1.1028],\n",
       "         [-1.3177, -1.0510, -0.6870, -0.2043,  0.2864,  0.6951,  1.0126,  1.2660],\n",
       "         [-1.0487, -0.8105, -0.3934,  0.0323,  0.3236,  0.5140,  0.6435,  0.7392],\n",
       "         [ 1.2233,  1.3109,  0.6747,  0.0236, -0.4391, -0.7437, -0.9495, -1.1002],\n",
       "         [ 1.5689,  1.1956,  0.6199,  0.0452, -0.4335, -0.7787, -1.0198, -1.1975],\n",
       "         [ 0.1344,  0.1039,  0.1424,  0.0558, -0.0301, -0.0934, -0.1390, -0.1739],\n",
       "         [ 1.7884,  1.0764,  0.4826, -0.0603, -0.4754, -0.7599, -0.9546, -1.0972],\n",
       "         [-1.2289, -1.0563, -0.5829, -0.0428,  0.3717,  0.6601,  0.8630,  1.0160],\n",
       "         [ 1.6575,  1.1522,  0.5693,  0.0076, -0.4491, -0.7737, -0.9990, -1.1648],\n",
       "         [ 1.4606,  1.2417,  0.6781,  0.0894, -0.4136, -0.7821, -1.0413, -1.2328],\n",
       "         [-1.2653, -1.1025, -0.6834, -0.1511,  0.3313,  0.7021,  0.9774,  1.1916],\n",
       "         [-1.2289, -1.0563, -0.5829, -0.0428,  0.3717,  0.6601,  0.8630,  1.0160]],\n",
       "        grad_fn=<NativeLayerNormBackward0>)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class EllipticalRBFKernel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim, \n",
    "        bandwidth\n",
    "    ):\n",
    "        super(EllipticalRBFKernel, self).__init__()\n",
    "        self.bandwidth = bandwidth\n",
    "        # Initialize the log of the scale vector to zero, which corresponds to scale factors of one\n",
    "        self.log_scale = nn.Parameter(torch.zeros(input_dim))\n",
    "\n",
    "    def forward(self, distances):\n",
    "        # Convert log scale to actual scale values\n",
    "        scale = torch.exp(self.log_scale)\n",
    "        \n",
    "        # Create a diagonal scale matrix\n",
    "        scale_matrix = torch.diag(scale)\n",
    "\n",
    "        # Calculate the scaled distances\n",
    "        scaled_distances = distances @ scale_matrix @ distances.t()\n",
    "        \n",
    "        # Normalize by the trace of the scale matrix\n",
    "        trace_scale_matrix = torch.trace(scale_matrix)\n",
    "        normalized_distances = scaled_distances / trace_scale_matrix\n",
    "\n",
    "        # Compute the RBF kernel output using the normalized distances\n",
    "        kernel_values = torch.exp(-normalized_distances / (2 * self.bandwidth ** 2))\n",
    "\n",
    "        return kernel_values\n",
    "\n",
    "class SurfaceContinuousKernelEmbedding(nn.Module):\n",
    "    def __init__(self, d_embedding):\n",
    "        super(SurfaceContinuousKernelEmbedding, self).__init__()\n",
    "        self.d_embedding = d_embedding\n",
    "\n",
    "        # Initialize multiple RBF kernels, each with a different fixed bandwidth\n",
    "        self.kernels = nn.ModuleList()\n",
    "        for i in range(1, d_embedding + 1):\n",
    "            bandwidth_value = torch.erfinv(torch.tensor(i / (d_embedding + 1))) * np.sqrt(2)\n",
    "            self.kernels.append(EllipticalRBFKernel(bandwidth=bandwidth_value, input_dim=2))\n",
    "\n",
    "        self.input_surface_layer_norm = nn.LayerNorm(d_embedding)\n",
    "        self.query_points_layer_norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, input_surface_batch, query_points_batch):\n",
    "        batch_size = len(input_surface_batch['Log Moneyness'])\n",
    "        input_surface_embeddings = []\n",
    "        query_points_embeddings = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Extract the coordinates and implied volatilities for each surface in the batch\n",
    "            surface_coords = torch.stack([\n",
    "                input_surface_batch['Log Moneyness'][i], \n",
    "                input_surface_batch['Time to Maturity'][i]\n",
    "            ], dim=-1)\n",
    "            surface_ivs = input_surface_batch['Implied Volatility'][i]\n",
    "\n",
    "            query_coords = torch.stack([\n",
    "                query_points_batch['Log Moneyness'][i], \n",
    "                query_points_batch['Time to Maturity'][i]\n",
    "            ], dim=-1)\n",
    "\n",
    "            all_coords = torch.cat((surface_coords, query_coords), dim=0)\n",
    "\n",
    "            # Compute the pairwise differences between all points and the input surface points\n",
    "            point_differences = all_coords.unsqueeze(1) - surface_coords.unsqueeze(0)  # (n+m, n, 2)\n",
    "\n",
    "            # Initialize the output embeddings for the current surface with d_embedding channels\n",
    "            all_embedded = torch.zeros((all_coords.shape[0], self.d_embedding), dtype=torch.float32, device=surface_coords.device)\n",
    "\n",
    "            for kernel_idx, kernel in enumerate(self.kernels):\n",
    "                # Apply the RBF kernel to each distance vector using torch.vmap\n",
    "                vmap_kernel = torch.vmap(kernel, in_dims=(0,))\n",
    "                kernel_outputs = vmap_kernel(point_differences.view(-1, point_differences.shape[-1]))  # ((n+m) * n)\n",
    "                kernel_outputs = kernel_outputs.view(all_coords.shape[0], surface_coords.shape[0])  # (n+m, n)\n",
    "\n",
    "                # Compute the weighted sum of IVs based on the kernel outputs\n",
    "                weighted_sum = (kernel_outputs * surface_ivs.unsqueeze(0)).sum(dim=1)\n",
    "                normalization_factor = kernel_outputs.sum(dim=1)\n",
    "\n",
    "                all_embedded[:, kernel_idx] = weighted_sum / normalization_factor\n",
    "\n",
    "            # Split the embeddings into input surface and query points embeddings\n",
    "            input_surface_embedded = all_embedded[:surface_coords.shape[0], :]\n",
    "            query_points_embedded = all_embedded[surface_coords.shape[0]:, :]\n",
    "\n",
    "            # Normalize the embedded surfaces\n",
    "            input_surface_embedded = self.input_surface_layer_norm(input_surface_embedded)\n",
    "            query_points_embedded = self.query_points_layer_norm(query_points_embedded)\n",
    "\n",
    "            # Append the encoded surface for this input surface to the batch list\n",
    "            input_surface_embeddings.append(input_surface_embedded)\n",
    "            query_points_embeddings.append(query_points_embedded)\n",
    "\n",
    "        # Keep all encoded surfaces as lists to handle variable lengths\n",
    "        return {\n",
    "            'Input Surface': input_surface_embeddings,\n",
    "            'Query Points': query_points_embedded\n",
    "        }\n",
    "\n",
    "\n",
    "# Example of initializing and using this module\n",
    "d_embedding = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Channels Dimension']  # Desired number of output channels\n",
    "\n",
    "continuous_kernel_embedding = SurfaceContinuousKernelEmbedding(d_embedding=d_embedding)\n",
    "embedded_batch = continuous_kernel_embedding(processed_batch['Input Surface'], processed_batch['Query Points'])\n",
    "embedded_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
