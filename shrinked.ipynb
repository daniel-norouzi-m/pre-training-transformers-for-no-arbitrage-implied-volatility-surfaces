{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "RANDOM_STATE = 0\n",
    "N_JOBS = 8\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    'Input Preprocessing' : {\n",
    "        'Mask Proportions' : [0.1, 0.3, 0.5, 0.7],\n",
    "        'Batch Size' : 4\n",
    "    },\n",
    "    'Surface Embedding' : {\n",
    "        'Embedding Dimension' : 8,\n",
    "    },\n",
    "    'Surface Encoding' : {\n",
    "        'Encoder' : {\n",
    "            'Number of Heads' : 4,\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "            'External Feature Dimension' : 3,\n",
    "        }\n",
    "    },\n",
    "    'Query Embedding' : {\n",
    "        'Pre-Decoder' : {\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'Surface Decoding' : {\n",
    "        'Decoder' : {\n",
    "            'Number of Heads' : 4,\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'No-Arbitrage' : {\n",
    "        'Butterfly' : 1,\n",
    "        'Calendar' : 1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Log Moneyness</th>\n",
       "      <th>Time to Maturity</th>\n",
       "      <th>Implied Volatility</th>\n",
       "      <th>Market Return</th>\n",
       "      <th>Market Volatility</th>\n",
       "      <th>Treasury Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.316688</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.316688</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.304266</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.304266</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.291996</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-06-28</th>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.427518</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.434898</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.434898</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.442224</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2402</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.442224</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574326 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Log Moneyness  Time to Maturity  Implied Volatility  \\\n",
       "Datetime   Symbol                                                        \n",
       "2013-01-02 AAPL        -0.316688          0.007937              0.3726   \n",
       "           AAPL        -0.316688          0.007937              0.6095   \n",
       "           AAPL        -0.304266          0.007937              0.3726   \n",
       "           AAPL        -0.304266          0.007937              0.6095   \n",
       "           AAPL        -0.291996          0.007937              0.3726   \n",
       "...                          ...               ...                 ...   \n",
       "2013-06-28 GOOGL        0.427518          2.253968              0.2430   \n",
       "           GOOGL        0.434898          2.253968              0.2383   \n",
       "           GOOGL        0.434898          2.253968              0.2426   \n",
       "           GOOGL        0.442224          2.253968              0.2402   \n",
       "           GOOGL        0.442224          2.253968              0.2433   \n",
       "\n",
       "                   Market Return  Market Volatility  Treasury Rate  \n",
       "Datetime   Symbol                                                   \n",
       "2013-01-02 AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "...                          ...                ...            ...  \n",
       "2013-06-28 GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "\n",
       "[574326 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_googl_data = pd.read_csv('volatility_surface_AAPL_GOOGL_2013_01_2013_06.csv', parse_dates=True, index_col=[0, 1], date_format=\"ISO8601\")\n",
    "aapl_googl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': Timestamp('2013-01-02 00:00:00'),\n",
       " 'Symbol': 'AAPL',\n",
       " 'Market Features': {'Market Return': 0.0250861159586972,\n",
       "  'Market Volatility': 14.68000030517578,\n",
       "  'Treasury Rate': 0.0549999997019767},\n",
       " 'Surface': {'Log Moneyness': array([-0.31668849, -0.31668849, -0.30426597, ...,  0.63882295,\n",
       "          0.6483924 ,  0.6483924 ]),\n",
       "  'Time to Maturity': array([0.00793651, 0.00793651, 0.00793651, ..., 2.95634921, 2.95634921,\n",
       "         2.95634921]),\n",
       "  'Implied Volatility': array([0.3726, 0.6095, 0.3726, ..., 0.3387, 0.3342, 0.3389])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def implied_volatility_surfaces(options_market_data):\n",
    "    # Group the data by Datetime and Symbol\n",
    "    grouped_data = options_market_data.groupby(level=['Datetime', 'Symbol'])\n",
    "\n",
    "    surfaces = []\n",
    "    for (date, symbol), surface in grouped_data:\n",
    "        surface_dict = {\n",
    "            'Datetime': date,\n",
    "            'Symbol': symbol,\n",
    "            'Market Features': {\n",
    "                'Market Return': surface['Market Return'].values[0],\n",
    "                'Market Volatility': surface['Market Volatility'].values[0],\n",
    "                'Treasury Rate': surface['Treasury Rate'].values[0],\n",
    "            },\n",
    "            'Surface': {\n",
    "                'Log Moneyness': surface['Log Moneyness'].values,\n",
    "                'Time to Maturity': surface['Time to Maturity'].values,\n",
    "                'Implied Volatility': surface['Implied Volatility'].values,\n",
    "            }\n",
    "        }\n",
    "        surfaces.append(surface_dict)\n",
    "\n",
    "    return surfaces\n",
    "\n",
    "surfaces = implied_volatility_surfaces(aapl_googl_data)\n",
    "surfaces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': [Timestamp('2013-06-10 00:00:00'),\n",
       "  Timestamp('2013-01-28 00:00:00'),\n",
       "  Timestamp('2013-05-20 00:00:00'),\n",
       "  Timestamp('2013-03-07 00:00:00')],\n",
       " 'Symbol': ['AAPL', 'AAPL', 'GOOGL', 'AAPL'],\n",
       " 'Market Features': {'Market Return': tensor([-0.0003, -0.0019, -0.0007,  0.0018]),\n",
       "  'Market Volatility': tensor([15.4400, 13.5700, 13.0200, 13.0600]),\n",
       "  'Treasury Rate': tensor([0.0400, 0.0600, 0.0350, 0.0900])},\n",
       " 'Input Surface': {'Log Moneyness': [tensor([0.4524, 0.4597, 0.4668, 0.4739, 0.4739, 0.4880, 0.4950, 0.4950, 0.5019,\n",
       "           0.5019, 0.5088, 0.5088, 0.5156, 0.5156, 0.5224, 0.5224, 0.5291, 0.5358,\n",
       "           0.5358, 0.5425, 0.5491, 0.5556, 0.5556, 0.5621, 0.5621, 0.5686, 0.5686,\n",
       "           0.5750, 0.5750, 0.5814, 0.5814, 0.5878, 0.5878, 0.5941, 0.6004, 0.6004,\n",
       "           0.6066, 0.6066, 0.6128, 0.6128, 0.6189, 0.6251, 0.6251, 0.6311, 0.6372,\n",
       "           0.6372, 0.6432, 0.6492, 0.6492, 0.6551, 0.6551, 0.6610, 0.6610, 0.6669,\n",
       "           0.6669, 0.6727, 0.6727, 0.6785, 0.6785, 0.6842, 0.6842, 0.6900, 0.6900,\n",
       "           0.6957, 0.6957, 0.0138, 0.0138, 0.0250, 0.0250, 0.0360, 0.0360, 0.0470,\n",
       "           0.0578, 0.0578, 0.0685, 0.0685, 0.0791, 0.0791, 0.0895, 0.0999, 0.0999,\n",
       "           0.1102, 0.1203, 0.1203, 0.1304, 0.1304, 0.1403, 0.1403, 0.1502, 0.1599,\n",
       "           0.1599, 0.1696, 0.1696, 0.1791, 0.1791, 0.1886, 0.1886, 0.1980, 0.1980,\n",
       "           0.2073, 0.2073, 0.2165, 0.2257, 0.2257, 0.2347, 0.2347, 0.2437, 0.2437,\n",
       "           0.2526, 0.2526, 0.2614, 0.2614, 0.2701, 0.2701, 0.2788, 0.2874, 0.2874,\n",
       "           0.2959, 0.2959, 0.3043, 0.3043, 0.3127, 0.3210, 0.3292, 0.3374, 0.3455,\n",
       "           0.3535, 0.3535, 0.3615, 0.3615, 0.3694, 0.3694, 0.3772, 0.3772, 0.3850,\n",
       "           0.3850, 0.3927, 0.3927, 0.4080, 0.4155, 0.4155, 0.4230, 0.4305, 0.4378,\n",
       "           0.4378, 0.4452, 0.4452, 0.4524, 0.4524, 0.4597, 0.4597, 0.4668, 0.4739,\n",
       "           0.4739, 0.4810, 0.4810, 0.4880, 0.5019, 0.5088, 0.5088, 0.5156, 0.5156,\n",
       "           0.5224, 0.5224, 0.5291, 0.5291, 0.5358, 0.5425, 0.5491, 0.5491, 0.5556,\n",
       "           0.5556, 0.5621, 0.5686, 0.5750, 0.5814, 0.5814, 0.5878, 0.5878, 0.5941,\n",
       "           0.5941, 0.6004, 0.6066, 0.6066, 0.6128, 0.6189, 0.6251, 0.6251, 0.6311,\n",
       "           0.6311, 0.6372, 0.6372, 0.6432, 0.6492, 0.6492, 0.6551, 0.6551, 0.6610,\n",
       "           0.6610, 0.6669, 0.6727, 0.6785, 0.6785, 0.6842, 0.6842, 0.6900, 0.6900,\n",
       "           0.6957, 0.7013, 0.7013, 0.7070, 0.7126, 0.7126, 0.7181, 0.7237, 0.7237,\n",
       "           0.7401, 0.7401, 0.7455, 0.7455, 0.7509, 0.7509, 0.7563, 0.7563, 0.7669,\n",
       "           0.7669, 0.7775, 0.7775, 0.7827, 0.7827, 0.7879, 0.7879, 0.7930, 0.7930,\n",
       "           0.7982, 0.7982, 0.8033, 0.8084, 0.8135, 0.8135, 0.8185, 0.8235, 0.8335,\n",
       "           0.8433, 0.8433, 0.8531, 0.8531, 0.8627, 0.8627, 0.8723, 0.8723, 0.0470,\n",
       "           0.0470, 0.0578, 0.0685, 0.0791, 0.0791, 0.0895, 0.0895, 0.0999, 0.1102,\n",
       "           0.1102, 0.1203, 0.1304, 0.1304, 0.1403, 0.1403, 0.1502, 0.1502, 0.1599,\n",
       "           0.1696, 0.1696, 0.1791, 0.1791, 0.1886, 0.1886, 0.1980, 0.1980, 0.2073,\n",
       "           0.2073, 0.2165, 0.2165, 0.2257, 0.2347, 0.2347, 0.2437, 0.2437, 0.2526,\n",
       "           0.2526, 0.2614, 0.2701, 0.2701, 0.2788, 0.2788, 0.2959, 0.3043, 0.3043,\n",
       "           0.3210, 0.3210, 0.3374, 0.3374, 0.3455, 0.3455, 0.3535, 0.3535, 0.3615,\n",
       "           0.3615, 0.3694, 0.3694, 0.3772, 0.3772, 0.3850, 0.3927, 0.3927, 0.4004,\n",
       "           0.4004, 0.4080, 0.4155, 0.4155, 0.4230]),\n",
       "   tensor([-2.5094e-01, -5.2914e-01, -5.2914e-01, -5.1045e-01, -4.9210e-01,\n",
       "           -4.7408e-01, -4.7408e-01, -4.5638e-01, -4.3899e-01, -4.2189e-01,\n",
       "           -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.7230e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01, -3.2504e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01, -2.7992e-01,\n",
       "           -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.3675e-01, -2.3675e-01,\n",
       "           -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.2914e-01,\n",
       "           -5.1045e-01, -5.1045e-01, -4.9210e-01, -4.9210e-01, -4.7408e-01,\n",
       "           -4.7408e-01, -4.5638e-01, -4.3899e-01, -4.3899e-01, -4.2189e-01,\n",
       "           -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.7230e-01, -3.5630e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01,\n",
       "           -3.2504e-01, -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01,\n",
       "           -2.7992e-01, -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01,\n",
       "           -2.0897e-01, -5.6761e-01, -5.6761e-01, -5.4819e-01, -5.4819e-01,\n",
       "           -5.2914e-01, -5.2914e-01, -5.1045e-01, -5.1045e-01, -4.9210e-01,\n",
       "           -4.9210e-01, -4.7408e-01, -4.7408e-01, -4.5638e-01, -4.5638e-01,\n",
       "           -4.3899e-01, -4.3899e-01, -4.2189e-01, -4.2189e-01, -4.0509e-01,\n",
       "           -4.0509e-01, -3.8856e-01, -3.8856e-01, -3.7230e-01, -3.5630e-01,\n",
       "           -3.4055e-01, -3.4055e-01, -3.2504e-01, -3.0978e-01, -2.9474e-01,\n",
       "           -2.9474e-01, -2.7992e-01, -2.7992e-01, -2.6533e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.0897e-01, -1.9537e-01,\n",
       "           -1.9537e-01, -1.8194e-01, -1.8194e-01, -1.6870e-01, -1.6870e-01,\n",
       "           -5.6761e-01, -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01,\n",
       "           -5.2914e-01, -5.1045e-01, -4.9210e-01, -4.9210e-01, -4.7408e-01,\n",
       "           -4.7408e-01, -4.5638e-01, -4.5638e-01, -4.3899e-01, -4.3899e-01,\n",
       "           -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.5630e-01, -3.5630e-01, -3.4055e-01, -3.2504e-01, -3.0978e-01,\n",
       "           -3.0978e-01, -2.9474e-01, -2.7992e-01, -2.6533e-01, -2.6533e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.0897e-01, -2.0897e-01,\n",
       "           -1.9537e-01, -1.9537e-01, -1.8194e-01, -1.6870e-01, -1.5563e-01,\n",
       "           -1.4272e-01, -1.4272e-01, -1.2998e-01, -1.2998e-01, -5.6761e-01,\n",
       "           -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.1045e-01,\n",
       "           -5.1045e-01, -4.9210e-01, -4.9210e-01, -4.7408e-01, -4.3899e-01,\n",
       "           -4.2189e-01, -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01,\n",
       "           -3.8856e-01, -3.7230e-01, -3.7230e-01, -3.5630e-01, -3.5630e-01,\n",
       "           -3.4055e-01, -3.4055e-01, -3.2504e-01, -3.2504e-01, -3.0978e-01,\n",
       "           -2.9474e-01, -2.9474e-01, -2.7992e-01, -2.6533e-01, -2.6533e-01,\n",
       "           -2.5094e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01, -2.0897e-01,\n",
       "           -1.9537e-01, -1.9537e-01, -1.8194e-01, -1.8194e-01, -1.5563e-01,\n",
       "           -1.5563e-01, -1.4272e-01, -1.4272e-01, -1.2998e-01, -1.1741e-01,\n",
       "           -1.0498e-01, -9.2713e-02, -9.2713e-02, -5.6761e-01, -5.6761e-01,\n",
       "           -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.1045e-01, -5.1045e-01,\n",
       "           -4.9210e-01, -4.7408e-01, -4.5638e-01, -4.5638e-01, -4.3899e-01,\n",
       "           -4.3899e-01, -4.2189e-01, -4.0509e-01, -3.8856e-01, -3.8856e-01,\n",
       "           -3.7230e-01, -3.7230e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01, -2.7992e-01,\n",
       "           -2.7992e-01, -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01, -1.9537e-01,\n",
       "           -1.9537e-01, -1.8194e-01, -1.8194e-01, -1.6870e-01, -1.5563e-01,\n",
       "           -1.5563e-01, -1.4272e-01, -1.2998e-01, -1.2998e-01, -1.1741e-01,\n",
       "           -1.0498e-01, -1.0498e-01, -9.2713e-02, -9.2713e-02, -8.0591e-02,\n",
       "           -6.8615e-02, -5.6781e-02, -5.6761e-01, -5.6761e-01, -5.4819e-01,\n",
       "           -5.4819e-01, -5.2914e-01, -5.1045e-01, -5.1045e-01, -4.9210e-01,\n",
       "           -4.7408e-01, -4.7408e-01, -4.5638e-01, -4.3899e-01, -4.3899e-01,\n",
       "           -4.2189e-01, -4.0509e-01, -4.0509e-01, -3.8856e-01, -3.7230e-01,\n",
       "           -3.7230e-01, -3.5630e-01, -3.4055e-01, -3.4055e-01, -3.2504e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01,\n",
       "           -2.7992e-01, -2.7992e-01, -2.6533e-01, -2.5094e-01, -2.3675e-01,\n",
       "           -2.3675e-01, -2.2277e-01, -2.0897e-01, -2.0897e-01, -1.9537e-01,\n",
       "           -1.8194e-01, -1.6870e-01, -1.6870e-01, -1.5563e-01, -1.5563e-01,\n",
       "           -1.4272e-01, -1.4272e-01, -1.2998e-01, -1.2998e-01, -1.1741e-01,\n",
       "           -1.0498e-01, -1.0498e-01, -9.2713e-02, -9.2713e-02, -8.0591e-02,\n",
       "           -6.8615e-02, -5.6781e-02, -4.5085e-02, -4.5085e-02, -3.3524e-02,\n",
       "           -3.3524e-02, -2.2095e-02, -1.0795e-02, -1.0795e-02,  3.7784e-04,\n",
       "            1.1428e-02,  1.1428e-02,  2.2357e-02,  2.2357e-02,  3.3168e-02,\n",
       "            3.3168e-02, -7.3823e-01, -7.3823e-01, -7.1524e-01, -6.9277e-01,\n",
       "           -6.9277e-01, -6.7079e-01, -6.7079e-01, -6.4928e-01, -6.2823e-01,\n",
       "           -6.2823e-01, -6.0761e-01, -6.0761e-01, -5.8741e-01, -5.8741e-01,\n",
       "           -5.6761e-01, -5.4819e-01, -5.4819e-01, -5.2914e-01, -5.2914e-01,\n",
       "           -5.1045e-01, -4.9210e-01, -4.7408e-01, -4.7408e-01, -4.5638e-01,\n",
       "           -4.5638e-01, -4.3899e-01, -4.3899e-01, -4.2189e-01, -4.0509e-01,\n",
       "           -3.8856e-01, -3.7230e-01, -3.5630e-01, -3.5630e-01, -3.4055e-01,\n",
       "           -3.2504e-01, -3.0978e-01, -2.9474e-01, -2.9474e-01, -2.7992e-01,\n",
       "           -2.7992e-01, -2.6533e-01, -2.6533e-01, -2.5094e-01, -2.5094e-01,\n",
       "           -2.3675e-01, -2.3675e-01, -2.2277e-01, -2.2277e-01, -2.0897e-01,\n",
       "           -2.0897e-01, -1.9537e-01, -1.8194e-01, -1.6870e-01, -1.6870e-01,\n",
       "           -1.5563e-01, -1.5563e-01, -1.4272e-01, -1.4272e-01, -1.2998e-01,\n",
       "           -1.2998e-01, -1.1741e-01, -1.1741e-01, -1.0498e-01, -1.0498e-01,\n",
       "           -9.2713e-02, -9.2713e-02, -8.0591e-02, -8.0591e-02, -6.8615e-02,\n",
       "           -6.8615e-02, -5.6781e-02, -5.6781e-02, -4.5085e-02, -3.3524e-02,\n",
       "           -3.3524e-02]),\n",
       "   tensor([-0.0549, -0.0433, -0.0433, -0.0376, -0.0319, -0.0262, -0.0206, -0.0150,\n",
       "           -0.0094, -0.0094, -0.0039, -0.0039,  0.0016,  0.0016,  0.0071,  0.0071,\n",
       "            0.0125,  0.0125,  0.0180,  0.0180,  0.0234,  0.0287,  0.0287,  0.0341,\n",
       "            0.0394,  0.0446,  0.0446,  0.0499,  0.0499,  0.0551,  0.0551,  0.0603,\n",
       "            0.0603,  0.0655,  0.0655,  0.0706,  0.0706,  0.0757,  0.0757,  0.0808,\n",
       "            0.0859,  0.0859,  0.0909,  0.0909,  0.0959,  0.0959,  0.1059,  0.1157,\n",
       "            0.1157,  0.1255,  0.1255,  0.1351,  0.1447,  0.1447,  0.1542,  0.1542,\n",
       "            0.1636,  0.1729,  0.1729,  0.1821,  0.1821,  0.1912,  0.1912,  0.2003,\n",
       "            0.2003,  0.2093,  0.2093,  0.2181,  0.2181,  0.2270,  0.2270,  0.2357,\n",
       "            0.2357,  0.2443,  0.2443,  0.2529,  0.2529,  0.2614,  0.2614,  0.2699,\n",
       "            0.2699,  0.2782,  0.2782, -0.3196, -0.3196, -0.3120, -0.3046, -0.3046,\n",
       "           -0.2971, -0.2971, -0.2897, -0.2824, -0.2824, -0.2751, -0.2751, -0.2679,\n",
       "           -0.2679, -0.2607, -0.2536, -0.2536, -0.2466, -0.2466, -0.2395, -0.2326,\n",
       "           -0.2326, -0.2257, -0.2257, -0.2188, -0.2188, -0.2120, -0.2120, -0.2052,\n",
       "           -0.2052, -0.1984, -0.1984, -0.1918, -0.1918, -0.1851, -0.1785, -0.1785,\n",
       "           -0.1720, -0.1720, -0.1654, -0.1654, -0.1590, -0.1525, -0.1525, -0.1461,\n",
       "           -0.1461, -0.1398, -0.1335, -0.1272, -0.1210, -0.1210, -0.1148, -0.1086,\n",
       "           -0.1025, -0.1025, -0.0964, -0.0904, -0.0844, -0.0844, -0.0784, -0.0784,\n",
       "           -0.0725, -0.0666, -0.0666, -0.0607, -0.0607, -0.0549, -0.0491, -0.0491,\n",
       "           -0.0433, -0.0433, -0.0376, -0.0376, -0.0319, -0.0262, -0.0206, -0.0150,\n",
       "           -0.0094, -0.0039, -0.0039,  0.0016,  0.0016,  0.0071,  0.0071,  0.0125,\n",
       "            0.0125,  0.0180,  0.0180,  0.0234,  0.0234,  0.0287,  0.0341,  0.0341,\n",
       "            0.0394,  0.0394,  0.0446,  0.0551,  0.0603,  0.0603,  0.0655,  0.0655,\n",
       "            0.0706,  0.0706,  0.0757,  0.0757,  0.0808,  0.0859,  0.0909,  0.0909,\n",
       "            0.0959,  0.1009,  0.1059,  0.1059,  0.1108,  0.1108,  0.1157,  0.1255,\n",
       "            0.1351,  0.1351,  0.1447,  0.1447,  0.1542,  0.1636,  0.1636,  0.1729,\n",
       "            0.1729,  0.1821,  0.1912,  0.1912,  0.2003,  0.2093,  0.2093,  0.2181,\n",
       "            0.2181,  0.2270,  0.2270,  0.2443,  0.2443,  0.2529,  0.2529,  0.2614,\n",
       "            0.2614,  0.2782, -0.3272, -0.3272, -0.3196, -0.3196, -0.3120, -0.3120,\n",
       "           -0.3046, -0.3046, -0.2971, -0.2897, -0.2824, -0.2824, -0.2751, -0.2679,\n",
       "           -0.2679, -0.2607, -0.2607, -0.2536, -0.2466, -0.2395, -0.2395, -0.2326,\n",
       "           -0.2257, -0.2257, -0.2188, -0.2188, -0.2120, -0.2052, -0.2052, -0.1984,\n",
       "           -0.1918, -0.1851, -0.1851, -0.1785, -0.1785, -0.1720, -0.1654, -0.1654,\n",
       "           -0.1590, -0.1590, -0.1525, -0.1525, -0.1461, -0.1461, -0.1398, -0.1398,\n",
       "           -0.1335, -0.1272, -0.1210, -0.1210, -0.1148, -0.1148, -0.1086, -0.1025,\n",
       "           -0.0964, -0.0964, -0.0904, -0.0904, -0.0844, -0.0844, -0.0784, -0.0784,\n",
       "           -0.0725, -0.0725, -0.0666, -0.0607, -0.0549, -0.0549, -0.0491, -0.0491,\n",
       "           -0.0433, -0.0433, -0.0376, -0.0319, -0.0262, -0.0262, -0.0206, -0.0206,\n",
       "           -0.0150, -0.0150, -0.0094, -0.0039, -0.0039,  0.0016,  0.0016,  0.0071,\n",
       "            0.0071,  0.0125,  0.0125,  0.0180,  0.0180,  0.0234,  0.0234,  0.0287,\n",
       "            0.0287,  0.0341,  0.0394,  0.0446,  0.0446,  0.0499,  0.0499,  0.0551,\n",
       "            0.0603,  0.0655,  0.0655,  0.0706,  0.0757,  0.0757,  0.0808,  0.0808,\n",
       "            0.0909,  0.0909,  0.0959,  0.1059,  0.1059,  0.1157,  0.1255,  0.1255,\n",
       "            0.1351,  0.1351,  0.1447,  0.1542,  0.1542,  0.1636,  0.1636,  0.1729,\n",
       "            0.1729,  0.1821,  0.1912,  0.1912,  0.2003,  0.2093,  0.2181,  0.2270,\n",
       "            0.2270,  0.2443,  0.2443,  0.2529,  0.2614,  0.2699,  0.2699,  0.2782]),\n",
       "   tensor([-0.6945, -0.6715, -0.6490, -0.6271, -0.6271, -0.6055, -0.6055, -0.5845,\n",
       "           -0.5437, -0.5437, -0.5045, -0.4667, -0.4303, -0.4303, -0.3953, -0.3953,\n",
       "           -0.3614, -0.3614, -0.3286, -0.3286, -0.2968, -0.2660, -0.2660, -0.2362,\n",
       "           -0.2072, -0.1790, -0.1790, -0.1516, -0.1516, -0.0990, -0.0990, -0.0737,\n",
       "           -0.0737, -0.0490, -0.0490, -0.0249, -0.0249, -0.0013,  0.0216,  0.0216,\n",
       "            0.0441,  0.0441,  0.0661,  0.0661,  0.0876,  0.1087,  0.1087,  0.1293,\n",
       "            0.1293,  0.1495,  0.1495])],\n",
       "  'Time to Maturity': [tensor([0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198, 0.5198,\n",
       "           0.5198, 0.5198, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421, 1.2421,\n",
       "           1.2421, 1.2421, 1.2421, 1.2421, 1.2421]),\n",
       "   tensor([0.0159, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
       "           0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
       "           0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
       "           0.0754, 0.0754, 0.0754, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865,\n",
       "           0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.1865, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254,\n",
       "           0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.3254, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365,\n",
       "           0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.4365, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754, 0.5754,\n",
       "           0.5754, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865, 0.6865,\n",
       "           0.6865, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476,\n",
       "           1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.0476, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           1.4087]),\n",
       "   tensor([0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532, 0.8532,\n",
       "           0.8532, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643]),\n",
       "   tensor([2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024])],\n",
       "  'Implied Volatility': [tensor([0.3229, 0.3229, 0.3229, 0.3229, 0.2849, 0.3124, 0.3069, 0.2849, 0.3091,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124,\n",
       "           0.2849, 0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124,\n",
       "           0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.2718, 0.2748, 0.2716, 0.2743, 0.2711, 0.2737, 0.2707,\n",
       "           0.2703, 0.2732, 0.2702, 0.2727, 0.2698, 0.2723, 0.2727, 0.2690, 0.2725,\n",
       "           0.2686, 0.2682, 0.2725, 0.2678, 0.2728, 0.2679, 0.2731, 0.2733, 0.2673,\n",
       "           0.2728, 0.2671, 0.2741, 0.2675, 0.2740, 0.2677, 0.2746, 0.2683, 0.2736,\n",
       "           0.2683, 0.2765, 0.2685, 0.2687, 0.2779, 0.2691, 0.2785, 0.2690, 0.2798,\n",
       "           0.2698, 0.2794, 0.2702, 0.2821, 0.2717, 0.2804, 0.2721, 0.2733, 0.2824,\n",
       "           0.2738, 0.2876, 0.2745, 0.2879, 0.2901, 0.2760, 0.2937, 0.2965, 0.2775,\n",
       "           0.2782, 0.3004, 0.2794, 0.2990, 0.2804, 0.3029, 0.2818, 0.3037, 0.2827,\n",
       "           0.3085, 0.2857, 0.3088, 0.2875, 0.2885, 0.3089, 0.2892, 0.3089, 0.2918,\n",
       "           0.3089, 0.2932, 0.3089, 0.2943, 0.3089, 0.2964, 0.3089, 0.2965, 0.2998,\n",
       "           0.3089, 0.3015, 0.3089, 0.3042, 0.3089, 0.3091, 0.3089, 0.3096, 0.3089,\n",
       "           0.3127, 0.3089, 0.3116, 0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3116, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.2797,\n",
       "           0.2829, 0.2824, 0.2786, 0.2784, 0.2819, 0.2780, 0.2817, 0.2818, 0.2776,\n",
       "           0.2817, 0.2816, 0.2770, 0.2811, 0.2771, 0.2814, 0.2765, 0.2808, 0.2811,\n",
       "           0.2764, 0.2811, 0.2763, 0.2814, 0.2762, 0.2819, 0.2763, 0.2819, 0.2772,\n",
       "           0.2824, 0.2767, 0.2824, 0.2767, 0.2765, 0.2817, 0.2764, 0.2824, 0.2765,\n",
       "           0.2841, 0.2772, 0.2777, 0.2852, 0.2783, 0.2858, 0.2779, 0.2783, 0.2871,\n",
       "           0.2791, 0.2882, 0.2807, 0.2927, 0.2812, 0.2968, 0.2818, 0.2938, 0.2823,\n",
       "           0.2938, 0.2829, 0.2975, 0.2839, 0.2978, 0.3004, 0.2849, 0.3000, 0.2853,\n",
       "           0.2980, 0.2856, 0.2870, 0.2999, 0.2999]),\n",
       "   tensor([0.4101, 0.7247, 0.3801, 0.3801, 0.7247, 0.7247, 0.3801, 0.3801, 0.3801,\n",
       "           0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.3801, 0.7247,\n",
       "           0.3801, 0.7247, 0.3801, 0.3801, 0.7247, 0.3801, 0.7247, 0.7247, 0.3801,\n",
       "           0.7104, 0.6707, 0.3801, 0.5372, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.5191, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3855, 0.3962, 0.3481, 0.3055, 0.3962, 0.3481,\n",
       "           0.3962, 0.3347, 0.3962, 0.3481, 0.3962, 0.3493, 0.3909, 0.3374, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355,\n",
       "           0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3355, 0.3632, 0.3632, 0.3355, 0.3355, 0.3355,\n",
       "           0.3632, 0.3355, 0.3570, 0.3318, 0.3277, 0.3231, 0.3379, 0.3194, 0.3372,\n",
       "           0.3129, 0.3226, 0.3094, 0.3147, 0.3068, 0.3101, 0.3040, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.3484, 0.3484,\n",
       "           0.4352, 0.3484, 0.3429, 0.4122, 0.3953, 0.3444, 0.3835, 0.3753, 0.3739,\n",
       "           0.3358, 0.3570, 0.3293, 0.3245, 0.3413, 0.3237, 0.3356, 0.3221, 0.3173,\n",
       "           0.3161, 0.3231, 0.3221, 0.3128, 0.3187, 0.3110, 0.4089, 0.3532, 0.4089,\n",
       "           0.3532, 0.3532, 0.4089, 0.3306, 0.4089, 0.3532, 0.3439, 0.4089, 0.4089,\n",
       "           0.3356, 0.4089, 0.3532, 0.4089, 0.3407, 0.3976, 0.3439, 0.3822, 0.3405,\n",
       "           0.3716, 0.3346, 0.3633, 0.3286, 0.3605, 0.3439, 0.3254, 0.3225, 0.3393,\n",
       "           0.3182, 0.3260, 0.3226, 0.3096, 0.3162, 0.3071, 0.3090, 0.3064, 0.3063,\n",
       "           0.3047, 0.3030, 0.2998, 0.3005, 0.2977, 0.2965, 0.2965, 0.2912, 0.2891,\n",
       "           0.2916, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3792, 0.3370, 0.3370,\n",
       "           0.3792, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3396, 0.3792, 0.3317,\n",
       "           0.3690, 0.3352, 0.3646, 0.3534, 0.3273, 0.3442, 0.3353, 0.3286, 0.3150,\n",
       "           0.3222, 0.3121, 0.3166, 0.3108, 0.3126, 0.3070, 0.3071, 0.3081, 0.3051,\n",
       "           0.3024, 0.2994, 0.3020, 0.2969, 0.2969, 0.2973, 0.2949, 0.2960, 0.2921,\n",
       "           0.2897, 0.2912, 0.2858, 0.2854, 0.2883, 0.2834, 0.2882, 0.2870, 0.2810,\n",
       "           0.2792, 0.4797, 0.3385, 0.4674, 0.3353, 0.4503, 0.4401, 0.3400, 0.4230,\n",
       "           0.4074, 0.3331, 0.3976, 0.3877, 0.3264, 0.3230, 0.3690, 0.3173, 0.3187,\n",
       "           0.3479, 0.3088, 0.3357, 0.3313, 0.3114, 0.3227, 0.3064, 0.3177, 0.3004,\n",
       "           0.3160, 0.3030, 0.3108, 0.3012, 0.3054, 0.2979, 0.3003, 0.2969, 0.2962,\n",
       "           0.2937, 0.2944, 0.2927, 0.2910, 0.2922, 0.2887, 0.2859, 0.2885, 0.2833,\n",
       "           0.2873, 0.2841, 0.2864, 0.2803, 0.2793, 0.2844, 0.2800, 0.2844, 0.2784,\n",
       "           0.2795, 0.2819, 0.2738, 0.2798, 0.2748, 0.2798, 0.2702, 0.2723, 0.2790,\n",
       "           0.2723, 0.2720, 0.2796, 0.2711, 0.2788, 0.2671, 0.2767, 0.3372, 0.3342,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3342, 0.3372,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3358, 0.3372, 0.3280, 0.3294,\n",
       "           0.3196, 0.3372, 0.3249, 0.3372, 0.3230, 0.3372, 0.3163, 0.3372, 0.3153,\n",
       "           0.3432, 0.3371, 0.3294, 0.3124, 0.3232, 0.3027, 0.3059, 0.3133, 0.3030,\n",
       "           0.3111, 0.3025, 0.3034, 0.2974, 0.3012, 0.2988, 0.2992, 0.2993, 0.2988,\n",
       "           0.2975, 0.2953, 0.2959, 0.2926, 0.2927, 0.2848, 0.2920, 0.2854, 0.2931,\n",
       "           0.2836, 0.2914, 0.2810, 0.2895, 0.2774, 0.2888, 0.2811, 0.2896, 0.2795,\n",
       "           0.2870, 0.2785, 0.2880, 0.2794, 0.2853, 0.2798, 0.2858, 0.2784, 0.2745,\n",
       "           0.2848]),\n",
       "   tensor([0.2326, 0.2317, 0.2282, 0.2274, 0.2262, 0.2286, 0.2275, 0.2275, 0.2253,\n",
       "           0.2231, 0.2252, 0.2221, 0.2242, 0.2214, 0.2234, 0.2208, 0.2237, 0.2205,\n",
       "           0.2228, 0.2202, 0.2189, 0.2221, 0.2196, 0.2191, 0.2213, 0.2206, 0.2165,\n",
       "           0.2205, 0.2173, 0.2197, 0.2155, 0.2196, 0.2158, 0.2193, 0.2160, 0.2197,\n",
       "           0.2146, 0.2190, 0.2151, 0.2186, 0.2185, 0.2146, 0.2190, 0.2126, 0.2185,\n",
       "           0.2138, 0.2143, 0.2194, 0.2124, 0.2191, 0.2165, 0.2191, 0.2195, 0.2172,\n",
       "           0.2204, 0.2174, 0.2188, 0.2225, 0.2123, 0.2231, 0.2166, 0.2241, 0.2156,\n",
       "           0.2246, 0.2205, 0.2279, 0.2139, 0.2274, 0.2198, 0.2342, 0.2137, 0.2299,\n",
       "           0.2137, 0.2315, 0.2137, 0.2330, 0.2137, 0.2343, 0.2118, 0.2344, 0.2137,\n",
       "           0.2403, 0.2137, 0.2851, 0.2756, 0.2723, 0.2813, 0.2715, 0.2803, 0.2693,\n",
       "           0.2780, 0.2765, 0.2693, 0.2769, 0.2686, 0.2743, 0.2650, 0.2631, 0.2702,\n",
       "           0.2635, 0.2691, 0.2620, 0.2671, 0.2661, 0.2596, 0.2626, 0.2575, 0.2631,\n",
       "           0.2605, 0.2620, 0.2561, 0.2587, 0.2552, 0.2597, 0.2544, 0.2574, 0.2528,\n",
       "           0.2525, 0.2541, 0.2505, 0.2537, 0.2489, 0.2523, 0.2479, 0.2518, 0.2509,\n",
       "           0.2470, 0.2495, 0.2457, 0.2441, 0.2480, 0.2421, 0.2461, 0.2412, 0.2426,\n",
       "           0.2400, 0.2426, 0.2386, 0.2373, 0.2405, 0.2399, 0.2363, 0.2391, 0.2347,\n",
       "           0.2343, 0.2371, 0.2337, 0.2367, 0.2335, 0.2322, 0.2346, 0.2308, 0.2326,\n",
       "           0.2310, 0.2327, 0.2294, 0.2290, 0.2307, 0.2303, 0.2287, 0.2286, 0.2274,\n",
       "           0.2257, 0.2274, 0.2252, 0.2272, 0.2258, 0.2262, 0.2241, 0.2263, 0.2237,\n",
       "           0.2248, 0.2233, 0.2247, 0.2241, 0.2232, 0.2236, 0.2233, 0.2210, 0.2212,\n",
       "           0.2228, 0.2210, 0.2228, 0.2207, 0.2222, 0.2199, 0.2216, 0.2200, 0.2227,\n",
       "           0.2214, 0.2224, 0.2200, 0.2225, 0.2187, 0.2213, 0.2184, 0.2222, 0.2184,\n",
       "           0.2183, 0.2221, 0.2227, 0.2177, 0.2217, 0.2180, 0.2215, 0.2215, 0.2196,\n",
       "           0.2218, 0.2205, 0.2209, 0.2231, 0.2218, 0.2229, 0.2236, 0.2226, 0.2259,\n",
       "           0.2230, 0.2268, 0.2239, 0.2280, 0.2259, 0.2283, 0.2255, 0.2265, 0.2251,\n",
       "           0.2313, 0.2810, 0.2642, 0.2789, 0.2642, 0.2775, 0.2642, 0.2761, 0.2642,\n",
       "           0.2745, 0.2731, 0.2712, 0.2642, 0.2700, 0.2692, 0.2605, 0.2646, 0.2607,\n",
       "           0.2646, 0.2567, 0.2628, 0.2558, 0.2533, 0.2591, 0.2552, 0.2589, 0.2534,\n",
       "           0.2562, 0.2553, 0.2502, 0.2548, 0.2519, 0.2500, 0.2468, 0.2513, 0.2460,\n",
       "           0.2483, 0.2477, 0.2438, 0.2491, 0.2424, 0.2468, 0.2421, 0.2451, 0.2413,\n",
       "           0.2436, 0.2401, 0.2389, 0.2422, 0.2416, 0.2369, 0.2402, 0.2358, 0.2394,\n",
       "           0.2343, 0.2371, 0.2335, 0.2375, 0.2324, 0.2365, 0.2320, 0.2356, 0.2305,\n",
       "           0.2351, 0.2304, 0.2321, 0.2333, 0.2310, 0.2283, 0.2297, 0.2277, 0.2306,\n",
       "           0.2271, 0.2265, 0.2257, 0.2275, 0.2251, 0.2274, 0.2246, 0.2256, 0.2238,\n",
       "           0.2232, 0.2258, 0.2227, 0.2252, 0.2221, 0.2240, 0.2219, 0.2241, 0.2213,\n",
       "           0.2231, 0.2207, 0.2233, 0.2203, 0.2222, 0.2198, 0.2197, 0.2214, 0.2222,\n",
       "           0.2181, 0.2218, 0.2184, 0.2181, 0.2174, 0.2210, 0.2172, 0.2167, 0.2203,\n",
       "           0.2181, 0.2200, 0.2174, 0.2199, 0.2166, 0.2194, 0.2190, 0.2164, 0.2192,\n",
       "           0.2183, 0.2150, 0.2183, 0.2152, 0.2189, 0.2186, 0.2172, 0.2180, 0.2156,\n",
       "           0.2182, 0.2162, 0.2179, 0.2191, 0.2163, 0.2195, 0.2188, 0.2174, 0.2206,\n",
       "           0.2193, 0.2218, 0.2173, 0.2220, 0.2211, 0.2226, 0.2208, 0.2229]),\n",
       "   tensor([0.3600, 0.3587, 0.3557, 0.4459, 0.3539, 0.4343, 0.3496, 0.3521, 0.4066,\n",
       "           0.3464, 0.3444, 0.3424, 0.3633, 0.3404, 0.3564, 0.3388, 0.3491, 0.3375,\n",
       "           0.3425, 0.3351, 0.3372, 0.3307, 0.3313, 0.3277, 0.3263, 0.3217, 0.3271,\n",
       "           0.3212, 0.3253, 0.3166, 0.3235, 0.3180, 0.3231, 0.3128, 0.3222, 0.3124,\n",
       "           0.3200, 0.3197, 0.3105, 0.3187, 0.3090, 0.3170, 0.3088, 0.3177, 0.3164,\n",
       "           0.3044, 0.3156, 0.3043, 0.3150, 0.3042, 0.3148])]},\n",
       " 'Query Points': {'Log Moneyness': [tensor([0.4004, 0.7347, 0.4810, 0.6727, 0.7070, 0.4080, 0.4668, 0.2874, 0.4810,\n",
       "           0.3292, 0.5425, 0.6432, 0.5019, 0.2614, 0.1203, 0.2257, 0.4597, 0.3210,\n",
       "           0.4452, 0.5358, 0.4524, 0.6004, 0.6669, 0.7292, 0.4004, 0.7181, 0.6432,\n",
       "           0.1599, 0.7722, 0.4230, 0.7292, 0.5750, 0.3127, 0.0895, 0.0685, 0.8185,\n",
       "           0.3127, 0.4950, 0.3455, 0.4668, 0.3292, 0.0470, 0.8335, 0.8235, 0.5491,\n",
       "           0.1502, 0.6128, 0.6189, 0.5941, 0.6311, 0.8084, 0.4880, 0.5425, 0.6189,\n",
       "           0.4880, 0.7722, 0.4080, 0.0999, 0.3850, 0.7616, 0.8033, 0.4230, 0.2165,\n",
       "           0.5291, 0.1102, 0.4452, 0.2959, 0.5686, 0.0578, 0.3374, 0.2788, 0.6957,\n",
       "           0.3127, 0.5621, 0.4305, 0.7347, 0.3292, 0.4950, 0.7616, 0.2874],\n",
       "          requires_grad=True),\n",
       "   tensor([-1.8194e-01, -4.2189e-01, -3.0978e-01, -1.8194e-01, -3.2504e-01,\n",
       "           -2.7992e-01, -2.2277e-01, -3.5630e-01, -1.1741e-01, -2.3675e-01,\n",
       "           -2.7992e-01, -4.9210e-01, -1.6870e-01, -2.2095e-02, -1.2998e-01,\n",
       "            3.7784e-04, -4.7408e-01, -3.2504e-01, -2.0897e-01, -3.0978e-01,\n",
       "           -2.3675e-01, -2.5094e-01, -5.2914e-01, -2.5094e-01, -4.5638e-01,\n",
       "           -8.0591e-02, -2.3675e-01, -1.6870e-01, -1.6870e-01, -6.8615e-02,\n",
       "           -1.4272e-01, -5.1045e-01, -5.4819e-01, -1.1741e-01, -4.9210e-01,\n",
       "           -3.7230e-01, -1.6870e-01, -1.5563e-01, -5.2914e-01, -3.2504e-01,\n",
       "           -3.4055e-01, -4.5085e-02, -3.7230e-01, -2.7992e-01, -4.3899e-01,\n",
       "           -3.5630e-01, -1.0498e-01, -1.1741e-01, -5.6761e-01, -4.5638e-01,\n",
       "           -2.5094e-01, -3.5630e-01, -2.7992e-01, -1.9537e-01, -3.7230e-01,\n",
       "           -3.0978e-01, -4.5638e-01, -3.4055e-01, -5.6781e-02, -4.3899e-01,\n",
       "           -6.4928e-01, -5.1045e-01, -3.2504e-01, -4.5638e-01, -3.8856e-01,\n",
       "           -5.1045e-01, -4.5638e-01, -3.8856e-01, -2.5094e-01, -5.6761e-01,\n",
       "           -2.5094e-01, -3.5630e-01, -3.8856e-01, -2.9474e-01, -5.6781e-02,\n",
       "           -2.5094e-01, -2.5094e-01, -4.2189e-01, -3.8856e-01, -7.1524e-01,\n",
       "           -1.8194e-01, -3.0978e-01, -4.2189e-01, -4.9210e-01, -4.0509e-01,\n",
       "           -4.2189e-01, -4.9210e-01, -4.2189e-01, -2.2277e-01, -5.2914e-01,\n",
       "           -2.6533e-01, -5.4819e-01, -6.8615e-02, -2.0897e-01, -4.0509e-01,\n",
       "           -1.9537e-01, -4.7408e-01, -3.0978e-01, -3.0978e-01, -2.2277e-01,\n",
       "           -8.0591e-02, -2.6533e-01], requires_grad=True),\n",
       "   tensor([-0.0376, -0.2536,  0.0808,  0.1542, -0.0666, -0.2971,  0.2357,  0.0341,\n",
       "           -0.0262,  0.1447, -0.0319, -0.1335,  0.2699,  0.0808, -0.1272, -0.1148,\n",
       "            0.2357, -0.2751,  0.0499,  0.2003, -0.2326,  0.1636,  0.1255, -0.0491,\n",
       "            0.2782,  0.2003,  0.0959, -0.1590,  0.0341,  0.2357, -0.1398,  0.2357,\n",
       "            0.0394,  0.2782, -0.0262, -0.0964,  0.2614, -0.1272, -0.0607,  0.0859,\n",
       "            0.1821, -0.1086,  0.2529, -0.2466, -0.0549,  0.1009,  0.0394,  0.0499,\n",
       "           -0.3120,  0.0959, -0.0725, -0.1086,  0.0859,  0.2699, -0.1918,  0.0287,\n",
       "           -0.1720, -0.0319, -0.2395,  0.0234,  0.0603,  0.0859,  0.0446,  0.2093,\n",
       "           -0.0094, -0.2607,  0.2181,  0.1157,  0.1821,  0.1157, -0.0094, -0.1335,\n",
       "           -0.0904, -0.0206, -0.0491,  0.0551, -0.0150, -0.0549, -0.0376, -0.1851,\n",
       "            0.0706, -0.2897, -0.0206, -0.2120,  0.0551, -0.0319, -0.1025,  0.1351,\n",
       "           -0.0150, -0.2897,  0.1059, -0.1984], requires_grad=True),\n",
       "   tensor([-0.2362, -0.5045,  0.0876, -0.2072, -0.4667, -0.6715, -0.2968, -0.5845,\n",
       "           -0.1250, -0.6490, -0.6945, -0.0013, -0.1250], requires_grad=True)],\n",
       "  'Time to Maturity': [tensor([0.8810, 0.8810, 0.5198, 0.8810, 0.8810, 0.8810, 0.5198, 1.2421, 0.5198,\n",
       "           1.2421, 0.8810, 0.5198, 0.8810, 1.2421, 1.2421, 1.2421, 0.5198, 0.8810,\n",
       "           0.5198, 0.8810, 0.5198, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           1.2421, 0.8810, 1.2421, 0.8810, 0.8810, 0.8810, 0.8810, 1.2421, 0.8810,\n",
       "           1.2421, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.8810, 0.5198,\n",
       "           0.8810, 0.8810, 0.8810, 0.5198, 0.5198, 0.8810, 0.8810, 0.5198, 0.5198,\n",
       "           0.5198, 0.8810, 1.2421, 1.2421, 1.2421, 0.8810, 0.8810, 0.8810, 0.8810,\n",
       "           0.5198, 0.8810, 0.5198, 1.2421, 0.8810, 1.2421, 0.8810, 0.8810, 0.8810,\n",
       "           1.2421, 0.8810, 0.8810, 0.8810, 1.2421, 0.8810, 0.8810, 1.2421],\n",
       "          requires_grad=True),\n",
       "   tensor([0.4365, 0.6865, 0.3254, 1.0476, 1.4087, 0.0754, 0.3254, 0.3254, 1.0476,\n",
       "           0.5754, 0.1865, 1.4087, 0.5754, 1.0476, 0.5754, 1.0476, 0.5754, 0.4365,\n",
       "           0.3254, 0.6865, 0.5754, 0.4365, 0.6865, 0.0754, 0.5754, 1.0476, 0.6865,\n",
       "           0.5754, 0.4365, 0.6865, 0.6865, 0.4365, 0.0754, 0.6865, 0.6865, 0.4365,\n",
       "           0.6865, 0.4365, 1.0476, 0.3254, 0.4365, 1.4087, 1.4087, 0.5754, 0.5754,\n",
       "           0.6865, 0.5754, 0.5754, 1.4087, 1.0476, 0.5754, 0.0754, 0.4365, 1.4087,\n",
       "           0.3254, 1.4087, 0.5754, 1.4087, 0.6865, 0.0754, 1.4087, 1.4087, 0.6865,\n",
       "           0.0754, 1.0476, 0.0754, 0.1865, 0.4365, 0.3254, 0.1865, 1.0476, 1.0476,\n",
       "           0.1865, 0.4365, 1.0476, 0.0159, 0.4365, 1.4087, 1.4087, 1.4087, 1.4087,\n",
       "           0.5754, 0.4365, 0.0754, 0.6865, 0.0754, 1.0476, 1.0476, 0.4365, 0.5754,\n",
       "           0.3254, 0.0754, 1.0476, 0.6865, 1.4087, 1.0476, 0.6865, 0.0754, 0.1865,\n",
       "           1.0476, 0.6865, 1.0476], requires_grad=True),\n",
       "   tensor([0.9643, 0.9643, 0.8532, 0.8532, 0.9643, 0.9643, 0.9643, 0.9643, 0.4921,\n",
       "           0.9643, 0.9643, 0.9643, 0.8532, 0.4921, 0.8532, 0.8532, 0.8532, 0.9643,\n",
       "           0.8532, 0.8532, 0.9643, 0.4921, 0.8532, 0.4921, 0.9643, 0.9643, 0.8532,\n",
       "           0.8532, 0.4921, 0.8532, 0.8532, 0.9643, 0.4921, 0.8532, 0.8532, 0.8532,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.8532, 0.9643, 0.9643, 0.4921,\n",
       "           0.8532, 0.9643, 0.8532, 0.8532, 0.9643, 0.8532, 0.9643, 0.9643, 0.8532,\n",
       "           0.9643, 0.8532, 0.9643, 0.4921, 0.8532, 0.4921, 0.9643, 0.8532, 0.8532,\n",
       "           0.9643, 0.8532, 0.8532, 0.9643, 0.8532, 0.8532, 0.9643, 0.9643, 0.8532,\n",
       "           0.8532, 0.8532, 0.4921, 0.8532, 0.8532, 0.8532, 0.4921, 0.8532, 0.9643,\n",
       "           0.8532, 0.4921, 0.9643, 0.9643, 0.8532, 0.9643, 0.4921, 0.4921, 0.9643,\n",
       "           0.4921, 0.9643], requires_grad=True),\n",
       "   tensor([2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024, 2.7024,\n",
       "           2.7024, 2.7024, 2.7024, 2.7024], requires_grad=True)],\n",
       "  'Implied Volatility': [tensor([0.3085, 0.3116, 0.2849, 0.3116, 0.3116, 0.3089, 0.2849, 0.2774, 0.3124,\n",
       "           0.2800, 0.3116, 0.2849, 0.3057, 0.2848, 0.2772, 0.2829, 0.2849, 0.2911,\n",
       "           0.3229, 0.3116, 0.2849, 0.3089, 0.3116, 0.3089, 0.2856, 0.3116, 0.3089,\n",
       "           0.2765, 0.3089, 0.2872, 0.3116, 0.3116, 0.2740, 0.2688, 0.2822, 0.3089,\n",
       "           0.2895, 0.3048, 0.2942, 0.3089, 0.2760, 0.2733, 0.3116, 0.3116, 0.2849,\n",
       "           0.2672, 0.3089, 0.3089, 0.2849, 0.2849, 0.3116, 0.3089, 0.3124, 0.3124,\n",
       "           0.2849, 0.3116, 0.3009, 0.2779, 0.2837, 0.3089, 0.3089, 0.3089, 0.2765,\n",
       "           0.3124, 0.2727, 0.2849, 0.2890, 0.3116, 0.2792, 0.2772, 0.2854, 0.3116,\n",
       "           0.2788, 0.3089, 0.2902, 0.3089, 0.2902, 0.3089, 0.3116, 0.2866]),\n",
       "   tensor([0.3331, 0.3792, 0.3632, 0.2953, 0.3212, 0.3801, 0.3153, 0.3355, 0.2859,\n",
       "           0.3278, 0.3962, 0.3372, 0.3044, 0.2785, 0.2967, 0.2794, 0.4089, 0.3464,\n",
       "           0.3263, 0.3174, 0.3109, 0.3256, 0.3792, 0.3801, 0.3532, 0.2837, 0.3050,\n",
       "           0.3021, 0.3295, 0.2847, 0.2945, 0.3484, 0.3801, 0.2892, 0.3792, 0.4487,\n",
       "           0.2964, 0.3143, 0.3435, 0.3632, 0.4214, 0.2859, 0.3126, 0.3410, 0.3496,\n",
       "           0.3274, 0.2932, 0.2939, 0.3360, 0.3296, 0.3172, 0.7247, 0.3365, 0.2949,\n",
       "           0.3632, 0.3165, 0.4089, 0.3026, 0.2834, 0.7247, 0.3342, 0.3372, 0.3232,\n",
       "           0.7247, 0.3554, 0.7247, 0.3481, 0.4610, 0.3592, 0.3962, 0.3043, 0.3103,\n",
       "           0.3481, 0.3401, 0.2750, 0.4484, 0.3654, 0.3168, 0.3152, 0.3372, 0.2934,\n",
       "           0.3235, 0.3484, 0.3801, 0.3792, 0.7247, 0.3363, 0.3754, 0.3477, 0.4089,\n",
       "           0.3396, 0.7247, 0.2817, 0.3015, 0.3372, 0.2935, 0.3370, 0.7247, 0.3962,\n",
       "           0.2948, 0.2819, 0.2994]),\n",
       "   tensor([0.2287, 0.2577, 0.2192, 0.2196, 0.2295, 0.2642, 0.2217, 0.2220, 0.2258,\n",
       "           0.2151, 0.2285, 0.2442, 0.2301, 0.2175, 0.2465, 0.2403, 0.2238, 0.2579,\n",
       "           0.2217, 0.2225, 0.2597, 0.2207, 0.2183, 0.2325, 0.2231, 0.2173, 0.2193,\n",
       "           0.2479, 0.2217, 0.2272, 0.2469, 0.2193, 0.2180, 0.2287, 0.2292, 0.2414,\n",
       "           0.2187, 0.2380, 0.2288, 0.2198, 0.2165, 0.2437, 0.2198, 0.2647, 0.2302,\n",
       "           0.2212, 0.2195, 0.2228, 0.2852, 0.2166, 0.2381, 0.2352, 0.2176, 0.2267,\n",
       "           0.2480, 0.2230, 0.2453, 0.2294, 0.2602, 0.2212, 0.2211, 0.2197, 0.2235,\n",
       "           0.2171, 0.2268, 0.2723, 0.2201, 0.2220, 0.2248, 0.2146, 0.2256, 0.2426,\n",
       "           0.2374, 0.2289, 0.2297, 0.2226, 0.2281, 0.2358, 0.2310, 0.2570, 0.2204,\n",
       "           0.2698, 0.2250, 0.2524, 0.2214, 0.2318, 0.2384, 0.2171, 0.2238, 0.2642,\n",
       "           0.2185, 0.2492]),\n",
       "   tensor([0.3301, 0.3884, 0.3060, 0.3280, 0.3755, 0.4660, 0.3333, 0.4248, 0.3245,\n",
       "           0.4548, 0.4785, 0.3126, 0.3192])]}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "class IVSurfaceDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        data, \n",
    "        proportion, \n",
    "        random_state=0\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.proportion = proportion\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        surface_data = self.data[idx]\n",
    "        \n",
    "        # Extract the surface coordinates and volatilities\n",
    "        points_coordinates = np.stack([\n",
    "            surface_data['Surface']['Log Moneyness'], \n",
    "            surface_data['Surface']['Time to Maturity']\n",
    "        ], axis=1)\n",
    "        points_volatilities = surface_data['Surface']['Implied Volatility']\n",
    "\n",
    "        # Perform clustering\n",
    "        n_clusters = int(np.ceil(1 / self.proportion))\n",
    "        pipeline = Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('kmeans', KMeans(n_clusters=n_clusters, random_state=self.random_state, n_init='auto'))\n",
    "        ])\n",
    "        labels = pipeline.fit_predict(points_coordinates)\n",
    "\n",
    "        rng = np.random.default_rng(self.random_state)\n",
    "        cluster_indices = np.where(labels == rng.integers(n_clusters))[0]\n",
    "        num_to_mask = int(np.ceil(len(cluster_indices) * self.proportion))\n",
    "        masked_indices = rng.choice(cluster_indices, size=num_to_mask, replace=False)\n",
    "        \n",
    "        unmasked_indices = np.setdiff1d(cluster_indices, masked_indices)\n",
    "\n",
    "\n",
    "        data_item = {\n",
    "            'Datetime': surface_data['Datetime'],\n",
    "            'Symbol': surface_data['Symbol'],\n",
    "            'Market Features': {\n",
    "                'Market Return': torch.tensor(surface_data['Market Features']['Market Return'], dtype=torch.float32),\n",
    "                'Market Volatility': torch.tensor(surface_data['Market Features']['Market Volatility'], dtype=torch.float32),\n",
    "                'Treasury Rate': torch.tensor(surface_data['Market Features']['Treasury Rate'], dtype=torch.float32),\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': torch.tensor(points_coordinates[unmasked_indices, 0], dtype=torch.float32),\n",
    "                'Time to Maturity': torch.tensor(points_coordinates[unmasked_indices, 1], dtype=torch.float32),\n",
    "                'Implied Volatility': torch.tensor(points_volatilities[unmasked_indices], dtype=torch.float32)\n",
    "            },\n",
    "            'Query Points': {\n",
    "                'Log Moneyness': torch.tensor(points_coordinates[masked_indices, 0], dtype=torch.float32),\n",
    "                'Time to Maturity': torch.tensor(points_coordinates[masked_indices, 1], dtype=torch.float32),\n",
    "                'Implied Volatility': torch.tensor(points_volatilities[masked_indices], dtype=torch.float32)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return data_item\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(batch):\n",
    "        batched_data = {\n",
    "            'Datetime': [item['Datetime'] for item in batch],\n",
    "            'Symbol': [item['Symbol'] for item in batch],\n",
    "            'Market Features': {\n",
    "                'Market Return': default_collate([item['Market Features']['Market Return'] for item in batch]),\n",
    "                'Market Volatility': default_collate([item['Market Features']['Market Volatility'] for item in batch]),\n",
    "                'Treasury Rate': default_collate([item['Market Features']['Treasury Rate'] for item in batch]),\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': [item['Input Surface']['Log Moneyness'].clone().detach() for item in batch],\n",
    "                'Time to Maturity': [item['Input Surface']['Time to Maturity'].clone().detach() for item in batch],\n",
    "                'Implied Volatility': [item['Input Surface']['Implied Volatility'].clone().detach() for item in batch],\n",
    "            },\n",
    "            'Query Points': {\n",
    "                'Log Moneyness': [item['Query Points']['Log Moneyness'].clone().detach().requires_grad_(True) for item in batch],\n",
    "                'Time to Maturity': [item['Query Points']['Time to Maturity'].clone().detach().requires_grad_(True) for item in batch],\n",
    "                'Implied Volatility': [item['Query Points']['Implied Volatility'].clone().detach() for item in batch],\n",
    "            }\n",
    "        }\n",
    "\n",
    "        return batched_data\n",
    "\n",
    "\n",
    "# Assuming surfaces is the output from the implied_volatility_surfaces function\n",
    "proportion = 0.2  # example proportion\n",
    "dataset = IVSurfaceDataset(surfaces, proportion)\n",
    "data_loader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=HYPERPARAMETERS['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "\n",
    "# Fetch one batch from the DataLoader\n",
    "batch = next(iter(data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': [Timestamp('2013-06-10 00:00:00'),\n",
       "  Timestamp('2013-01-28 00:00:00'),\n",
       "  Timestamp('2013-05-20 00:00:00'),\n",
       "  Timestamp('2013-03-07 00:00:00')],\n",
       " 'Symbol': ['AAPL', 'AAPL', 'GOOGL', 'AAPL'],\n",
       " 'Market Features': {'Market Return': tensor([-0.0216, -0.4603, -0.1269,  0.6087], grad_fn=<SqueezeBackward1>),\n",
       "  'Market Volatility': tensor([ 1.6897, -0.2052, -0.7625, -0.7220], grad_fn=<SqueezeBackward1>),\n",
       "  'Treasury Rate': tensor([-0.7439,  0.1717, -0.9728,  1.5450], grad_fn=<SqueezeBackward1>)},\n",
       " 'Input Surface': {'Log Moneyness': [tensor([1.2476, 1.2676, 1.2873, 1.3070, 1.3070, 1.3458, 1.3650, 1.3650, 1.3841,\n",
       "           1.3841, 1.4030, 1.4030, 1.4219, 1.4219, 1.4406, 1.4406, 1.4591, 1.4776,\n",
       "           1.4776, 1.4959, 1.5141, 1.5322, 1.5322, 1.5501, 1.5501, 1.5680, 1.5680,\n",
       "           1.5857, 1.5857, 1.6033, 1.6033, 1.6209, 1.6209, 1.6383, 1.6555, 1.6555,\n",
       "           1.6727, 1.6727, 1.6898, 1.6898, 1.7068, 1.7236, 1.7236, 1.7404, 1.7571,\n",
       "           1.7571, 1.7736, 1.7901, 1.7901, 1.8064, 1.8064, 1.8227, 1.8227, 1.8389,\n",
       "           1.8389, 1.8550, 1.8550, 1.8710, 1.8710, 1.8869, 1.8869, 1.9027, 1.9027,\n",
       "           1.9184, 1.9184, 0.0381, 0.0381, 0.0690, 0.0690, 0.0994, 0.0994, 0.1296,\n",
       "           0.1594, 0.1594, 0.1889, 0.1889, 0.2180, 0.2180, 0.2469, 0.2755, 0.2755,\n",
       "           0.3038, 0.3318, 0.3318, 0.3595, 0.3595, 0.3869, 0.3869, 0.4141, 0.4410,\n",
       "           0.4410, 0.4676, 0.4676, 0.4940, 0.4940, 0.5202, 0.5202, 0.5461, 0.5461,\n",
       "           0.5717, 0.5717, 0.5971, 0.6223, 0.6223, 0.6473, 0.6473, 0.6720, 0.6720,\n",
       "           0.6965, 0.6965, 0.7208, 0.7208, 0.7449, 0.7449, 0.7688, 0.7924, 0.7924,\n",
       "           0.8159, 0.8159, 0.8392, 0.8392, 0.8622, 0.8851, 0.9078, 0.9303, 0.9527,\n",
       "           0.9748, 0.9748, 0.9968, 0.9968, 1.0186, 1.0186, 1.0402, 1.0402, 1.0617,\n",
       "           1.0617, 1.0830, 1.0830, 1.1251, 1.1459, 1.1459, 1.1665, 1.1870, 1.2074,\n",
       "           1.2074, 1.2276, 1.2276, 1.2476, 1.2476, 1.2676, 1.2676, 1.2873, 1.3070,\n",
       "           1.3070, 1.3264, 1.3264, 1.3458, 1.3841, 1.4030, 1.4030, 1.4219, 1.4219,\n",
       "           1.4406, 1.4406, 1.4591, 1.4591, 1.4776, 1.4959, 1.5141, 1.5141, 1.5322,\n",
       "           1.5322, 1.5501, 1.5680, 1.5857, 1.6033, 1.6033, 1.6209, 1.6209, 1.6383,\n",
       "           1.6383, 1.6555, 1.6727, 1.6727, 1.6898, 1.7068, 1.7236, 1.7236, 1.7404,\n",
       "           1.7404, 1.7571, 1.7571, 1.7736, 1.7901, 1.7901, 1.8064, 1.8064, 1.8227,\n",
       "           1.8227, 1.8389, 1.8550, 1.8710, 1.8710, 1.8869, 1.8869, 1.9027, 1.9027,\n",
       "           1.9184, 1.9340, 1.9340, 1.9495, 1.9650, 1.9650, 1.9803, 1.9956, 1.9956,\n",
       "           2.0409, 2.0409, 2.0559, 2.0559, 2.0708, 2.0708, 2.0855, 2.0855, 2.1149,\n",
       "           2.1149, 2.1439, 2.1439, 2.1583, 2.1583, 2.1726, 2.1726, 2.1869, 2.1869,\n",
       "           2.2011, 2.2011, 2.2152, 2.2292, 2.2432, 2.2432, 2.2570, 2.2709, 2.2983,\n",
       "           2.3255, 2.3255, 2.3524, 2.3524, 2.3790, 2.3790, 2.4054, 2.4054, 0.1296,\n",
       "           0.1296, 0.1594, 0.1889, 0.2180, 0.2180, 0.2469, 0.2469, 0.2755, 0.3038,\n",
       "           0.3038, 0.3318, 0.3595, 0.3595, 0.3869, 0.3869, 0.4141, 0.4141, 0.4410,\n",
       "           0.4676, 0.4676, 0.4940, 0.4940, 0.5202, 0.5202, 0.5461, 0.5461, 0.5717,\n",
       "           0.5717, 0.5971, 0.5971, 0.6223, 0.6473, 0.6473, 0.6720, 0.6720, 0.6965,\n",
       "           0.6965, 0.7208, 0.7449, 0.7449, 0.7688, 0.7688, 0.8159, 0.8392, 0.8392,\n",
       "           0.8851, 0.8851, 0.9303, 0.9303, 0.9527, 0.9527, 0.9748, 0.9748, 0.9968,\n",
       "           0.9968, 1.0186, 1.0186, 1.0402, 1.0402, 1.0617, 1.0830, 1.0830, 1.1041,\n",
       "           1.1041, 1.1251, 1.1459, 1.1459, 1.1665],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-6.9195e-01, -1.4591e+00, -1.4591e+00, -1.4076e+00, -1.3570e+00,\n",
       "           -1.3073e+00, -1.3073e+00, -1.2585e+00, -1.2105e+00, -1.1634e+00,\n",
       "           -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -1.0266e+00, -9.8249e-01, -9.3906e-01, -9.3906e-01, -8.9631e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01, -7.7189e-01,\n",
       "           -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.5284e-01, -6.5284e-01,\n",
       "           -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4591e+00,\n",
       "           -1.4076e+00, -1.4076e+00, -1.3570e+00, -1.3570e+00, -1.3073e+00,\n",
       "           -1.3073e+00, -1.2585e+00, -1.2105e+00, -1.2105e+00, -1.1634e+00,\n",
       "           -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -1.0266e+00, -9.8249e-01, -9.8249e-01, -9.3906e-01, -9.3906e-01,\n",
       "           -8.9631e-01, -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01,\n",
       "           -7.7189e-01, -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01,\n",
       "           -5.7623e-01, -1.5652e+00, -1.5652e+00, -1.5116e+00, -1.5116e+00,\n",
       "           -1.4591e+00, -1.4591e+00, -1.4076e+00, -1.4076e+00, -1.3570e+00,\n",
       "           -1.3570e+00, -1.3073e+00, -1.3073e+00, -1.2585e+00, -1.2585e+00,\n",
       "           -1.2105e+00, -1.2105e+00, -1.1634e+00, -1.1634e+00, -1.1170e+00,\n",
       "           -1.1170e+00, -1.0714e+00, -1.0714e+00, -1.0266e+00, -9.8249e-01,\n",
       "           -9.3906e-01, -9.3906e-01, -8.9631e-01, -8.5421e-01, -8.1274e-01,\n",
       "           -8.1274e-01, -7.7189e-01, -7.7189e-01, -7.3163e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -5.7623e-01, -5.3872e-01,\n",
       "           -5.3872e-01, -5.0170e-01, -5.0170e-01, -4.6518e-01, -4.6518e-01,\n",
       "           -1.5652e+00, -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00,\n",
       "           -1.4591e+00, -1.4076e+00, -1.3570e+00, -1.3570e+00, -1.3073e+00,\n",
       "           -1.3073e+00, -1.2585e+00, -1.2585e+00, -1.2105e+00, -1.2105e+00,\n",
       "           -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -9.8249e-01, -9.8249e-01, -9.3906e-01, -8.9631e-01, -8.5421e-01,\n",
       "           -8.5421e-01, -8.1274e-01, -7.7189e-01, -7.3163e-01, -7.3163e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -5.7623e-01, -5.7623e-01,\n",
       "           -5.3872e-01, -5.3872e-01, -5.0170e-01, -4.6518e-01, -4.2913e-01,\n",
       "           -3.9355e-01, -3.9355e-01, -3.5842e-01, -3.5842e-01, -1.5652e+00,\n",
       "           -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4076e+00,\n",
       "           -1.4076e+00, -1.3570e+00, -1.3570e+00, -1.3073e+00, -1.2105e+00,\n",
       "           -1.1634e+00, -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00,\n",
       "           -1.0714e+00, -1.0266e+00, -1.0266e+00, -9.8249e-01, -9.8249e-01,\n",
       "           -9.3906e-01, -9.3906e-01, -8.9631e-01, -8.9631e-01, -8.5421e-01,\n",
       "           -8.1274e-01, -8.1274e-01, -7.7189e-01, -7.3163e-01, -7.3163e-01,\n",
       "           -6.9195e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01, -5.7623e-01,\n",
       "           -5.3872e-01, -5.3872e-01, -5.0170e-01, -5.0170e-01, -4.2913e-01,\n",
       "           -4.2913e-01, -3.9355e-01, -3.9355e-01, -3.5842e-01, -3.2373e-01,\n",
       "           -2.8948e-01, -2.5564e-01, -2.5564e-01, -1.5652e+00, -1.5652e+00,\n",
       "           -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4076e+00, -1.4076e+00,\n",
       "           -1.3570e+00, -1.3073e+00, -1.2585e+00, -1.2585e+00, -1.2105e+00,\n",
       "           -1.2105e+00, -1.1634e+00, -1.1170e+00, -1.0714e+00, -1.0714e+00,\n",
       "           -1.0266e+00, -1.0266e+00, -9.8249e-01, -9.3906e-01, -9.3906e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01, -7.7189e-01,\n",
       "           -7.7189e-01, -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01, -5.3872e-01,\n",
       "           -5.3872e-01, -5.0170e-01, -5.0170e-01, -4.6518e-01, -4.2913e-01,\n",
       "           -4.2913e-01, -3.9355e-01, -3.5842e-01, -3.5842e-01, -3.2373e-01,\n",
       "           -2.8948e-01, -2.8948e-01, -2.5564e-01, -2.5564e-01, -2.2222e-01,\n",
       "           -1.8919e-01, -1.5656e-01, -1.5652e+00, -1.5652e+00, -1.5116e+00,\n",
       "           -1.5116e+00, -1.4591e+00, -1.4076e+00, -1.4076e+00, -1.3570e+00,\n",
       "           -1.3073e+00, -1.3073e+00, -1.2585e+00, -1.2105e+00, -1.2105e+00,\n",
       "           -1.1634e+00, -1.1170e+00, -1.1170e+00, -1.0714e+00, -1.0266e+00,\n",
       "           -1.0266e+00, -9.8249e-01, -9.3906e-01, -9.3906e-01, -8.9631e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01,\n",
       "           -7.7189e-01, -7.7189e-01, -7.3163e-01, -6.9195e-01, -6.5284e-01,\n",
       "           -6.5284e-01, -6.1427e-01, -5.7623e-01, -5.7623e-01, -5.3872e-01,\n",
       "           -5.0170e-01, -4.6518e-01, -4.6518e-01, -4.2913e-01, -4.2913e-01,\n",
       "           -3.9355e-01, -3.9355e-01, -3.5842e-01, -3.5842e-01, -3.2373e-01,\n",
       "           -2.8948e-01, -2.8948e-01, -2.5564e-01, -2.5564e-01, -2.2222e-01,\n",
       "           -1.8919e-01, -1.5656e-01, -1.2431e-01, -1.2431e-01, -9.2427e-02,\n",
       "           -9.2427e-02, -6.0912e-02, -2.9753e-02, -2.9753e-02,  1.0579e-03,\n",
       "            3.1528e-02,  3.1528e-02,  6.1666e-02,  6.1666e-02,  9.1477e-02,\n",
       "            9.1477e-02, -2.0357e+00, -2.0357e+00, -1.9723e+00, -1.9103e+00,\n",
       "           -1.9103e+00, -1.8497e+00, -1.8497e+00, -1.7904e+00, -1.7324e+00,\n",
       "           -1.7324e+00, -1.6755e+00, -1.6755e+00, -1.6198e+00, -1.6198e+00,\n",
       "           -1.5652e+00, -1.5116e+00, -1.5116e+00, -1.4591e+00, -1.4591e+00,\n",
       "           -1.4076e+00, -1.3570e+00, -1.3073e+00, -1.3073e+00, -1.2585e+00,\n",
       "           -1.2585e+00, -1.2105e+00, -1.2105e+00, -1.1634e+00, -1.1170e+00,\n",
       "           -1.0714e+00, -1.0266e+00, -9.8249e-01, -9.8249e-01, -9.3906e-01,\n",
       "           -8.9631e-01, -8.5421e-01, -8.1274e-01, -8.1274e-01, -7.7189e-01,\n",
       "           -7.7189e-01, -7.3163e-01, -7.3163e-01, -6.9195e-01, -6.9195e-01,\n",
       "           -6.5284e-01, -6.5284e-01, -6.1427e-01, -6.1427e-01, -5.7623e-01,\n",
       "           -5.7623e-01, -5.3872e-01, -5.0170e-01, -4.6518e-01, -4.6518e-01,\n",
       "           -4.2913e-01, -4.2913e-01, -3.9355e-01, -3.9355e-01, -3.5842e-01,\n",
       "           -3.5842e-01, -3.2373e-01, -3.2373e-01, -2.8948e-01, -2.8948e-01,\n",
       "           -2.5564e-01, -2.5564e-01, -2.2222e-01, -2.2222e-01, -1.8919e-01,\n",
       "           -1.8919e-01, -1.5656e-01, -1.5656e-01, -1.2431e-01, -9.2427e-02,\n",
       "           -9.2427e-02], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.1514, -0.1195, -0.1195, -0.1037, -0.0880, -0.0723, -0.0568, -0.0414,\n",
       "           -0.0260, -0.0260, -0.0107, -0.0107,  0.0045,  0.0045,  0.0196,  0.0196,\n",
       "            0.0346,  0.0346,  0.0496,  0.0496,  0.0644,  0.0792,  0.0792,  0.0939,\n",
       "            0.1085,  0.1231,  0.1231,  0.1376,  0.1376,  0.1520,  0.1520,  0.1663,\n",
       "            0.1663,  0.1805,  0.1805,  0.1947,  0.1947,  0.2088,  0.2088,  0.2229,\n",
       "            0.2368,  0.2368,  0.2507,  0.2507,  0.2645,  0.2645,  0.2920,  0.3191,\n",
       "            0.3191,  0.3460,  0.3460,  0.3727,  0.3991,  0.3991,  0.4252,  0.4252,\n",
       "            0.4511,  0.4768,  0.4768,  0.5022,  0.5022,  0.5274,  0.5274,  0.5523,\n",
       "            0.5523,  0.5770,  0.5770,  0.6016,  0.6016,  0.6259,  0.6259,  0.6499,\n",
       "            0.6499,  0.6738,  0.6738,  0.6975,  0.6975,  0.7210,  0.7210,  0.7442,\n",
       "            0.7442,  0.7673,  0.7673, -0.8813, -0.8813, -0.8605, -0.8398, -0.8398,\n",
       "           -0.8193, -0.8193, -0.7989, -0.7787, -0.7787, -0.7587, -0.7587, -0.7388,\n",
       "           -0.7388, -0.7190, -0.6994, -0.6994, -0.6799, -0.6799, -0.6605, -0.6413,\n",
       "           -0.6413, -0.6222, -0.6222, -0.6033, -0.6033, -0.5845, -0.5845, -0.5658,\n",
       "           -0.5658, -0.5472, -0.5472, -0.5288, -0.5288, -0.5104, -0.4922, -0.4922,\n",
       "           -0.4741, -0.4741, -0.4562, -0.4562, -0.4383, -0.4206, -0.4206, -0.4030,\n",
       "           -0.4030, -0.3855, -0.3681, -0.3508, -0.3336, -0.3336, -0.3165, -0.2996,\n",
       "           -0.2827, -0.2827, -0.2659, -0.2493, -0.2327, -0.2327, -0.2162, -0.2162,\n",
       "           -0.1999, -0.1836, -0.1836, -0.1674, -0.1674, -0.1514, -0.1354, -0.1354,\n",
       "           -0.1195, -0.1195, -0.1037, -0.1037, -0.0880, -0.0723, -0.0568, -0.0414,\n",
       "           -0.0260, -0.0107, -0.0107,  0.0045,  0.0045,  0.0196,  0.0196,  0.0346,\n",
       "            0.0346,  0.0496,  0.0496,  0.0644,  0.0644,  0.0792,  0.0939,  0.0939,\n",
       "            0.1085,  0.1085,  0.1231,  0.1520,  0.1663,  0.1663,  0.1805,  0.1805,\n",
       "            0.1947,  0.1947,  0.2088,  0.2088,  0.2229,  0.2368,  0.2507,  0.2507,\n",
       "            0.2645,  0.2783,  0.2920,  0.2920,  0.3056,  0.3056,  0.3191,  0.3460,\n",
       "            0.3727,  0.3727,  0.3991,  0.3991,  0.4252,  0.4511,  0.4511,  0.4768,\n",
       "            0.4768,  0.5022,  0.5274,  0.5274,  0.5523,  0.5770,  0.5770,  0.6016,\n",
       "            0.6016,  0.6259,  0.6259,  0.6738,  0.6738,  0.6975,  0.6975,  0.7210,\n",
       "            0.7210,  0.7673, -0.9022, -0.9022, -0.8813, -0.8813, -0.8605, -0.8605,\n",
       "           -0.8398, -0.8398, -0.8193, -0.7989, -0.7787, -0.7787, -0.7587, -0.7388,\n",
       "           -0.7388, -0.7190, -0.7190, -0.6994, -0.6799, -0.6605, -0.6605, -0.6413,\n",
       "           -0.6222, -0.6222, -0.6033, -0.6033, -0.5845, -0.5658, -0.5658, -0.5472,\n",
       "           -0.5288, -0.5104, -0.5104, -0.4922, -0.4922, -0.4741, -0.4562, -0.4562,\n",
       "           -0.4383, -0.4383, -0.4206, -0.4206, -0.4030, -0.4030, -0.3855, -0.3855,\n",
       "           -0.3681, -0.3508, -0.3336, -0.3336, -0.3165, -0.3165, -0.2996, -0.2827,\n",
       "           -0.2659, -0.2659, -0.2493, -0.2493, -0.2327, -0.2327, -0.2162, -0.2162,\n",
       "           -0.1999, -0.1999, -0.1836, -0.1674, -0.1514, -0.1514, -0.1354, -0.1354,\n",
       "           -0.1195, -0.1195, -0.1037, -0.0880, -0.0723, -0.0723, -0.0568, -0.0568,\n",
       "           -0.0414, -0.0414, -0.0260, -0.0107, -0.0107,  0.0045,  0.0045,  0.0196,\n",
       "            0.0196,  0.0346,  0.0346,  0.0496,  0.0496,  0.0644,  0.0644,  0.0792,\n",
       "            0.0792,  0.0939,  0.1085,  0.1231,  0.1231,  0.1376,  0.1376,  0.1520,\n",
       "            0.1663,  0.1805,  0.1805,  0.1947,  0.2088,  0.2088,  0.2229,  0.2229,\n",
       "            0.2507,  0.2507,  0.2645,  0.2920,  0.2920,  0.3191,  0.3460,  0.3460,\n",
       "            0.3727,  0.3727,  0.3991,  0.4252,  0.4252,  0.4511,  0.4511,  0.4768,\n",
       "            0.4768,  0.5022,  0.5274,  0.5274,  0.5523,  0.5770,  0.6016,  0.6259,\n",
       "            0.6259,  0.6738,  0.6738,  0.6975,  0.7210,  0.7442,  0.7442,  0.7673],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-1.9151, -1.8517, -1.7897, -1.7291, -1.7291, -1.6698, -1.6698, -1.6118,\n",
       "           -1.4992, -1.4992, -1.3910, -1.2870, -1.1867, -1.1867, -1.0899, -1.0899,\n",
       "           -0.9964, -0.9964, -0.9060, -0.9060, -0.8185, -0.7336, -0.7336, -0.6513,\n",
       "           -0.5713, -0.4937, -0.4937, -0.4181, -0.4181, -0.2729, -0.2729, -0.2031,\n",
       "           -0.2031, -0.1350, -0.1350, -0.0686, -0.0686, -0.0037,  0.0597,  0.0597,\n",
       "            0.1217,  0.1217,  0.1823,  0.1823,  0.2416,  0.2996,  0.2996,  0.3565,\n",
       "            0.3565,  0.4122,  0.4122], grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Time to Maturity': [tensor([-0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150, -0.7150,\n",
       "           -0.7150,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,\n",
       "            0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187,  0.7187],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-1.7154, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972,\n",
       "           -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972,\n",
       "           -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972,\n",
       "           -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.5972, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767,\n",
       "           -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.3767, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010, -1.1010,\n",
       "           -1.1010, -1.1010, -1.1010, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804,\n",
       "           -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.8804, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047, -0.6047,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,\n",
       "           -0.3841, -0.3841, -0.3841, -0.3841, -0.3841, -0.3841,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,  0.3327,\n",
       "            0.3327,  0.3327,  0.3327,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495,  1.0495,  1.0495,  1.0495,  1.0495,  1.0495],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701, -0.7701,\n",
       "           -0.7701, -0.7701, -0.7701, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533, -0.0533,\n",
       "           -0.0533, -0.0533,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673,  0.1673],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174],\n",
       "          grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Implied Volatility': [tensor([0.3229, 0.3229, 0.3229, 0.3229, 0.2849, 0.3124, 0.3069, 0.2849, 0.3091,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124,\n",
       "           0.2849, 0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.3124, 0.2849, 0.2849, 0.3124, 0.2849, 0.3124, 0.3124,\n",
       "           0.2849, 0.3124, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124,\n",
       "           0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849, 0.3124, 0.2849,\n",
       "           0.3124, 0.2849, 0.2718, 0.2748, 0.2716, 0.2743, 0.2711, 0.2737, 0.2707,\n",
       "           0.2703, 0.2732, 0.2702, 0.2727, 0.2698, 0.2723, 0.2727, 0.2690, 0.2725,\n",
       "           0.2686, 0.2682, 0.2725, 0.2678, 0.2728, 0.2679, 0.2731, 0.2733, 0.2673,\n",
       "           0.2728, 0.2671, 0.2741, 0.2675, 0.2740, 0.2677, 0.2746, 0.2683, 0.2736,\n",
       "           0.2683, 0.2765, 0.2685, 0.2687, 0.2779, 0.2691, 0.2785, 0.2690, 0.2798,\n",
       "           0.2698, 0.2794, 0.2702, 0.2821, 0.2717, 0.2804, 0.2721, 0.2733, 0.2824,\n",
       "           0.2738, 0.2876, 0.2745, 0.2879, 0.2901, 0.2760, 0.2937, 0.2965, 0.2775,\n",
       "           0.2782, 0.3004, 0.2794, 0.2990, 0.2804, 0.3029, 0.2818, 0.3037, 0.2827,\n",
       "           0.3085, 0.2857, 0.3088, 0.2875, 0.2885, 0.3089, 0.2892, 0.3089, 0.2918,\n",
       "           0.3089, 0.2932, 0.3089, 0.2943, 0.3089, 0.2964, 0.3089, 0.2965, 0.2998,\n",
       "           0.3089, 0.3015, 0.3089, 0.3042, 0.3089, 0.3091, 0.3089, 0.3096, 0.3089,\n",
       "           0.3127, 0.3089, 0.3116, 0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3116, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3089, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116,\n",
       "           0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3089,\n",
       "           0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.3116, 0.3089, 0.2797,\n",
       "           0.2829, 0.2824, 0.2786, 0.2784, 0.2819, 0.2780, 0.2817, 0.2818, 0.2776,\n",
       "           0.2817, 0.2816, 0.2770, 0.2811, 0.2771, 0.2814, 0.2765, 0.2808, 0.2811,\n",
       "           0.2764, 0.2811, 0.2763, 0.2814, 0.2762, 0.2819, 0.2763, 0.2819, 0.2772,\n",
       "           0.2824, 0.2767, 0.2824, 0.2767, 0.2765, 0.2817, 0.2764, 0.2824, 0.2765,\n",
       "           0.2841, 0.2772, 0.2777, 0.2852, 0.2783, 0.2858, 0.2779, 0.2783, 0.2871,\n",
       "           0.2791, 0.2882, 0.2807, 0.2927, 0.2812, 0.2968, 0.2818, 0.2938, 0.2823,\n",
       "           0.2938, 0.2829, 0.2975, 0.2839, 0.2978, 0.3004, 0.2849, 0.3000, 0.2853,\n",
       "           0.2980, 0.2856, 0.2870, 0.2999, 0.2999]),\n",
       "   tensor([0.4101, 0.7247, 0.3801, 0.3801, 0.7247, 0.7247, 0.3801, 0.3801, 0.3801,\n",
       "           0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.7247, 0.3801, 0.3801, 0.7247,\n",
       "           0.3801, 0.7247, 0.3801, 0.3801, 0.7247, 0.3801, 0.7247, 0.7247, 0.3801,\n",
       "           0.7104, 0.6707, 0.3801, 0.5372, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.5191, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3962, 0.3962, 0.3481, 0.3962, 0.3481, 0.3962,\n",
       "           0.3481, 0.3962, 0.3481, 0.3855, 0.3962, 0.3481, 0.3055, 0.3962, 0.3481,\n",
       "           0.3962, 0.3347, 0.3962, 0.3481, 0.3962, 0.3493, 0.3909, 0.3374, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355,\n",
       "           0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632, 0.3355, 0.3632,\n",
       "           0.3355, 0.3632, 0.3355, 0.3355, 0.3632, 0.3632, 0.3355, 0.3355, 0.3355,\n",
       "           0.3632, 0.3355, 0.3570, 0.3318, 0.3277, 0.3231, 0.3379, 0.3194, 0.3372,\n",
       "           0.3129, 0.3226, 0.3094, 0.3147, 0.3068, 0.3101, 0.3040, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.4610, 0.3484,\n",
       "           0.4610, 0.3484, 0.4610, 0.3484, 0.4610, 0.4610, 0.3484, 0.3484, 0.3484,\n",
       "           0.4352, 0.3484, 0.3429, 0.4122, 0.3953, 0.3444, 0.3835, 0.3753, 0.3739,\n",
       "           0.3358, 0.3570, 0.3293, 0.3245, 0.3413, 0.3237, 0.3356, 0.3221, 0.3173,\n",
       "           0.3161, 0.3231, 0.3221, 0.3128, 0.3187, 0.3110, 0.4089, 0.3532, 0.4089,\n",
       "           0.3532, 0.3532, 0.4089, 0.3306, 0.4089, 0.3532, 0.3439, 0.4089, 0.4089,\n",
       "           0.3356, 0.4089, 0.3532, 0.4089, 0.3407, 0.3976, 0.3439, 0.3822, 0.3405,\n",
       "           0.3716, 0.3346, 0.3633, 0.3286, 0.3605, 0.3439, 0.3254, 0.3225, 0.3393,\n",
       "           0.3182, 0.3260, 0.3226, 0.3096, 0.3162, 0.3071, 0.3090, 0.3064, 0.3063,\n",
       "           0.3047, 0.3030, 0.2998, 0.3005, 0.2977, 0.2965, 0.2965, 0.2912, 0.2891,\n",
       "           0.2916, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3792, 0.3370, 0.3370,\n",
       "           0.3792, 0.3792, 0.3370, 0.3792, 0.3370, 0.3370, 0.3396, 0.3792, 0.3317,\n",
       "           0.3690, 0.3352, 0.3646, 0.3534, 0.3273, 0.3442, 0.3353, 0.3286, 0.3150,\n",
       "           0.3222, 0.3121, 0.3166, 0.3108, 0.3126, 0.3070, 0.3071, 0.3081, 0.3051,\n",
       "           0.3024, 0.2994, 0.3020, 0.2969, 0.2969, 0.2973, 0.2949, 0.2960, 0.2921,\n",
       "           0.2897, 0.2912, 0.2858, 0.2854, 0.2883, 0.2834, 0.2882, 0.2870, 0.2810,\n",
       "           0.2792, 0.4797, 0.3385, 0.4674, 0.3353, 0.4503, 0.4401, 0.3400, 0.4230,\n",
       "           0.4074, 0.3331, 0.3976, 0.3877, 0.3264, 0.3230, 0.3690, 0.3173, 0.3187,\n",
       "           0.3479, 0.3088, 0.3357, 0.3313, 0.3114, 0.3227, 0.3064, 0.3177, 0.3004,\n",
       "           0.3160, 0.3030, 0.3108, 0.3012, 0.3054, 0.2979, 0.3003, 0.2969, 0.2962,\n",
       "           0.2937, 0.2944, 0.2927, 0.2910, 0.2922, 0.2887, 0.2859, 0.2885, 0.2833,\n",
       "           0.2873, 0.2841, 0.2864, 0.2803, 0.2793, 0.2844, 0.2800, 0.2844, 0.2784,\n",
       "           0.2795, 0.2819, 0.2738, 0.2798, 0.2748, 0.2798, 0.2702, 0.2723, 0.2790,\n",
       "           0.2723, 0.2720, 0.2796, 0.2711, 0.2788, 0.2671, 0.2767, 0.3372, 0.3342,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3342, 0.3372,\n",
       "           0.3342, 0.3372, 0.3342, 0.3372, 0.3372, 0.3358, 0.3372, 0.3280, 0.3294,\n",
       "           0.3196, 0.3372, 0.3249, 0.3372, 0.3230, 0.3372, 0.3163, 0.3372, 0.3153,\n",
       "           0.3432, 0.3371, 0.3294, 0.3124, 0.3232, 0.3027, 0.3059, 0.3133, 0.3030,\n",
       "           0.3111, 0.3025, 0.3034, 0.2974, 0.3012, 0.2988, 0.2992, 0.2993, 0.2988,\n",
       "           0.2975, 0.2953, 0.2959, 0.2926, 0.2927, 0.2848, 0.2920, 0.2854, 0.2931,\n",
       "           0.2836, 0.2914, 0.2810, 0.2895, 0.2774, 0.2888, 0.2811, 0.2896, 0.2795,\n",
       "           0.2870, 0.2785, 0.2880, 0.2794, 0.2853, 0.2798, 0.2858, 0.2784, 0.2745,\n",
       "           0.2848]),\n",
       "   tensor([0.2326, 0.2317, 0.2282, 0.2274, 0.2262, 0.2286, 0.2275, 0.2275, 0.2253,\n",
       "           0.2231, 0.2252, 0.2221, 0.2242, 0.2214, 0.2234, 0.2208, 0.2237, 0.2205,\n",
       "           0.2228, 0.2202, 0.2189, 0.2221, 0.2196, 0.2191, 0.2213, 0.2206, 0.2165,\n",
       "           0.2205, 0.2173, 0.2197, 0.2155, 0.2196, 0.2158, 0.2193, 0.2160, 0.2197,\n",
       "           0.2146, 0.2190, 0.2151, 0.2186, 0.2185, 0.2146, 0.2190, 0.2126, 0.2185,\n",
       "           0.2138, 0.2143, 0.2194, 0.2124, 0.2191, 0.2165, 0.2191, 0.2195, 0.2172,\n",
       "           0.2204, 0.2174, 0.2188, 0.2225, 0.2123, 0.2231, 0.2166, 0.2241, 0.2156,\n",
       "           0.2246, 0.2205, 0.2279, 0.2139, 0.2274, 0.2198, 0.2342, 0.2137, 0.2299,\n",
       "           0.2137, 0.2315, 0.2137, 0.2330, 0.2137, 0.2343, 0.2118, 0.2344, 0.2137,\n",
       "           0.2403, 0.2137, 0.2851, 0.2756, 0.2723, 0.2813, 0.2715, 0.2803, 0.2693,\n",
       "           0.2780, 0.2765, 0.2693, 0.2769, 0.2686, 0.2743, 0.2650, 0.2631, 0.2702,\n",
       "           0.2635, 0.2691, 0.2620, 0.2671, 0.2661, 0.2596, 0.2626, 0.2575, 0.2631,\n",
       "           0.2605, 0.2620, 0.2561, 0.2587, 0.2552, 0.2597, 0.2544, 0.2574, 0.2528,\n",
       "           0.2525, 0.2541, 0.2505, 0.2537, 0.2489, 0.2523, 0.2479, 0.2518, 0.2509,\n",
       "           0.2470, 0.2495, 0.2457, 0.2441, 0.2480, 0.2421, 0.2461, 0.2412, 0.2426,\n",
       "           0.2400, 0.2426, 0.2386, 0.2373, 0.2405, 0.2399, 0.2363, 0.2391, 0.2347,\n",
       "           0.2343, 0.2371, 0.2337, 0.2367, 0.2335, 0.2322, 0.2346, 0.2308, 0.2326,\n",
       "           0.2310, 0.2327, 0.2294, 0.2290, 0.2307, 0.2303, 0.2287, 0.2286, 0.2274,\n",
       "           0.2257, 0.2274, 0.2252, 0.2272, 0.2258, 0.2262, 0.2241, 0.2263, 0.2237,\n",
       "           0.2248, 0.2233, 0.2247, 0.2241, 0.2232, 0.2236, 0.2233, 0.2210, 0.2212,\n",
       "           0.2228, 0.2210, 0.2228, 0.2207, 0.2222, 0.2199, 0.2216, 0.2200, 0.2227,\n",
       "           0.2214, 0.2224, 0.2200, 0.2225, 0.2187, 0.2213, 0.2184, 0.2222, 0.2184,\n",
       "           0.2183, 0.2221, 0.2227, 0.2177, 0.2217, 0.2180, 0.2215, 0.2215, 0.2196,\n",
       "           0.2218, 0.2205, 0.2209, 0.2231, 0.2218, 0.2229, 0.2236, 0.2226, 0.2259,\n",
       "           0.2230, 0.2268, 0.2239, 0.2280, 0.2259, 0.2283, 0.2255, 0.2265, 0.2251,\n",
       "           0.2313, 0.2810, 0.2642, 0.2789, 0.2642, 0.2775, 0.2642, 0.2761, 0.2642,\n",
       "           0.2745, 0.2731, 0.2712, 0.2642, 0.2700, 0.2692, 0.2605, 0.2646, 0.2607,\n",
       "           0.2646, 0.2567, 0.2628, 0.2558, 0.2533, 0.2591, 0.2552, 0.2589, 0.2534,\n",
       "           0.2562, 0.2553, 0.2502, 0.2548, 0.2519, 0.2500, 0.2468, 0.2513, 0.2460,\n",
       "           0.2483, 0.2477, 0.2438, 0.2491, 0.2424, 0.2468, 0.2421, 0.2451, 0.2413,\n",
       "           0.2436, 0.2401, 0.2389, 0.2422, 0.2416, 0.2369, 0.2402, 0.2358, 0.2394,\n",
       "           0.2343, 0.2371, 0.2335, 0.2375, 0.2324, 0.2365, 0.2320, 0.2356, 0.2305,\n",
       "           0.2351, 0.2304, 0.2321, 0.2333, 0.2310, 0.2283, 0.2297, 0.2277, 0.2306,\n",
       "           0.2271, 0.2265, 0.2257, 0.2275, 0.2251, 0.2274, 0.2246, 0.2256, 0.2238,\n",
       "           0.2232, 0.2258, 0.2227, 0.2252, 0.2221, 0.2240, 0.2219, 0.2241, 0.2213,\n",
       "           0.2231, 0.2207, 0.2233, 0.2203, 0.2222, 0.2198, 0.2197, 0.2214, 0.2222,\n",
       "           0.2181, 0.2218, 0.2184, 0.2181, 0.2174, 0.2210, 0.2172, 0.2167, 0.2203,\n",
       "           0.2181, 0.2200, 0.2174, 0.2199, 0.2166, 0.2194, 0.2190, 0.2164, 0.2192,\n",
       "           0.2183, 0.2150, 0.2183, 0.2152, 0.2189, 0.2186, 0.2172, 0.2180, 0.2156,\n",
       "           0.2182, 0.2162, 0.2179, 0.2191, 0.2163, 0.2195, 0.2188, 0.2174, 0.2206,\n",
       "           0.2193, 0.2218, 0.2173, 0.2220, 0.2211, 0.2226, 0.2208, 0.2229]),\n",
       "   tensor([0.3600, 0.3587, 0.3557, 0.4459, 0.3539, 0.4343, 0.3496, 0.3521, 0.4066,\n",
       "           0.3464, 0.3444, 0.3424, 0.3633, 0.3404, 0.3564, 0.3388, 0.3491, 0.3375,\n",
       "           0.3425, 0.3351, 0.3372, 0.3307, 0.3313, 0.3277, 0.3263, 0.3217, 0.3271,\n",
       "           0.3212, 0.3253, 0.3166, 0.3235, 0.3180, 0.3231, 0.3128, 0.3222, 0.3124,\n",
       "           0.3200, 0.3197, 0.3105, 0.3187, 0.3090, 0.3170, 0.3088, 0.3177, 0.3164,\n",
       "           0.3044, 0.3156, 0.3043, 0.3150, 0.3042, 0.3148])]},\n",
       " 'Query Points': {'Log Moneyness': [tensor([1.1041, 2.0259, 1.3264, 1.8550, 1.9495, 1.1251, 1.2873, 0.7924, 1.3264,\n",
       "           0.9078, 1.4959, 1.7736, 1.3841, 0.7208, 0.3318, 0.6223, 1.2676, 0.8851,\n",
       "           1.2276, 1.4776, 1.2476, 1.6555, 1.8389, 2.0108, 1.1041, 1.9803, 1.7736,\n",
       "           0.4410, 2.1294, 1.1665, 2.0108, 1.5857, 0.8622, 0.2469, 0.1889, 2.2570,\n",
       "           0.8622, 1.3650, 0.9527, 1.2873, 0.9078, 0.1296, 2.2983, 2.2709, 1.5141,\n",
       "           0.4141, 1.6898, 1.7068, 1.6383, 1.7404, 2.2292, 1.3458, 1.4959, 1.7068,\n",
       "           1.3458, 2.1294, 1.1251, 0.2755, 1.0617, 2.1002, 2.2152, 1.1665, 0.5971,\n",
       "           1.4591, 0.3038, 1.2276, 0.8159, 1.5680, 0.1594, 0.9303, 0.7688, 1.9184,\n",
       "           0.8622, 1.5501, 1.1870, 2.0259, 0.9078, 1.3650, 2.1002, 0.7924],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-5.0170e-01, -1.1634e+00, -8.5421e-01, -5.0170e-01, -8.9631e-01,\n",
       "           -7.7189e-01, -6.1427e-01, -9.8249e-01, -3.2373e-01, -6.5284e-01,\n",
       "           -7.7189e-01, -1.3570e+00, -4.6518e-01, -6.0912e-02, -3.5842e-01,\n",
       "            1.0579e-03, -1.3073e+00, -8.9631e-01, -5.7623e-01, -8.5421e-01,\n",
       "           -6.5284e-01, -6.9195e-01, -1.4591e+00, -6.9195e-01, -1.2585e+00,\n",
       "           -2.2222e-01, -6.5284e-01, -4.6518e-01, -4.6518e-01, -1.8919e-01,\n",
       "           -3.9355e-01, -1.4076e+00, -1.5116e+00, -3.2373e-01, -1.3570e+00,\n",
       "           -1.0266e+00, -4.6518e-01, -4.2913e-01, -1.4591e+00, -8.9631e-01,\n",
       "           -9.3906e-01, -1.2431e-01, -1.0266e+00, -7.7189e-01, -1.2105e+00,\n",
       "           -9.8249e-01, -2.8948e-01, -3.2373e-01, -1.5652e+00, -1.2585e+00,\n",
       "           -6.9195e-01, -9.8249e-01, -7.7189e-01, -5.3872e-01, -1.0266e+00,\n",
       "           -8.5421e-01, -1.2585e+00, -9.3906e-01, -1.5656e-01, -1.2105e+00,\n",
       "           -1.7904e+00, -1.4076e+00, -8.9631e-01, -1.2585e+00, -1.0714e+00,\n",
       "           -1.4076e+00, -1.2585e+00, -1.0714e+00, -6.9195e-01, -1.5652e+00,\n",
       "           -6.9195e-01, -9.8249e-01, -1.0714e+00, -8.1274e-01, -1.5656e-01,\n",
       "           -6.9195e-01, -6.9195e-01, -1.1634e+00, -1.0714e+00, -1.9723e+00,\n",
       "           -5.0170e-01, -8.5421e-01, -1.1634e+00, -1.3570e+00, -1.1170e+00,\n",
       "           -1.1634e+00, -1.3570e+00, -1.1634e+00, -6.1427e-01, -1.4591e+00,\n",
       "           -7.3163e-01, -1.5116e+00, -1.8919e-01, -5.7623e-01, -1.1170e+00,\n",
       "           -5.3872e-01, -1.3073e+00, -8.5421e-01, -8.5421e-01, -6.1427e-01,\n",
       "           -2.2222e-01, -7.3163e-01], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.1037, -0.6994,  0.2229,  0.4252, -0.1836, -0.8193,  0.6499,  0.0939,\n",
       "           -0.0723,  0.3991, -0.0880, -0.3681,  0.7442,  0.2229, -0.3508, -0.3165,\n",
       "            0.6499, -0.7587,  0.1376,  0.5523, -0.6413,  0.4511,  0.3460, -0.1354,\n",
       "            0.7673,  0.5523,  0.2645, -0.4383,  0.0939,  0.6499, -0.3855,  0.6499,\n",
       "            0.1085,  0.7673, -0.0723, -0.2659,  0.7210, -0.3508, -0.1674,  0.2368,\n",
       "            0.5022, -0.2996,  0.6975, -0.6799, -0.1514,  0.2783,  0.1085,  0.1376,\n",
       "           -0.8605,  0.2645, -0.1999, -0.2996,  0.2368,  0.7442, -0.5288,  0.0792,\n",
       "           -0.4741, -0.0880, -0.6605,  0.0644,  0.1663,  0.2368,  0.1231,  0.5770,\n",
       "           -0.0260, -0.7190,  0.6016,  0.3191,  0.5022,  0.3191, -0.0260, -0.3681,\n",
       "           -0.2493, -0.0568, -0.1354,  0.1520, -0.0414, -0.1514, -0.1037, -0.5104,\n",
       "            0.1947, -0.7989, -0.0568, -0.5845,  0.1520, -0.0880, -0.2827,  0.3727,\n",
       "           -0.0414, -0.7989,  0.2920, -0.5472], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.6513, -1.3910,  0.2416, -0.5713, -1.2870, -1.8517, -0.8185, -1.6118,\n",
       "           -0.3446, -1.7897, -1.9151, -0.0037, -0.3446],\n",
       "          grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Time to Maturity': [tensor([ 0.0018,  0.0018, -0.7150,  0.0018,  0.0018,  0.0018, -0.7150,  0.7187,\n",
       "           -0.7150,  0.7187,  0.0018, -0.7150,  0.0018,  0.7187,  0.7187,  0.7187,\n",
       "           -0.7150,  0.0018, -0.7150,  0.0018, -0.7150,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.7187,  0.0018,  0.7187,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.7187,  0.0018,  0.7187,  0.0018,  0.0018,  0.0018,\n",
       "            0.0018,  0.0018,  0.0018,  0.0018, -0.7150,  0.0018,  0.0018,  0.0018,\n",
       "           -0.7150, -0.7150,  0.0018,  0.0018, -0.7150, -0.7150, -0.7150,  0.0018,\n",
       "            0.7187,  0.7187,  0.7187,  0.0018,  0.0018,  0.0018,  0.0018, -0.7150,\n",
       "            0.0018, -0.7150,  0.7187,  0.0018,  0.7187,  0.0018,  0.0018,  0.0018,\n",
       "            0.7187,  0.0018,  0.0018,  0.0018,  0.7187,  0.0018,  0.0018,  0.7187],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.8804, -0.3841, -1.1010,  0.3327,  1.0495, -1.5972, -1.1010, -1.1010,\n",
       "            0.3327, -0.6047, -1.3767,  1.0495, -0.6047,  0.3327, -0.6047,  0.3327,\n",
       "           -0.6047, -0.8804, -1.1010, -0.3841, -0.6047, -0.8804, -0.3841, -1.5972,\n",
       "           -0.6047,  0.3327, -0.3841, -0.6047, -0.8804, -0.3841, -0.3841, -0.8804,\n",
       "           -1.5972, -0.3841, -0.3841, -0.8804, -0.3841, -0.8804,  0.3327, -1.1010,\n",
       "           -0.8804,  1.0495,  1.0495, -0.6047, -0.6047, -0.3841, -0.6047, -0.6047,\n",
       "            1.0495,  0.3327, -0.6047, -1.5972, -0.8804,  1.0495, -1.1010,  1.0495,\n",
       "           -0.6047,  1.0495, -0.3841, -1.5972,  1.0495,  1.0495, -0.3841, -1.5972,\n",
       "            0.3327, -1.5972, -1.3767, -0.8804, -1.1010, -1.3767,  0.3327,  0.3327,\n",
       "           -1.3767, -0.8804,  0.3327, -1.7154, -0.8804,  1.0495,  1.0495,  1.0495,\n",
       "            1.0495, -0.6047, -0.8804, -1.5972, -0.3841, -1.5972,  0.3327,  0.3327,\n",
       "           -0.8804, -0.6047, -1.1010, -1.5972,  0.3327, -0.3841,  1.0495,  0.3327,\n",
       "           -0.3841, -1.5972, -1.3767,  0.3327, -0.3841,  0.3327],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([ 0.1673,  0.1673, -0.0533, -0.0533,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "           -0.7701,  0.1673,  0.1673,  0.1673, -0.0533, -0.7701, -0.0533, -0.0533,\n",
       "           -0.0533,  0.1673, -0.0533, -0.0533,  0.1673, -0.7701, -0.0533, -0.7701,\n",
       "            0.1673,  0.1673, -0.0533, -0.0533, -0.7701, -0.0533, -0.0533,  0.1673,\n",
       "           -0.7701, -0.0533, -0.0533, -0.0533,  0.1673,  0.1673,  0.1673,  0.1673,\n",
       "            0.1673, -0.0533,  0.1673,  0.1673, -0.7701, -0.0533,  0.1673, -0.0533,\n",
       "           -0.0533,  0.1673, -0.0533,  0.1673,  0.1673, -0.0533,  0.1673, -0.0533,\n",
       "            0.1673, -0.7701, -0.0533, -0.7701,  0.1673, -0.0533, -0.0533,  0.1673,\n",
       "           -0.0533, -0.0533,  0.1673, -0.0533, -0.0533,  0.1673,  0.1673, -0.0533,\n",
       "           -0.0533, -0.0533, -0.7701, -0.0533, -0.0533, -0.0533, -0.7701, -0.0533,\n",
       "            0.1673, -0.0533, -0.7701,  0.1673,  0.1673, -0.0533,  0.1673, -0.7701,\n",
       "           -0.7701,  0.1673, -0.7701,  0.1673], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174, 3.6174,\n",
       "           3.6174, 3.6174, 3.6174, 3.6174], grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Implied Volatility': [tensor([0.3085, 0.3116, 0.2849, 0.3116, 0.3116, 0.3089, 0.2849, 0.2774, 0.3124,\n",
       "           0.2800, 0.3116, 0.2849, 0.3057, 0.2848, 0.2772, 0.2829, 0.2849, 0.2911,\n",
       "           0.3229, 0.3116, 0.2849, 0.3089, 0.3116, 0.3089, 0.2856, 0.3116, 0.3089,\n",
       "           0.2765, 0.3089, 0.2872, 0.3116, 0.3116, 0.2740, 0.2688, 0.2822, 0.3089,\n",
       "           0.2895, 0.3048, 0.2942, 0.3089, 0.2760, 0.2733, 0.3116, 0.3116, 0.2849,\n",
       "           0.2672, 0.3089, 0.3089, 0.2849, 0.2849, 0.3116, 0.3089, 0.3124, 0.3124,\n",
       "           0.2849, 0.3116, 0.3009, 0.2779, 0.2837, 0.3089, 0.3089, 0.3089, 0.2765,\n",
       "           0.3124, 0.2727, 0.2849, 0.2890, 0.3116, 0.2792, 0.2772, 0.2854, 0.3116,\n",
       "           0.2788, 0.3089, 0.2902, 0.3089, 0.2902, 0.3089, 0.3116, 0.2866]),\n",
       "   tensor([0.3331, 0.3792, 0.3632, 0.2953, 0.3212, 0.3801, 0.3153, 0.3355, 0.2859,\n",
       "           0.3278, 0.3962, 0.3372, 0.3044, 0.2785, 0.2967, 0.2794, 0.4089, 0.3464,\n",
       "           0.3263, 0.3174, 0.3109, 0.3256, 0.3792, 0.3801, 0.3532, 0.2837, 0.3050,\n",
       "           0.3021, 0.3295, 0.2847, 0.2945, 0.3484, 0.3801, 0.2892, 0.3792, 0.4487,\n",
       "           0.2964, 0.3143, 0.3435, 0.3632, 0.4214, 0.2859, 0.3126, 0.3410, 0.3496,\n",
       "           0.3274, 0.2932, 0.2939, 0.3360, 0.3296, 0.3172, 0.7247, 0.3365, 0.2949,\n",
       "           0.3632, 0.3165, 0.4089, 0.3026, 0.2834, 0.7247, 0.3342, 0.3372, 0.3232,\n",
       "           0.7247, 0.3554, 0.7247, 0.3481, 0.4610, 0.3592, 0.3962, 0.3043, 0.3103,\n",
       "           0.3481, 0.3401, 0.2750, 0.4484, 0.3654, 0.3168, 0.3152, 0.3372, 0.2934,\n",
       "           0.3235, 0.3484, 0.3801, 0.3792, 0.7247, 0.3363, 0.3754, 0.3477, 0.4089,\n",
       "           0.3396, 0.7247, 0.2817, 0.3015, 0.3372, 0.2935, 0.3370, 0.7247, 0.3962,\n",
       "           0.2948, 0.2819, 0.2994]),\n",
       "   tensor([0.2287, 0.2577, 0.2192, 0.2196, 0.2295, 0.2642, 0.2217, 0.2220, 0.2258,\n",
       "           0.2151, 0.2285, 0.2442, 0.2301, 0.2175, 0.2465, 0.2403, 0.2238, 0.2579,\n",
       "           0.2217, 0.2225, 0.2597, 0.2207, 0.2183, 0.2325, 0.2231, 0.2173, 0.2193,\n",
       "           0.2479, 0.2217, 0.2272, 0.2469, 0.2193, 0.2180, 0.2287, 0.2292, 0.2414,\n",
       "           0.2187, 0.2380, 0.2288, 0.2198, 0.2165, 0.2437, 0.2198, 0.2647, 0.2302,\n",
       "           0.2212, 0.2195, 0.2228, 0.2852, 0.2166, 0.2381, 0.2352, 0.2176, 0.2267,\n",
       "           0.2480, 0.2230, 0.2453, 0.2294, 0.2602, 0.2212, 0.2211, 0.2197, 0.2235,\n",
       "           0.2171, 0.2268, 0.2723, 0.2201, 0.2220, 0.2248, 0.2146, 0.2256, 0.2426,\n",
       "           0.2374, 0.2289, 0.2297, 0.2226, 0.2281, 0.2358, 0.2310, 0.2570, 0.2204,\n",
       "           0.2698, 0.2250, 0.2524, 0.2214, 0.2318, 0.2384, 0.2171, 0.2238, 0.2642,\n",
       "           0.2185, 0.2492]),\n",
       "   tensor([0.3301, 0.3884, 0.3060, 0.3280, 0.3755, 0.4660, 0.3333, 0.4248, 0.3245,\n",
       "           0.4548, 0.4785, 0.3126, 0.3192])]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data._utils.collate import default_collate\n",
    "\n",
    "class SurfaceBatchNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_features=1, \n",
    "        momentum=0.1\n",
    "    ):\n",
    "        super(SurfaceBatchNorm, self).__init__()\n",
    "        self.log_moneyness_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.time_to_maturity_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.market_return_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.market_volatility_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.treasury_rate_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Concatenate all tensors from the Input Surface into one tensor for each feature\n",
    "        input_surface_log_moneyness = torch.cat([x for x in batch['Input Surface']['Log Moneyness']])\n",
    "        input_surface_time_to_maturity = torch.cat([x for x in batch['Input Surface']['Time to Maturity']])\n",
    "\n",
    "        # Concatenate Input Surface tensors with Query Points tensors\n",
    "        total_log_moneyness = torch.cat([input_surface_log_moneyness] + [x for x in batch['Query Points']['Log Moneyness']])\n",
    "        total_time_to_maturity = torch.cat([input_surface_time_to_maturity] + [x for x in batch['Query Points']['Time to Maturity']])\n",
    "\n",
    "        # Normalize Log Moneyness and Time to Maturity\n",
    "        norm_log_moneyness = self.log_moneyness_bn(total_log_moneyness.unsqueeze(1)).squeeze(1)\n",
    "        norm_time_to_maturity = self.time_to_maturity_bn(total_time_to_maturity.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Split the normalized results back to corresponding structures\n",
    "        input_surface_sizes = [len(x) for x in batch['Input Surface']['Log Moneyness']]\n",
    "        query_points_sizes = [len(x) for x in batch['Query Points']['Log Moneyness']]\n",
    "        total_input_size = sum(input_surface_sizes)\n",
    "\n",
    "        # Normalizing Market Features\n",
    "        market_features = batch['Market Features']\n",
    "        norm_market_return = self.market_return_bn(market_features['Market Return'].unsqueeze(1)).squeeze(1)\n",
    "        norm_market_volatility = self.market_volatility_bn(market_features['Market Volatility'].unsqueeze(1)).squeeze(1)\n",
    "        norm_treasury_rate = self.treasury_rate_bn(market_features['Treasury Rate'].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Reconstructing the batch with normalized data\n",
    "        output = {\n",
    "            'Datetime': batch['Datetime'],\n",
    "            'Symbol': batch['Symbol'],\n",
    "            'Market Features': {\n",
    "                'Market Return': norm_market_return,\n",
    "                'Market Volatility': norm_market_volatility,\n",
    "                'Treasury Rate': norm_treasury_rate\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': list(torch.split(norm_log_moneyness[:total_input_size], input_surface_sizes)),\n",
    "                'Time to Maturity': list(torch.split(norm_time_to_maturity[:total_input_size], input_surface_sizes)),\n",
    "                'Implied Volatility': batch['Input Surface']['Implied Volatility']\n",
    "            },\n",
    "            'Query Points': {\n",
    "                'Log Moneyness': list(torch.split(norm_log_moneyness[total_input_size:], query_points_sizes)),\n",
    "                'Time to Maturity': list(torch.split(norm_time_to_maturity[total_input_size:], query_points_sizes)),\n",
    "                'Implied Volatility': batch['Query Points']['Implied Volatility']\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Ensure requires_grad is True for query point values\n",
    "        for key in output['Query Points']:\n",
    "            if key != 'Implied Volatility':  # We only set requires_grad for Log Moneyness and Time to Maturity\n",
    "                for tensor in output['Query Points'][key]:\n",
    "                    tensor.requires_grad_()\n",
    "\n",
    "        return output\n",
    "\n",
    "# Usage\n",
    "surfacebatchnorm = SurfaceBatchNorm()\n",
    "processed_batch = surfacebatchnorm(batch)\n",
    "processed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Input Surface': [tensor([[ 2.5797,  1.1175, -0.6514,  ...,  0.9242, -0.6169,  0.7202],\n",
       "          [ 2.5106,  1.1143, -0.6118,  ...,  0.9240, -0.6249,  0.7063],\n",
       "          [ 2.4414,  1.1081, -0.5732,  ...,  0.9248, -0.6319,  0.6934],\n",
       "          ...,\n",
       "          [ 0.6927, -0.2153,  0.6305,  ...,  1.8009,  0.4823,  1.9477],\n",
       "          [ 0.6927, -0.2153,  0.6305,  ...,  1.8009,  0.4823,  1.9477],\n",
       "          [ 0.7100, -0.1950,  0.6664,  ...,  1.7790,  0.4526,  1.9125]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[ 1.3965,  1.8080, -1.3322,  ...,  0.7615, -0.8103,  0.5183],\n",
       "          [ 0.6581,  1.0516, -1.0983,  ...,  0.7090, -0.9440,  0.3138],\n",
       "          [ 0.6581,  1.0516, -1.0983,  ...,  0.7090, -0.9440,  0.3138],\n",
       "          ...,\n",
       "          [-1.5078,  0.2822,  0.4336,  ...,  2.1350,  1.1476,  2.8897],\n",
       "          [-1.4543,  0.2870,  0.4280,  ...,  2.1351,  1.1496,  2.8930],\n",
       "          [-1.4543,  0.2870,  0.4280,  ...,  2.1351,  1.1496,  2.8930]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[-1.7151,  0.4982, -1.0078,  ...,  1.9335,  0.5532,  2.0088],\n",
       "          [-1.6672,  0.4630, -1.0433,  ...,  1.9521,  0.5791,  2.0400],\n",
       "          [-1.6672,  0.4630, -1.0433,  ...,  1.9521,  0.5791,  2.0400],\n",
       "          ...,\n",
       "          [-0.2285, -0.0447, -0.2919,  ...,  2.0556,  0.8137,  2.3514],\n",
       "          [-0.2285, -0.0447, -0.2919,  ...,  2.0556,  0.8137,  2.3514],\n",
       "          [-0.1727, -0.0710, -0.3111,  ...,  2.0552,  0.8185,  2.3605]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[ 0.1294,  0.7644,  0.0303, -1.1677, -0.4407,  0.6319, -0.9902,  0.1805],\n",
       "          [ 0.2101,  0.8035, -0.0279, -1.2120, -0.4597,  0.6353, -0.9687,  0.2157],\n",
       "          [ 0.2771,  0.8450, -0.0785, -1.2495, -0.4744,  0.6403, -0.9479,  0.2485],\n",
       "          [ 0.3284,  0.8923, -0.1196, -1.2799, -0.4854,  0.6458, -0.9292,  0.2771],\n",
       "          [ 0.3284,  0.8923, -0.1196, -1.2799, -0.4854,  0.6458, -0.9292,  0.2771],\n",
       "          [ 0.3621,  0.9490, -0.1491, -1.3027, -0.4931,  0.6507, -0.9140,  0.3000],\n",
       "          [ 0.3621,  0.9490, -0.1491, -1.3027, -0.4931,  0.6507, -0.9140,  0.3000],\n",
       "          [ 0.3753,  1.0185, -0.1652, -1.3174, -0.4982,  0.6542, -0.9034,  0.3161],\n",
       "          [ 0.3216,  1.2100, -0.1490, -1.3202, -0.5003,  0.6549, -0.8984,  0.3244],\n",
       "          [ 0.3216,  1.2100, -0.1490, -1.3202, -0.5003,  0.6549, -0.8984,  0.3244],\n",
       "          [ 0.1318,  1.4682, -0.0679, -1.2858, -0.4881,  0.6536, -0.9070,  0.3105],\n",
       "          [-0.1344,  1.7070,  0.0268, -1.2335, -0.4573,  0.6704, -0.8984,  0.3131],\n",
       "          [-0.3047,  1.8206,  0.0605, -1.1994, -0.4180,  0.7121, -0.8542,  0.3588],\n",
       "          [-0.3047,  1.8206,  0.0605, -1.1994, -0.4180,  0.7121, -0.8542,  0.3588],\n",
       "          [-0.3429,  1.7984,  0.0153, -1.1924, -0.3741,  0.7777, -0.7736,  0.4500],\n",
       "          [-0.3429,  1.7984,  0.0153, -1.1924, -0.3741,  0.7777, -0.7736,  0.4500],\n",
       "          [-0.3701,  1.6619, -0.0972, -1.1982, -0.3092,  0.8849, -0.6378,  0.6064],\n",
       "          [-0.3701,  1.6619, -0.0972, -1.1982, -0.3092,  0.8849, -0.6378,  0.6064],\n",
       "          [-0.5304,  1.4138, -0.2734, -1.2028, -0.2008,  1.0625, -0.4133,  0.8647],\n",
       "          [-0.5304,  1.4138, -0.2734, -1.2028, -0.2008,  1.0625, -0.4133,  0.8647],\n",
       "          [-0.8981,  1.0703, -0.5054, -1.2013, -0.0417,  1.3207, -0.0879,  1.2394],\n",
       "          [-1.3516,  0.7317, -0.7412, -1.2000,  0.1265,  1.5964,  0.2616,  1.6435],\n",
       "          [-1.3516,  0.7317, -0.7412, -1.2000,  0.1265,  1.5964,  0.2616,  1.6435],\n",
       "          [-1.6741,  0.5029, -0.9207, -1.2076,  0.2478,  1.8026,  0.5274,  1.9537],\n",
       "          [-1.8135,  0.3791, -1.0412, -1.2248,  0.3155,  1.9282,  0.6946,  2.1525],\n",
       "          [-1.8300,  0.3162, -1.1245, -1.2480,  0.3488,  2.0018,  0.7983,  2.2794],\n",
       "          [-1.8300,  0.3162, -1.1245, -1.2480,  0.3488,  2.0018,  0.7983,  2.2794],\n",
       "          [-1.7829,  0.2860, -1.1852, -1.2738,  0.3631,  2.0463,  0.8664,  2.3659],\n",
       "          [-1.7829,  0.2860, -1.1852, -1.2738,  0.3631,  2.0463,  0.8664,  2.3659],\n",
       "          [-1.6179,  0.2745, -1.2653, -1.3253,  0.3645,  2.0922,  0.9493,  2.4786],\n",
       "          [-1.6179,  0.2745, -1.2653, -1.3253,  0.3645,  2.0922,  0.9493,  2.4786],\n",
       "          [-1.5256,  0.2804, -1.2916, -1.3493,  0.3584,  2.1036,  0.9763,  2.5185],\n",
       "          [-1.5256,  0.2804, -1.2916, -1.3493,  0.3584,  2.1036,  0.9763,  2.5185],\n",
       "          [-1.4353,  0.2898, -1.3107, -1.3713,  0.3502,  2.1106,  0.9976,  2.5519],\n",
       "          [-1.4353,  0.2898, -1.3107, -1.3713,  0.3502,  2.1106,  0.9976,  2.5519],\n",
       "          [-1.3500,  0.3008, -1.3236, -1.3910,  0.3410,  2.1145,  1.0147,  2.5804],\n",
       "          [-1.3500,  0.3008, -1.3236, -1.3910,  0.3410,  2.1145,  1.0147,  2.5804],\n",
       "          [-1.2706,  0.3117, -1.3312, -1.4082,  0.3312,  2.1163,  1.0285,  2.6049],\n",
       "          [-1.1957,  0.3207, -1.3348, -1.4233,  0.3212,  2.1163,  1.0398,  2.6264],\n",
       "          [-1.1957,  0.3207, -1.3348, -1.4233,  0.3212,  2.1163,  1.0398,  2.6264],\n",
       "          [-1.1233,  0.3262, -1.3359, -1.4369,  0.3110,  2.1149,  1.0492,  2.6456],\n",
       "          [-1.1233,  0.3262, -1.3359, -1.4369,  0.3110,  2.1149,  1.0492,  2.6456],\n",
       "          [-1.0516,  0.3269, -1.3356, -1.4494,  0.3006,  2.1125,  1.0570,  2.6630],\n",
       "          [-1.0516,  0.3269, -1.3356, -1.4494,  0.3006,  2.1125,  1.0570,  2.6630],\n",
       "          [-0.9793,  0.3221, -1.3348, -1.4614,  0.2898,  2.1093,  1.0637,  2.6793],\n",
       "          [-0.9062,  0.3116, -1.3342, -1.4731,  0.2788,  2.1053,  1.0696,  2.6947],\n",
       "          [-0.9062,  0.3116, -1.3342, -1.4731,  0.2788,  2.1053,  1.0696,  2.6947],\n",
       "          [-0.8323,  0.2955, -1.3338, -1.4844,  0.2675,  2.1008,  1.0748,  2.7095],\n",
       "          [-0.8323,  0.2955, -1.3338, -1.4844,  0.2675,  2.1008,  1.0748,  2.7095],\n",
       "          [-0.7582,  0.2743, -1.3338, -1.4956,  0.2562,  2.0958,  1.0794,  2.7238],\n",
       "          [-0.7582,  0.2743, -1.3338, -1.4956,  0.2562,  2.0958,  1.0794,  2.7238]],\n",
       "         grad_fn=<AddBackward0>)],\n",
       " 'Query Points': [tensor([[ 1.5694,  0.6615, -0.0638,  1.3442, -0.0449,  1.3626, -0.0444,  1.3754],\n",
       "          [ 2.6174,  0.4763,  0.5569,  1.4300, -0.3693,  0.7270, -0.8893,  0.3732],\n",
       "          [ 2.3054,  1.0868, -0.4999,  1.0997, -0.2554,  0.9284, -0.6434,  0.6703],\n",
       "          [ 2.8176,  0.6807,  0.4641,  1.3494, -0.4074,  0.7344, -0.8480,  0.4415],\n",
       "          [ 2.7083,  0.5705,  0.5190,  1.3946, -0.3873,  0.7289, -0.8724,  0.4022],\n",
       "          [ 1.7724,  0.7370, -0.0454,  1.3168, -0.0974,  1.2948, -0.1220,  1.2907],\n",
       "          [ 2.4414,  1.1081, -0.5732,  1.0483, -0.2804,  0.9248, -0.6319,  0.6934],\n",
       "          [-0.1127, -0.0359,  0.3560,  1.0401,  0.3866,  2.0490,  0.8171,  2.3450],\n",
       "          [ 2.3054,  1.0868, -0.4999,  1.0997, -0.2554,  0.9284, -0.6434,  0.6703],\n",
       "          [ 0.2062, -0.1690,  0.3878,  1.0512,  0.3626,  1.9946,  0.7426,  2.2559],\n",
       "          [ 3.0570,  1.0055,  0.2165,  1.2063, -0.4346,  0.8061, -0.7080,  0.6336],\n",
       "          [ 1.4280,  0.3734, -0.0749,  1.5245,  0.0069,  1.0134, -0.6955,  0.5085],\n",
       "          [ 2.9699,  1.0634,  0.1461,  1.1910, -0.4089,  0.8624, -0.6318,  0.7247],\n",
       "          [-0.2733,  0.0461,  0.3413,  1.0285,  0.3916,  2.0705,  0.8497,  2.3858],\n",
       "          [-0.6049,  0.2796,  0.1682,  0.8568,  0.3164,  2.1034,  0.9609,  2.5561],\n",
       "          [-0.4263,  0.1364,  0.3113,  1.0005,  0.3865,  2.0893,  0.8851,  2.4335],\n",
       "          [ 2.5106,  1.1143, -0.6118,  1.0224, -0.2922,  0.9240, -0.6249,  0.7063],\n",
       "          [-0.3196,  0.1218, -0.1659,  1.6046,  0.4070,  1.9318,  0.5980,  2.0700],\n",
       "          [ 2.6482,  1.1175, -0.6920,  0.9715, -0.3137,  0.9252, -0.6080,  0.7351],\n",
       "          [ 3.0513,  1.0176,  0.2046,  1.2023, -0.4322,  0.8134, -0.6976,  0.6465],\n",
       "          [ 2.5797,  1.1175, -0.6514,  0.9968, -0.3033,  0.9242, -0.6169,  0.7202],\n",
       "          [ 3.0104,  0.8797,  0.3270,  1.2586, -0.4361,  0.7616, -0.7816,  0.5382],\n",
       "          [ 2.8356,  0.6986,  0.4540,  1.3417, -0.4105,  0.7357, -0.8435,  0.4485],\n",
       "          [ 2.6355,  0.4952,  0.5499,  1.4231, -0.3730,  0.7272, -0.8862,  0.3787],\n",
       "          [ 1.5694,  0.6615, -0.0638,  1.3442, -0.0449,  1.3626, -0.0444,  1.3754],\n",
       "          [ 2.6719,  0.5329,  0.5350,  1.4090, -0.3802,  0.7279, -0.8795,  0.3902],\n",
       "          [ 2.9057,  0.7677,  0.4107,  1.3107, -0.4219,  0.7426, -0.8236,  0.4786],\n",
       "          [-0.5614,  0.2387,  0.2255,  0.9173,  0.3498,  2.1038,  0.9365,  2.5127],\n",
       "          [ 2.4910,  0.3460,  0.5994,  1.4757, -0.3433,  0.7276, -0.9089,  0.3373],\n",
       "          [ 0.7100, -0.1950,  0.6664,  1.1186,  0.2629,  1.7790,  0.4526,  1.9125],\n",
       "          [ 2.6355,  0.4952,  0.5499,  1.4231, -0.3730,  0.7272, -0.8862,  0.3787],\n",
       "          [ 3.0488,  0.9385,  0.2774,  1.2323, -0.4390,  0.7777, -0.7524,  0.5772],\n",
       "          [-0.4241,  0.1132, -0.1697,  1.6169,  0.4278,  1.9581,  0.6275,  2.1018],\n",
       "          [-1.2639,  0.2079, -0.4700,  1.5179,  0.4936,  2.1507,  0.8992,  2.4304],\n",
       "          [-0.6608,  0.3238,  0.1001,  0.7760,  0.2652,  2.0947,  0.9856,  2.6067],\n",
       "          [ 2.3270,  0.1883,  0.6402,  1.5280, -0.3096,  0.7321, -0.9286,  0.2973],\n",
       "          [ 0.0761, -0.1194,  0.3718,  1.0470,  0.3742,  2.0193,  0.7759,  2.2954],\n",
       "          [ 2.9400,  1.0678,  0.1343,  1.1909, -0.4010,  0.8759, -0.6146,  0.7446],\n",
       "          [ 0.0953,  0.1916, -0.1519,  1.5503,  0.3173,  1.8200,  0.4728,  1.9354],\n",
       "          [ 2.7522,  1.0553,  0.0844,  1.2012, -0.3526,  0.9506, -0.5230,  0.8487],\n",
       "          [-0.1993,  0.1367, -0.1619,  1.5895,  0.3820,  1.9006,  0.5630,  2.0324],\n",
       "          [-1.3352,  0.2091, -0.5450,  1.4622,  0.4724,  2.1608,  0.9305,  2.4774],\n",
       "          [ 2.2717,  0.1392,  0.6511,  1.5439, -0.2984,  0.7343, -0.9340,  0.2853],\n",
       "          [ 2.3086,  0.1717,  0.6440,  1.5334, -0.3058,  0.7328, -0.9305,  0.2933],\n",
       "          [ 1.7770,  0.8490, -0.2346,  1.3225, -0.1292,  0.9661, -0.6708,  0.5923],\n",
       "          [-1.1578,  0.1965, -0.3605,  1.5865,  0.5124,  2.1279,  0.8492,  2.3606],\n",
       "          [ 2.9842,  0.8490,  0.3516,  1.2729, -0.4330,  0.7551, -0.7946,  0.5202],\n",
       "          [ 2.9697,  0.8332,  0.3637,  1.2803, -0.4311,  0.7522, -0.8008,  0.5115],\n",
       "          [ 1.5796,  0.6237, -0.1370,  1.4321, -0.0587,  0.9903, -0.6830,  0.5508],\n",
       "          [ 1.4639,  0.4334, -0.0872,  1.5038, -0.0086,  1.0077, -0.6928,  0.5184],\n",
       "          [ 2.3637,  0.2221,  0.6323,  1.5170, -0.3170,  0.7308, -0.9247,  0.3057],\n",
       "          [ 2.9041,  1.0698,  0.1223,  1.1918, -0.3918,  0.8911, -0.5956,  0.7665],\n",
       "          [ 1.8154,  0.8793, -0.2536,  1.3039, -0.1406,  0.9621, -0.6691,  0.5986],\n",
       "          [ 1.5003,  0.4953, -0.1013,  1.4816, -0.0246,  1.0020, -0.6898,  0.5288],\n",
       "          [ 2.2397,  1.0720, -0.4656,  1.1251, -0.2424,  0.9311, -0.6480,  0.6601],\n",
       "          [ 2.4910,  0.3460,  0.5994,  1.4757, -0.3433,  0.7276, -0.9089,  0.3373],\n",
       "          [ 0.6711, -0.2312,  0.5968,  1.1018,  0.2824,  1.8222,  0.5109,  1.9817],\n",
       "          [-0.6257,  0.2980,  0.1400,  0.8249,  0.2970,  2.1010,  0.9716,  2.5769],\n",
       "          [ 0.5783, -0.2526,  0.5091,  1.0803,  0.3092,  1.8815,  0.5910,  2.0765],\n",
       "          [ 2.5271,  0.3828,  0.5884,  1.4631, -0.3508,  0.7271, -0.9037,  0.3470],\n",
       "          [ 2.3820,  0.2392,  0.6281,  1.5113, -0.3208,  0.7302, -0.9226,  0.3100],\n",
       "          [ 2.1234,  0.8662, -0.0088,  1.2709, -0.1888,  1.1750, -0.2598,  1.1400],\n",
       "          [-0.9992,  0.1635, -0.2555,  1.6366,  0.5133,  2.0904,  0.7876,  2.2816],\n",
       "          [ 1.9020,  0.9371, -0.2962,  1.2640, -0.1647,  0.9539, -0.6653,  0.6117],\n",
       "          [-1.2297,  0.2057, -0.4324,  1.5431,  0.5017,  2.1440,  0.8828,  2.4069],\n",
       "          [ 2.6482,  1.1175, -0.6920,  0.9715, -0.3137,  0.9252, -0.6080,  0.7351],\n",
       "          [-0.0518, -0.0642,  0.3606,  1.0427,  0.3832,  2.0401,  0.8045,  2.3296],\n",
       "          [ 3.0546,  0.9526,  0.2650,  1.2264, -0.4390,  0.7825, -0.7444,  0.5877],\n",
       "          [-0.6741,  0.3319,  0.0876,  0.7596,  0.2540,  2.0919,  0.9898,  2.6164],\n",
       "          [-0.0615,  0.1595, -0.1574,  1.5715,  0.3523,  1.8636,  0.5215,  1.9878],\n",
       "          [-0.7235,  0.1174, -0.1892,  1.6441,  0.4808,  2.0285,  0.7081,  2.1896],\n",
       "          [ 2.7448,  0.6077,  0.5019,  1.3798, -0.3942,  0.7303, -0.8648,  0.4147],\n",
       "          [ 0.0761, -0.1194,  0.3718,  1.0470,  0.3742,  2.0193,  0.7759,  2.2954],\n",
       "          [ 3.0585,  0.9663,  0.2528,  1.2208, -0.4386,  0.7878, -0.7360,  0.5985],\n",
       "          [ 2.2695,  0.9178,  0.0087,  1.2528, -0.2270,  1.1243, -0.3187,  1.0753],\n",
       "          [ 2.6174,  0.4763,  0.5569,  1.4300, -0.3693,  0.7270, -0.8893,  0.3732],\n",
       "          [ 0.2062, -0.1690,  0.3878,  1.0512,  0.3626,  1.9946,  0.7426,  2.2559],\n",
       "          [ 2.9400,  1.0678,  0.1343,  1.1909, -0.4010,  0.8759, -0.6146,  0.7446],\n",
       "          [ 2.5271,  0.3828,  0.5884,  1.4631, -0.3508,  0.7271, -0.9037,  0.3470],\n",
       "          [-0.1127, -0.0359,  0.3560,  1.0401,  0.3866,  2.0490,  0.8171,  2.3450]],\n",
       "         grad_fn=<AddBackward0>),\n",
       "  tensor([[-2.9348e+00,  4.9448e-01, -7.1478e-01,  1.5736e+00,  6.4471e-01,\n",
       "            1.9591e+00,  4.1785e-01,  1.7388e+00],\n",
       "          [ 1.2354e-01,  1.0139e+00, -6.0114e-01,  1.1656e+00, -2.6964e-01,\n",
       "            1.0438e+00, -4.7875e-01,  8.5221e-01],\n",
       "          [-1.7846e+00,  2.1707e+00, -7.3648e-02,  1.3418e+00,  1.0213e-01,\n",
       "            9.9015e-01, -8.8328e-01,  1.7928e-01],\n",
       "          [-2.2958e+00,  2.0155e-02, -1.2825e-01,  1.3136e+00,  4.2624e-01,\n",
       "            2.1875e+00,  1.0284e+00,  2.6326e+00],\n",
       "          [-2.0834e+00, -1.6691e-01,  3.5208e-01,  1.9419e-01,  2.5901e-02,\n",
       "            2.0376e+00,  1.1626e+00,  3.0176e+00],\n",
       "          [ 1.2698e+00,  1.7641e+00, -1.2971e+00, -2.6721e-01, -4.8327e-01,\n",
       "            7.5074e-01, -8.3871e-01,  4.7229e-01],\n",
       "          [-2.8715e+00,  1.6669e+00, -2.6123e-01,  1.4642e+00,  4.4051e-01,\n",
       "            1.4818e+00, -2.7512e-01,  8.7838e-01],\n",
       "          [-1.2884e+00,  2.1739e+00, -1.3669e-01,  1.2101e+00, -4.6697e-02,\n",
       "            8.4528e-01, -1.0209e+00,  4.9927e-02],\n",
       "          [-2.0582e+00,  1.0625e-01, -1.4194e-01,  1.3165e+00,  4.3757e-01,\n",
       "            2.1949e+00,  1.0318e+00,  2.6310e+00],\n",
       "          [-2.9831e+00,  1.9039e-01, -7.3527e-01,  1.6637e+00,  6.1619e-01,\n",
       "            2.0556e+00,  6.1551e-01,  2.0114e+00],\n",
       "          [ 7.7551e-01,  2.1332e+00, -9.2875e-01,  2.6121e-01, -4.1190e-01,\n",
       "            6.8692e-01, -1.0110e+00,  2.0482e-01],\n",
       "          [-1.5185e+00,  6.8557e-02,  3.5311e-01, -3.3290e-01, -5.6349e-01,\n",
       "            1.6254e+00,  9.7838e-01,  3.0620e+00],\n",
       "          [-2.7870e+00,  2.9310e-01, -8.2266e-01,  1.5996e+00,  6.0698e-01,\n",
       "            2.0938e+00,  6.9456e-01,  2.1239e+00],\n",
       "          [-1.6527e+00,  1.7692e-01, -1.9138e-01,  1.2831e+00,  4.3280e-01,\n",
       "            2.2033e+00,  1.0498e+00,  2.6544e+00],\n",
       "          [-2.6160e+00,  3.0575e-01, -8.7882e-01,  1.5702e+00,  6.0652e-01,\n",
       "            2.1132e+00,  7.2992e-01,  2.1717e+00],\n",
       "          [-1.5499e+00,  1.8004e-01, -2.0596e-01,  1.2708e+00,  4.2899e-01,\n",
       "            2.2049e+00,  1.0555e+00,  2.6630e+00],\n",
       "          [ 5.1498e-01,  1.0773e+00, -4.7841e-01,  1.1780e+00, -3.5503e-01,\n",
       "            7.7422e-01, -8.8818e-01,  3.4068e-01],\n",
       "          [-9.7659e-01,  1.1510e+00, -9.6470e-02,  1.6861e+00,  2.1319e-01,\n",
       "            1.0696e+00, -8.3920e-01,  1.8435e-01],\n",
       "          [-2.9396e+00,  1.5692e+00, -3.2284e-01,  1.4544e+00,  4.7417e-01,\n",
       "            1.5495e+00, -1.8041e-01,  9.9475e-01],\n",
       "          [-2.7028e+00, -1.2587e-01, -8.0714e-01,  1.5850e+00,  5.2650e-01,\n",
       "            2.0780e+00,  7.2235e-01,  2.1785e+00],\n",
       "          [-2.9831e+00,  1.9039e-01, -7.3527e-01,  1.6637e+00,  6.1619e-01,\n",
       "            2.0556e+00,  6.1551e-01,  2.0114e+00],\n",
       "          [-2.9244e+00,  6.0248e-01, -4.0120e-01,  1.7520e+00,  6.2928e-01,\n",
       "            1.7703e+00,  8.5636e-02,  1.2889e+00],\n",
       "          [-3.1326e-01,  1.5319e+00, -5.1804e-02,  1.2758e+00, -4.1631e-01,\n",
       "            7.5589e-01, -8.5732e-01,  4.1068e-01],\n",
       "          [ 1.3656e+00,  1.8261e+00, -1.3098e+00, -2.7296e-01, -4.8243e-01,\n",
       "            7.5461e-01, -8.3166e-01,  4.8187e-01],\n",
       "          [ 5.6687e-01,  1.0581e+00, -5.1488e-01,  1.1776e+00, -3.3896e-01,\n",
       "            7.9645e-01, -8.6276e-01,  3.6775e-01],\n",
       "          [-1.9075e+00,  1.4315e-01, -1.5835e-01,  1.3076e+00,  4.3814e-01,\n",
       "            2.1985e+00,  1.0374e+00,  2.6373e+00],\n",
       "          [-2.8903e+00,  1.2570e-01, -7.2023e-01,  1.6233e+00,  5.6168e-01,\n",
       "            2.1224e+00,  7.8249e-01,  2.2541e+00],\n",
       "          [-2.7870e+00,  2.9310e-01, -8.2266e-01,  1.5996e+00,  6.0698e-01,\n",
       "            2.0938e+00,  6.9456e-01,  2.1239e+00],\n",
       "          [-2.8871e+00,  4.7738e-01, -7.5600e-01,  1.5519e+00,  6.4570e-01,\n",
       "            1.9787e+00,  4.5270e-01,  1.7859e+00],\n",
       "          [-2.1923e+00,  2.4485e-01, -8.6826e-01,  1.5529e+00,  5.6952e-01,\n",
       "            2.1753e+00,  8.7177e-01,  2.3706e+00],\n",
       "          [-2.5582e+00,  2.4065e-01, -7.7778e-01,  1.5959e+00,  5.6892e-01,\n",
       "            2.1503e+00,  8.2844e-01,  2.3141e+00],\n",
       "          [ 2.5841e-01,  1.1054e+00, -4.7642e-01,  1.0816e+00, -3.1374e-01,\n",
       "            7.0960e-01, -1.0433e+00,  1.1899e-01],\n",
       "          [ 6.6025e-01,  9.5998e-01, -1.0980e+00, -1.4141e-01, -4.5501e-01,\n",
       "            7.1097e-01, -9.4397e-01,  3.1208e-01],\n",
       "          [-2.4383e+00,  2.4771e-01, -8.0653e-01,  1.5827e+00,  5.6977e-01,\n",
       "            2.1589e+00,  8.4304e-01,  2.3330e+00],\n",
       "          [-7.6890e-02,  1.4741e+00, -2.1879e-01,  1.2140e+00, -4.0971e-01,\n",
       "            8.0201e-01, -7.8452e-01,  5.0264e-01],\n",
       "          [ 7.1002e-02,  1.3323e+00, -3.4319e-01,  1.3134e+00, -1.2143e-01,\n",
       "            8.1649e-01, -1.0140e+00,  7.9380e-02],\n",
       "          [-2.6723e+00,  2.2550e-01, -7.5224e-01,  1.6073e+00,  5.6748e-01,\n",
       "            2.1416e+00,  8.1411e-01,  2.2956e+00],\n",
       "          [-2.8337e+00,  4.5970e-01, -7.9389e-01,  1.5326e+00,  6.4682e-01,\n",
       "            1.9961e+00,  4.8314e-01,  1.8269e+00],\n",
       "          [ 1.0730e+00,  4.8986e-01, -6.5287e-02,  6.6080e-01, -6.0864e-01,\n",
       "            9.5801e-01, -3.2984e-01,  1.1852e+00],\n",
       "          [-1.5871e+00,  2.1905e+00, -9.0426e-02,  1.2952e+00,  4.4762e-02,\n",
       "            9.3011e-01, -9.4398e-01,  1.1892e-01],\n",
       "          [-4.9613e-01,  1.2534e+00, -1.7390e-01,  1.5480e+00,  7.3950e-02,\n",
       "            9.4718e-01, -9.4326e-01,  9.7542e-02],\n",
       "          [-1.5078e+00,  2.8218e-01,  4.3362e-01,  3.9470e-01,  2.2493e-01,\n",
       "            2.1350e+00,  1.1476e+00,  2.8897e+00],\n",
       "          [-1.8332e+00, -2.1611e-01,  2.6013e-01,  1.7866e-02, -1.2961e-01,\n",
       "            1.9520e+00,  1.1521e+00,  3.0783e+00],\n",
       "          [-2.8814e+00,  3.1392e-02, -6.8016e-01,  1.7326e+00,  6.2828e-01,\n",
       "            2.0040e+00,  5.0669e-01,  1.8539e+00],\n",
       "          [ 5.9957e-01,  1.0282e+00, -5.4432e-01,  1.1874e+00, -3.1492e-01,\n",
       "            8.2334e-01, -8.3577e-01,  3.9368e-01],\n",
       "          [-1.5612e+00, -5.0439e-02, -9.1311e-01,  1.4233e+00,  3.0377e-01,\n",
       "            1.7981e+00,  3.9227e-01,  1.8059e+00],\n",
       "          [-2.4965e+00,  3.0565e-01, -9.1640e-01,  1.5515e+00,  6.0644e-01,\n",
       "            2.1251e+00,  7.5109e-01,  2.1999e+00],\n",
       "          [-2.5565e+00,  3.0632e-01, -8.9764e-01,  1.5608e+00,  6.0650e-01,\n",
       "            2.1193e+00,  7.4072e-01,  2.1861e+00],\n",
       "          [-1.5046e+00,  1.3972e-01,  6.4533e-01, -3.6794e-01, -7.5253e-01,\n",
       "            1.4235e+00,  8.1287e-01,  2.9488e+00],\n",
       "          [ 9.1749e-01,  5.2486e-01, -4.1187e-01,  4.6398e-01, -5.9431e-01,\n",
       "            1.1520e+00,  8.8957e-03,  1.6414e+00],\n",
       "          [-2.9853e+00,  1.4709e-01, -7.1835e-01,  1.6826e+00,  6.2057e-01,\n",
       "            2.0445e+00,  5.9046e-01,  1.9746e+00],\n",
       "          [ 9.9754e-01,  1.6268e+00, -1.2251e+00, -2.3250e-01, -4.8240e-01,\n",
       "            7.2960e-01, -8.7981e-01,  4.1484e-01],\n",
       "          [-2.5214e+00,  7.3754e-01, -1.9579e-01,  1.8436e+00,  5.6602e-01,\n",
       "            1.5672e+00, -2.3209e-01,  8.7716e-01],\n",
       "          [-2.0549e+00,  8.7392e-02,  4.6479e-01,  4.0194e-01,  2.0490e-01,\n",
       "            2.1178e+00,  1.1386e+00,  2.8940e+00],\n",
       "          [-1.1871e+00,  2.1454e+00, -1.5875e-01,  1.1756e+00, -8.0682e-02,\n",
       "            8.1694e-01, -1.0438e+00,  3.2209e-02],\n",
       "          [-2.1280e+00, -1.3980e-01,  3.7829e-01,  2.3889e-01,  6.3373e-02,\n",
       "            2.0556e+00,  1.1601e+00,  2.9958e+00],\n",
       "          [ 5.6687e-01,  1.0581e+00, -5.1488e-01,  1.1776e+00, -3.3896e-01,\n",
       "            7.9645e-01, -8.6276e-01,  3.6775e-01],\n",
       "          [-2.0175e+00, -1.9088e-01,  3.2196e-01,  1.4163e-01, -1.8837e-02,\n",
       "            2.0149e+00,  1.1631e+00,  3.0400e+00],\n",
       "          [-2.1307e+00,  2.4134e-01, -8.8391e-01,  1.5449e+00,  5.6906e-01,\n",
       "            2.1791e+00,  8.7870e-01,  2.3798e+00],\n",
       "          [ 7.3367e-01,  1.4422e+00, -1.1260e+00, -1.7759e-01, -4.7268e-01,\n",
       "            7.0671e-01, -9.3205e-01,  3.3822e-01],\n",
       "          [-1.6064e+00, -1.3878e-01,  1.0211e+00, -2.2315e-01, -8.1081e-01,\n",
       "            1.2984e+00,  6.8219e-01,  2.8375e+00],\n",
       "          [-1.5206e+00,  1.1313e-01,  4.1449e-01, -3.5486e-01, -6.1739e-01,\n",
       "            1.5738e+00,  9.3989e-01,  3.0397e+00],\n",
       "          [-2.4829e+00, -1.6928e-01, -8.4896e-01,  1.5536e+00,  4.9199e-01,\n",
       "            2.0356e+00,  6.7105e-01,  2.1189e+00],\n",
       "          [ 7.0101e-01,  1.3808e+00, -1.1135e+00, -1.6865e-01, -4.6986e-01,\n",
       "            7.0507e-01, -9.3804e-01,  3.2854e-01],\n",
       "          [-1.2462e+00, -5.8466e-02, -7.6992e-01,  5.4158e-01, -1.3049e-01,\n",
       "            1.9124e+00,  9.9568e-01,  2.8075e+00],\n",
       "          [ 6.5912e-01,  1.1420e+00, -1.0988e+00, -1.5050e-01, -4.6116e-01,\n",
       "            7.0703e-01, -9.4413e-01,  3.1541e-01],\n",
       "          [ 1.1078e-01,  1.7289e+00, -7.4553e-01,  3.6198e-01, -3.8740e-01,\n",
       "            6.6408e-01, -1.0754e+00,  1.0744e-01],\n",
       "          [ 2.1134e-01,  1.3304e+00, -4.0658e-01,  1.2327e+00, -1.8196e-01,\n",
       "            7.8477e-01, -1.0199e+00,  9.5896e-02],\n",
       "          [-2.6233e+00,  1.8748e+00, -1.4746e-01,  1.4645e+00,  3.5003e-01,\n",
       "            1.3214e+00, -4.9038e-01,  6.1933e-01],\n",
       "          [ 1.1227e-01,  1.1873e+00, -7.2686e-01,  3.9772e-01, -3.6908e-01,\n",
       "            6.6896e-01, -1.0867e+00,  8.1915e-02],\n",
       "          [-2.4679e+00, -9.5082e-02, -1.6368e-01,  1.2605e+00,  3.8770e-01,\n",
       "            2.1771e+00,  1.0421e+00,  2.6678e+00],\n",
       "          [-2.1595e+00, -1.7075e-01, -4.9900e-01,  8.8142e-01,  1.4216e-01,\n",
       "            2.0942e+00,  1.0973e+00,  2.8402e+00],\n",
       "          [ 3.4652e-01,  1.9208e+00, -8.2836e-01,  3.0832e-01, -4.0668e-01,\n",
       "            6.6940e-01, -1.0481e+00,  1.5258e-01],\n",
       "          [-2.1051e+00,  8.5956e-01, -1.0529e-01,  1.8514e+00,  4.8519e-01,\n",
       "            1.4110e+00, -4.4858e-01,  6.1182e-01],\n",
       "          [-1.8061e+00,  1.6110e-01, -1.7083e-01,  1.2991e+00,  4.3682e-01,\n",
       "            2.2006e+00,  1.0419e+00,  2.6433e+00],\n",
       "          [ 1.3965e+00,  1.8080e+00, -1.3322e+00, -4.6956e-01, -4.9466e-01,\n",
       "            7.6148e-01, -8.1027e-01,  5.1829e-01],\n",
       "          [-2.9244e+00,  6.0248e-01, -4.0120e-01,  1.7520e+00,  6.2928e-01,\n",
       "            1.7703e+00,  8.5636e-02,  1.2889e+00],\n",
       "          [-1.5760e+00, -1.5149e-01,  2.2193e-01, -1.6957e-01, -3.2319e-01,\n",
       "            1.8215e+00,  1.0976e+00,  3.0985e+00],\n",
       "          [-1.7326e+00, -2.0998e-01,  2.3636e-01, -4.7693e-02, -1.9280e-01,\n",
       "            1.9120e+00,  1.1386e+00,  3.0904e+00],\n",
       "          [-1.8047e+00, -5.7185e-01,  1.2811e+00,  1.6766e-02, -7.2776e-01,\n",
       "            1.2927e+00,  6.3425e-01,  2.7707e+00],\n",
       "          [-2.0231e+00,  1.1405e-01,  4.6760e-01,  4.0898e-01,  2.1213e-01,\n",
       "            2.1211e+00,  1.1374e+00,  2.8884e+00],\n",
       "          [-2.3971e+00, -7.5958e-02, -6.2496e-01,  1.7876e+00,  5.9596e-01,\n",
       "            1.8763e+00,  2.9555e-01,  1.5723e+00],\n",
       "          [ 3.3828e-01,  1.2876e+00, -4.8431e-01,  1.1309e+00, -2.5710e-01,\n",
       "            7.4942e-01, -1.0199e+00,  1.2666e-01],\n",
       "          [ 6.6517e-01,  1.2287e+00, -1.1007e+00, -1.5541e-01, -4.6409e-01,\n",
       "            7.0550e-01, -9.4362e-01,  3.1777e-01],\n",
       "          [-2.9048e-02,  7.9043e-01, -7.0602e-01,  1.1907e+00, -1.7552e-01,\n",
       "            1.1742e+00, -3.2658e-01,  1.0189e+00],\n",
       "          [ 7.7593e-01,  1.4932e+00, -1.1424e+00, -1.8794e-01, -4.7535e-01,\n",
       "            7.0967e-01, -9.2386e-01,  3.5080e-01],\n",
       "          [ 1.0563e+00,  5.4311e-01, -1.9048e-01,  5.8880e-01, -6.0703e-01,\n",
       "            1.0207e+00, -2.1792e-01,  1.3370e+00],\n",
       "          [ 2.4806e-01,  2.9866e-01, -7.4689e-01,  3.3463e-01, -4.7905e-01,\n",
       "            1.4730e+00,  4.9242e-01,  2.2562e+00],\n",
       "          [-3.0105e+00,  5.4635e-01, -5.5721e-01,  1.6629e+00,  6.4142e-01,\n",
       "            1.8749e+00,  2.6694e-01,  1.5333e+00],\n",
       "          [ 3.0099e-01,  1.0810e+00, -3.4131e-01,  1.2194e+00, -3.7227e-01,\n",
       "            7.2560e-01, -9.5820e-01,  2.5547e-01],\n",
       "          [-2.4409e+00,  1.9744e+00, -1.0479e-01,  1.4497e+00,  2.9289e-01,\n",
       "            1.2330e+00, -6.0288e-01,  4.8783e-01],\n",
       "          [ 6.6025e-01,  9.5998e-01, -1.0980e+00, -1.4141e-01, -4.5501e-01,\n",
       "            7.1097e-01, -9.4397e-01,  3.1208e-01],\n",
       "          [-1.8569e+00,  1.5284e-01, -1.6446e-01,  1.3036e+00,  4.3763e-01,\n",
       "            2.1996e+00,  1.0396e+00,  2.6401e+00],\n",
       "          [-2.8210e+00,  1.7983e-01, -7.2515e-01,  1.6198e+00,  5.6441e-01,\n",
       "            2.1295e+00,  7.9419e-01,  2.2697e+00],\n",
       "          [-1.6434e+00, -1.8828e-01,  2.2275e-01, -1.1109e-01, -2.5807e-01,\n",
       "            1.8679e+00,  1.1201e+00,  3.0969e+00],\n",
       "          [-2.3377e+00, -1.1842e-03, -1.2993e-01,  1.3084e+00,  4.2149e-01,\n",
       "            2.1858e+00,  1.0294e+00,  2.6361e+00],\n",
       "          [ 3.1810e-02,  1.4062e+00, -3.0923e-01,  1.1887e+00, -3.9577e-01,\n",
       "            8.3793e-01, -7.3422e-01,  5.6307e-01],\n",
       "          [ 1.1665e+00,  1.7065e+00, -1.2754e+00, -2.5703e-01, -4.8360e-01,\n",
       "            7.4412e-01, -8.5121e-01,  4.5501e-01],\n",
       "          [ 6.9131e-01,  2.0596e+00, -9.2416e-01,  2.5891e-01, -4.1692e-01,\n",
       "            6.8374e-01, -1.0127e+00,  2.0461e-01],\n",
       "          [-2.4111e+00, -4.7459e-02, -1.4064e-01,  1.2908e+00,  4.0812e-01,\n",
       "            2.1820e+00,  1.0339e+00,  2.6480e+00],\n",
       "          [-2.2540e+00,  2.4733e-01, -8.5260e-01,  1.5607e+00,  5.6983e-01,\n",
       "            2.1714e+00,  8.6472e-01,  2.3613e+00],\n",
       "          [-2.4885e+00, -1.1730e-01, -1.8104e-01,  1.2391e+00,  3.7381e-01,\n",
       "            2.1737e+00,  1.0478e+00,  2.6812e+00]], grad_fn=<AddBackward0>),\n",
       "  tensor([[-1.1118e+00,  1.4173e+00,  4.8602e-01,  1.6191e+00,  1.7126e-01,\n",
       "            1.5452e+00,  1.0234e-01,  1.4902e+00],\n",
       "          [ 1.0308e+00,  2.0813e+00,  4.5211e-01,  1.1309e+00, -5.4469e-01,\n",
       "            7.1967e-01, -7.9380e-01,  5.4630e-01],\n",
       "          [-1.2460e+00,  6.0236e-01, -2.1520e-01,  1.6319e+00,  4.2362e-01,\n",
       "            1.9550e+00,  6.1824e-01,  2.0895e+00],\n",
       "          [-8.7896e-01,  3.3375e-01, -3.8371e-01,  1.5616e+00,  4.3700e-01,\n",
       "            2.0219e+00,  7.2477e-01,  2.2259e+00],\n",
       "          [-5.7124e-01,  1.7618e+00,  5.5424e-01,  1.5239e+00, -1.4273e-02,\n",
       "            1.3083e+00, -1.6813e-01,  1.1957e+00],\n",
       "          [ 9.2984e-01,  1.9863e+00,  4.7030e-01,  1.1330e+00, -5.5546e-01,\n",
       "            7.0437e-01, -8.1255e-01,  5.2544e-01],\n",
       "          [-4.6596e-01,  6.9868e-02, -2.0820e-01,  1.4719e+00,  4.2861e-01,\n",
       "            2.0537e+00,  7.9030e-01,  2.3113e+00],\n",
       "          [-1.4767e+00,  8.4849e-01,  2.8278e-01,  1.6824e+00,  3.9600e-01,\n",
       "            1.8644e+00,  4.8556e-01,  1.9197e+00],\n",
       "          [-1.6009e+00,  4.2437e-01, -1.0909e+00,  1.2931e+00,  4.5983e-01,\n",
       "            1.9757e+00,  6.1283e-01,  2.0812e+00],\n",
       "          [-1.0689e+00,  4.0151e-01,  2.2635e-02,  1.6074e+00,  4.6134e-01,\n",
       "            2.0160e+00,  6.9930e-01,  2.1796e+00],\n",
       "          [-1.1865e+00,  1.3554e+00,  4.6958e-01,  1.6319e+00,  2.0080e-01,\n",
       "            1.5844e+00,  1.4797e-01,  1.5404e+00],\n",
       "          [ 7.4737e-01,  2.2388e+00,  5.3251e-01,  1.2573e+00, -4.0065e-01,\n",
       "            8.6103e-01, -6.5391e-01,  6.8365e-01],\n",
       "          [ 1.0753e-03, -7.8636e-02, -6.8819e-01,  1.3553e+00,  3.5955e-01,\n",
       "            2.0383e+00,  8.1410e-01,  2.3718e+00],\n",
       "          [-1.2181e+00,  3.4075e-01, -1.3008e+00,  1.1929e+00,  4.6988e-01,\n",
       "            2.0568e+00,  7.4672e-01,  2.2548e+00],\n",
       "          [ 9.3848e-01,  2.1582e+00,  1.0224e-01,  1.2103e+00, -4.1599e-01,\n",
       "            8.7963e-01, -6.1475e-01,  7.4356e-01],\n",
       "          [ 7.9199e-01,  2.1224e+00,  1.1121e-01,  1.2433e+00, -3.7157e-01,\n",
       "            9.2929e-01, -5.6171e-01,  7.9885e-01],\n",
       "          [-2.6544e-01,  3.2999e-02, -6.0191e-01,  1.4230e+00,  3.9165e-01,\n",
       "            2.0426e+00,  7.9617e-01,  2.3364e+00],\n",
       "          [ 9.8537e-01,  2.0343e+00,  4.5861e-01,  1.1303e+00, -5.5077e-01,\n",
       "            7.1192e-01, -8.0288e-01,  5.3645e-01],\n",
       "          [-1.3204e+00,  7.3283e-01, -1.4820e-01,  1.6433e+00,  3.9525e-01,\n",
       "            1.9026e+00,  5.4870e-01,  2.0073e+00],\n",
       "          [-5.4663e-01,  1.6117e-01, -5.0586e-01,  1.4892e+00,  4.1790e-01,\n",
       "            2.0395e+00,  7.7025e-01,  2.2927e+00],\n",
       "          [ 1.0627e+00,  2.1270e+00,  4.5118e-01,  1.1352e+00, -5.3660e-01,\n",
       "            7.2827e-01, -7.8465e-01,  5.5567e-01],\n",
       "          [-7.3966e-01,  2.0900e-01, -1.4680e+00,  1.0732e+00,  4.2993e-01,\n",
       "            2.0750e+00,  8.1047e-01,  2.3537e+00],\n",
       "          [-1.0494e+00,  4.3822e-01, -3.1433e-01,  1.5959e+00,  4.3885e-01,\n",
       "            2.0024e+00,  6.8938e-01,  2.1784e+00],\n",
       "          [-1.6908e+00,  4.7955e-01, -1.0259e+00,  1.3126e+00,  4.4673e-01,\n",
       "            1.9431e+00,  5.6649e-01,  2.0248e+00],\n",
       "          [-1.7269e-01, -7.1020e-02, -3.1107e-01,  1.3953e+00,  3.9644e-01,\n",
       "            2.0552e+00,  8.1855e-01,  2.3605e+00],\n",
       "          [-7.1555e-01,  1.9791e-01, -1.1665e-01,  1.5313e+00,  4.4819e-01,\n",
       "            2.0450e+00,  7.5996e-01,  2.2643e+00],\n",
       "          [-1.1896e+00,  5.4528e-01, -2.4798e-01,  1.6221e+00,  4.3159e-01,\n",
       "            1.9739e+00,  6.4520e-01,  2.1224e+00],\n",
       "          [ 1.1383e+00,  2.1799e+00,  8.1431e-02,  1.1556e+00, -4.8641e-01,\n",
       "            8.0342e-01, -6.9481e-01,  6.6107e-01],\n",
       "          [-1.3918e+00,  3.6507e-01, -1.2210e+00,  1.2395e+00,  4.7395e-01,\n",
       "            2.0322e+00,  7.0031e-01,  2.1918e+00],\n",
       "          [-2.6544e-01,  3.2999e-02, -6.0191e-01,  1.4230e+00,  3.9165e-01,\n",
       "            2.0426e+00,  7.9617e-01,  2.3364e+00],\n",
       "          [ 1.0434e+00,  2.1762e+00,  9.3097e-02,  1.1842e+00, -4.5004e-01,\n",
       "            8.4235e-01, -6.5414e-01,  7.0280e-01],\n",
       "          [-4.6596e-01,  6.9868e-02, -2.0820e-01,  1.4719e+00,  4.2861e-01,\n",
       "            2.0537e+00,  7.9030e-01,  2.3113e+00],\n",
       "          [-1.3737e+00,  3.6261e-01, -1.2305e+00,  1.2345e+00,  4.7408e-01,\n",
       "            2.0357e+00,  7.0628e-01,  2.1996e+00],\n",
       "          [ 6.3350e-02, -1.0380e-01, -7.0770e-01,  1.3387e+00,  3.5100e-01,\n",
       "            2.0363e+00,  8.1756e-01,  2.3796e+00],\n",
       "          [-9.8765e-01,  1.2673e+00,  3.0445e-02,  1.5780e+00,  1.8226e-01,\n",
       "            1.6036e+00,  1.9096e-01,  1.6069e+00],\n",
       "          [ 4.8538e-01,  2.0249e+00,  1.2048e-01,  1.3065e+00, -2.8193e-01,\n",
       "            1.0322e+00, -4.5022e-01,  9.1622e-01],\n",
       "          [-2.8584e-01, -1.7509e-02, -2.7195e-01,  1.4259e+00,  4.1005e-01,\n",
       "            2.0556e+00,  8.0842e-01,  2.3420e+00],\n",
       "          [ 6.7057e-01,  2.2259e+00,  5.4123e-01,  1.2756e+00, -3.7849e-01,\n",
       "            8.8449e-01, -6.2972e-01,  7.0826e-01],\n",
       "          [-6.9995e-01,  1.6908e+00,  5.4356e-01,  1.5470e+00,  2.7085e-02,\n",
       "            1.3599e+00, -1.0994e-01,  1.2586e+00],\n",
       "          [-1.3483e+00,  6.1564e-01,  1.5824e-01,  1.6609e+00,  4.4684e-01,\n",
       "            1.9588e+00,  6.1080e-01,  2.0676e+00],\n",
       "          [-8.3868e-01,  2.6513e-01, -6.9790e-02,  1.5588e+00,  4.5503e-01,\n",
       "            2.0377e+00,  7.4190e-01,  2.2380e+00],\n",
       "          [ 7.0147e-01,  2.0963e+00,  1.1510e-01,  1.2626e+00, -3.4487e-01,\n",
       "            9.5961e-01, -5.2907e-01,  8.3308e-01],\n",
       "          [-3.4468e-01,  1.0669e-02, -2.5133e-01,  1.4413e+00,  4.1651e-01,\n",
       "            2.0554e+00,  8.0279e-01,  2.3322e+00],\n",
       "          [ 1.0432e+00,  2.0967e+00,  4.5116e-01,  1.1319e+00, -5.4226e-01,\n",
       "            7.2240e-01, -7.9081e-01,  5.4942e-01],\n",
       "          [-1.7151e+00,  4.9823e-01, -1.0078e+00,  1.3174e+00,  4.4249e-01,\n",
       "            1.9335e+00,  5.5319e-01,  2.0088e+00],\n",
       "          [-1.1686e+00,  5.2695e-01, -2.5892e-01,  1.6184e+00,  4.3354e-01,\n",
       "            1.9795e+00,  6.5336e-01,  2.1326e+00],\n",
       "          [-1.4715e+00,  8.2048e-01,  2.6926e-01,  1.6816e+00,  4.0376e-01,\n",
       "            1.8773e+00,  5.0190e-01,  1.9386e+00],\n",
       "          [-1.3204e+00,  7.3283e-01, -1.4820e-01,  1.6433e+00,  3.9525e-01,\n",
       "            1.9026e+00,  5.4870e-01,  2.0073e+00],\n",
       "          [ 9.2894e-01,  1.9382e+00,  1.2793e-01,  1.1261e+00, -5.6561e-01,\n",
       "            7.0707e-01, -8.0406e-01,  5.4379e-01],\n",
       "          [-1.3086e+00,  5.7753e-01,  1.3531e-01,  1.6537e+00,  4.5182e-01,\n",
       "            1.9713e+00,  6.2865e-01,  2.0895e+00],\n",
       "          [-5.3026e-02,  1.8055e+00,  1.1438e-01,  1.4091e+00, -1.2371e-01,\n",
       "            1.2204e+00, -2.4278e-01,  1.1372e+00],\n",
       "          [ 3.7382e-01,  2.1525e+00,  5.6385e-01,  1.3412e+00, -2.9418e-01,\n",
       "            9.7689e-01, -5.3240e-01,  8.0872e-01],\n",
       "          [-1.3483e+00,  6.1564e-01,  1.5824e-01,  1.6609e+00,  4.4684e-01,\n",
       "            1.9588e+00,  6.1080e-01,  2.0676e+00],\n",
       "          [ 1.0753e-03, -7.8636e-02, -6.8819e-01,  1.3553e+00,  3.5955e-01,\n",
       "            2.0383e+00,  8.1410e-01,  2.3718e+00],\n",
       "          [ 1.0647e+00,  2.2086e+00,  4.6705e-01,  1.1585e+00, -5.0972e-01,\n",
       "            7.5336e-01, -7.6043e-01,  5.7883e-01],\n",
       "          [-1.3263e+00,  8.4099e-01, -1.0095e-01,  1.6423e+00,  3.6265e-01,\n",
       "            1.8513e+00,  4.8422e-01,  1.9331e+00],\n",
       "          [ 1.0172e+00,  2.2381e+00,  4.8404e-01,  1.1805e+00, -4.8666e-01,\n",
       "            7.7486e-01, -7.3992e-01,  5.9838e-01],\n",
       "          [-1.6223e+00,  4.3561e-01, -1.0757e+00,  1.2980e+00,  4.5708e-01,\n",
       "            1.9683e+00,  6.0219e-01,  2.0682e+00],\n",
       "          [ 1.1237e+00,  2.0772e+00,  7.8650e-02,  1.1153e+00, -5.4798e-01,\n",
       "            7.3641e-01, -7.6618e-01,  5.8723e-01],\n",
       "          [-1.4280e+00,  3.7062e-01, -1.2012e+00,  1.2493e+00,  4.7318e-01,\n",
       "            2.0246e+00,  6.8760e-01,  2.1752e+00],\n",
       "          [-1.4307e+00,  7.2074e-01,  2.1788e-01,  1.6751e+00,  4.2796e-01,\n",
       "            1.9198e+00,  5.5742e-01,  2.0036e+00],\n",
       "          [-1.2283e+00,  5.8292e-01, -2.2614e-01,  1.6290e+00,  4.2665e-01,\n",
       "            1.9617e+00,  6.2769e-01,  2.1010e+00],\n",
       "          [-1.3261e+00,  7.5782e-01, -1.3663e-01,  1.6438e+00,  3.8838e-01,\n",
       "            1.8913e+00,  5.3429e-01,  1.9906e+00],\n",
       "          [-6.5305e-01,  1.6492e-01, -1.3996e-01,  1.5168e+00,  4.4398e-01,\n",
       "            2.0479e+00,  7.6825e-01,  2.2767e+00],\n",
       "          [-1.1684e+00,  1.1076e+00, -1.0486e-02,  1.6109e+00,  2.5744e-01,\n",
       "            1.7031e+00,  3.0670e-01,  1.7343e+00],\n",
       "          [ 1.0739e+00,  2.0390e+00,  8.8949e-02,  1.1155e+00, -5.5475e-01,\n",
       "            7.2708e-01, -7.7743e-01,  5.7476e-01],\n",
       "          [-5.9040e-01,  1.3251e-01, -1.6305e-01,  1.5021e+00,  4.3928e-01,\n",
       "            2.0503e+00,  7.7606e-01,  2.2887e+00],\n",
       "          [-1.0998e+00,  4.7331e-01, -2.9197e-01,  1.6056e+00,  4.3755e-01,\n",
       "            1.9941e+00,  6.7583e-01,  2.1609e+00],\n",
       "          [-6.8475e-01,  2.2946e-01, -4.5649e-01,  1.5201e+00,  4.2767e-01,\n",
       "            2.0344e+00,  7.5388e-01,  2.2676e+00],\n",
       "          [-1.2202e+00,  5.0523e-01,  9.0201e-02,  1.6372e+00,  4.5838e-01,\n",
       "            1.9922e+00,  6.6004e-01,  2.1287e+00],\n",
       "          [-1.3859e+00,  1.1419e+00,  4.0300e-01,  1.6659e+00,  2.9401e-01,\n",
       "            1.7120e+00,  2.9865e-01,  1.7076e+00],\n",
       "          [ 9.9569e-01,  2.1691e+00,  9.7611e-02,  1.1965e+00, -4.3418e-01,\n",
       "            8.5963e-01, -6.3594e-01,  7.2160e-01],\n",
       "          [ 3.6123e-01,  1.9792e+00,  1.2138e-01,  1.3308e+00, -2.4584e-01,\n",
       "            1.0745e+00, -4.0398e-01,  9.6523e-01],\n",
       "          [-1.0579e+00,  1.2105e+00,  1.6838e-02,  1.5907e+00,  2.0990e-01,\n",
       "            1.6397e+00,  2.3282e-01,  1.6529e+00],\n",
       "          [-1.6908e+00,  4.7955e-01, -1.0259e+00,  1.3126e+00,  4.4673e-01,\n",
       "            1.9431e+00,  5.6649e-01,  2.0248e+00],\n",
       "          [-1.3125e+00,  7.0894e-01, -1.5962e-01,  1.6423e+00,  4.0141e-01,\n",
       "            1.9130e+00,  5.6216e-01,  2.0229e+00],\n",
       "          [-1.1179e+00,  1.1573e+00,  3.1576e-03,  1.6016e+00,  2.3489e-01,\n",
       "            1.6729e+00,  2.7134e-01,  1.6953e+00],\n",
       "          [-4.6876e-01,  1.5979e+00,  9.1573e-02,  1.4849e+00,  4.3409e-03,\n",
       "            1.3775e+00, -6.6769e-02,  1.3265e+00],\n",
       "          [-1.6444e+00,  4.4843e-01, -1.0599e+00,  1.3029e+00,  4.5400e-01,\n",
       "            1.9605e+00,  5.9095e-01,  2.0545e+00],\n",
       "          [ 1.1835e+00,  2.1592e+00,  7.2305e-02,  1.1322e+00, -5.1690e-01,\n",
       "            7.7130e-01, -7.2820e-01,  6.2702e-01],\n",
       "          [-1.4011e+00,  6.7665e-01,  1.9353e-01,  1.6701e+00,  4.3677e-01,\n",
       "            1.9370e+00,  5.8052e-01,  2.0311e+00],\n",
       "          [ 9.9478e-01,  1.9834e+00,  1.0880e-01,  1.1200e+00, -5.6164e-01,\n",
       "            7.1553e-01, -7.9238e-01,  5.5758e-01],\n",
       "          [-1.5800e+00,  4.1456e-01, -1.1053e+00,  1.2882e+00,  4.6229e-01,\n",
       "            1.9826e+00,  6.2292e-01,  2.0937e+00],\n",
       "          [ 1.0763e+00,  2.1702e+00,  4.5610e-01,  1.1440e+00, -5.2550e-01,\n",
       "            7.3887e-01, -7.7421e-01,  5.6580e-01],\n",
       "          [-1.4435e+00,  7.4407e-01,  2.3036e-01,  1.6772e+00,  4.2280e-01,\n",
       "            1.9103e+00,  5.4483e-01,  1.9887e+00],\n",
       "          [-9.0635e-01,  1.3277e+00,  4.3870e-02,  1.5634e+00,  1.5193e-01,\n",
       "            1.5642e+00,  1.4568e-01,  1.5573e+00],\n",
       "          [ 2.5351e-01,  2.1148e+00,  5.6902e-01,  1.3662e+00, -2.5997e-01,\n",
       "            1.0156e+00, -4.9092e-01,  8.5207e-01],\n",
       "          [-9.3651e-01,  2.7130e-01, -1.4029e+00,  1.1218e+00,  4.4916e-01,\n",
       "            2.0722e+00,  7.9029e-01,  2.3201e+00],\n",
       "          [-1.5598e+00,  4.0600e-01, -1.1191e+00,  1.2833e+00,  4.6446e-01,\n",
       "            1.9891e+00,  6.3249e-01,  2.1055e+00],\n",
       "          [ 9.4929e-01,  2.0025e+00,  4.6586e-01,  1.1318e+00, -5.5403e-01,\n",
       "            7.0689e-01, -8.0923e-01,  5.2926e-01],\n",
       "          [-1.1027e+00,  3.1684e-01, -1.3447e+00,  1.1633e+00,  4.6268e-01,\n",
       "            2.0654e+00,  7.6765e-01,  2.2852e+00],\n",
       "          [ 1.0720e+00,  2.1965e+00,  4.6273e-01,  1.1529e+00, -5.1564e-01,\n",
       "            7.4794e-01, -7.6556e-01,  5.7398e-01]], grad_fn=<AddBackward0>),\n",
       "  tensor([[-1.6741,  0.5029, -0.9207, -1.2076,  0.2478,  1.8026,  0.5274,  1.9537],\n",
       "          [ 0.1318,  1.4682, -0.0679, -1.2858, -0.4881,  0.6536, -0.9070,  0.3105],\n",
       "          [-0.9793,  0.3221, -1.3348, -1.4614,  0.2898,  2.1093,  1.0637,  2.6793],\n",
       "          [-1.8135,  0.3791, -1.0412, -1.2248,  0.3155,  1.9282,  0.6946,  2.1525],\n",
       "          [-0.1344,  1.7070,  0.0268, -1.2335, -0.4573,  0.6704, -0.8984,  0.3131],\n",
       "          [ 0.2101,  0.8035, -0.0279, -1.2120, -0.4597,  0.6353, -0.9687,  0.2157],\n",
       "          [-0.8981,  1.0703, -0.5054, -1.2013, -0.0417,  1.3207, -0.0879,  1.2394],\n",
       "          [ 0.3753,  1.0185, -0.1652, -1.3174, -0.4982,  0.6542, -0.9034,  0.3161],\n",
       "          [-1.7066,  0.2748, -1.2307, -1.2999,  0.3669,  2.0743,  0.9141,  2.4293],\n",
       "          [ 0.2771,  0.8450, -0.0785, -1.2495, -0.4744,  0.6403, -0.9479,  0.2485],\n",
       "          [ 0.1294,  0.7644,  0.0303, -1.1677, -0.4407,  0.6319, -0.9902,  0.1805],\n",
       "          [-1.2706,  0.3117, -1.3312, -1.4082,  0.3312,  2.1163,  1.0285,  2.6049],\n",
       "          [-1.7066,  0.2748, -1.2307, -1.2999,  0.3669,  2.0743,  0.9141,  2.4293]],\n",
       "         grad_fn=<AddBackward0>)]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class EllipticalRBFKernel(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_dim, \n",
    "        bandwidth\n",
    "    ):\n",
    "        super(EllipticalRBFKernel, self).__init__()\n",
    "        self.bandwidth = bandwidth\n",
    "        # Initialize the log of the scale vector to zero, which corresponds to scale factors of one\n",
    "        self.log_scale = nn.Parameter(torch.zeros(input_dim))\n",
    "\n",
    "    def forward(self, distances):\n",
    "        # Convert log scale to actual scale values\n",
    "        scale = torch.exp(self.log_scale)\n",
    "        \n",
    "        # Create a diagonal scale matrix\n",
    "        scale_matrix = torch.diag(scale)\n",
    "\n",
    "        # Calculate the scaled distances\n",
    "        scaled_distances = distances @ scale_matrix @ distances.t()\n",
    "        \n",
    "        # Normalize by the trace of the scale matrix\n",
    "        trace_scale_matrix = torch.trace(scale_matrix)\n",
    "        normalized_distances = scaled_distances / trace_scale_matrix\n",
    "\n",
    "        # Compute the RBF kernel output using the normalized distances\n",
    "        kernel_values = torch.exp(-normalized_distances / (2 * self.bandwidth ** 2))\n",
    "\n",
    "        return kernel_values\n",
    "\n",
    "class SurfaceContinuousKernelPositionalEmbedding(nn.Module):\n",
    "    def __init__(self, d_embedding):\n",
    "        super(SurfaceContinuousKernelPositionalEmbedding, self).__init__()\n",
    "        self.d_embedding = d_embedding\n",
    "\n",
    "        # Initialize multiple RBF kernels, each with a different fixed bandwidth\n",
    "        self.kernels = nn.ModuleList()\n",
    "        for i in range(1, d_embedding + 1):\n",
    "            bandwidth_value = torch.erfinv(torch.tensor(i / (d_embedding + 1))) * np.sqrt(2)\n",
    "            self.kernels.append(EllipticalRBFKernel(bandwidth=bandwidth_value, input_dim=2))\n",
    "\n",
    "        self.input_surface_layer_norm = nn.LayerNorm(d_embedding)\n",
    "        self.query_points_layer_norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "        # Initialize learnable scaling parameter (the base for positional embedding)\n",
    "        self.log_scale = nn.Parameter(torch.log(torch.tensor(10000.0)))\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        input_surface_batch, \n",
    "        query_points_batch\n",
    "    ):\n",
    "        batch_size = len(input_surface_batch['Log Moneyness'])\n",
    "\n",
    "        input_surface_embeddings = []\n",
    "        query_points_embeddings = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Extract the coordinates and implied volatilities for each surface in the batch\n",
    "            surface_coords = torch.stack([\n",
    "                input_surface_batch['Log Moneyness'][i], \n",
    "                input_surface_batch['Time to Maturity'][i]\n",
    "            ], dim=-1)\n",
    "            surface_ivs = input_surface_batch['Implied Volatility'][i]\n",
    "\n",
    "            query_coords = torch.stack([\n",
    "                query_points_batch['Log Moneyness'][i], \n",
    "                query_points_batch['Time to Maturity'][i]\n",
    "            ], dim=-1)\n",
    "\n",
    "            all_coords = torch.cat((surface_coords, query_coords), dim=0)\n",
    "\n",
    "            # Compute the pairwise differences between all points and the input surface points\n",
    "            point_differences = all_coords.unsqueeze(1) - surface_coords.unsqueeze(0)  # (n+m, n, 2)\n",
    "\n",
    "            # Initialize the output embeddings for the current surface with d_embedding channels\n",
    "            all_embedded = torch.zeros((all_coords.shape[0], self.d_embedding), dtype=torch.float32, device=surface_coords.device)\n",
    "\n",
    "            for kernel_idx, kernel in enumerate(self.kernels):\n",
    "                # Apply the RBF kernel to each distance vector using torch.vmap\n",
    "                vmap_kernel = torch.vmap(kernel, in_dims=(0,))\n",
    "                kernel_outputs = vmap_kernel(point_differences.view(-1, point_differences.shape[-1]))  # ((n+m) * n)\n",
    "                kernel_outputs = kernel_outputs.view(all_coords.shape[0], surface_coords.shape[0])  # (n+m, n)\n",
    "\n",
    "                # Compute the weighted sum of IVs based on the kernel outputs\n",
    "                weighted_sum = (kernel_outputs * surface_ivs.unsqueeze(0)).sum(dim=1)\n",
    "                normalization_factor = kernel_outputs.sum(dim=1)\n",
    "\n",
    "                all_embedded[:, kernel_idx] = weighted_sum / normalization_factor\n",
    "\n",
    "            # Split the embeddings into input surface and query points embeddings\n",
    "            input_surface_embedded = all_embedded[:surface_coords.shape[0], :]\n",
    "            query_points_embedded = all_embedded[surface_coords.shape[0]:, :]\n",
    "\n",
    "            # Normalize the embedded surfaces\n",
    "            input_surface_embedded = self.input_surface_layer_norm(input_surface_embedded)\n",
    "            query_points_embedded = self.query_points_layer_norm(query_points_embedded)\n",
    "\n",
    "            # Positional embedding for input surface points\n",
    "            input_surface_pe = self._compute_positional_embedding(surface_coords)\n",
    "\n",
    "            # Positional embedding for query points\n",
    "            query_points_pe = self._compute_positional_embedding(query_coords)\n",
    "\n",
    "            # Add positional embeddings with a factor of sqrt(2)\n",
    "            input_surface_final = input_surface_embedded + input_surface_pe * np.sqrt(2)\n",
    "            query_points_final = query_points_embedded + query_points_pe * np.sqrt(2)\n",
    "\n",
    "            # Append the encoded surface for this input surface to the batch list\n",
    "            input_surface_embeddings.append(input_surface_final)\n",
    "            query_points_embeddings.append(query_points_final)\n",
    "\n",
    "        # Keep all encoded surfaces as lists to handle variable lengths\n",
    "        return {\n",
    "            'Input Surface': input_surface_embeddings,\n",
    "            'Query Points': query_points_embeddings\n",
    "        }\n",
    "\n",
    "    def _compute_positional_embedding(\n",
    "        self, \n",
    "        coords, \n",
    "    ):\n",
    "        positional_embedding = torch.zeros(coords.size(0), self.d_embedding, device=coords.device)\n",
    "\n",
    "        for i in range(self.d_embedding // 4):\n",
    "            div_factor = torch.exp(self.log_scale) ** (4 * i / self.d_embedding)\n",
    "            positional_embedding[:, 4 * i] = torch.sin(coords[:, 0] / div_factor)\n",
    "            positional_embedding[:, 4 * i + 1] = torch.cos(coords[:, 0] / div_factor)\n",
    "            positional_embedding[:, 4 * i + 2] = torch.sin(coords[:, 1] / div_factor)\n",
    "            positional_embedding[:, 4 * i + 3] = torch.cos(coords[:, 1] / div_factor)\n",
    "\n",
    "        return positional_embedding\n",
    "\n",
    "# Example of initializing and using this module\n",
    "d_embedding = HYPERPARAMETERS['Surface Embedding']['Embedding Dimension']  # Desired number of output channels\n",
    "\n",
    "continuous_kernel_positional_embedding = SurfaceContinuousKernelPositionalEmbedding(d_embedding=d_embedding)\n",
    "kernel_positional_embedded_batch = continuous_kernel_positional_embedding(processed_batch['Input Surface'], processed_batch['Query Points'])\n",
    "kernel_positional_embedded_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 1.9445,  0.5113, -1.2225,  ...,  0.3218, -1.1887,  0.1219],\n",
       "         [ 1.9201,  0.5216, -1.2073,  ...,  0.3310, -1.2205,  0.1129],\n",
       "         [ 1.8941,  0.5291, -1.1922,  ...,  0.3414, -1.2523,  0.1045],\n",
       "         ...,\n",
       "         [ 1.6405, -0.1604, -0.8763,  ...,  1.4830, -1.4023, -0.5574],\n",
       "         [ 1.5223, -0.4795, -0.5474,  ...,  1.5152, -1.5193, -0.7181],\n",
       "         [-0.1815, -0.9409, -0.8970,  ...,  2.2985, -0.7164,  0.3199]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[ 1.1722,  1.5662, -1.4404,  ...,  0.5642, -0.9407,  0.3314],\n",
       "         [ 0.8662,  1.3928, -1.4840,  ...,  0.9343, -1.2776,  0.4055],\n",
       "         [ 0.8662,  1.3928, -1.4840,  ...,  0.9343, -1.2776,  0.4055],\n",
       "         ...,\n",
       "         [-1.2376, -0.6706, -0.8891,  ...,  2.1195, -0.3624,  0.5512],\n",
       "         [-1.1061, -0.4833, -1.2120,  ...,  2.0781, -0.4209,  0.4089],\n",
       "         [-1.2496, -0.6847, -0.8856,  ...,  2.1084, -0.3361,  0.5780]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[-1.7979, -0.0045, -1.2248,  ...,  1.1584,  0.0400,  1.2194],\n",
       "         [-1.7618, -0.0382, -1.2570,  ...,  1.1666,  0.0557,  1.2377],\n",
       "         [-1.7618, -0.0382, -1.2570,  ...,  1.1666,  0.0557,  1.2377],\n",
       "         ...,\n",
       "         [ 0.7399,  0.5797, -0.6987,  ...,  1.8029, -1.6950, -0.6902],\n",
       "         [-0.5326, -0.4615, -1.5179,  ...,  2.1066, -0.4853,  0.3880],\n",
       "         [ 0.7689,  0.6596, -0.7325,  ...,  1.7601, -1.6816, -0.6917]],\n",
       "        grad_fn=<NativeLayerNormBackward0>),\n",
       " tensor([[ 3.5964e-01,  1.3225e+00,  2.0935e-01, -1.6073e+00, -5.0488e-01,\n",
       "           1.1216e+00, -1.3380e+00,  4.3710e-01],\n",
       "         [ 4.5791e-01,  1.3331e+00,  1.0702e-01, -1.6392e+00, -5.2979e-01,\n",
       "           1.0850e+00, -1.2804e+00,  4.6627e-01],\n",
       "         [ 5.3021e-01,  1.3452e+00,  1.9965e-02, -1.6603e+00, -5.4810e-01,\n",
       "           1.0515e+00, -1.2275e+00,  4.8917e-01],\n",
       "         [ 5.7627e-01,  1.3646e+00, -4.9995e-02, -1.6721e+00, -5.6137e-01,\n",
       "           1.0200e+00, -1.1819e+00,  5.0449e-01],\n",
       "         [ 5.7627e-01,  1.3646e+00, -4.9995e-02, -1.6721e+00, -5.6137e-01,\n",
       "           1.0200e+00, -1.1819e+00,  5.0449e-01],\n",
       "         [ 5.9584e-01,  1.3964e+00, -1.0162e-01, -1.6753e+00, -5.7091e-01,\n",
       "           9.8957e-01, -1.1451e+00,  5.1115e-01],\n",
       "         [ 5.9584e-01,  1.3964e+00, -1.0162e-01, -1.6753e+00, -5.7091e-01,\n",
       "           9.8957e-01, -1.1451e+00,  5.1115e-01],\n",
       "         [ 5.8718e-01,  1.4447e+00, -1.3363e-01, -1.6700e+00, -5.7755e-01,\n",
       "           9.5898e-01, -1.1179e+00,  5.0817e-01],\n",
       "         [ 4.6752e-01,  1.6017e+00, -1.3324e-01, -1.6285e+00, -5.8177e-01,\n",
       "           8.9309e-01, -1.0900e+00,  4.7117e-01],\n",
       "         [ 4.6752e-01,  1.6017e+00, -1.3324e-01, -1.6285e+00, -5.8177e-01,\n",
       "           8.9309e-01, -1.0900e+00,  4.7117e-01],\n",
       "         [ 1.8828e-01,  1.8133e+00, -5.4458e-02, -1.5353e+00, -5.6542e-01,\n",
       "           8.2281e-01, -1.0748e+00,  4.0558e-01],\n",
       "         [-1.5402e-01,  1.9690e+00,  3.1839e-02, -1.4213e+00, -5.2640e-01,\n",
       "           7.7387e-01, -1.0349e+00,  3.6190e-01],\n",
       "         [-3.6565e-01,  2.0131e+00,  4.3105e-02, -1.3670e+00, -4.9240e-01,\n",
       "           7.7243e-01, -9.8065e-01,  3.7701e-01],\n",
       "         [-3.6565e-01,  2.0131e+00,  4.3105e-02, -1.3670e+00, -4.9240e-01,\n",
       "           7.7243e-01, -9.8065e-01,  3.7701e-01],\n",
       "         [-4.3679e-01,  1.9755e+00, -3.3220e-02, -1.3938e+00, -4.7187e-01,\n",
       "           8.2563e-01, -9.2196e-01,  4.5651e-01],\n",
       "         [-4.3679e-01,  1.9755e+00, -3.3220e-02, -1.3938e+00, -4.7187e-01,\n",
       "           8.2563e-01, -9.2196e-01,  4.5651e-01],\n",
       "         [-5.0704e-01,  1.8470e+00, -1.9089e-01, -1.4664e+00, -4.3653e-01,\n",
       "           9.4683e-01, -8.1717e-01,  6.2423e-01],\n",
       "         [-5.0704e-01,  1.8470e+00, -1.9089e-01, -1.4664e+00, -4.3653e-01,\n",
       "           9.4683e-01, -8.1717e-01,  6.2423e-01],\n",
       "         [-7.2705e-01,  1.5514e+00, -4.2595e-01, -1.5152e+00, -3.4086e-01,\n",
       "           1.1397e+00, -5.8992e-01,  9.0786e-01],\n",
       "         [-7.2705e-01,  1.5514e+00, -4.2595e-01, -1.5152e+00, -3.4086e-01,\n",
       "           1.1397e+00, -5.8992e-01,  9.0786e-01],\n",
       "         [-1.0924e+00,  1.0364e+00, -6.6767e-01, -1.4203e+00, -1.6620e-01,\n",
       "           1.3072e+00, -2.1619e-01,  1.2192e+00],\n",
       "         [-1.3596e+00,  5.4780e-01, -8.0073e-01, -1.2208e+00, -6.2493e-03,\n",
       "           1.3395e+00,  1.1743e-01,  1.3826e+00],\n",
       "         [-1.3596e+00,  5.4780e-01, -8.0073e-01, -1.2208e+00, -6.2493e-03,\n",
       "           1.3395e+00,  1.1743e-01,  1.3826e+00],\n",
       "         [-1.4580e+00,  2.7824e-01, -8.5711e-01, -1.0859e+00,  7.4813e-02,\n",
       "           1.3148e+00,  2.9778e-01,  1.4353e+00],\n",
       "         [-1.4656e+00,  1.5144e-01, -8.9609e-01, -1.0315e+00,  1.0450e-01,\n",
       "           1.2938e+00,  3.8410e-01,  1.4593e+00],\n",
       "         [-1.4332e+00,  8.7484e-02, -9.3331e-01, -1.0209e+00,  1.1058e-01,\n",
       "           1.2818e+00,  4.2908e-01,  1.4784e+00],\n",
       "         [-1.4332e+00,  8.7484e-02, -9.3331e-01, -1.0209e+00,  1.1058e-01,\n",
       "           1.2818e+00,  4.2908e-01,  1.4784e+00],\n",
       "         [-1.3840e+00,  5.2270e-02, -9.6904e-01, -1.0306e+00,  1.0578e-01,\n",
       "           1.2743e+00,  4.5519e-01,  1.4961e+00],\n",
       "         [-1.3840e+00,  5.2270e-02, -9.6904e-01, -1.0306e+00,  1.0578e-01,\n",
       "           1.2743e+00,  4.5519e-01,  1.4961e+00],\n",
       "         [-1.2723e+00,  2.0954e-02, -1.0313e+00, -1.0723e+00,  8.2463e-02,\n",
       "           1.2632e+00,  4.8212e-01,  1.5272e+00],\n",
       "         [-1.2723e+00,  2.0954e-02, -1.0313e+00, -1.0723e+00,  8.2463e-02,\n",
       "           1.2632e+00,  4.8212e-01,  1.5272e+00],\n",
       "         [-1.2167e+00,  1.4697e-02, -1.0571e+00, -1.0965e+00,  6.7876e-02,\n",
       "           1.2578e+00,  4.8918e-01,  1.5407e+00],\n",
       "         [-1.2167e+00,  1.4697e-02, -1.0571e+00, -1.0965e+00,  6.7876e-02,\n",
       "           1.2578e+00,  4.8918e-01,  1.5407e+00],\n",
       "         [-1.1639e+00,  1.1529e-02, -1.0790e+00, -1.1203e+00,  5.2714e-02,\n",
       "           1.2522e+00,  4.9382e-01,  1.5529e+00],\n",
       "         [-1.1639e+00,  1.1529e-02, -1.0790e+00, -1.1203e+00,  5.2714e-02,\n",
       "           1.2522e+00,  4.9382e-01,  1.5529e+00],\n",
       "         [-1.1149e+00,  1.0165e-02, -1.0969e+00, -1.1429e+00,  3.7569e-02,\n",
       "           1.2464e+00,  4.9676e-01,  1.5639e+00],\n",
       "         [-1.1149e+00,  1.0165e-02, -1.0969e+00, -1.1429e+00,  3.7569e-02,\n",
       "           1.2464e+00,  4.9676e-01,  1.5639e+00],\n",
       "         [-1.0700e+00,  9.4407e-03, -1.1113e+00, -1.1639e+00,  2.2777e-02,\n",
       "           1.2406e+00,  4.9850e-01,  1.5739e+00],\n",
       "         [-1.0279e+00,  8.1301e-03, -1.1230e+00, -1.1834e+00,  8.4731e-03,\n",
       "           1.2349e+00,  4.9944e-01,  1.5834e+00],\n",
       "         [-1.0279e+00,  8.1301e-03, -1.1230e+00, -1.1834e+00,  8.4731e-03,\n",
       "           1.2349e+00,  4.9944e-01,  1.5834e+00],\n",
       "         [-9.8720e-01,  5.0490e-03, -1.1327e+00, -1.2018e+00, -5.3611e-03,\n",
       "           1.2294e+00,  4.9990e-01,  1.5927e+00],\n",
       "         [-9.8720e-01,  5.0490e-03, -1.1327e+00, -1.2018e+00, -5.3611e-03,\n",
       "           1.2294e+00,  4.9990e-01,  1.5927e+00],\n",
       "         [-9.4637e-01, -6.8422e-04, -1.1412e+00, -1.2193e+00, -1.8777e-02,\n",
       "           1.2243e+00,  5.0014e-01,  1.6019e+00],\n",
       "         [-9.4637e-01, -6.8422e-04, -1.1412e+00, -1.2193e+00, -1.8777e-02,\n",
       "           1.2243e+00,  5.0014e-01,  1.6019e+00],\n",
       "         [-9.0450e-01, -9.6015e-03, -1.1489e+00, -1.2360e+00, -3.1816e-02,\n",
       "           1.2193e+00,  5.0033e-01,  1.6112e+00],\n",
       "         [-8.6119e-01, -2.1882e-02, -1.1562e+00, -1.2519e+00, -4.4481e-02,\n",
       "           1.2144e+00,  5.0056e-01,  1.6207e+00],\n",
       "         [-8.6119e-01, -2.1882e-02, -1.1562e+00, -1.2519e+00, -4.4481e-02,\n",
       "           1.2144e+00,  5.0056e-01,  1.6207e+00],\n",
       "         [-8.1648e-01, -3.7423e-02, -1.1629e+00, -1.2670e+00, -5.6749e-02,\n",
       "           1.2096e+00,  5.0087e-01,  1.6301e+00],\n",
       "         [-8.1648e-01, -3.7423e-02, -1.1629e+00, -1.2670e+00, -5.6749e-02,\n",
       "           1.2096e+00,  5.0087e-01,  1.6301e+00],\n",
       "         [-7.7064e-01, -5.5994e-02, -1.1691e+00, -1.2811e+00, -6.8574e-02,\n",
       "           1.2047e+00,  5.0125e-01,  1.6394e+00],\n",
       "         [-7.7064e-01, -5.5994e-02, -1.1691e+00, -1.2811e+00, -6.8574e-02,\n",
       "           1.2047e+00,  5.0125e-01,  1.6394e+00],\n",
       "         [-5.9404e-01, -1.3338e-01, -1.0360e+00, -1.1060e+00,  6.9432e-01,\n",
       "           2.1281e+00, -3.7693e-01,  4.2390e-01],\n",
       "         [ 5.0940e-01,  5.4017e-01, -5.9462e-01, -1.2459e+00,  4.7877e-01,\n",
       "           1.9200e+00, -1.2130e+00, -3.9474e-01],\n",
       "         [-3.0155e-01, -2.9426e-01, -1.2323e+00, -1.2205e+00,  5.7010e-01,\n",
       "           2.0100e+00, -1.7761e-01,  6.4623e-01],\n",
       "         [-6.5104e-01, -1.9983e-01, -1.0671e+00, -1.0830e+00,  6.9216e-01,\n",
       "           2.1011e+00, -2.8944e-01,  4.9711e-01],\n",
       "         [ 3.3455e-01,  6.7498e-01, -5.5255e-01, -1.2324e+00,  4.8583e-01,\n",
       "           1.9241e+00, -1.2262e+00, -4.0835e-01],\n",
       "         [ 6.1468e-01,  1.8454e-01, -5.3178e-01, -1.1731e+00,  5.5254e-01,\n",
       "           1.9891e+00, -1.2238e+00, -4.1221e-01],\n",
       "         [-1.9336e-01,  2.0542e-01, -9.0363e-01, -1.2218e+00,  6.4009e-01,\n",
       "           2.1482e+00, -7.6104e-01,  8.6155e-02],\n",
       "         [ 6.8133e-01,  2.9007e-01, -6.2623e-01, -1.2352e+00,  4.9646e-01,\n",
       "           1.9390e+00, -1.1810e+00, -3.6441e-01],\n",
       "         [-5.9920e-01, -2.6727e-01, -1.1397e+00, -1.1005e+00,  6.6267e-01,\n",
       "           2.0593e+00, -1.9860e-01,  5.8320e-01],\n",
       "         [ 6.4699e-01,  2.0396e-01, -5.6443e-01, -1.1934e+00,  5.3486e-01,\n",
       "           1.9740e+00, -1.2078e+00, -3.9422e-01],\n",
       "         [ 5.7317e-01,  1.6596e-01, -4.9459e-01, -1.1491e+00,  5.7291e-01,\n",
       "           2.0056e+00, -1.2413e+00, -4.3260e-01],\n",
       "         [-4.2053e-01, -2.8047e-01, -1.2098e+00, -1.1746e+00,  6.0651e-01,\n",
       "           2.0269e+00, -1.7577e-01,  6.2771e-01],\n",
       "         [-5.9920e-01, -2.6727e-01, -1.1397e+00, -1.1005e+00,  6.6267e-01,\n",
       "           2.0593e+00, -1.9860e-01,  5.8320e-01]],\n",
       "        grad_fn=<NativeLayerNormBackward0>)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class SurfaceEmbedding(nn.Module):\n",
    "    def __init__(self, d_embedding, momentum=0.1):\n",
    "        super(SurfaceEmbedding, self).__init__()\n",
    "        self.batch_norm = SurfaceBatchNorm(num_features=1, momentum=momentum)\n",
    "        self.kernel_positional_embedding = SurfaceContinuousKernelPositionalEmbedding(d_embedding)\n",
    "        self.layer_norm = nn.LayerNorm(d_embedding)\n",
    "        self.mask_token = nn.Parameter(torch.randn(d_embedding))\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Apply batch normalization\n",
    "        norm_batch = self.batch_norm(batch)\n",
    "\n",
    "        # Extract market features from processed batch and create external_features tensor\n",
    "        market_features = norm_batch['Market Features']\n",
    "        external_features = torch.stack([\n",
    "            market_features['Market Return'],\n",
    "            market_features['Market Volatility'],\n",
    "            market_features['Treasury Rate']\n",
    "        ], dim=-1)  # (batch, features)\n",
    "\n",
    "        # Compute kernel and positional embeddings\n",
    "        embeddings = self.kernel_positional_embedding(norm_batch['Input Surface'], norm_batch['Query Points'])\n",
    "\n",
    "        input_surface_embeddings = embeddings['Input Surface']\n",
    "        query_points_embeddings = embeddings['Query Points']\n",
    "\n",
    "        embedded_sequences = []\n",
    "\n",
    "        for input_surface_embedding, query_points_embedding in zip(input_surface_embeddings, query_points_embeddings):\n",
    "            # Add mask token to the query point embeddings\n",
    "            masked_query_points_embedding = query_points_embedding + self.mask_token\n",
    "\n",
    "            # Combine input surface embeddings and masked query points embeddings\n",
    "            combined_sequence = torch.cat((input_surface_embedding, masked_query_points_embedding), dim=0)\n",
    "\n",
    "            # Apply layer normalization\n",
    "            combined_sequence = self.layer_norm(combined_sequence)\n",
    "\n",
    "            embedded_sequences.append(combined_sequence)\n",
    "\n",
    "        return embedded_sequences, external_features\n",
    "\n",
    "\n",
    "# Example of initializing and using this module\n",
    "d_embedding = HYPERPARAMETERS['Surface Embedding']['Embedding Dimension']  # Desired number of output channels\n",
    "surface_embedding = SurfaceEmbedding(d_embedding=d_embedding)\n",
    "embedded_sequences_batch, external_features = surface_embedding(batch)\n",
    "embedded_sequences_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surface Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Num Heads'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 120\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m encoded_sequences_batch\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# Example of initializing and using these modules\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# d_embedding = HYPERPARAMETERS['Surface Encoding']['Embedding Dimension']\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m num_heads \u001b[38;5;241m=\u001b[39m \u001b[43mHYPERPARAMETERS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSurface Encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNum Heads\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    121\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m HYPERPARAMETERS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurface Encoding\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHidden Dimension\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    122\u001b[0m dropout \u001b[38;5;241m=\u001b[39m HYPERPARAMETERS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSurface Encoding\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Num Heads'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ResidualNorm(nn.Module):\n",
    "    def __init__(self, d_embedding):\n",
    "        super(ResidualNorm, self).__init__()\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, x, sublayer_output):\n",
    "        return self.norm(x + sublayer_output)\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_embedding, hidden_dim, dropout):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(d_embedding, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, d_embedding),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feedforward(x)\n",
    "\n",
    "class GatedAttentionFusion(nn.Module):\n",
    "    def __init__(self, d_embedding):\n",
    "        super(GatedAttentionFusion, self).__init__()\n",
    "        self.gate_layer = nn.Sequential(\n",
    "            nn.Linear(d_embedding * 2, d_embedding),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, self_attn_output, ext_attn_output):\n",
    "        # Concatenate self-attention and external attention outputs\n",
    "        concatenated_output = torch.cat((self_attn_output, ext_attn_output), dim=-1)\n",
    "        # Compute gate values\n",
    "        gate_values = self.gate_layer(concatenated_output)\n",
    "        # Calculate gated embedding\n",
    "        gated_embedding = gate_values * self_attn_output + (1 - gate_values) * ext_attn_output\n",
    "        return gated_embedding\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads, dropout):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(d_embedding, num_heads, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "        return self.dropout(attn_output)\n",
    "\n",
    "class CrossAttention(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads, dropout):\n",
    "        super(CrossAttention, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(d_embedding, num_heads, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, external_features):\n",
    "        attn_output, _ = self.attention(x, external_features, external_features)\n",
    "        return self.dropout(attn_output)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_embedding, num_heads, hidden_dim, dropout):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attention = SelfAttention(d_embedding, num_heads, dropout)\n",
    "        self.cross_attention = CrossAttention(d_embedding, num_heads, dropout)\n",
    "        self.gated_attention_fusion = GatedAttentionFusion(d_embedding)\n",
    "        self.residual_norm1 = ResidualNorm(d_embedding)\n",
    "        self.feed_forward = FeedForwardNetwork(d_embedding, hidden_dim, dropout)\n",
    "        self.residual_norm2 = ResidualNorm(d_embedding)\n",
    "\n",
    "    def forward(self, x, external_features):\n",
    "        # Self-Attention\n",
    "        self_attn_output = self.self_attention(x)\n",
    "        \n",
    "        # Cross-Attention\n",
    "        ext_attn_output = self.cross_attention(x, external_features)\n",
    "        \n",
    "        # Gated Attention Fusion\n",
    "        gated_embedding = self.gated_attention_fusion(self_attn_output, ext_attn_output)\n",
    "        \n",
    "        # Residual Connection and Layer Normalization\n",
    "        x = self.residual_norm1(x, gated_embedding)\n",
    "        \n",
    "        # Feed-Forward Network\n",
    "        ffn_output = self.feed_forward(x)\n",
    "        \n",
    "        # Final Residual Connection and Layer Normalization\n",
    "        x = self.residual_norm2(x, ffn_output)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class SurfaceEncoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_embedding, num_heads, hidden_dim, dropout):\n",
    "        super(SurfaceEncoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderBlock(d_embedding, num_heads, hidden_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, embedded_sequences_batch, external_features):\n",
    "        batch_size = len(embedded_sequences_batch)\n",
    "        encoded_sequences_batch = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            x = embedded_sequences_batch[i]\n",
    "            for layer in self.layers:\n",
    "                x = layer(x, external_features[i])\n",
    "            encoded_sequences_batch.append(x)\n",
    "        \n",
    "        return encoded_sequences_batch\n",
    "\n",
    "# Example of initializing and using these modules\n",
    "# d_embedding = HYPERPARAMETERS['Surface Encoding']['Embedding Dimension']\n",
    "num_heads = HYPERPARAMETERS['Surface Encoding']['Num Heads']\n",
    "hidden_dim = HYPERPARAMETERS['Surface Encoding']['Hidden Dimension']\n",
    "dropout = HYPERPARAMETERS['Surface Encoding']['Dropout']\n",
    "num_layers = HYPERPARAMETERS['Surface Encoding']['Num Layers']\n",
    "\n",
    "surface_encoder = SurfaceEncoder(num_layers, d_embedding, num_heads, hidden_dim, dropout)\n",
    "\n",
    "# Assume embedded_sequences_batch is the output of the SurfaceEmbedding module and\n",
    "# external_features is the formatted external market features batch\n",
    "encoded_sequences_batch = surface_encoder(embedded_sequences_batch, external_features)\n",
    "encoded_sequences_batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
