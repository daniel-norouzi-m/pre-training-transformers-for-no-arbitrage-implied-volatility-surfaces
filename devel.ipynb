{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "RANDOM_STATE = 0\n",
    "N_JOBS = 8\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMETERS = {\n",
    "    'Input Preprocessing' : {\n",
    "        'Mask Proportions' : [0.1, 0.2, 0.4, 0.8],\n",
    "        'Batch Size' : 4\n",
    "    },\n",
    "    'Input Embedding' : {\n",
    "        'Surface Embedding' : {\n",
    "            'Grid Dimension' : 3,\n",
    "            'Channels Dimension' : 8,\n",
    "        },\n",
    "        'Pre-Encoder' : {\n",
    "            'Branch Channels Dimension' : 4,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'Surface Encoding' : {\n",
    "        'Encoder' : {\n",
    "            'Number of Heads' : 4,\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "            'External Feature Dimension' : 3,\n",
    "        }\n",
    "    },\n",
    "    'Query Embedding' : {\n",
    "        'Pre-Decoder' : {\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'Surface Decoding' : {\n",
    "        'Decoder' : {\n",
    "            'Number of Heads' : 4,\n",
    "            'Hidden Dimension' : 16,\n",
    "            'Dropout' : 0.1,\n",
    "            'Number of Blocks' : 2,\n",
    "        }\n",
    "    },\n",
    "    'No-Arbitrage' : {\n",
    "        'Butterfly' : 1,\n",
    "        'Calendar' : 1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Log Moneyness</th>\n",
       "      <th>Time to Maturity</th>\n",
       "      <th>Implied Volatility</th>\n",
       "      <th>Market Return</th>\n",
       "      <th>Market Volatility</th>\n",
       "      <th>Treasury Rate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-01-02</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.316688</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.316688</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.304266</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.304266</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.6095</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAPL</th>\n",
       "      <td>-0.291996</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>14.680000</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2013-06-28</th>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.427518</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.434898</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.434898</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.442224</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2402</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GOOGL</th>\n",
       "      <td>0.442224</td>\n",
       "      <td>2.253968</td>\n",
       "      <td>0.2433</td>\n",
       "      <td>-0.004299</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574326 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Log Moneyness  Time to Maturity  Implied Volatility  \\\n",
       "Datetime   Symbol                                                        \n",
       "2013-01-02 AAPL        -0.316688          0.007937              0.3726   \n",
       "           AAPL        -0.316688          0.007937              0.6095   \n",
       "           AAPL        -0.304266          0.007937              0.3726   \n",
       "           AAPL        -0.304266          0.007937              0.6095   \n",
       "           AAPL        -0.291996          0.007937              0.3726   \n",
       "...                          ...               ...                 ...   \n",
       "2013-06-28 GOOGL        0.427518          2.253968              0.2430   \n",
       "           GOOGL        0.434898          2.253968              0.2383   \n",
       "           GOOGL        0.434898          2.253968              0.2426   \n",
       "           GOOGL        0.442224          2.253968              0.2402   \n",
       "           GOOGL        0.442224          2.253968              0.2433   \n",
       "\n",
       "                   Market Return  Market Volatility  Treasury Rate  \n",
       "Datetime   Symbol                                                   \n",
       "2013-01-02 AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "           AAPL         0.025086          14.680000          0.055  \n",
       "...                          ...                ...            ...  \n",
       "2013-06-28 GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "           GOOGL       -0.004299          16.860001          0.030  \n",
       "\n",
       "[574326 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_googl_data = pd.read_csv('volatility_surface_AAPL_GOOGL_2013_01_2013_06.csv', parse_dates=True, index_col=[0, 1], date_format=\"ISO8601\")\n",
    "aapl_googl_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0e4a12d2f040d296c9c5b86518e413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# Flatten the list of lists into a single list of datasets\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [item \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m surface_datasets \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m sublist]\n\u001b[0;32m--> 106\u001b[0m aapl_googl_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mimplied_volatility_surface_datasets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43maapl_googl_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mHYPERPARAMETERS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mInput Preprocessing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMask Proportions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_JOBS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mRANDOM_STATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_chunks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\n\u001b[1;32m    112\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 95\u001b[0m, in \u001b[0;36mimplied_volatility_surface_datasets\u001b[0;34m(options_market_data, proportions, n_jobs, random_state, n_chunks)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m joblib_progress(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSurfaces...\u001b[39m\u001b[38;5;124m\"\u001b[39m, total\u001b[38;5;241m=\u001b[39mn_surfaces): \n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;66;03m# Process the current chunk in parallel\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_surface\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurface\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msurface\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_surfaces\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;66;03m# Extend the overall results with the current chunk's results\u001b[39;00m\n\u001b[1;32m    100\u001b[0m         surface_datasets\u001b[38;5;241m.\u001b[39mextend(output)\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/envs/Apache/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gc\n",
    "from joblib_progress import joblib_progress\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "def implied_volatility_surface_datasets(\n",
    "    options_market_data, \n",
    "    proportions, \n",
    "    n_jobs=1,\n",
    "    random_state=0,\n",
    "    n_chunks=1\n",
    "):\n",
    "    def mask_surface(\n",
    "        date, \n",
    "        symbol, \n",
    "        surface, \n",
    "        rng\n",
    "    ):\n",
    "        def mask_surface_with_proportion(\n",
    "            surface_data, \n",
    "            proportion, \n",
    "        ):\n",
    "            n_clusters = int(np.ceil(1 / proportion))\n",
    "            points_coordinates = surface_data['points_coordinates']\n",
    "            points_volatilities = surface_data['points_volatilities']\n",
    "\n",
    "            # Create the clustering pipeline\n",
    "            pipeline = Pipeline([\n",
    "                ('scaler', StandardScaler()),\n",
    "                ('kmeans', KMeans(n_clusters=n_clusters, random_state=random_state, n_init='auto'))\n",
    "            ])\n",
    "            \n",
    "            # Fit the pipeline to the data points\n",
    "            labels = pipeline.fit_predict(points_coordinates)\n",
    "            \n",
    "            single_surface_datasets = []\n",
    "            for cluster in range(n_clusters):\n",
    "                cluster_indices = np.where(labels == cluster)[0]\n",
    "                num_to_mask = int(np.ceil(len(cluster_indices) * proportion))\n",
    "                masked_indices = rng.choice(cluster_indices, size=num_to_mask, replace=False)\n",
    "                \n",
    "                for idx in masked_indices:\n",
    "                    unmasked_indices = np.setdiff1d(cluster_indices, masked_indices)\n",
    "\n",
    "                    single_surface_datasets.append({\n",
    "                        'Datetime': surface_data['datetime'],\n",
    "                        'Symbol': surface_data['symbol'],\n",
    "                        'Market Features': surface_data['market_features'],\n",
    "                        'Input Surface': {\n",
    "                            'Log Moneyness': points_coordinates[unmasked_indices, 0],\n",
    "                            'Time to Maturity': points_coordinates[unmasked_indices, 1],\n",
    "                            'Implied Volatility': points_volatilities[unmasked_indices]\n",
    "                        },\n",
    "                        'Query Point': {\n",
    "                            'Log Moneyness': points_coordinates[idx, 0],\n",
    "                            'Time to Maturity': points_coordinates[idx, 1]\n",
    "                        },\n",
    "                        'Target Volatility': points_volatilities[idx]\n",
    "                    })\n",
    "\n",
    "            return single_surface_datasets\n",
    "        \n",
    "        surface_data = {\n",
    "            'datetime': date,\n",
    "            'symbol': symbol,\n",
    "            'points_coordinates': surface[['Log Moneyness', 'Time to Maturity']].values,\n",
    "            'points_volatilities': surface['Implied Volatility'].values,\n",
    "            'market_features': {\n",
    "                'Market Return': surface['Market Return'].values[0],\n",
    "                'Market Volatility': surface['Market Volatility'].values[0],\n",
    "                'Treasury Rate': surface['Treasury Rate'].values[0]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        datasets = []\n",
    "        for proportion in proportions:\n",
    "            datasets.extend(mask_surface_with_proportion(surface_data, proportion))\n",
    "\n",
    "        return datasets\n",
    "\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    all_surfaces = list(options_market_data.groupby(level=['Datetime', 'Symbol']))\n",
    "    n_surfaces = len(all_surfaces)\n",
    "    \n",
    "    # Split the array into 'n_chunks' chunks\n",
    "    chunks = np.array_split(range(n_surfaces), n_chunks)\n",
    "    # Initialize the list to hold all results\n",
    "    surface_datasets = []\n",
    "    # Process each chunk sequentially\n",
    "    with joblib_progress(\"Surfaces...\", total=n_surfaces): \n",
    "        for chunk in chunks:\n",
    "            # Process the current chunk in parallel\n",
    "            output = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(mask_surface)(date, symbol, surface, rng)\n",
    "                for (date, symbol), surface in [all_surfaces[i] for i in chunk]\n",
    "            )\n",
    "            # Extend the overall results with the current chunk's results\n",
    "            surface_datasets.extend(output)\n",
    "            gc.collect()  \n",
    "\n",
    "    # Flatten the list of lists into a single list of datasets\n",
    "    return [item for sublist in surface_datasets for item in sublist]\n",
    "\n",
    "aapl_googl_dataset = implied_volatility_surface_datasets(\n",
    "    aapl_googl_data,\n",
    "    HYPERPARAMETERS['Input Preprocessing']['Mask Proportions'],\n",
    "    n_jobs=N_JOBS,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_chunks=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('aapl_googl_dataset.pickle', 'wb') as handle:\n",
    "#     pickle.dump(aapl_googl_dataset, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# with open('aapl_googl_dataset.pickle', 'rb') as handle:\n",
    "#     aapl_googl_dataset_ = pickle.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "863511"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aapl_googl_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': Timestamp('2013-01-02 00:00:00'),\n",
       " 'Symbol': 'AAPL',\n",
       " 'Market Features': {'Market Return': 0.0250861159586972,\n",
       "  'Market Volatility': 14.68000030517578,\n",
       "  'Treasury Rate': 0.0549999997019767},\n",
       " 'Input Surface': {'Log Moneyness': array([-0.74747141, -0.72842322, -0.72842322, -0.70973108, -0.69138194,\n",
       "         -0.69138194, -0.67336344, -0.67336344, -0.63827212, -0.63827212,\n",
       "         -0.62117768, -0.62117768, -0.60437057, -0.60437057, -0.58784126,\n",
       "         -0.58784126, -0.57158074, -0.5555804 , -0.5555804 , -0.53983205,\n",
       "         -0.53983205, -0.52432786, -0.52432786, -0.50906039, -0.50906039,\n",
       "         -0.49402251, -0.49402251, -0.47920742, -0.47920742, -0.46460862,\n",
       "         -0.46460862, -0.45021989, -0.45021989, -0.43603525, -0.43603525,\n",
       "         -0.42204901, -0.42204901, -0.40825569, -0.40825569, -0.39465004,\n",
       "         -0.39465004, -0.74747141, -0.74747141, -0.72842322, -0.70973108,\n",
       "         -0.70973108, -0.69138194, -0.69138194, -0.67336344, -0.67336344,\n",
       "         -0.65566386, -0.65566386, -0.63827212, -0.63827212, -0.62117768,\n",
       "         -0.62117768, -0.60437057, -0.60437057, -0.58784126, -0.58784126,\n",
       "         -0.57158074, -0.57158074, -0.5555804 , -0.5555804 , -0.53983205,\n",
       "         -0.53983205, -0.52432786, -0.50906039, -0.50906039, -0.49402251,\n",
       "         -0.49402251, -0.47920742, -0.47920742, -0.46460862, -0.45021989,\n",
       "         -0.45021989, -0.43603525, -0.42204901, -0.42204901, -0.40825569,\n",
       "         -0.40825569, -0.39465004, -0.39465004, -0.74747141, -0.74747141,\n",
       "         -0.72842322, -0.72842322, -0.70973108, -0.70973108, -0.69138194,\n",
       "         -0.69138194, -0.67336344, -0.67336344, -0.65566386, -0.65566386,\n",
       "         -0.63827212, -0.63827212, -0.62117768, -0.62117768, -0.60437057,\n",
       "         -0.60437057, -0.58784126, -0.58784126, -0.57158074, -0.57158074,\n",
       "         -0.5555804 , -0.5555804 , -0.53983205, -0.52432786, -0.52432786,\n",
       "         -0.50906039, -0.50906039, -0.49402251, -0.49402251, -0.47920742,\n",
       "         -0.47920742, -0.46460862, -0.46460862, -0.45021989, -0.45021989,\n",
       "         -0.43603525, -0.43603525, -0.42204901, -0.42204901, -0.40825569,\n",
       "         -0.40825569, -0.39465004, -0.39465004, -0.38122702, -0.74747141,\n",
       "         -0.74747141, -0.72842322, -0.70973108, -0.70973108, -0.69138194,\n",
       "         -0.69138194, -0.67336344, -0.67336344, -0.65566386, -0.65566386,\n",
       "         -0.63827212, -0.63827212, -0.62117768, -0.62117768, -0.60437057,\n",
       "         -0.58784126, -0.58784126, -0.57158074, -0.5555804 , -0.5555804 ,\n",
       "         -0.53983205, -0.52432786, -0.52432786, -0.50906039, -0.50906039,\n",
       "         -0.49402251, -0.49402251, -0.46460862, -0.46460862, -0.45021989,\n",
       "         -0.45021989, -0.43603525, -0.43603525, -0.42204901, -0.40825569,\n",
       "         -0.39465004, -0.39465004, -0.38122702, -0.38122702, -0.36798179,\n",
       "         -0.36798179, -0.7668895 , -0.7668895 , -0.74747141, -0.74747141,\n",
       "         -0.72842322, -0.72842322, -0.70973108, -0.69138194, -0.69138194,\n",
       "         -0.67336344, -0.67336344, -0.65566386, -0.65566386, -0.63827212,\n",
       "         -0.63827212, -0.62117768, -0.62117768, -0.60437057, -0.58784126,\n",
       "         -0.58784126, -0.57158074, -0.57158074, -0.5555804 , -0.5555804 ,\n",
       "         -0.53983205, -0.53983205, -0.52432786, -0.50906039, -0.50906039,\n",
       "         -0.49402251, -0.49402251, -0.47920742, -0.47920742, -0.46460862,\n",
       "         -0.45021989, -0.43603525, -0.42204901, -0.42204901, -0.40825569,\n",
       "         -0.40825569, -0.39465004, -0.39465004, -0.38122702, -0.36798179,\n",
       "         -0.36798179, -0.35490971, -0.35490971, -0.7668895 , -0.7668895 ,\n",
       "         -0.74747141, -0.74747141, -0.72842322, -0.72842322, -0.70973108,\n",
       "         -0.70973108, -0.69138194, -0.67336344, -0.67336344, -0.65566386,\n",
       "         -0.63827212, -0.63827212, -0.62117768, -0.62117768, -0.60437057,\n",
       "         -0.60437057, -0.58784126, -0.58784126, -0.57158074, -0.57158074,\n",
       "         -0.5555804 , -0.5555804 , -0.53983205, -0.52432786, -0.52432786,\n",
       "         -0.50906039, -0.50906039, -0.49402251, -0.47920742, -0.47920742,\n",
       "         -0.46460862, -0.46460862, -0.45021989, -0.45021989, -0.43603525,\n",
       "         -0.43603525, -0.42204901, -0.42204901, -0.40825569, -0.40825569,\n",
       "         -0.39465004, -0.39465004, -0.38122702, -0.38122702, -0.36798179,\n",
       "         -0.36798179, -0.35490971, -0.35490971, -0.3420063 , -0.3420063 ]),\n",
       "  'Time to Maturity': array([0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.06746032, 0.06746032, 0.06746032, 0.06746032,\n",
       "         0.06746032, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.17857143, 0.17857143,\n",
       "         0.17857143, 0.17857143, 0.17857143, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.28968254,\n",
       "         0.28968254, 0.28968254, 0.28968254, 0.28968254, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.42857143, 0.42857143, 0.42857143, 0.42857143,\n",
       "         0.42857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.67857143, 0.67857143,\n",
       "         0.67857143, 0.67857143, 0.67857143, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254,\n",
       "         0.78968254, 0.78968254, 0.78968254, 0.78968254, 0.78968254]),\n",
       "  'Implied Volatility': array([0.422 , 0.2954, 0.422 , 0.422 , 0.2954, 0.422 , 0.2954, 0.422 ,\n",
       "         0.2954, 0.422 , 0.2954, 0.422 , 0.2954, 0.422 , 0.2954, 0.422 ,\n",
       "         0.422 , 0.2954, 0.422 , 0.2954, 0.422 , 0.2954, 0.422 , 0.2954,\n",
       "         0.422 , 0.2954, 0.422 , 0.2954, 0.422 , 0.2954, 0.422 , 0.2954,\n",
       "         0.422 , 0.2954, 0.422 , 0.2954, 0.422 , 0.2954, 0.422 , 0.2954,\n",
       "         0.422 , 0.4803, 0.4523, 0.4523, 0.4803, 0.4523, 0.4803, 0.4523,\n",
       "         0.4803, 0.4523, 0.4803, 0.4523, 0.4803, 0.4523, 0.4803, 0.4523,\n",
       "         0.4803, 0.4523, 0.4803, 0.4523, 0.4803, 0.4523, 0.4803, 0.4523,\n",
       "         0.4803, 0.4523, 0.4803, 0.4803, 0.4523, 0.4803, 0.4523, 0.4803,\n",
       "         0.4523, 0.4523, 0.4803, 0.4523, 0.4523, 0.4803, 0.4523, 0.4803,\n",
       "         0.4523, 0.4803, 0.4523, 0.4849, 0.3824, 0.4849, 0.6449, 0.4849,\n",
       "         0.6428, 0.4849, 0.3824, 0.4849, 0.6288, 0.4849, 0.6159, 0.4849,\n",
       "         0.6055, 0.4849, 0.5883, 0.4849, 0.3824, 0.4849, 0.5735, 0.4849,\n",
       "         0.5627, 0.4849, 0.5535, 0.5441, 0.4849, 0.533 , 0.4849, 0.5218,\n",
       "         0.4849, 0.5133, 0.4849, 0.5059, 0.4849, 0.4967, 0.4849, 0.3824,\n",
       "         0.4849, 0.4818, 0.4849, 0.4729, 0.4849, 0.3824, 0.4849, 0.3824,\n",
       "         0.4847, 0.4351, 0.4247, 0.4247, 0.4351, 0.4247, 0.4351, 0.4247,\n",
       "         0.4351, 0.4247, 0.4351, 0.4247, 0.4351, 0.4247, 0.4351, 0.4247,\n",
       "         0.4247, 0.4351, 0.4247, 0.4351, 0.4351, 0.4247, 0.4247, 0.4351,\n",
       "         0.4247, 0.4351, 0.4247, 0.4351, 0.4247, 0.4351, 0.4247, 0.4351,\n",
       "         0.4247, 0.4344, 0.4247, 0.4351, 0.4227, 0.4351, 0.4176, 0.4273,\n",
       "         0.4167, 0.4303, 0.4082, 0.539 , 0.378 , 0.539 , 0.5097, 0.539 ,\n",
       "         0.378 , 0.4887, 0.539 , 0.4896, 0.539 , 0.4803, 0.539 , 0.4753,\n",
       "         0.539 , 0.378 , 0.539 , 0.378 , 0.378 , 0.5365, 0.378 , 0.5233,\n",
       "         0.378 , 0.5093, 0.378 , 0.5044, 0.378 , 0.378 , 0.486 , 0.378 ,\n",
       "         0.4757, 0.378 , 0.4618, 0.378 , 0.4532, 0.378 , 0.3822, 0.4384,\n",
       "         0.3822, 0.432 , 0.3822, 0.4274, 0.3847, 0.3876, 0.4098, 0.3862,\n",
       "         0.4118, 0.3861, 0.5285, 0.3856, 0.5285, 0.3856, 0.5285, 0.3856,\n",
       "         0.5285, 0.3856, 0.5285, 0.5285, 0.3856, 0.5285, 0.5285, 0.3856,\n",
       "         0.5189, 0.3856, 0.5101, 0.3856, 0.499 , 0.3856, 0.4851, 0.3856,\n",
       "         0.479 , 0.3852, 0.469 , 0.4628, 0.3856, 0.4582, 0.3856, 0.3776,\n",
       "         0.4417, 0.3856, 0.428 , 0.3856, 0.4267, 0.3856, 0.4161, 0.3946,\n",
       "         0.418 , 0.3891, 0.4099, 0.3898, 0.3973, 0.385 , 0.396 , 0.3837,\n",
       "         0.392 , 0.381 , 0.3921, 0.3769, 0.382 , 0.3753])},\n",
       " 'Query Point': {'Log Moneyness': -0.6043705664556404,\n",
       "  'Time to Maturity': 0.6785714285714286},\n",
       " 'Target Volatility': 0.539}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aapl_googl_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': [Timestamp('2013-03-14 00:00:00'),\n",
       "  Timestamp('2013-01-31 00:00:00'),\n",
       "  Timestamp('2013-02-05 00:00:00'),\n",
       "  Timestamp('2013-05-20 00:00:00')],\n",
       " 'Symbol': ['GOOGL', 'AAPL', 'AAPL', 'AAPL'],\n",
       " 'Market Features': {'Market Return': tensor([ 0.0056, -0.0026,  0.0104, -0.0007]),\n",
       "  'Market Volatility': tensor([11.3000, 14.2800, 13.7200, 13.0200]),\n",
       "  'Treasury Rate': tensor([0.0900, 0.0650, 0.0700, 0.0350])},\n",
       " 'Input Surface': {'Log Moneyness': [tensor([-0.9121, -0.7450, -0.7197, -0.6950, -0.6829, -0.6591, -0.6358, -0.5800,\n",
       "           -0.5479, -0.4670, -0.4670, -0.4383, -0.4013, -0.3922, -0.3655, -0.3482,\n",
       "           -0.3396, -0.3311, -0.3226, -0.2977, -0.2342, -0.2039, -0.1745, -0.1250,\n",
       "           -0.1113, -0.1045, -0.0911, -0.0779, -0.0648, -0.0455, -0.0203, -0.0141,\n",
       "           -0.0080, -0.0080,  0.0163,  0.0573,  0.0744,  0.0856,  0.1023,  0.1240,\n",
       "            0.1294,  0.1400,  0.1505,  0.1609,  0.1815,  0.2261,  0.2642,  0.3009,\n",
       "            0.3621, -0.1601, -0.1601, -0.1459, -0.1319, -0.1181, -0.0648, -0.0328,\n",
       "           -0.0328, -0.0080, -0.0019,  0.0163,  0.0341,  0.0341,  0.0515,  0.0912,\n",
       "            0.1023, -0.1601, -0.1459, -0.1045, -0.0779, -0.0779, -0.0519, -0.0391,\n",
       "            0.0222,  0.0573,  0.0573,  0.0800, -0.2815, -0.2497, -0.1459, -0.1045,\n",
       "           -0.1045, -0.0779, -0.0266, -0.0019,  0.0222,  0.0222,  0.0687, -0.1891,\n",
       "           -0.1891, -0.1745, -0.1745, -0.1181, -0.1045, -0.0911, -0.0779, -0.0519,\n",
       "           -0.0391,  0.0341,  0.0687,  0.0800,  0.0912, -0.7710, -0.7197, -0.6358,\n",
       "           -0.6019, -0.5800, -0.5691, -0.5270, -0.4574, -0.4383, -0.4289, -0.4104,\n",
       "           -0.3832, -0.3744, -0.3396, -0.3311, -0.3060, -0.2977, -0.2896, -0.2734,\n",
       "           -0.2576, -0.2189, -0.2039, -0.1530, -0.1319, -0.1250, -0.0911, -0.0779,\n",
       "           -0.0779, -0.0713, -0.0648, -0.0583, -0.0583, -0.0391, -0.0391, -0.0080,\n",
       "           -0.0019,  0.0042,  0.0163,  0.0573,  0.0912,  0.0912,  0.1132,  0.1240,\n",
       "            0.1294,  0.1294,  0.1347,  0.1609,  0.1764,  0.1815,  0.1916,  0.2065,\n",
       "            0.2310,  0.2358,  0.2642,  0.2642,  0.2828,  0.2828,  0.2919,  0.3009,\n",
       "            0.3363,  0.3450,  0.3705,  0.3789, -0.7710, -0.7323, -0.6709, -0.6358,\n",
       "           -0.6131, -0.5800, -0.5691, -0.5479, -0.5168, -0.5066, -0.4383, -0.4196,\n",
       "           -0.3922, -0.3744, -0.3568, -0.3311, -0.3226, -0.3143, -0.2896, -0.2815,\n",
       "           -0.2655, -0.2419, -0.2039, -0.1745, -0.1601, -0.1530, -0.1459, -0.1389,\n",
       "           -0.1319, -0.1250, -0.1250, -0.1181, -0.0978, -0.0911, -0.0845, -0.0845,\n",
       "           -0.0648, -0.0455, -0.0455, -0.0391, -0.0266, -0.0203,  0.0163,  0.0222,\n",
       "            0.0222,  0.0341,  0.0399,  0.0515,  0.0573,  0.0630,  0.0687,  0.0912,\n",
       "            0.1077,  0.1186,  0.1294,  0.1347,  0.1764,  0.1815,  0.2065,  0.2164,\n",
       "            0.3099,  0.3188,  0.3276,  0.3450,  0.3789, -0.8822, -0.8676, -0.8532,\n",
       "           -0.7710, -0.7579, -0.7450, -0.7323, -0.7323, -0.7197, -0.6019, -0.5584,\n",
       "           -0.5066, -0.4966, -0.4478, -0.4478, -0.4289, -0.4013, -0.3832, -0.3744,\n",
       "           -0.3655, -0.3568, -0.3568, -0.3482, -0.2734, -0.2734, -0.2655, -0.2576,\n",
       "           -0.2497, -0.2419, -0.1818, -0.1673, -0.1601, -0.1459, -0.1389, -0.1045,\n",
       "           -0.0845, -0.0779, -0.0713, -0.0455, -0.0141,  0.0102,  0.0163,  0.0222,\n",
       "            0.0222,  0.0458,  0.0515,  0.0573,  0.0800,  0.0912,  0.1023,  0.1558,\n",
       "            0.1713,  0.2065,  0.2358,  0.2454,  0.3009,  0.3363, -0.7977, -0.7977,\n",
       "           -0.7843, -0.7710, -0.7450, -0.7323, -0.6950, -0.6591, -0.6474, -0.6474,\n",
       "           -0.6358, -0.5800, -0.5584, -0.5479, -0.5374, -0.5066, -0.4966, -0.4866,\n",
       "           -0.4866, -0.4768, -0.4478, -0.4289, -0.3744, -0.3655, -0.3396, -0.3311,\n",
       "           -0.3060, -0.2896, -0.2896, -0.2815, -0.2734, -0.1891, -0.1818, -0.1818,\n",
       "           -0.1530, -0.1181, -0.1181, -0.0845, -0.0519, -0.0141,  0.0042,  0.0222,\n",
       "            0.0515,  0.0573,  0.0573,  0.0912,  0.1077,  0.1294,  0.1609,  0.1661,\n",
       "            0.1661,  0.1764,  0.1865,  0.2548,  0.2735,  0.2735,  0.3188,  0.3276,\n",
       "            0.3536, -1.0413, -1.0242, -0.9586, -0.9586, -0.9429, -0.9121, -0.8971,\n",
       "           -0.8676, -0.8676, -0.8532, -0.7977, -0.7450, -0.7450, -0.6829, -0.6591,\n",
       "           -0.6244, -0.6131, -0.5374, -0.5270, -0.5066, -0.4866, -0.4670, -0.4670,\n",
       "           -0.4574, -0.4289, -0.4013, -0.3744, -0.3744, -0.3655, -0.3568, -0.2655,\n",
       "           -0.2497, -0.2039, -0.1891, -0.1673, -0.1530, -0.1389, -0.1319, -0.1250,\n",
       "           -0.1113, -0.1045, -0.0978, -0.0583, -0.0455, -0.0455, -0.0328, -0.0266,\n",
       "           -0.0141,  0.0102,  0.0222,  0.0515,  0.0573,  0.0573,  0.0630,  0.0744,\n",
       "            0.1023,  0.1240,  0.1505,  0.1713,  0.1865,  0.1966,  0.2919,  0.3188,\n",
       "            0.3621,  0.3705,  0.3705]),\n",
       "   tensor([-0.0011,  0.0099,  0.0099,  0.0207,  0.0207,  0.0314,  0.0419,  0.0419,\n",
       "            0.0524,  0.0730,  0.0832,  0.0932,  0.0932,  0.1032,  0.1032,  0.1228,\n",
       "            0.1325,  0.1515,  0.1515,  0.1609,  0.1702,  0.1702,  0.1794,  0.1885,\n",
       "            0.1885,  0.1976,  0.1976,  0.2243,  0.2330,  0.2330,  0.2417,  0.2417,\n",
       "            0.2587,  0.2587,  0.2672,  0.2756,  0.2756,  0.2839,  0.2921,  0.2921,\n",
       "            0.3002,  0.3002,  0.3083,  0.3164,  0.3164,  0.3243,  0.3323,  0.3401,\n",
       "            0.3479,  0.3479,  0.3556,  0.3633,  0.3633,  0.3784,  0.3859,  0.3933,\n",
       "            0.4080,  0.4153,  0.4153,  0.4225,  0.4225,  0.4297,  0.4297,  0.4368,\n",
       "            0.4368,  0.4509,  0.4509,  0.4579,  0.4648,  0.4717,  0.4785,  0.4853,\n",
       "            0.4853,  0.4920,  0.4920,  0.4987,  0.5053,  0.5053,  0.5119,  0.5119,\n",
       "            0.5185,  0.5315,  0.5379,  0.5379,  0.5443,  0.5443,  0.5507,  0.5507,\n",
       "            0.5570,  0.5632,  0.5632,  0.5695,  0.5695,  0.5757,  0.5818,  0.5879,\n",
       "            0.6061,  0.6061,  0.6120,  0.6180,  0.6180,  0.6239,  0.6297,  0.6356,\n",
       "            0.6414,  0.6471,  0.6529,  0.6585,  0.6585,  0.6698,  0.6810,  0.6810,\n",
       "            0.6866,  0.6921,  0.6976,  0.6976,  0.7030,  0.7084,  0.7084,  0.7138,\n",
       "            0.7138,  0.7192,  0.7245,  0.7351,  0.7403,  0.7403,  0.7456,  0.7456,\n",
       "            0.7508,  0.7559,  0.7611,  0.7662,  0.7713,  0.7763,  0.7763,  0.7814,\n",
       "            0.7864,  0.8062,  0.8062,  0.8159,  0.8159,  0.8256,  0.8256,  0.8352,\n",
       "           -0.6833, -0.6833, -0.6407, -0.6407, -0.5999, -0.5607, -0.5230, -0.4866,\n",
       "           -0.4866, -0.4515, -0.4176, -0.3531, -0.2924, -0.2924, -0.2634, -0.2634,\n",
       "           -0.2353, -0.2353, -0.2079, -0.1812, -0.1552, -0.1299, -0.1052, -0.1052,\n",
       "           -0.0811, -0.0576, -0.0576, -0.0346, -0.0121, -0.0121,  0.0099,  0.0099,\n",
       "            0.0314,  0.0730,  0.0932,  0.1130,  0.1325,  0.1325,  0.1515,  0.1515,\n",
       "            0.1885,  0.2066,  0.2417,  0.2587,  0.2756,  0.2756,  0.2921,  0.2921,\n",
       "            0.3083,  0.3243,  0.3556,  0.3556,  0.3709,  0.4153,  0.4297,  0.4579,\n",
       "            0.4579,  0.4717,  0.4853,  0.4853,  0.4987,  0.5119,  0.5119,  0.5250,\n",
       "            0.5379,  0.5507,  0.6001,  0.6001,  0.6120,  0.6120,  0.6239,  0.6239,\n",
       "            0.6356,  0.6356,  0.6471,  0.6585,  0.6585,  0.6698,  0.6810,  0.7030,\n",
       "            0.7351,  0.7456,  0.7559,  0.7662,  0.7662,  0.7763,  0.7763,  0.7864,\n",
       "            0.7864,  0.7963,  0.8062,  0.8159,  0.8256,  0.8352]),\n",
       "   tensor([-0.1863, -0.1604, -0.1476, -0.0627, -0.0512,  0.0155,  0.0155,  0.0679,\n",
       "            0.1273,  0.1650,  0.2103,  0.2704,  0.2869, -0.5468, -0.5468, -0.5281,\n",
       "           -0.4917, -0.4227, -0.3899, -0.2976, -0.2686, -0.2404, -0.1996, -0.1604,\n",
       "           -0.1226, -0.0173,  0.0155,  0.0262,  0.0679,  0.0780,  0.1176,  0.1834,\n",
       "            0.2014,  0.2103,  0.2103,  0.2620,  0.2620,  0.2787,  0.2787,  0.2951,\n",
       "            0.3505,  0.3657,  0.4174,  0.4527,  0.4527,  0.4734,  0.4801,  0.4936,\n",
       "            0.5134,  0.5263,  0.5263,  0.5392,  0.5581,  0.5643,  0.5767,  0.5889,\n",
       "            0.6187,  0.6187,  0.6304,  0.6304,  0.6477,  0.6591,  0.6647,  0.6759,\n",
       "            0.6814,  0.7033,  0.7140,  0.7352,  0.7352,  0.7404,  0.7508,  0.7508,\n",
       "            0.7610,  0.7610,  0.8108,  0.8205, -0.1351, -0.1104, -0.0397, -0.0173,\n",
       "           -0.0173,  0.0047,  0.0473,  0.0473,  0.0576,  0.0679,  0.0679,  0.0881,\n",
       "            0.1079,  0.1176,  0.1369,  0.1924,  0.2365, -0.1863, -0.1863,  0.0368,\n",
       "            0.0881,  0.1079,  0.1079,  0.1176,  0.1557,  0.1834,  0.1834,  0.2014,\n",
       "            0.2014, -0.5853, -0.4917, -0.4740, -0.4395, -0.4227, -0.3899, -0.3582,\n",
       "           -0.3427, -0.3124, -0.2266, -0.2266, -0.2130, -0.1604, -0.1604, -0.0744,\n",
       "           -0.0397, -0.0397, -0.0062,  0.0155,  0.0368,  0.0473,  0.0679,  0.0780,\n",
       "            0.0881,  0.0881,  0.0980,  0.1079,  0.1079,  0.1464,  0.1557,  0.1834,\n",
       "            0.2103,  0.2279,  0.2365,  0.2451,  0.2536,  0.2620,  0.2704,  0.2869,\n",
       "            0.2951,  0.3192,  0.3271,  0.3349,  0.3505,  0.3657,  0.3956,  0.4029,\n",
       "            0.4102,  0.4246,  0.4246,  0.4734,  0.5068,  0.5134,  0.5134,  0.5392,\n",
       "            0.5455,  0.5643,  0.5705,  0.5767,  0.6246,  0.6362,  0.6477,  0.6534,\n",
       "            0.6703, -0.5658, -0.4917, -0.4740, -0.4566, -0.4395, -0.4062, -0.3899,\n",
       "           -0.3899, -0.3739, -0.3739, -0.3582, -0.2266, -0.1604, -0.1476, -0.1476,\n",
       "           -0.1226, -0.0284,  0.0155,  0.0262,  0.0679,  0.0780,  0.0980,  0.1176,\n",
       "            0.1273,  0.1369,  0.1464,  0.1557,  0.1650,  0.1924,  0.2103,  0.2365,\n",
       "            0.2451,  0.2536,  0.2536,  0.2620,  0.2704,  0.2787,  0.2787,  0.2869,\n",
       "            0.2951,  0.3112,  0.3271,  0.3657,  0.3808,  0.3808,  0.3956,  0.4597,\n",
       "            0.4597,  0.4734,  0.5134,  0.5134,  0.5199,  0.5263,  0.5455,  0.5455,\n",
       "            0.5518,  0.5581,  0.5643,  0.5767,  0.5828,  0.5889,  0.5949,  0.6009,\n",
       "            0.6009,  0.6069,  0.6477,  0.6534,  0.6647,  0.6759,  0.6979,  0.7140,\n",
       "            0.7194,  0.7247,  0.7456,  0.7456,  0.7559,  0.7762,  0.7912,  0.8010,\n",
       "            0.8205, -0.4740, -0.4395, -0.4227, -0.4062, -0.3899, -0.3739, -0.3582,\n",
       "           -0.3427, -0.2544, -0.2404, -0.2266, -0.2130, -0.2130, -0.1226, -0.0744,\n",
       "           -0.0397, -0.0284, -0.0062,  0.0262,  0.0679,  0.0679,  0.0780,  0.0980,\n",
       "            0.1079,  0.1369,  0.1557,  0.1650,  0.2014,  0.2103,  0.3192,  0.3192,\n",
       "            0.3349,  0.3427,  0.3505,  0.3808,  0.3956,  0.4387,  0.4597,  0.4665,\n",
       "            0.4734, -0.5097, -0.4566, -0.4062, -0.3739, -0.2830, -0.2404, -0.1604,\n",
       "           -0.1104, -0.0982, -0.0982, -0.0863, -0.0744, -0.0627, -0.0284, -0.0173,\n",
       "           -0.0062,  0.0047,  0.0473,  0.1557,  0.1834,  0.2365,  0.2365,  0.2620,\n",
       "            0.2704,  0.2869,  0.3032,  0.3657,  0.3882,  0.4029,  0.4174,  0.4246,\n",
       "            0.4317,  0.4527,  0.4597,  0.4801,  0.4869,  0.4936,  0.4936,  0.5002,\n",
       "            0.5068,  0.5328,  0.5392,  0.5392,  0.5455,  0.5643,  0.5767,  0.6009,\n",
       "            0.6128,  0.6304,  0.6304,  0.6362,  0.6759,  0.6924,  0.7299,  0.7404,\n",
       "           -0.5468, -0.5097, -0.4917, -0.4395, -0.4062, -0.3739, -0.3427, -0.3124,\n",
       "           -0.2130, -0.0744, -0.0284,  0.0262,  0.0576,  0.1464,  0.1557,  0.1650,\n",
       "            0.1743,  0.1834,  0.1834,  0.1924,  0.2279,  0.2365,  0.2951,  0.3505,\n",
       "            0.3581,  0.4246,  0.4527,  0.4665,  0.5199,  0.5455,  0.5581,  0.5705,\n",
       "            0.5889,  0.5889,  0.6009,  0.6187,  0.6246,  0.6246,  0.6362,  0.6420,\n",
       "            0.6647,  0.6924,  0.6979,  0.7247,  0.7247,  0.7299,  0.7610,  0.7762,\n",
       "            0.7912,  0.8108, -0.5281, -0.5097, -0.4917, -0.3899, -0.3427, -0.3427,\n",
       "           -0.3274, -0.3274, -0.2830, -0.2404, -0.1863, -0.1604, -0.1476, -0.1476,\n",
       "           -0.0627, -0.0284, -0.0284, -0.0062,  0.0047,  0.0576,  0.0980,  0.1464,\n",
       "            0.1464,  0.1650,  0.1650,  0.1743,  0.1834,  0.2103,  0.2103,  0.2191,\n",
       "            0.2365,  0.2365,  0.3032,  0.3112,  0.3427,  0.3427,  0.3581,  0.3808,\n",
       "            0.4458,  0.4527,  0.4801,  0.5134,  0.5199,  0.5392,  0.5767,  0.5889,\n",
       "            0.6187,  0.6420, -0.7559, -0.6253, -0.6051, -0.5658, -0.5281, -0.5097,\n",
       "           -0.4917, -0.4227, -0.4062, -0.3582, -0.2544, -0.1733, -0.0982, -0.0627,\n",
       "           -0.0512, -0.0397,  0.0047,  0.0473,  0.0473,  0.0679,  0.0780,  0.1079,\n",
       "            0.1079,  0.1273,  0.1369,  0.1464,  0.1743,  0.2103,  0.2191,  0.2451,\n",
       "            0.2451,  0.3112,  0.3349,  0.3808,  0.4527,  0.4597,  0.5392,  0.5518,\n",
       "            0.5828,  0.5949,  0.6009,  0.6069,  0.6187,  0.6420,  0.6591,  0.6703,\n",
       "            0.6759,  0.6924,  0.7087,  0.7299,  0.7404,  0.7456,  0.7762]),\n",
       "   tensor([-0.3896, -0.3568, -0.3408, -0.3251, -0.3096, -0.2943, -0.2943, -0.2793,\n",
       "           -0.2645, -0.2645, -0.2499, -0.1935, -0.1665, -0.1532, -0.1402, -0.1273,\n",
       "           -0.1273, -0.1019, -0.0895, -0.0773, -0.0773, -0.0651, -0.0532, -0.0532,\n",
       "           -0.0413, -0.0413, -0.0181, -0.0066,  0.0047,  0.0047,  0.0158,  0.0269,\n",
       "            0.0378,  0.0486,  0.0699,  0.0804,  0.0804, -0.3896, -0.3896, -0.3731,\n",
       "           -0.3568, -0.3408, -0.3251, -0.3096, -0.3096, -0.2943, -0.2943, -0.2793,\n",
       "           -0.2645, -0.2355, -0.2073, -0.1935, -0.1799, -0.1665, -0.1532, -0.1532,\n",
       "           -0.1402, -0.1273, -0.1145, -0.1019, -0.0773, -0.0651, -0.0532, -0.0413,\n",
       "           -0.0413, -0.0296, -0.0296, -0.0066, -0.0066,  0.0047,  0.0378,  0.0378,\n",
       "            0.0486,  0.0486,  0.0593,  0.0699,  0.0804, -0.2943, -0.2943, -0.2645,\n",
       "           -0.2213, -0.2213, -0.2073, -0.1935, -0.1935, -0.1532, -0.1402, -0.1402,\n",
       "           -0.1273, -0.1145, -0.1145, -0.1019, -0.0895, -0.0895, -0.0773, -0.0651,\n",
       "           -0.0532, -0.0413, -0.0413, -0.0066,  0.0047,  0.0047,  0.0158,  0.0269,\n",
       "            0.0378,  0.0378,  0.0486,  0.0486,  0.0593,  0.0593,  0.0699,  0.0699,\n",
       "            0.0804,  0.0804, -0.3251, -0.3251, -0.2943, -0.2943, -0.2645, -0.2355,\n",
       "           -0.1935, -0.1799, -0.1532, -0.1532, -0.1402, -0.1273, -0.1273, -0.1145,\n",
       "           -0.1019, -0.1019, -0.0895, -0.0895, -0.0773, -0.0773, -0.0651, -0.0651,\n",
       "           -0.0532, -0.0413, -0.0296, -0.0181, -0.0066, -0.0066,  0.0047,  0.0158,\n",
       "            0.0269,  0.0269,  0.0378,  0.0378,  0.0486,  0.0486,  0.0593,  0.0699,\n",
       "            0.0804, -0.7951, -0.7704, -0.7463, -0.7463, -0.7228, -0.7228, -0.6998,\n",
       "           -0.6998, -0.6773, -0.6773, -0.6553, -0.6338, -0.6338, -0.6128, -0.6128,\n",
       "           -0.5922, -0.5720, -0.5720, -0.5521, -0.5327, -0.5137, -0.5137, -0.4950,\n",
       "           -0.4950, -0.4766, -0.4586, -0.4586, -0.4409, -0.4235, -0.4064, -0.3896,\n",
       "           -0.3731, -0.3731, -0.3408, -0.3408, -0.3251, -0.3096, -0.2943, -0.2793,\n",
       "           -0.2645, -0.2645, -0.2499, -0.2355, -0.2355, -0.2213, -0.2073, -0.2073,\n",
       "           -0.1935, -0.1935, -0.1665, -0.1665, -0.1532, -0.1532, -0.1273, -0.1145,\n",
       "           -0.1019, -0.1019, -0.0773, -0.0651, -0.0532, -0.0532, -0.0413, -0.0296,\n",
       "           -0.0181, -0.0181, -0.0066, -0.0066,  0.0047,  0.0158,  0.0269,  0.0486,\n",
       "            0.0486,  0.0593,  0.0593,  0.0699,  0.0804,  0.0804, -0.6553, -0.6553,\n",
       "           -0.5922, -0.5922, -0.5720, -0.5521, -0.5521, -0.5327, -0.5137, -0.5137,\n",
       "           -0.4766, -0.4766, -0.4586, -0.4064, -0.3896, -0.3896, -0.3408, -0.3408,\n",
       "           -0.3251, -0.2793, -0.2793, -0.2645, -0.2645, -0.2355, -0.2355, -0.2213,\n",
       "           -0.2073, -0.2073, -0.1935, -0.1799, -0.1799, -0.1532, -0.1402, -0.1273,\n",
       "           -0.1273, -0.1145, -0.1145, -0.1019, -0.1019, -0.0895, -0.0895, -0.0773,\n",
       "           -0.0651, -0.0651, -0.0532, -0.0296, -0.0296, -0.0181, -0.0066,  0.0047,\n",
       "            0.0047,  0.0158,  0.0269,  0.0269,  0.0378,  0.0593,  0.0699,  0.0699,\n",
       "           -0.7704, -0.7704, -0.7463, -0.6998, -0.6773, -0.6773, -0.6553, -0.6338,\n",
       "           -0.6338, -0.6128, -0.6128, -0.5922, -0.5720, -0.5521, -0.5327, -0.5137,\n",
       "           -0.4950, -0.4950, -0.4409, -0.4235, -0.3896, -0.3896, -0.3731, -0.3568,\n",
       "           -0.3568, -0.3408, -0.3408, -0.3096, -0.3096, -0.2943, -0.2645, -0.2645,\n",
       "           -0.2499, -0.2355, -0.2213, -0.2213, -0.2073, -0.1935, -0.1799, -0.1665,\n",
       "           -0.1532, -0.1532, -0.1402, -0.1402, -0.1273, -0.1273, -0.1145, -0.1145,\n",
       "           -0.1019, -0.0895, -0.0773, -0.0532, -0.0413, -0.0296, -0.0181, -0.0066,\n",
       "           -0.0066,  0.0158,  0.0269,  0.0269,  0.0378,  0.0486,  0.0486,  0.0593,\n",
       "            0.0699,  0.0699, -0.7463, -0.7463, -0.7228, -0.7228, -0.6773, -0.6553,\n",
       "           -0.6553, -0.6338, -0.6128, -0.5922, -0.5922, -0.5720, -0.5521, -0.5327,\n",
       "           -0.5327, -0.5137, -0.4950, -0.4766, -0.4586, -0.4409, -0.4409, -0.4235,\n",
       "           -0.4235, -0.4064, -0.4064, -0.3896, -0.3408, -0.3251, -0.3096, -0.3096,\n",
       "           -0.2943, -0.2793, -0.2645, -0.2499, -0.2355, -0.2355, -0.2213, -0.2073,\n",
       "           -0.1935, -0.1799, -0.1532, -0.1532, -0.1402, -0.1273, -0.1145, -0.1019,\n",
       "           -0.0895, -0.0773, -0.0651, -0.0532, -0.0413, -0.0296, -0.0181, -0.0066,\n",
       "           -0.0066,  0.0047,  0.0047,  0.0158,  0.0158,  0.0378,  0.0486,  0.0593,\n",
       "            0.0593,  0.0699, -0.6998, -0.6998, -0.6773, -0.6773, -0.6553, -0.6553,\n",
       "           -0.6338, -0.6128, -0.5922, -0.5922, -0.5720, -0.5521, -0.5137, -0.4950,\n",
       "           -0.4586, -0.4586, -0.4409, -0.4235, -0.4064, -0.3896, -0.3896, -0.3408,\n",
       "           -0.3408, -0.3251, -0.3251, -0.3096, -0.3096, -0.2793, -0.2793, -0.2645,\n",
       "           -0.2499, -0.2355, -0.2213, -0.2213, -0.2073, -0.2073, -0.1935, -0.1935,\n",
       "           -0.1665, -0.1532, -0.1532, -0.1402, -0.1273, -0.1145, -0.1019, -0.0773,\n",
       "           -0.0651, -0.0532, -0.0413, -0.0296, -0.0296, -0.0181, -0.0181, -0.0066,\n",
       "            0.0047,  0.0047,  0.0158,  0.0378,  0.0593,  0.0699,  0.0699, -0.8204,\n",
       "           -0.7951, -0.7704, -0.7228, -0.7228, -0.6998, -0.6998, -0.6773, -0.6553,\n",
       "           -0.6553, -0.6338, -0.6128, -0.6128, -0.5922, -0.5720, -0.5521, -0.5521,\n",
       "           -0.5327, -0.4950, -0.4950, -0.4766, -0.4409, -0.4235, -0.4235, -0.4064,\n",
       "           -0.3896, -0.3896, -0.3731, -0.3568, -0.3408, -0.3096, -0.3096, -0.2943,\n",
       "           -0.2793, -0.2645, -0.2499, -0.2213, -0.2213, -0.2073, -0.1935, -0.1799,\n",
       "           -0.1665, -0.1532, -0.1402, -0.1145, -0.1019, -0.0895, -0.0773, -0.0773,\n",
       "           -0.0651, -0.0651, -0.0532, -0.0532, -0.0413, -0.0296, -0.0296, -0.0181,\n",
       "           -0.0181,  0.0047,  0.0158,  0.0269,  0.0378,  0.0378,  0.0486,  0.0593,\n",
       "           -0.7951, -0.7463, -0.7463, -0.7228, -0.6998, -0.6773, -0.6553, -0.6553,\n",
       "           -0.6338, -0.6128, -0.6128, -0.5720, -0.5521, -0.5521, -0.5327, -0.5137,\n",
       "           -0.4950, -0.4950, -0.4766, -0.4766, -0.4586, -0.4586, -0.4409, -0.4064,\n",
       "           -0.3896, -0.3896, -0.3731, -0.3731, -0.3568, -0.3408, -0.3408, -0.3251,\n",
       "           -0.3251, -0.2943, -0.2793, -0.2793, -0.2355, -0.2355, -0.2213, -0.2213,\n",
       "           -0.2073, -0.1935, -0.1935, -0.1799, -0.1665, -0.1665, -0.1532, -0.1532,\n",
       "           -0.1402, -0.1273, -0.1273, -0.1019, -0.0895, -0.0773, -0.0651, -0.0651,\n",
       "           -0.0413, -0.0296, -0.0296, -0.0181, -0.0181, -0.0066, -0.0066,  0.0047,\n",
       "            0.0158,  0.0158,  0.0269,  0.0269,  0.0378])],\n",
       "  'Time to Maturity': [tensor([0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079,\n",
       "           0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079,\n",
       "           0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079,\n",
       "           0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079,\n",
       "           0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079, 0.0079,\n",
       "           0.0079, 0.0079, 0.0079, 0.0079, 0.0317, 0.0317, 0.0317, 0.0317, 0.0317,\n",
       "           0.0317, 0.0317, 0.0317, 0.0317, 0.0317, 0.0317, 0.0317, 0.0317, 0.0317,\n",
       "           0.0317, 0.0317, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556,\n",
       "           0.0556, 0.0556, 0.0556, 0.0556, 0.0873, 0.0873, 0.0873, 0.0873, 0.0873,\n",
       "           0.0873, 0.0873, 0.0873, 0.0873, 0.0873, 0.0873, 0.1151, 0.1151, 0.1151,\n",
       "           0.1151, 0.1151, 0.1151, 0.1151, 0.1151, 0.1151, 0.1151, 0.1151, 0.1151,\n",
       "           0.1151, 0.1151, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468,\n",
       "           0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468,\n",
       "           0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468,\n",
       "           0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468,\n",
       "           0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468,\n",
       "           0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468,\n",
       "           0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468, 0.1468,\n",
       "           0.1468, 0.1468, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579,\n",
       "           0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579,\n",
       "           0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579,\n",
       "           0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579,\n",
       "           0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579,\n",
       "           0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579,\n",
       "           0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579, 0.2579,\n",
       "           0.2579, 0.2579, 0.2579, 0.2579, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968,\n",
       "           0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968,\n",
       "           0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968,\n",
       "           0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968,\n",
       "           0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968,\n",
       "           0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968,\n",
       "           0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.3968, 0.7579, 0.7579,\n",
       "           0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579,\n",
       "           0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579,\n",
       "           0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579,\n",
       "           0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579,\n",
       "           0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579,\n",
       "           0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579, 0.7579,\n",
       "           0.7579, 0.7579, 0.7579, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302,\n",
       "           1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302,\n",
       "           1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302,\n",
       "           1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302,\n",
       "           1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302,\n",
       "           1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302,\n",
       "           1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302,\n",
       "           1.2302, 1.2302, 1.2302, 1.2302, 1.2302, 1.2302]),\n",
       "   tensor([1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968, 1.3968,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413, 2.8413,\n",
       "           2.8413, 2.8413, 2.8413, 2.8413]),\n",
       "   tensor([0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119,\n",
       "           0.0119, 0.0119, 0.0119, 0.0119, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675,\n",
       "           0.0675, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675, 0.0675,\n",
       "           0.0675, 0.0675, 0.0675, 0.0952, 0.0952, 0.0952, 0.0952, 0.0952, 0.0952,\n",
       "           0.0952, 0.0952, 0.0952, 0.0952, 0.0952, 0.0952, 0.1548, 0.1548, 0.1548,\n",
       "           0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548,\n",
       "           0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548,\n",
       "           0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548,\n",
       "           0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548,\n",
       "           0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548,\n",
       "           0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548,\n",
       "           0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.1548, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937,\n",
       "           0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.2937, 0.4048, 0.4048, 0.4048,\n",
       "           0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048,\n",
       "           0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048,\n",
       "           0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048,\n",
       "           0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048, 0.4048,\n",
       "           0.4048, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437,\n",
       "           0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437,\n",
       "           0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437,\n",
       "           0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437,\n",
       "           0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437,\n",
       "           0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437, 0.5437,\n",
       "           0.5437, 0.5437, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548,\n",
       "           0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548,\n",
       "           0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548,\n",
       "           0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548,\n",
       "           0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548,\n",
       "           0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 0.6548, 1.0159, 1.0159,\n",
       "           1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159,\n",
       "           1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159,\n",
       "           1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159,\n",
       "           1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159,\n",
       "           1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159, 1.0159,\n",
       "           1.0159, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770,\n",
       "           1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770,\n",
       "           1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770,\n",
       "           1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770,\n",
       "           1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770,\n",
       "           1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770, 1.3770]),\n",
       "   tensor([0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159,\n",
       "           0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159,\n",
       "           0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159,\n",
       "           0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159, 0.0159,\n",
       "           0.0159, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0437,\n",
       "           0.0437, 0.0437, 0.0437, 0.0437, 0.0437, 0.0714, 0.0714, 0.0714, 0.0714,\n",
       "           0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,\n",
       "           0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,\n",
       "           0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,\n",
       "           0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0992, 0.0992, 0.0992,\n",
       "           0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992,\n",
       "           0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992,\n",
       "           0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992,\n",
       "           0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992, 0.0992,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.1310,\n",
       "           0.1310, 0.1310, 0.1310, 0.1310, 0.1310, 0.2421, 0.2421, 0.2421, 0.2421,\n",
       "           0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421,\n",
       "           0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421,\n",
       "           0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421,\n",
       "           0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421,\n",
       "           0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421,\n",
       "           0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421, 0.2421,\n",
       "           0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532,\n",
       "           0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532,\n",
       "           0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532,\n",
       "           0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532,\n",
       "           0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532,\n",
       "           0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532,\n",
       "           0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532, 0.3532,\n",
       "           0.3532, 0.3532, 0.3532, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921, 0.4921,\n",
       "           0.4921, 0.4921, 0.4921, 0.4921, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032,\n",
       "           0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032,\n",
       "           0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032,\n",
       "           0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032,\n",
       "           0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032,\n",
       "           0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032,\n",
       "           0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032, 0.6032,\n",
       "           0.6032, 0.6032, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643, 0.9643,\n",
       "           0.9643, 0.9643, 0.9643, 0.9643, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254, 1.3254,\n",
       "           1.3254])],\n",
       "  'Implied Volatility': [tensor([0.3923, 0.3923, 0.1797, 0.3923, 0.3923, 0.1797, 0.3923, 0.1797, 0.1797,\n",
       "           0.1797, 0.3923, 0.3923, 0.1797, 0.1797, 0.1797, 0.1797, 0.1797, 0.3923,\n",
       "           0.3923, 0.1797, 0.3923, 0.3923, 0.1797, 0.3923, 0.1797, 0.1797, 0.3923,\n",
       "           0.3923, 0.3923, 0.3923, 0.2193, 0.1797, 0.1590, 0.1631, 0.1689, 0.1225,\n",
       "           0.1797, 0.1225, 0.1225, 0.1797, 0.1797, 0.1225, 0.1225, 0.1225, 0.1225,\n",
       "           0.1225, 0.1797, 0.1797, 0.1225, 0.2669, 0.5074, 0.2669, 0.4758, 0.4473,\n",
       "           0.2669, 0.2154, 0.2126, 0.1607, 0.1533, 0.1533, 0.1686, 0.1772, 0.1961,\n",
       "           0.2081, 0.1769, 0.4566, 0.4253, 0.3597, 0.2968, 0.3032, 0.2326, 0.2068,\n",
       "           0.1466, 0.1640, 0.1411, 0.1411, 0.3817, 0.3817, 0.3551, 0.2892, 0.2965,\n",
       "           0.2523, 0.1733, 0.1482, 0.1441, 0.1432, 0.1598, 0.3750, 0.3472, 0.3597,\n",
       "           0.3386, 0.2844, 0.2718, 0.2510, 0.2381, 0.2073, 0.1999, 0.1607, 0.1535,\n",
       "           0.1763, 0.1834, 0.3083, 0.3204, 0.7702, 0.3083, 0.7073, 0.3083, 0.3083,\n",
       "           0.5686, 0.3204, 0.3083, 0.5151, 0.4840, 0.4738, 0.3083, 0.3204, 0.3204,\n",
       "           0.3083, 0.3204, 0.3083, 0.3083, 0.3083, 0.3204, 0.2911, 0.2828, 0.2812,\n",
       "           0.2627, 0.2587, 0.2574, 0.2564, 0.2556, 0.2560, 0.2511, 0.2460, 0.2445,\n",
       "           0.2376, 0.2363, 0.2348, 0.2325, 0.2237, 0.2219, 0.2197, 0.2114, 0.1900,\n",
       "           0.2282, 0.2114, 0.2114, 0.2287, 0.2114, 0.2324, 0.2324, 0.2114, 0.2324,\n",
       "           0.2324, 0.2324, 0.2114, 0.2324, 0.2114, 0.2114, 0.2114, 0.2114, 0.2324,\n",
       "           0.2114, 0.2114, 0.2814, 0.2928, 0.2814, 0.2814, 0.2814, 0.5563, 0.5467,\n",
       "           0.2814, 0.5006, 0.4916, 0.2814, 0.4292, 0.2928, 0.2814, 0.2814, 0.2928,\n",
       "           0.2928, 0.2928, 0.2814, 0.2928, 0.2928, 0.2814, 0.2814, 0.2683, 0.2619,\n",
       "           0.2590, 0.2575, 0.2536, 0.2510, 0.2492, 0.2493, 0.2507, 0.2420, 0.2409,\n",
       "           0.2373, 0.2362, 0.2306, 0.2266, 0.2255, 0.2257, 0.2216, 0.2215, 0.2148,\n",
       "           0.2140, 0.2124, 0.2114, 0.2112, 0.2102, 0.2061, 0.2066, 0.2068, 0.2047,\n",
       "           0.2070, 0.2022, 0.2068, 0.2068, 0.2109, 0.2004, 0.2004, 0.2004, 0.2223,\n",
       "           0.2223, 0.2223, 0.2223, 0.2223, 0.2738, 0.2738, 0.6135, 0.2738, 0.5489,\n",
       "           0.2738, 0.2738, 0.5315, 0.5230, 0.2789, 0.2789, 0.2738, 0.2738, 0.2738,\n",
       "           0.2789, 0.2738, 0.2789, 0.2789, 0.2789, 0.2789, 0.2738, 0.2789, 0.2789,\n",
       "           0.2738, 0.2789, 0.2789, 0.2772, 0.2738, 0.2720, 0.2490, 0.2468, 0.2453,\n",
       "           0.2367, 0.2387, 0.2288, 0.2203, 0.2189, 0.2176, 0.2118, 0.2079, 0.2020,\n",
       "           0.2011, 0.2020, 0.2008, 0.1967, 0.1964, 0.1962, 0.1959, 0.1933, 0.1918,\n",
       "           0.1927, 0.1825, 0.1955, 0.1840, 0.1840, 0.2271, 0.1840, 0.2962, 0.3032,\n",
       "           0.2962, 0.2962, 0.2962, 0.2962, 0.3032, 0.2962, 0.2962, 0.3032, 0.3032,\n",
       "           0.2962, 0.2962, 0.3032, 0.2962, 0.3032, 0.2962, 0.2962, 0.3032, 0.2962,\n",
       "           0.2962, 0.2962, 0.2962, 0.2963, 0.2895, 0.2882, 0.2807, 0.2761, 0.2751,\n",
       "           0.2735, 0.2717, 0.2489, 0.2482, 0.2485, 0.2414, 0.2353, 0.2357, 0.2292,\n",
       "           0.2243, 0.2168, 0.2155, 0.2112, 0.2075, 0.2084, 0.2067, 0.2052, 0.2027,\n",
       "           0.2014, 0.2005, 0.1986, 0.2001, 0.1984, 0.2001, 0.2029, 0.2003, 0.1976,\n",
       "           0.1976, 0.1976, 0.2010, 0.2879, 0.2983, 0.2983, 0.2879, 0.2879, 0.2879,\n",
       "           0.2879, 0.2983, 0.2879, 0.2983, 0.2983, 0.2983, 0.2879, 0.2983, 0.2879,\n",
       "           0.2879, 0.2879, 0.2983, 0.2983, 0.2879, 0.2983, 0.2983, 0.2879, 0.2983,\n",
       "           0.2940, 0.2869, 0.2819, 0.2829, 0.2819, 0.2787, 0.2609, 0.2564, 0.2511,\n",
       "           0.2492, 0.2456, 0.2435, 0.2416, 0.2385, 0.2382, 0.2354, 0.2356, 0.2341,\n",
       "           0.2289, 0.2259, 0.2268, 0.2236, 0.2240, 0.2228, 0.2204, 0.2184, 0.2154,\n",
       "           0.2133, 0.2142, 0.2135, 0.2130, 0.2095, 0.2072, 0.2055, 0.2038, 0.2025,\n",
       "           0.2025, 0.2033, 0.2041, 0.2094, 0.2061, 0.2038]),\n",
       "   tensor([0.2782, 0.2701, 0.2781, 0.2696, 0.2772, 0.2768, 0.2688, 0.2763, 0.2764,\n",
       "           0.2664, 0.2751, 0.2659, 0.2748, 0.2653, 0.2746, 0.2645, 0.2746, 0.2635,\n",
       "           0.2740, 0.2635, 0.2632, 0.2742, 0.2630, 0.2632, 0.2728, 0.2628, 0.2742,\n",
       "           0.2623, 0.2622, 0.2758, 0.2626, 0.2768, 0.2626, 0.2780, 0.2779, 0.2623,\n",
       "           0.2785, 0.2630, 0.2636, 0.2794, 0.2640, 0.2822, 0.2801, 0.2634, 0.2836,\n",
       "           0.2638, 0.2642, 0.2654, 0.2655, 0.2866, 0.2657, 0.2654, 0.2816, 0.2816,\n",
       "           0.2677, 0.2688, 0.2816, 0.2703, 0.2816, 0.2692, 0.2816, 0.2695, 0.2816,\n",
       "           0.2698, 0.2816, 0.2713, 0.2816, 0.2816, 0.2816, 0.2816, 0.2735, 0.2738,\n",
       "           0.2816, 0.2756, 0.2816, 0.2783, 0.2774, 0.2816, 0.2786, 0.2816, 0.2794,\n",
       "           0.2816, 0.2812, 0.2816, 0.2836, 0.2816, 0.2831, 0.2816, 0.2816, 0.2829,\n",
       "           0.2816, 0.2831, 0.2816, 0.2857, 0.2858, 0.2853, 0.2853, 0.2816, 0.2816,\n",
       "           0.2853, 0.2816, 0.2853, 0.2853, 0.2853, 0.2816, 0.2816, 0.2816, 0.2853,\n",
       "           0.2816, 0.2816, 0.2853, 0.2816, 0.2816, 0.2853, 0.2853, 0.2816, 0.2853,\n",
       "           0.2853, 0.2816, 0.2853, 0.2816, 0.2816, 0.2853, 0.2853, 0.2853, 0.2816,\n",
       "           0.2853, 0.2816, 0.2853, 0.2816, 0.2816, 0.2816, 0.2816, 0.2853, 0.2816,\n",
       "           0.2853, 0.2816, 0.2853, 0.2816, 0.2853, 0.2816, 0.2853, 0.2816, 0.2816,\n",
       "           0.4502, 0.3309, 0.4256, 0.3315, 0.3258, 0.3820, 0.3605, 0.3499, 0.3192,\n",
       "           0.3191, 0.3159, 0.3147, 0.3115, 0.3120, 0.3091, 0.3101, 0.3050, 0.3095,\n",
       "           0.3084, 0.3066, 0.2980, 0.3041, 0.2969, 0.3050, 0.2949, 0.2940, 0.3039,\n",
       "           0.2928, 0.2935, 0.3026, 0.2923, 0.3009, 0.3022, 0.2892, 0.2909, 0.2879,\n",
       "           0.2880, 0.2994, 0.2874, 0.2996, 0.2868, 0.2861, 0.2869, 0.3009, 0.2878,\n",
       "           0.2998, 0.2867, 0.2969, 0.2973, 0.2992, 0.2858, 0.2998, 0.2994, 0.2861,\n",
       "           0.2868, 0.2853, 0.3033, 0.3053, 0.2861, 0.3042, 0.2875, 0.2864, 0.3051,\n",
       "           0.3059, 0.2864, 0.3093, 0.2886, 0.3101, 0.2883, 0.3129, 0.2888, 0.3133,\n",
       "           0.2893, 0.3155, 0.2886, 0.2907, 0.3148, 0.2902, 0.3189, 0.2925, 0.3191,\n",
       "           0.3191, 0.2921, 0.2942, 0.3191, 0.2965, 0.3191, 0.2990, 0.3191, 0.3191,\n",
       "           0.3191, 0.3191, 0.3191, 0.3191]),\n",
       "   tensor([0.2434, 0.4594, 0.4594, 0.4340, 0.2434, 0.2434, 0.4851, 0.2434, 1.3178,\n",
       "           1.5871, 1.6773, 1.6773, 0.2434, 0.4873, 0.3676, 0.3676, 0.4873, 0.4873,\n",
       "           0.3676, 0.3676, 0.3676, 0.4873, 0.3676, 0.4873, 0.4873, 0.2448, 0.2937,\n",
       "           0.2508, 0.2793, 0.4018, 0.5160, 0.5944, 0.5944, 0.4677, 0.5944, 0.4677,\n",
       "           0.5944, 0.4677, 0.5944, 0.5944, 0.4677, 0.5944, 0.5944, 0.4677, 0.5944,\n",
       "           0.5944, 0.4677, 0.4677, 0.4677, 0.4677, 0.5944, 0.4677, 0.4677, 0.5944,\n",
       "           0.5944, 0.5944, 0.4677, 0.5944, 0.4677, 0.5944, 0.5944, 0.4677, 0.4677,\n",
       "           0.5944, 0.4677, 0.5944, 0.4677, 0.4677, 0.5944, 0.5944, 0.4677, 0.5944,\n",
       "           0.4677, 0.5944, 0.4677, 0.5944, 0.4534, 0.3363, 0.2584, 0.2522, 0.2796,\n",
       "           0.2490, 0.2538, 0.2933, 0.3037, 0.2642, 0.3151, 0.2809, 0.2975, 0.3050,\n",
       "           0.3322, 0.4625, 0.4625, 0.4739, 0.3705, 0.2534, 0.3163, 0.2832, 0.3337,\n",
       "           0.3491, 0.3237, 0.3466, 0.4004, 0.3638, 0.4004, 0.3890, 0.3890, 0.3890,\n",
       "           0.3351, 0.3351, 0.3890, 0.3890, 0.3351, 0.3351, 0.3890, 0.3351, 0.3351,\n",
       "           0.3510, 0.3096, 0.2639, 0.2586, 0.2718, 0.2549, 0.2529, 0.2653, 0.2527,\n",
       "           0.2538, 0.2559, 0.2592, 0.2782, 0.2859, 0.2641, 0.2901, 0.2805, 0.3284,\n",
       "           0.3580, 0.3184, 0.3723, 0.3723, 0.3444, 0.3471, 0.3723, 0.3570, 0.3723,\n",
       "           0.3723, 0.3570, 0.3570, 0.3723, 0.3723, 0.3723, 0.3723, 0.3723, 0.3723,\n",
       "           0.3570, 0.3723, 0.3723, 0.3570, 0.3570, 0.3723, 0.3570, 0.3723, 0.3723,\n",
       "           0.3570, 0.3570, 0.3723, 0.3570, 0.3723, 0.3570, 0.3570, 0.3019, 0.3230,\n",
       "           0.3230, 0.3230, 0.3019, 0.3019, 0.3019, 0.3230, 0.3019, 0.3230, 0.3230,\n",
       "           0.3019, 0.2804, 0.2753, 0.2881, 0.2831, 0.2664, 0.2622, 0.2542, 0.2529,\n",
       "           0.2542, 0.2661, 0.2683, 0.2728, 0.2748, 0.2780, 0.2624, 0.2644, 0.2708,\n",
       "           0.2751, 0.3268, 0.2892, 0.2923, 0.3424, 0.2970, 0.3424, 0.3073, 0.3424,\n",
       "           0.3424, 0.3424, 0.3202, 0.3271, 0.3424, 0.3317, 0.3424, 0.3317, 0.3317,\n",
       "           0.3424, 0.3424, 0.3317, 0.3424, 0.3317, 0.3317, 0.3317, 0.3424, 0.3317,\n",
       "           0.3424, 0.3424, 0.3424, 0.3424, 0.3424, 0.3424, 0.3317, 0.3424, 0.3317,\n",
       "           0.3424, 0.3317, 0.3424, 0.3317, 0.3424, 0.3317, 0.3424, 0.3317, 0.3317,\n",
       "           0.3424, 0.3424, 0.3424, 0.3424, 0.3317, 0.3317, 0.3459, 0.5289, 0.3464,\n",
       "           0.3338, 0.3464, 0.4614, 0.3464, 0.4289, 0.3227, 0.3348, 0.3256, 0.3226,\n",
       "           0.3138, 0.2970, 0.2910, 0.2800, 0.2866, 0.2849, 0.2841, 0.2695, 0.2849,\n",
       "           0.2700, 0.2884, 0.2701, 0.2944, 0.2718, 0.3028, 0.2776, 0.3234, 0.3066,\n",
       "           0.3459, 0.3125, 0.3459, 0.3205, 0.3459, 0.3259, 0.3459, 0.3259, 0.3259,\n",
       "           0.3459, 0.4329, 0.4329, 0.4329, 0.3358, 0.3131, 0.3022, 0.2906, 0.2742,\n",
       "           0.2721, 0.2816, 0.2720, 0.2696, 0.2682, 0.2642, 0.2636, 0.2731, 0.2722,\n",
       "           0.2589, 0.2595, 0.2619, 0.2702, 0.3071, 0.2733, 0.2761, 0.2778, 0.3342,\n",
       "           0.3398, 0.3398, 0.3398, 0.3398, 0.3091, 0.3398, 0.3091, 0.3398, 0.3091,\n",
       "           0.3398, 0.3091, 0.3398, 0.3398, 0.3091, 0.3091, 0.3091, 0.3398, 0.3398,\n",
       "           0.3091, 0.3091, 0.3091, 0.3091, 0.3091, 0.3398, 0.3398, 0.3398, 0.3091,\n",
       "           0.3091, 0.3091, 0.3289, 0.3111, 0.3111, 0.3289, 0.3111, 0.3229, 0.3178,\n",
       "           0.3111, 0.2948, 0.2673, 0.2722, 0.2579, 0.2679, 0.2713, 0.2564, 0.2757,\n",
       "           0.2766, 0.2564, 0.2779, 0.2570, 0.2597, 0.2612, 0.2672, 0.3202, 0.2769,\n",
       "           0.2885, 0.2885, 0.2885, 0.3202, 0.3202, 0.3202, 0.2885, 0.2885, 0.3202,\n",
       "           0.3202, 0.3202, 0.2885, 0.3202, 0.2885, 0.3202, 0.2885, 0.3202, 0.3202,\n",
       "           0.2885, 0.3202, 0.2885, 0.3202, 0.3202, 0.2885, 0.2885, 0.3322, 0.3322,\n",
       "           0.3312, 0.3469, 0.3234, 0.3083, 0.3155, 0.3058, 0.3039, 0.2949, 0.2836,\n",
       "           0.2806, 0.2774, 0.2849, 0.2768, 0.2668, 0.2747, 0.2647, 0.2725, 0.2697,\n",
       "           0.2582, 0.2570, 0.2697, 0.2565, 0.2696, 0.2695, 0.2720, 0.2558, 0.2722,\n",
       "           0.2561, 0.2556, 0.2765, 0.2597, 0.2597, 0.2592, 0.2937, 0.3002, 0.2642,\n",
       "           0.2990, 0.2711, 0.2990, 0.2786, 0.2786, 0.2786, 0.2990, 0.2990, 0.2786,\n",
       "           0.2990, 0.5692, 0.3397, 0.4719, 0.4457, 0.3336, 0.4074, 0.3285, 0.3205,\n",
       "           0.3186, 0.3222, 0.3010, 0.2881, 0.2873, 0.2849, 0.2762, 0.2834, 0.2810,\n",
       "           0.2700, 0.2792, 0.2681, 0.2678, 0.2663, 0.2770, 0.2657, 0.2652, 0.2648,\n",
       "           0.2773, 0.2636, 0.2789, 0.2634, 0.2785, 0.2638, 0.2657, 0.2674, 0.2722,\n",
       "           0.3094, 0.2781, 0.3094, 0.3094, 0.2781, 0.3094, 0.2781, 0.3094, 0.2781,\n",
       "           0.2781, 0.3094, 0.3094, 0.2781, 0.3094, 0.2781, 0.2781, 0.2781, 0.3094]),\n",
       "   tensor([0.3781, 0.4787, 0.4787, 0.4787, 0.3781, 0.3781, 0.4787, 0.3781, 0.3781,\n",
       "           0.4787, 0.4787, 0.3781, 0.4787, 0.4787, 0.4787, 0.3781, 0.4787, 0.3781,\n",
       "           0.3781, 0.3781, 0.4505, 0.4237, 0.3781, 0.3990, 0.3656, 0.3770, 0.3439,\n",
       "           0.3362, 0.3320, 0.3346, 0.3309, 0.3318, 0.3533, 0.3467, 0.3977, 0.3781,\n",
       "           0.3977, 0.3671, 0.3920, 0.3920, 0.3671, 0.3920, 0.3671, 0.3671, 0.3920,\n",
       "           0.3671, 0.3920, 0.3920, 0.3671, 0.3671, 0.3671, 0.3920, 0.3671, 0.3671,\n",
       "           0.3671, 0.3920, 0.3920, 0.3671, 0.3782, 0.3630, 0.3333, 0.3196, 0.3075,\n",
       "           0.3033, 0.3014, 0.2933, 0.2945, 0.2847, 0.2852, 0.2803, 0.2788, 0.2817,\n",
       "           0.2819, 0.2787, 0.2864, 0.2930, 0.2985, 0.3264, 0.3710, 0.3264, 0.3264,\n",
       "           0.4434, 0.4275, 0.3264, 0.4119, 0.3710, 0.3264, 0.3590, 0.3468, 0.3338,\n",
       "           0.3358, 0.3252, 0.3181, 0.3149, 0.3116, 0.3020, 0.2930, 0.2864, 0.2862,\n",
       "           0.2740, 0.2715, 0.2718, 0.2702, 0.2686, 0.2700, 0.2708, 0.2700, 0.2705,\n",
       "           0.2717, 0.2688, 0.2744, 0.2715, 0.2777, 0.2747, 0.3283, 0.3610, 0.3283,\n",
       "           0.4655, 0.4361, 0.3973, 0.3721, 0.3464, 0.3283, 0.3421, 0.3283, 0.3236,\n",
       "           0.3255, 0.3180, 0.3143, 0.3109, 0.3066, 0.3050, 0.3024, 0.2990, 0.2974,\n",
       "           0.2945, 0.2915, 0.2861, 0.2826, 0.2782, 0.2769, 0.2755, 0.2749, 0.2728,\n",
       "           0.2725, 0.2703, 0.2715, 0.2717, 0.2725, 0.2708, 0.2728, 0.2738, 0.2756,\n",
       "           0.3446, 0.3435, 0.3446, 0.3435, 0.3446, 0.3435, 0.3446, 0.3435, 0.3446,\n",
       "           0.3435, 0.3435, 0.3446, 0.3435, 0.3446, 0.3435, 0.3435, 0.3446, 0.3435,\n",
       "           0.3435, 0.3435, 0.3446, 0.3435, 0.3446, 0.3435, 0.3446, 0.3446, 0.3435,\n",
       "           0.3435, 0.3446, 0.3446, 0.3435, 0.3446, 0.3435, 0.3446, 0.3435, 0.3446,\n",
       "           0.3446, 0.3446, 0.3446, 0.3446, 0.3435, 0.3435, 0.3446, 0.3435, 0.3634,\n",
       "           0.3456, 0.3435, 0.3447, 0.3435, 0.3302, 0.3263, 0.3231, 0.3186, 0.3062,\n",
       "           0.3003, 0.2967, 0.2942, 0.2846, 0.2809, 0.2774, 0.2772, 0.2758, 0.2718,\n",
       "           0.2690, 0.2693, 0.2673, 0.2666, 0.2647, 0.2636, 0.2625, 0.2612, 0.2620,\n",
       "           0.2624, 0.2612, 0.2624, 0.2631, 0.2605, 0.3292, 0.3320, 0.3292, 0.3320,\n",
       "           0.3320, 0.3292, 0.3320, 0.3292, 0.3292, 0.3320, 0.3292, 0.3320, 0.3292,\n",
       "           0.3320, 0.3292, 0.3320, 0.3292, 0.3320, 0.3292, 0.3457, 0.3320, 0.3449,\n",
       "           0.3320, 0.3292, 0.3262, 0.3296, 0.3189, 0.3135, 0.3163, 0.3113, 0.3040,\n",
       "           0.2950, 0.2911, 0.2912, 0.2868, 0.2867, 0.2834, 0.2822, 0.2798, 0.2789,\n",
       "           0.2762, 0.2759, 0.2733, 0.2715, 0.2708, 0.2663, 0.2652, 0.2630, 0.2630,\n",
       "           0.2619, 0.2599, 0.2590, 0.2592, 0.2577, 0.2562, 0.2579, 0.2575, 0.2555,\n",
       "           0.3368, 0.3563, 0.3368, 0.3368, 0.3368, 0.3563, 0.3368, 0.3368, 0.3563,\n",
       "           0.3368, 0.3563, 0.3368, 0.3563, 0.3368, 0.3368, 0.3563, 0.3368, 0.3563,\n",
       "           0.3563, 0.3563, 0.3368, 0.3563, 0.3368, 0.3368, 0.3563, 0.3368, 0.3563,\n",
       "           0.3368, 0.3520, 0.3466, 0.3275, 0.3378, 0.3211, 0.3176, 0.3135, 0.3257,\n",
       "           0.3219, 0.3185, 0.3152, 0.3120, 0.2985, 0.3098, 0.2948, 0.3068, 0.2924,\n",
       "           0.3052, 0.2906, 0.3027, 0.3003, 0.2841, 0.2810, 0.2769, 0.2758, 0.2947,\n",
       "           0.2934, 0.2718, 0.2930, 0.2933, 0.2695, 0.2939, 0.2940, 0.2683, 0.2953,\n",
       "           0.2960, 0.2673, 0.2972, 0.3009, 0.3424, 0.3009, 0.4795, 0.3009, 0.3009,\n",
       "           0.4553, 0.3009, 0.4363, 0.3009, 0.4266, 0.3009, 0.3009, 0.3009, 0.4037,\n",
       "           0.3009, 0.3009, 0.3822, 0.3757, 0.3009, 0.3691, 0.3009, 0.3635, 0.3009,\n",
       "           0.3578, 0.3525, 0.3150, 0.3333, 0.3002, 0.3290, 0.3250, 0.2977, 0.2936,\n",
       "           0.2869, 0.2893, 0.3109, 0.2828, 0.3051, 0.2780, 0.2778, 0.2743, 0.2953,\n",
       "           0.2935, 0.2706, 0.2899, 0.2883, 0.2867, 0.2858, 0.2846, 0.2609, 0.2606,\n",
       "           0.2822, 0.2587, 0.2585, 0.2814, 0.2575, 0.2807, 0.2572, 0.2808, 0.2565,\n",
       "           0.2560, 0.2562, 0.2821, 0.2560, 0.2864, 0.3459, 0.2864, 0.3459, 0.2864,\n",
       "           0.3459, 0.3459, 0.3459, 0.2864, 0.3459, 0.2864, 0.2864, 0.2864, 0.2864,\n",
       "           0.2864, 0.3459, 0.2864, 0.3459, 0.3459, 0.2864, 0.3415, 0.2864, 0.3269,\n",
       "           0.2864, 0.3230, 0.2864, 0.3190, 0.2816, 0.3116, 0.2759, 0.3051, 0.2769,\n",
       "           0.2707, 0.3000, 0.2723, 0.2974, 0.2683, 0.2950, 0.2907, 0.2637, 0.2886,\n",
       "           0.2638, 0.2857, 0.2601, 0.2829, 0.2799, 0.2572, 0.2789, 0.2779, 0.2556,\n",
       "           0.2777, 0.2554, 0.2773, 0.2546, 0.2545, 0.2763, 0.2541, 0.2762, 0.2537,\n",
       "           0.2536, 0.2770, 0.3446, 0.3446, 0.3446, 0.2546, 0.3446, 0.2546, 0.3446,\n",
       "           0.3446, 0.2546, 0.3446, 0.2546, 0.2546, 0.3446, 0.3446, 0.2546, 0.2546,\n",
       "           0.3446, 0.2546, 0.2546, 0.3446, 0.2546, 0.3331, 0.2546, 0.3309, 0.3280,\n",
       "           0.2546, 0.3241, 0.3204, 0.2492, 0.2546, 0.2512, 0.3101, 0.2498, 0.3059,\n",
       "           0.2518, 0.2518, 0.2511, 0.2990, 0.2510, 0.2536, 0.2945, 0.2936, 0.2514,\n",
       "           0.2922, 0.2511, 0.2885, 0.2888, 0.2497, 0.2871, 0.2509, 0.2874, 0.2511,\n",
       "           0.2870, 0.2512, 0.2510, 0.2866, 0.2503, 0.2866, 0.2864, 0.2511, 0.2859,\n",
       "           0.2508, 0.2874, 0.2867, 0.2511, 0.3595, 0.2132, 0.3554, 0.3504, 0.3512,\n",
       "           0.3484, 0.2132, 0.3456, 0.2132, 0.2132, 0.3394, 0.3337, 0.2132, 0.3315,\n",
       "           0.2132, 0.3274, 0.2132, 0.3244, 0.2132, 0.3226, 0.2132, 0.3207, 0.3192,\n",
       "           0.2132, 0.2132, 0.3133, 0.2132, 0.3118, 0.3104, 0.2132, 0.3098, 0.2132,\n",
       "           0.3083, 0.3057, 0.2132, 0.3047, 0.2132, 0.3017, 0.2132, 0.3013, 0.3004,\n",
       "           0.2132, 0.2997, 0.2132, 0.2132, 0.2980, 0.2132, 0.2983, 0.2979, 0.2132,\n",
       "           0.2974, 0.2967, 0.2964, 0.2953, 0.2132, 0.2962, 0.2132, 0.2132, 0.2960,\n",
       "           0.2132, 0.2964, 0.2132, 0.2965, 0.2132, 0.2132, 0.2969, 0.2132, 0.2975,\n",
       "           0.2132])]},\n",
       " 'Query Point': {'Log Moneyness': tensor([-0.7710,  0.2502,  0.3192, -0.5922], requires_grad=True),\n",
       "  'Time to Maturity': tensor([0.1468, 1.3968, 0.0437, 1.3254], requires_grad=True)},\n",
       " 'Target Volatility': tensor([0.3204, 0.2626, 0.5944, 0.3362])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IVSurfaceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "\n",
    "        # Convert each component of the data point into tensors as appropriate\n",
    "        return {\n",
    "            'Datetime': data_point['Datetime'],\n",
    "            'Symbol': data_point['Symbol'],\n",
    "            'Market Features': {\n",
    "                'Market Return': torch.tensor(data_point['Market Features']['Market Return'], dtype=torch.float32),\n",
    "                'Market Volatility': torch.tensor(data_point['Market Features']['Market Volatility'], dtype=torch.float32),\n",
    "                'Treasury Rate': torch.tensor(data_point['Market Features']['Treasury Rate'], dtype=torch.float32),\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': torch.tensor(data_point['Input Surface']['Log Moneyness'], dtype=torch.float32),\n",
    "                'Time to Maturity': torch.tensor(data_point['Input Surface']['Time to Maturity'], dtype=torch.float32),\n",
    "                'Implied Volatility': torch.tensor(data_point['Input Surface']['Implied Volatility'], dtype=torch.float32),\n",
    "            },\n",
    "            'Query Point': {\n",
    "                'Log Moneyness': torch.tensor(data_point['Query Point']['Log Moneyness'], dtype=torch.float32),\n",
    "                'Time to Maturity': torch.tensor(data_point['Query Point']['Time to Maturity'], dtype=torch.float32),\n",
    "            },\n",
    "            'Target Volatility': torch.tensor(data_point['Target Volatility'], dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "    def collate_fn(batch):\n",
    "        # Organize batch data by structuring as a dictionary with batched components\n",
    "        batched_data = {\n",
    "            'Datetime': [item['Datetime'] for item in batch],\n",
    "            'Symbol': [item['Symbol'] for item in batch],\n",
    "            'Market Features': {\n",
    "                'Market Return': default_collate([item['Market Features']['Market Return'] for item in batch]),\n",
    "                'Market Volatility': default_collate([item['Market Features']['Market Volatility'] for item in batch]),\n",
    "                'Treasury Rate': default_collate([item['Market Features']['Treasury Rate'] for item in batch]),\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': [item['Input Surface']['Log Moneyness'] for item in batch],\n",
    "                'Time to Maturity': [item['Input Surface']['Time to Maturity'] for item in batch],\n",
    "                'Implied Volatility': [item['Input Surface']['Implied Volatility'] for item in batch],\n",
    "            },\n",
    "            'Query Point': {\n",
    "                'Log Moneyness': default_collate([item['Query Point']['Log Moneyness'] for item in batch]),\n",
    "                'Time to Maturity': default_collate([item['Query Point']['Time to Maturity'] for item in batch]),\n",
    "            },\n",
    "            'Target Volatility': default_collate([item['Target Volatility'] for item in batch]),\n",
    "        }\n",
    "\n",
    "        # Set requires_grad=True for query point values\n",
    "        batched_data['Query Point']['Log Moneyness'].requires_grad_()\n",
    "        batched_data['Query Point']['Time to Maturity'].requires_grad_()\n",
    "\n",
    "        return batched_data\n",
    "\n",
    "\n",
    "\n",
    "aapl_googl_data_loader = DataLoader(\n",
    "    IVSurfaceDataset(aapl_googl_dataset), \n",
    "    batch_size=HYPERPARAMETERS['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "\n",
    "# Fetch one batch from the DataLoader\n",
    "batch = next(iter(aapl_googl_data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Datetime': [Timestamp('2013-03-14 00:00:00'),\n",
       "  Timestamp('2013-01-31 00:00:00'),\n",
       "  Timestamp('2013-02-05 00:00:00'),\n",
       "  Timestamp('2013-05-20 00:00:00')],\n",
       " 'Symbol': ['GOOGL', 'AAPL', 'AAPL', 'AAPL'],\n",
       " 'Market Features': {'Market Return': tensor([ 0.4010, -0.9509,  1.1927, -0.6427], grad_fn=<SqueezeBackward1>),\n",
       "  'Market Volatility': tensor([-1.5886,  1.0710,  0.5712, -0.0535], grad_fn=<SqueezeBackward1>),\n",
       "  'Treasury Rate': tensor([ 1.2539e+00, -1.0051e-07,  2.5078e-01, -1.5047e+00],\n",
       "         grad_fn=<SqueezeBackward1>)},\n",
       " 'Input Surface': {'Log Moneyness': [tensor([-2.2581e+00, -1.8348e+00, -1.7707e+00, -1.7081e+00, -1.6774e+00,\n",
       "           -1.6171e+00, -1.5582e+00, -1.4166e+00, -1.3353e+00, -1.1304e+00,\n",
       "           -1.1304e+00, -1.0576e+00, -9.6379e-01, -9.4085e-01, -8.7328e-01,\n",
       "           -8.2921e-01, -8.0746e-01, -7.8590e-01, -7.6452e-01, -7.0143e-01,\n",
       "           -5.4050e-01, -4.6371e-01, -3.8918e-01, -2.6380e-01, -2.2909e-01,\n",
       "           -2.1191e-01, -1.7790e-01, -1.4434e-01, -1.1122e-01, -6.2331e-02,\n",
       "            1.4165e-03,  1.7106e-02,  3.2699e-02,  3.2699e-02,  9.4129e-02,\n",
       "            1.9817e-01,  2.4149e-01,  2.6996e-01,  3.1207e-01,  3.6716e-01,\n",
       "            3.8074e-01,  4.0770e-01,  4.3437e-01,  4.6077e-01,  5.1274e-01,\n",
       "            6.2594e-01,  7.2248e-01,  8.1547e-01,  9.7043e-01, -3.5272e-01,\n",
       "           -3.5272e-01, -3.1678e-01, -2.8134e-01, -2.4639e-01, -1.1122e-01,\n",
       "           -3.0257e-02, -3.0257e-02,  3.2699e-02,  4.8197e-02,  9.4129e-02,\n",
       "            1.3924e-01,  1.3924e-01,  1.8357e-01,  2.8407e-01,  3.1207e-01,\n",
       "           -3.5272e-01, -3.1678e-01, -2.1191e-01, -1.4434e-01, -1.4434e-01,\n",
       "           -7.8522e-02, -4.6243e-02,  1.0926e-01,  1.9817e-01,  1.9817e-01,\n",
       "            2.5576e-01, -6.6023e-01, -5.7978e-01, -3.1678e-01, -2.1191e-01,\n",
       "           -2.1191e-01, -1.4434e-01, -1.4371e-02,  4.8197e-02,  1.0926e-01,\n",
       "            1.0926e-01,  2.2713e-01, -4.2617e-01, -4.2617e-01, -3.8918e-01,\n",
       "           -3.8918e-01, -2.4639e-01, -2.1191e-01, -1.7790e-01, -1.4434e-01,\n",
       "           -7.8522e-02, -4.6243e-02,  1.3924e-01,  2.2713e-01,  2.5576e-01,\n",
       "            2.8407e-01, -1.9007e+00, -1.7707e+00, -1.5582e+00, -1.4723e+00,\n",
       "           -1.4166e+00, -1.3892e+00, -1.2825e+00, -1.1059e+00, -1.0576e+00,\n",
       "           -1.0339e+00, -9.8693e-01, -9.1813e-01, -8.9561e-01, -8.0746e-01,\n",
       "           -7.8590e-01, -7.2228e-01, -7.0143e-01, -6.8075e-01, -6.3988e-01,\n",
       "           -5.9966e-01, -5.0181e-01, -4.6371e-01, -3.3468e-01, -2.8134e-01,\n",
       "           -2.6380e-01, -1.7790e-01, -1.4434e-01, -1.4434e-01, -1.2772e-01,\n",
       "           -1.1122e-01, -9.4817e-02, -9.4817e-02, -4.6243e-02, -4.6243e-02,\n",
       "            3.2699e-02,  4.8197e-02,  6.3600e-02,  9.4129e-02,  1.9817e-01,\n",
       "            2.8407e-01,  2.8407e-01,  3.3976e-01,  3.6716e-01,  3.8074e-01,\n",
       "            3.8074e-01,  3.9426e-01,  4.6077e-01,  4.9985e-01,  5.1274e-01,\n",
       "            5.3834e-01,  5.7625e-01,  6.3821e-01,  6.5042e-01,  7.2248e-01,\n",
       "            7.2248e-01,  7.6940e-01,  7.6940e-01,  7.9254e-01,  8.1547e-01,\n",
       "            9.0518e-01,  9.2711e-01,  9.9181e-01,  1.0130e+00, -1.9007e+00,\n",
       "           -1.8026e+00, -1.6471e+00, -1.5582e+00, -1.5006e+00, -1.4166e+00,\n",
       "           -1.3892e+00, -1.3353e+00, -1.2565e+00, -1.2308e+00, -1.0576e+00,\n",
       "           -1.0103e+00, -9.4085e-01, -8.9561e-01, -8.5115e-01, -7.8590e-01,\n",
       "           -7.6452e-01, -7.4331e-01, -6.8075e-01, -6.6023e-01, -6.1969e-01,\n",
       "           -5.6006e-01, -4.6371e-01, -3.8918e-01, -3.5272e-01, -3.3468e-01,\n",
       "           -3.1678e-01, -2.9900e-01, -2.8134e-01, -2.6380e-01, -2.6380e-01,\n",
       "           -2.4639e-01, -1.9485e-01, -1.7790e-01, -1.6107e-01, -1.6107e-01,\n",
       "           -1.1122e-01, -6.2331e-02, -6.2331e-02, -4.6243e-02, -1.4371e-02,\n",
       "            1.4165e-03,  9.4129e-02,  1.0926e-01,  1.0926e-01,  1.3924e-01,\n",
       "            1.5410e-01,  1.8357e-01,  1.9817e-01,  2.1269e-01,  2.2713e-01,\n",
       "            2.8407e-01,  3.2596e-01,  3.5350e-01,  3.8074e-01,  3.9426e-01,\n",
       "            4.9985e-01,  5.1274e-01,  5.7625e-01,  6.0122e-01,  8.3820e-01,\n",
       "            8.6072e-01,  8.8305e-01,  9.2711e-01,  1.0130e+00, -2.1825e+00,\n",
       "           -2.1455e+00, -2.1090e+00, -1.9007e+00, -1.8675e+00, -1.8348e+00,\n",
       "           -1.8026e+00, -1.8026e+00, -1.7707e+00, -1.4723e+00, -1.3621e+00,\n",
       "           -1.2308e+00, -1.2053e+00, -1.0817e+00, -1.0817e+00, -1.0339e+00,\n",
       "           -9.6379e-01, -9.1813e-01, -8.9561e-01, -8.7328e-01, -8.5115e-01,\n",
       "           -8.5115e-01, -8.2921e-01, -6.3988e-01, -6.3988e-01, -6.1969e-01,\n",
       "           -5.9966e-01, -5.7978e-01, -5.6006e-01, -4.0761e-01, -3.7088e-01,\n",
       "           -3.5272e-01, -3.1678e-01, -2.9900e-01, -2.1191e-01, -1.6107e-01,\n",
       "           -1.4434e-01, -1.2772e-01, -6.2331e-02,  1.7106e-02,  7.8910e-02,\n",
       "            9.4129e-02,  1.0926e-01,  1.0926e-01,  1.6888e-01,  1.8357e-01,\n",
       "            1.9817e-01,  2.5576e-01,  2.8407e-01,  3.1207e-01,  4.4760e-01,\n",
       "            4.8689e-01,  5.7625e-01,  6.5042e-01,  6.7467e-01,  8.1547e-01,\n",
       "            9.0518e-01, -1.9682e+00, -1.9682e+00, -1.9342e+00, -1.9007e+00,\n",
       "           -1.8348e+00, -1.8026e+00, -1.7081e+00, -1.6171e+00, -1.5874e+00,\n",
       "           -1.5874e+00, -1.5582e+00, -1.4166e+00, -1.3621e+00, -1.3353e+00,\n",
       "           -1.3087e+00, -1.2308e+00, -1.2053e+00, -1.1801e+00, -1.1801e+00,\n",
       "           -1.1551e+00, -1.0817e+00, -1.0339e+00, -8.9561e-01, -8.7328e-01,\n",
       "           -8.0746e-01, -7.8590e-01, -7.2228e-01, -6.8075e-01, -6.8075e-01,\n",
       "           -6.6023e-01, -6.3988e-01, -4.2617e-01, -4.0761e-01, -4.0761e-01,\n",
       "           -3.3468e-01, -2.4639e-01, -2.4639e-01, -1.6107e-01, -7.8522e-02,\n",
       "            1.7106e-02,  6.3600e-02,  1.0926e-01,  1.8357e-01,  1.9817e-01,\n",
       "            1.9817e-01,  2.8407e-01,  3.2596e-01,  3.8074e-01,  4.6077e-01,\n",
       "            4.7386e-01,  4.7386e-01,  4.9985e-01,  5.2557e-01,  6.9868e-01,\n",
       "            7.4605e-01,  7.4605e-01,  8.6072e-01,  8.8305e-01,  9.4886e-01,\n",
       "           -2.5855e+00, -2.5422e+00, -2.3760e+00, -2.3760e+00, -2.3361e+00,\n",
       "           -2.2581e+00, -2.2200e+00, -2.1455e+00, -2.1455e+00, -2.1090e+00,\n",
       "           -1.9682e+00, -1.8348e+00, -1.8348e+00, -1.6774e+00, -1.6171e+00,\n",
       "           -1.5292e+00, -1.5006e+00, -1.3087e+00, -1.2825e+00, -1.2308e+00,\n",
       "           -1.1801e+00, -1.1304e+00, -1.1304e+00, -1.1059e+00, -1.0339e+00,\n",
       "           -9.6379e-01, -8.9561e-01, -8.9561e-01, -8.7328e-01, -8.5115e-01,\n",
       "           -6.1969e-01, -5.7978e-01, -4.6371e-01, -4.2617e-01, -3.7088e-01,\n",
       "           -3.3468e-01, -2.9900e-01, -2.8134e-01, -2.6380e-01, -2.2909e-01,\n",
       "           -2.1191e-01, -1.9485e-01, -9.4817e-02, -6.2331e-02, -6.2331e-02,\n",
       "           -3.0257e-02, -1.4371e-02,  1.7106e-02,  7.8910e-02,  1.0926e-01,\n",
       "            1.8357e-01,  1.9817e-01,  1.9817e-01,  2.1269e-01,  2.4149e-01,\n",
       "            3.1207e-01,  3.6716e-01,  4.3437e-01,  4.8689e-01,  5.2557e-01,\n",
       "            5.5104e-01,  7.9254e-01,  8.6072e-01,  9.7043e-01,  9.9181e-01,\n",
       "            9.9181e-01], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([ 0.0502,  0.0779,  0.0779,  0.1053,  0.1053,  0.1324,  0.1592,  0.1592,\n",
       "            0.1858,  0.2380,  0.2637,  0.2892,  0.2892,  0.3144,  0.3144,  0.3641,\n",
       "            0.3886,  0.4368,  0.4368,  0.4606,  0.4842,  0.4842,  0.5076,  0.5307,\n",
       "            0.5307,  0.5536,  0.5536,  0.6212,  0.6433,  0.6433,  0.6653,  0.6653,\n",
       "            0.7086,  0.7086,  0.7300,  0.7512,  0.7512,  0.7722,  0.7930,  0.7930,\n",
       "            0.8137,  0.8137,  0.8343,  0.8546,  0.8546,  0.8748,  0.8948,  0.9147,\n",
       "            0.9344,  0.9344,  0.9540,  0.9734,  0.9734,  1.0118,  1.0308,  1.0496,\n",
       "            1.0869,  1.1053,  1.1053,  1.1236,  1.1236,  1.1418,  1.1418,  1.1598,\n",
       "            1.1598,  1.1955,  1.1955,  1.2131,  1.2307,  1.2481,  1.2654,  1.2826,\n",
       "            1.2826,  1.2996,  1.2996,  1.3166,  1.3334,  1.3334,  1.3501,  1.3501,\n",
       "            1.3668,  1.3997,  1.4160,  1.4160,  1.4321,  1.4321,  1.4482,  1.4482,\n",
       "            1.4642,  1.4801,  1.4801,  1.4959,  1.4959,  1.5116,  1.5272,  1.5427,\n",
       "            1.5886,  1.5886,  1.6037,  1.6188,  1.6188,  1.6337,  1.6486,  1.6634,\n",
       "            1.6780,  1.6927,  1.7072,  1.7216,  1.7216,  1.7502,  1.7786,  1.7786,\n",
       "            1.7926,  1.8066,  1.8204,  1.8204,  1.8342,  1.8480,  1.8480,  1.8616,\n",
       "            1.8616,  1.8752,  1.8887,  1.9156,  1.9289,  1.9289,  1.9421,  1.9421,\n",
       "            1.9552,  1.9683,  1.9814,  1.9943,  2.0072,  2.0201,  2.0201,  2.0328,\n",
       "            2.0455,  2.0957,  2.0957,  2.1204,  2.1204,  2.1449,  2.1449,  2.1691,\n",
       "           -1.6784, -1.6784, -1.5706, -1.5706, -1.4671, -1.3678, -1.2721, -1.1800,\n",
       "           -1.1800, -1.0911, -1.0052, -0.8416, -0.6880, -0.6880, -0.6146, -0.6146,\n",
       "           -0.5432, -0.5432, -0.4738, -0.4062, -0.3404, -0.2762, -0.2137, -0.2137,\n",
       "           -0.1526, -0.0930, -0.0930, -0.0347,  0.0222,  0.0222,  0.0779,  0.0779,\n",
       "            0.1324,  0.2380,  0.2892,  0.3394,  0.3886,  0.3886,  0.4368,  0.4368,\n",
       "            0.5307,  0.5763,  0.6653,  0.7086,  0.7512,  0.7512,  0.7930,  0.7930,\n",
       "            0.8343,  0.8748,  0.9540,  0.9540,  0.9927,  1.1053,  1.1418,  1.2131,\n",
       "            1.2131,  1.2481,  1.2826,  1.2826,  1.3166,  1.3501,  1.3501,  1.3833,\n",
       "            1.4160,  1.4482,  1.5734,  1.5734,  1.6037,  1.6037,  1.6337,  1.6337,\n",
       "            1.6634,  1.6634,  1.6927,  1.7216,  1.7216,  1.7502,  1.7786,  1.8342,\n",
       "            1.9156,  1.9421,  1.9683,  1.9943,  1.9943,  2.0201,  2.0201,  2.0455,\n",
       "            2.0455,  2.0707,  2.0957,  2.1204,  2.1449,  2.1691],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.4192, -0.3534, -0.3211, -0.1060, -0.0767,  0.0923,  0.0923,  0.2250,\n",
       "            0.3755,  0.4712,  0.5858,  0.7381,  0.7800, -1.3325, -1.3325, -1.2852,\n",
       "           -1.1930, -1.0182, -0.9351, -0.7011, -0.6276, -0.5562, -0.4528, -0.3534,\n",
       "           -0.2578,  0.0092,  0.0923,  0.1194,  0.2250,  0.2507,  0.3511,  0.5177,\n",
       "            0.5633,  0.5858,  0.5858,  0.7169,  0.7169,  0.7592,  0.7592,  0.8007,\n",
       "            0.9409,  0.9796,  1.1106,  1.2001,  1.2001,  1.2523,  1.2695,  1.3035,\n",
       "            1.3537,  1.3866,  1.3866,  1.4191,  1.4671,  1.4829,  1.5141,  1.5450,\n",
       "            1.6207,  1.6207,  1.6503,  1.6503,  1.6941,  1.7229,  1.7372,  1.7655,\n",
       "            1.7796,  1.8349,  1.8622,  1.9158,  1.9158,  1.9290,  1.9553,  1.9553,\n",
       "            1.9813,  1.9813,  2.1074,  2.1319, -0.2893, -0.2267, -0.0478,  0.0092,\n",
       "            0.0092,  0.0649,  0.1727,  0.1727,  0.1990,  0.2250,  0.2250,  0.2762,\n",
       "            0.3263,  0.3511,  0.3998,  0.5406,  0.6522, -0.4192, -0.4192,  0.1462,\n",
       "            0.2762,  0.3263,  0.3263,  0.3511,  0.4476,  0.5177,  0.5177,  0.5633,\n",
       "            0.5633, -1.4300, -1.1930, -1.1482, -1.0608, -1.0182, -0.9351, -0.8547,\n",
       "           -0.8154, -0.7386, -0.5213, -0.5213, -0.4868, -0.3534, -0.3534, -0.1356,\n",
       "           -0.0478, -0.0478,  0.0372,  0.0923,  0.1462,  0.1727,  0.2250,  0.2507,\n",
       "            0.2762,  0.2762,  0.3014,  0.3263,  0.3263,  0.4238,  0.4476,  0.5177,\n",
       "            0.5858,  0.6303,  0.6522,  0.6740,  0.6955,  0.7169,  0.7381,  0.7800,\n",
       "            0.8007,  0.8618,  0.8818,  0.9017,  0.9409,  0.9796,  1.0553,  1.0738,\n",
       "            1.0923,  1.1287,  1.1287,  1.2523,  1.3371,  1.3537,  1.3537,  1.4191,\n",
       "            1.4352,  1.4829,  1.4985,  1.5141,  1.6355,  1.6650,  1.6941,  1.7086,\n",
       "            1.7514, -1.3808, -1.1930, -1.1482, -1.1041, -1.0608, -0.9763, -0.9351,\n",
       "           -0.9351, -0.8946, -0.8946, -0.8547, -0.5213, -0.3534, -0.3211, -0.3211,\n",
       "           -0.2578, -0.0191,  0.0923,  0.1194,  0.2250,  0.2507,  0.3014,  0.3511,\n",
       "            0.3755,  0.3998,  0.4238,  0.4476,  0.4712,  0.5406,  0.5858,  0.6522,\n",
       "            0.6740,  0.6955,  0.6955,  0.7169,  0.7381,  0.7592,  0.7592,  0.7800,\n",
       "            0.8007,  0.8416,  0.8818,  0.9796,  1.0177,  1.0177,  1.0553,  1.2176,\n",
       "            1.2176,  1.2523,  1.3537,  1.3537,  1.3702,  1.3866,  1.4352,  1.4352,\n",
       "            1.4512,  1.4671,  1.4829,  1.5141,  1.5296,  1.5450,  1.5604,  1.5756,\n",
       "            1.5756,  1.5907,  1.6941,  1.7086,  1.7372,  1.7655,  1.8212,  1.8622,\n",
       "            1.8757,  1.8891,  1.9422,  1.9422,  1.9683,  2.0198,  2.0577,  2.0827,\n",
       "            2.1319, -1.1482, -1.0608, -1.0182, -0.9763, -0.9351, -0.8946, -0.8547,\n",
       "           -0.8154, -0.5917, -0.5562, -0.5213, -0.4868, -0.4868, -0.2578, -0.1356,\n",
       "           -0.0478, -0.0191,  0.0372,  0.1194,  0.2250,  0.2250,  0.2507,  0.3014,\n",
       "            0.3263,  0.3998,  0.4476,  0.4712,  0.5633,  0.5858,  0.8618,  0.8618,\n",
       "            0.9017,  0.9214,  0.9409,  1.0177,  1.0553,  1.1647,  1.2176,  1.2351,\n",
       "            1.2523, -1.2387, -1.1041, -0.9763, -0.8946, -0.6641, -0.5562, -0.3534,\n",
       "           -0.2267, -0.1960, -0.1960, -0.1656, -0.1356, -0.1060, -0.0191,  0.0092,\n",
       "            0.0372,  0.0649,  0.1727,  0.4476,  0.5177,  0.6522,  0.6522,  0.7169,\n",
       "            0.7381,  0.7800,  0.8212,  0.9796,  1.0366,  1.0738,  1.1106,  1.1287,\n",
       "            1.1468,  1.2001,  1.2176,  1.2695,  1.2866,  1.3035,  1.3035,  1.3204,\n",
       "            1.3371,  1.4029,  1.4191,  1.4191,  1.4352,  1.4829,  1.5141,  1.5756,\n",
       "            1.6057,  1.6503,  1.6503,  1.6650,  1.7655,  1.8074,  1.9025,  1.9290,\n",
       "           -1.3325, -1.2387, -1.1930, -1.0608, -0.9763, -0.8946, -0.8154, -0.7386,\n",
       "           -0.4868, -0.1356, -0.0191,  0.1194,  0.1990,  0.4238,  0.4476,  0.4712,\n",
       "            0.4945,  0.5177,  0.5177,  0.5406,  0.6303,  0.6522,  0.8007,  0.9409,\n",
       "            0.9604,  1.1287,  1.2001,  1.2351,  1.3702,  1.4352,  1.4671,  1.4985,\n",
       "            1.5450,  1.5450,  1.5756,  1.6207,  1.6355,  1.6355,  1.6650,  1.6796,\n",
       "            1.7372,  1.8074,  1.8212,  1.8891,  1.8891,  1.9025,  1.9813,  2.0198,\n",
       "            2.0577,  2.1074, -1.2852, -1.2387, -1.1930, -0.9351, -0.8154, -0.8154,\n",
       "           -0.7767, -0.7767, -0.6641, -0.5562, -0.4192, -0.3534, -0.3211, -0.3211,\n",
       "           -0.1060, -0.0191, -0.0191,  0.0372,  0.0649,  0.1990,  0.3014,  0.4238,\n",
       "            0.4238,  0.4712,  0.4712,  0.4945,  0.5177,  0.5858,  0.5858,  0.6082,\n",
       "            0.6522,  0.6522,  0.8212,  0.8416,  0.9214,  0.9214,  0.9604,  1.0177,\n",
       "            1.1824,  1.2001,  1.2695,  1.3537,  1.3702,  1.4191,  1.5141,  1.5450,\n",
       "            1.6207,  1.6796, -1.8623, -1.5314, -1.4802, -1.3808, -1.2852, -1.2387,\n",
       "           -1.1930, -1.0182, -0.9763, -0.8547, -0.5917, -0.3861, -0.1960, -0.1060,\n",
       "           -0.0767, -0.0478,  0.0649,  0.1727,  0.1727,  0.2250,  0.2507,  0.3263,\n",
       "            0.3263,  0.3755,  0.3998,  0.4238,  0.4945,  0.5858,  0.6082,  0.6740,\n",
       "            0.6740,  0.8416,  0.9017,  1.0177,  1.2001,  1.2176,  1.4191,  1.4512,\n",
       "            1.5296,  1.5604,  1.5756,  1.5907,  1.6207,  1.6796,  1.7229,  1.7514,\n",
       "            1.7655,  1.8074,  1.8486,  1.9025,  1.9290,  1.9422,  2.0198],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.9343, -0.8512, -0.8107, -0.7708, -0.7315, -0.6928, -0.6928, -0.6547,\n",
       "           -0.6172, -0.6172, -0.5802, -0.4374, -0.3689, -0.3353, -0.3022, -0.2695,\n",
       "           -0.2695, -0.2054, -0.1739, -0.1428, -0.1428, -0.1121, -0.0817, -0.0817,\n",
       "           -0.0518, -0.0518,  0.0072,  0.0361,  0.0648,  0.0648,  0.0931,  0.1211,\n",
       "            0.1488,  0.1762,  0.2301,  0.2566,  0.2566, -0.9343, -0.9343, -0.8924,\n",
       "           -0.8512, -0.8107, -0.7708, -0.7315, -0.7315, -0.6928, -0.6928, -0.6547,\n",
       "           -0.6172, -0.5437, -0.4723, -0.4374, -0.4029, -0.3689, -0.3353, -0.3353,\n",
       "           -0.3022, -0.2695, -0.2372, -0.2054, -0.1428, -0.1121, -0.0817, -0.0518,\n",
       "           -0.0518, -0.0221, -0.0221,  0.0361,  0.0361,  0.0648,  0.1488,  0.1488,\n",
       "            0.1762,  0.1762,  0.2033,  0.2301,  0.2566, -0.6928, -0.6928, -0.6172,\n",
       "           -0.5078, -0.5078, -0.4723, -0.4374, -0.4374, -0.3353, -0.3022, -0.3022,\n",
       "           -0.2695, -0.2372, -0.2372, -0.2054, -0.1739, -0.1739, -0.1428, -0.1121,\n",
       "           -0.0817, -0.0518, -0.0518,  0.0361,  0.0648,  0.0648,  0.0931,  0.1211,\n",
       "            0.1488,  0.1488,  0.1762,  0.1762,  0.2033,  0.2033,  0.2301,  0.2301,\n",
       "            0.2566,  0.2566, -0.7708, -0.7708, -0.6928, -0.6928, -0.6172, -0.5437,\n",
       "           -0.4374, -0.4029, -0.3353, -0.3353, -0.3022, -0.2695, -0.2695, -0.2372,\n",
       "           -0.2054, -0.2054, -0.1739, -0.1739, -0.1428, -0.1428, -0.1121, -0.1121,\n",
       "           -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,  0.0361,  0.0648,  0.0931,\n",
       "            0.1211,  0.1211,  0.1488,  0.1488,  0.1762,  0.1762,  0.2033,  0.2301,\n",
       "            0.2566, -1.9617, -1.8991, -1.8381, -1.8381, -1.7784, -1.7784, -1.7202,\n",
       "           -1.7202, -1.6633, -1.6633, -1.6076, -1.5531, -1.5531, -1.4997, -1.4997,\n",
       "           -1.4475, -1.3963, -1.3963, -1.3461, -1.2969, -1.2486, -1.2486, -1.2013,\n",
       "           -1.2013, -1.1548, -1.1091, -1.1091, -1.0643, -1.0202, -0.9769, -0.9343,\n",
       "           -0.8924, -0.8924, -0.8107, -0.8107, -0.7708, -0.7315, -0.6928, -0.6547,\n",
       "           -0.6172, -0.6172, -0.5802, -0.5437, -0.5437, -0.5078, -0.4723, -0.4723,\n",
       "           -0.4374, -0.4374, -0.3689, -0.3689, -0.3353, -0.3353, -0.2695, -0.2372,\n",
       "           -0.2054, -0.2054, -0.1428, -0.1121, -0.0817, -0.0817, -0.0518, -0.0221,\n",
       "            0.0072,  0.0072,  0.0361,  0.0361,  0.0648,  0.0931,  0.1211,  0.1762,\n",
       "            0.1762,  0.2033,  0.2033,  0.2301,  0.2566,  0.2566, -1.6076, -1.6076,\n",
       "           -1.4475, -1.4475, -1.3963, -1.3461, -1.3461, -1.2969, -1.2486, -1.2486,\n",
       "           -1.1548, -1.1548, -1.1091, -0.9769, -0.9343, -0.9343, -0.8107, -0.8107,\n",
       "           -0.7708, -0.6547, -0.6547, -0.6172, -0.6172, -0.5437, -0.5437, -0.5078,\n",
       "           -0.4723, -0.4723, -0.4374, -0.4029, -0.4029, -0.3353, -0.3022, -0.2695,\n",
       "           -0.2695, -0.2372, -0.2372, -0.2054, -0.2054, -0.1739, -0.1739, -0.1428,\n",
       "           -0.1121, -0.1121, -0.0817, -0.0221, -0.0221,  0.0072,  0.0361,  0.0648,\n",
       "            0.0648,  0.0931,  0.1211,  0.1211,  0.1488,  0.2033,  0.2301,  0.2301,\n",
       "           -1.8991, -1.8991, -1.8381, -1.7202, -1.6633, -1.6633, -1.6076, -1.5531,\n",
       "           -1.5531, -1.4997, -1.4997, -1.4475, -1.3963, -1.3461, -1.2969, -1.2486,\n",
       "           -1.2013, -1.2013, -1.0643, -1.0202, -0.9343, -0.9343, -0.8924, -0.8512,\n",
       "           -0.8512, -0.8107, -0.8107, -0.7315, -0.7315, -0.6928, -0.6172, -0.6172,\n",
       "           -0.5802, -0.5437, -0.5078, -0.5078, -0.4723, -0.4374, -0.4029, -0.3689,\n",
       "           -0.3353, -0.3353, -0.3022, -0.3022, -0.2695, -0.2695, -0.2372, -0.2372,\n",
       "           -0.2054, -0.1739, -0.1428, -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,\n",
       "            0.0361,  0.0931,  0.1211,  0.1211,  0.1488,  0.1762,  0.1762,  0.2033,\n",
       "            0.2301,  0.2301, -1.8381, -1.8381, -1.7784, -1.7784, -1.6633, -1.6076,\n",
       "           -1.6076, -1.5531, -1.4997, -1.4475, -1.4475, -1.3963, -1.3461, -1.2969,\n",
       "           -1.2969, -1.2486, -1.2013, -1.1548, -1.1091, -1.0643, -1.0643, -1.0202,\n",
       "           -1.0202, -0.9769, -0.9769, -0.9343, -0.8107, -0.7708, -0.7315, -0.7315,\n",
       "           -0.6928, -0.6547, -0.6172, -0.5802, -0.5437, -0.5437, -0.5078, -0.4723,\n",
       "           -0.4374, -0.4029, -0.3353, -0.3353, -0.3022, -0.2695, -0.2372, -0.2054,\n",
       "           -0.1739, -0.1428, -0.1121, -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,\n",
       "            0.0361,  0.0648,  0.0648,  0.0931,  0.0931,  0.1488,  0.1762,  0.2033,\n",
       "            0.2033,  0.2301, -1.7202, -1.7202, -1.6633, -1.6633, -1.6076, -1.6076,\n",
       "           -1.5531, -1.4997, -1.4475, -1.4475, -1.3963, -1.3461, -1.2486, -1.2013,\n",
       "           -1.1091, -1.1091, -1.0643, -1.0202, -0.9769, -0.9343, -0.9343, -0.8107,\n",
       "           -0.8107, -0.7708, -0.7708, -0.7315, -0.7315, -0.6547, -0.6547, -0.6172,\n",
       "           -0.5802, -0.5437, -0.5078, -0.5078, -0.4723, -0.4723, -0.4374, -0.4374,\n",
       "           -0.3689, -0.3353, -0.3353, -0.3022, -0.2695, -0.2372, -0.2054, -0.1428,\n",
       "           -0.1121, -0.0817, -0.0518, -0.0221, -0.0221,  0.0072,  0.0072,  0.0361,\n",
       "            0.0648,  0.0648,  0.0931,  0.1488,  0.2033,  0.2301,  0.2301, -2.0258,\n",
       "           -1.9617, -1.8991, -1.7784, -1.7784, -1.7202, -1.7202, -1.6633, -1.6076,\n",
       "           -1.6076, -1.5531, -1.4997, -1.4997, -1.4475, -1.3963, -1.3461, -1.3461,\n",
       "           -1.2969, -1.2013, -1.2013, -1.1548, -1.0643, -1.0202, -1.0202, -0.9769,\n",
       "           -0.9343, -0.9343, -0.8924, -0.8512, -0.8107, -0.7315, -0.7315, -0.6928,\n",
       "           -0.6547, -0.6172, -0.5802, -0.5078, -0.5078, -0.4723, -0.4374, -0.4029,\n",
       "           -0.3689, -0.3353, -0.3022, -0.2372, -0.2054, -0.1739, -0.1428, -0.1428,\n",
       "           -0.1121, -0.1121, -0.0817, -0.0817, -0.0518, -0.0221, -0.0221,  0.0072,\n",
       "            0.0072,  0.0648,  0.0931,  0.1211,  0.1488,  0.1488,  0.1762,  0.2033,\n",
       "           -1.9617, -1.8381, -1.8381, -1.7784, -1.7202, -1.6633, -1.6076, -1.6076,\n",
       "           -1.5531, -1.4997, -1.4997, -1.3963, -1.3461, -1.3461, -1.2969, -1.2486,\n",
       "           -1.2013, -1.2013, -1.1548, -1.1548, -1.1091, -1.1091, -1.0643, -0.9769,\n",
       "           -0.9343, -0.9343, -0.8924, -0.8924, -0.8512, -0.8107, -0.8107, -0.7708,\n",
       "           -0.7708, -0.6928, -0.6547, -0.6547, -0.5437, -0.5437, -0.5078, -0.5078,\n",
       "           -0.4723, -0.4374, -0.4374, -0.4029, -0.3689, -0.3689, -0.3353, -0.3353,\n",
       "           -0.3022, -0.2695, -0.2695, -0.2054, -0.1739, -0.1428, -0.1121, -0.1121,\n",
       "           -0.0518, -0.0221, -0.0221,  0.0072,  0.0072,  0.0361,  0.0361,  0.0648,\n",
       "            0.0931,  0.0931,  0.1211,  0.1211,  0.1488],\n",
       "          grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Time to Maturity': [tensor([-0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "           -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "           -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "           -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "           -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "           -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "           -0.9407, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065,\n",
       "           -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065,\n",
       "           -0.9065, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723,\n",
       "           -0.8723, -0.8723, -0.8723, -0.8723, -0.8267, -0.8267, -0.8267, -0.8267,\n",
       "           -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.7868,\n",
       "           -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868,\n",
       "           -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "           -0.7412, -0.7412, -0.7412, -0.7412, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "           -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.3823, -0.3823, -0.3823,\n",
       "           -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "           -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "           -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "           -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "           -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "           -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "           -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,  0.1363,  0.1363,\n",
       "            0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "            0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "            0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "            0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "            0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "            0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "            0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "            0.1363,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "            0.8143,  0.8143,  0.8143], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "           3.1277, 3.1277, 3.1277, 3.1277], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350,\n",
       "           -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8552, -0.8552, -0.8552, -0.8552,\n",
       "           -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552,\n",
       "           -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8153, -0.8153, -0.8153,\n",
       "           -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153,\n",
       "           -0.8153, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "           -0.7298, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "           -0.5304, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "           -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "           -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "           -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "           -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "           -0.3709, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "           -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "           -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "           -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "           -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "           -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "           -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "           -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "           -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "           -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "           -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "           -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "           -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "           -0.0119, -0.0119,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "            0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "            0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "            0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "            0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "            0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "            0.5066,  0.5066,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "            1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "            1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "            1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "            1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "            1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "            1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "           -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "           -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "           -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "           -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "           -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8495, -0.8495, -0.8495,\n",
       "           -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "           -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "           -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "           -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "           -0.8495, -0.8495, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "           -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "           -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "           -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "           -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "           -0.8096, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "           -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.6045, -0.6045,\n",
       "           -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "           -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "           -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "           -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "           -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "           -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "           -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "           -0.4449, -0.4449, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "           -0.2455, -0.2455, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "           -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "           -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "           -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "           -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "           -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "           -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "           -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "            0.9511,  0.9511,  0.9511,  0.9511,  0.9511],\n",
       "          grad_fn=<SplitWithSizesBackward0>)],\n",
       "  'Implied Volatility': [tensor([ 0.9100,  0.9100, -1.3298,  0.9100,  0.9100, -1.3298,  0.9100, -1.3298,\n",
       "           -1.3298, -1.3298,  0.9100,  0.9100, -1.3298, -1.3298, -1.3298, -1.3298,\n",
       "           -1.3298,  0.9100,  0.9100, -1.3298,  0.9100,  0.9100, -1.3298,  0.9100,\n",
       "           -1.3298, -1.3298,  0.9100,  0.9100,  0.9100,  0.9100, -0.9126, -1.3298,\n",
       "           -1.5479, -1.5047, -1.4436, -1.9325, -1.3298, -1.9325, -1.9325, -1.3298,\n",
       "           -1.3298, -1.9325, -1.9325, -1.9325, -1.9325, -1.9325, -1.3298, -1.3298,\n",
       "           -1.9325, -0.4111,  2.1227, -0.4111,  1.7898,  1.4895, -0.4111, -0.9537,\n",
       "           -0.9832, -1.5300, -1.6080, -1.6080, -1.4468, -1.3562, -1.1571, -1.0306,\n",
       "           -1.3593,  1.5875,  1.2577,  0.5666, -0.0961, -0.0287, -0.7725, -1.0443,\n",
       "           -1.6786, -1.4952, -1.7365, -1.7365,  0.7984,  0.7984,  0.5181, -0.1762,\n",
       "           -0.0993, -0.5649, -1.3973, -1.6617, -1.7049, -1.7144, -1.5395,  0.7278,\n",
       "            0.4349,  0.5666,  0.3443, -0.2268, -0.3595, -0.5786, -0.7146, -1.0391,\n",
       "           -1.1170, -1.5300, -1.6059, -1.3657, -1.2909,  0.0250,  0.1525,  4.8915,\n",
       "            0.0250,  4.2288,  0.0250,  0.0250,  2.7675,  0.1525,  0.0250,  2.2038,\n",
       "            1.8762,  1.7687,  0.0250,  0.1525,  0.1525,  0.0250,  0.1525,  0.0250,\n",
       "            0.0250,  0.0250,  0.1525, -0.1562, -0.2436, -0.2605, -0.4554, -0.4975,\n",
       "           -0.5112, -0.5218, -0.5302, -0.5260, -0.5776, -0.6313, -0.6471, -0.7198,\n",
       "           -0.7335, -0.7493, -0.7736, -0.8663, -0.8852, -0.9084, -0.9959, -1.2213,\n",
       "           -0.8189, -0.9959, -0.9959, -0.8136, -0.9959, -0.7746, -0.7746, -0.9959,\n",
       "           -0.7746, -0.7746, -0.7746, -0.9959, -0.7746, -0.9959, -0.9959, -0.9959,\n",
       "           -0.9959, -0.7746, -0.9959, -0.9959, -0.2584, -0.1383, -0.2584, -0.2584,\n",
       "           -0.2584,  2.6379,  2.5367, -0.2584,  2.0511,  1.9562, -0.2584,  1.2988,\n",
       "           -0.1383, -0.2584, -0.2584, -0.1383, -0.1383, -0.1383, -0.2584, -0.1383,\n",
       "           -0.1383, -0.2584, -0.2584, -0.3964, -0.4638, -0.4944, -0.5102, -0.5513,\n",
       "           -0.5786, -0.5976, -0.5966, -0.5818, -0.6735, -0.6851, -0.7230, -0.7346,\n",
       "           -0.7936, -0.8357, -0.8473, -0.8452, -0.8884, -0.8894, -0.9600, -0.9685,\n",
       "           -0.9853, -0.9959, -0.9980, -1.0085, -1.0517, -1.0464, -1.0443, -1.0664,\n",
       "           -1.0422, -1.0928, -1.0443, -1.0443, -1.0011, -1.1117, -1.1117, -1.1117,\n",
       "           -0.8810, -0.8810, -0.8810, -0.8810, -0.8810, -0.3384, -0.3384,  3.2405,\n",
       "           -0.3384,  2.5599, -0.3384, -0.3384,  2.3766,  2.2871, -0.2847, -0.2847,\n",
       "           -0.3384, -0.3384, -0.3384, -0.2847, -0.3384, -0.2847, -0.2847, -0.2847,\n",
       "           -0.2847, -0.3384, -0.2847, -0.2847, -0.3384, -0.2847, -0.2847, -0.3026,\n",
       "           -0.3384, -0.3574, -0.5997, -0.6229, -0.6387, -0.7293, -0.7082, -0.8125,\n",
       "           -0.9021, -0.9168, -0.9305, -0.9916, -1.0327, -1.0949, -1.1044, -1.0949,\n",
       "           -1.1075, -1.1507, -1.1539, -1.1560, -1.1592, -1.1866, -1.2024, -1.1929,\n",
       "           -1.3003, -1.1634, -1.2845, -1.2845, -0.8304, -1.2845, -0.1024, -0.0287,\n",
       "           -0.1024, -0.1024, -0.1024, -0.1024, -0.0287, -0.1024, -0.1024, -0.0287,\n",
       "           -0.0287, -0.1024, -0.1024, -0.0287, -0.1024, -0.0287, -0.1024, -0.1024,\n",
       "           -0.0287, -0.1024, -0.1024, -0.1024, -0.1024, -0.1014, -0.1730, -0.1867,\n",
       "           -0.2657, -0.3142, -0.3247, -0.3416, -0.3606, -0.6008, -0.6081, -0.6050,\n",
       "           -0.6798, -0.7441, -0.7398, -0.8083, -0.8599, -0.9390, -0.9527, -0.9980,\n",
       "           -1.0369, -1.0275, -1.0454, -1.0612, -1.0875, -1.1012, -1.1107, -1.1307,\n",
       "           -1.1149, -1.1328, -1.1149, -1.0854, -1.1128, -1.1412, -1.1412, -1.1412,\n",
       "           -1.1054, -0.1899, -0.0803, -0.0803, -0.1899, -0.1899, -0.1899, -0.1899,\n",
       "           -0.0803, -0.1899, -0.0803, -0.0803, -0.0803, -0.1899, -0.0803, -0.1899,\n",
       "           -0.1899, -0.1899, -0.0803, -0.0803, -0.1899, -0.0803, -0.0803, -0.1899,\n",
       "           -0.0803, -0.1256, -0.2004, -0.2531, -0.2426, -0.2531, -0.2868, -0.4743,\n",
       "           -0.5218, -0.5776, -0.5976, -0.6355, -0.6577, -0.6777, -0.7103, -0.7135,\n",
       "           -0.7430, -0.7409, -0.7567, -0.8115, -0.8431, -0.8336, -0.8673, -0.8631,\n",
       "           -0.8757, -0.9010, -0.9221, -0.9537, -0.9758, -0.9664, -0.9737, -0.9790,\n",
       "           -1.0159, -1.0401, -1.0580, -1.0759, -1.0896, -1.0896, -1.0812, -1.0728,\n",
       "           -1.0169, -1.0517, -1.0759], grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-2.9208e-01, -3.7741e-01, -2.9313e-01, -3.8268e-01, -3.0261e-01,\n",
       "           -3.0682e-01, -3.9111e-01, -3.1209e-01, -3.1104e-01, -4.1640e-01,\n",
       "           -3.2474e-01, -4.2166e-01, -3.2790e-01, -4.2798e-01, -3.3000e-01,\n",
       "           -4.3641e-01, -3.3000e-01, -4.4695e-01, -3.3632e-01, -4.4695e-01,\n",
       "           -4.5011e-01, -3.3422e-01, -4.5222e-01, -4.5011e-01, -3.4897e-01,\n",
       "           -4.5432e-01, -3.3422e-01, -4.5959e-01, -4.6065e-01, -3.1736e-01,\n",
       "           -4.5643e-01, -3.0682e-01, -4.5643e-01, -2.9418e-01, -2.9524e-01,\n",
       "           -4.5959e-01, -2.8891e-01, -4.5222e-01, -4.4590e-01, -2.7943e-01,\n",
       "           -4.4168e-01, -2.4993e-01, -2.7206e-01, -4.4800e-01, -2.3518e-01,\n",
       "           -4.4379e-01, -4.3957e-01, -4.2693e-01, -4.2588e-01, -2.0358e-01,\n",
       "           -4.2377e-01, -4.2693e-01, -2.5625e-01, -2.5625e-01, -4.0270e-01,\n",
       "           -3.9111e-01, -2.5625e-01, -3.7531e-01, -2.5625e-01, -3.8690e-01,\n",
       "           -2.5625e-01, -3.8374e-01, -2.5625e-01, -3.8057e-01, -2.5625e-01,\n",
       "           -3.6477e-01, -2.5625e-01, -2.5625e-01, -2.5625e-01, -2.5625e-01,\n",
       "           -3.4159e-01, -3.3843e-01, -2.5625e-01, -3.1947e-01, -2.5625e-01,\n",
       "           -2.9102e-01, -3.0050e-01, -2.5625e-01, -2.8786e-01, -2.5625e-01,\n",
       "           -2.7943e-01, -2.5625e-01, -2.6047e-01, -2.5625e-01, -2.3518e-01,\n",
       "           -2.5625e-01, -2.4045e-01, -2.5625e-01, -2.5625e-01, -2.4256e-01,\n",
       "           -2.5625e-01, -2.4045e-01, -2.5625e-01, -2.1306e-01, -2.1200e-01,\n",
       "           -2.1727e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01,\n",
       "           -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.1727e-01, -2.5625e-01,\n",
       "           -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01,\n",
       "           -2.1727e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.1727e-01,\n",
       "           -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01,\n",
       "           -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.1727e-01,\n",
       "           -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01,\n",
       "           -2.5625e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01,\n",
       "           -2.1727e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01,\n",
       "           -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01,  1.5201e+00,\n",
       "            2.6315e-01,  1.2609e+00,  2.6947e-01,  2.0942e-01,  8.0152e-01,\n",
       "            5.7501e-01,  4.6333e-01,  1.3989e-01,  1.3883e-01,  1.0512e-01,\n",
       "            9.2476e-02,  5.8762e-02,  6.4030e-02,  3.3476e-02,  4.4012e-02,\n",
       "           -9.7199e-03,  3.7691e-02,  2.6101e-02,  7.1371e-03, -8.3469e-02,\n",
       "           -1.9202e-02, -9.5059e-02, -9.7199e-03, -1.1613e-01, -1.2561e-01,\n",
       "           -2.1309e-02, -1.3825e-01, -1.3088e-01, -3.5006e-02, -1.4352e-01,\n",
       "           -5.2916e-02, -3.9220e-02, -1.7618e-01, -1.5827e-01, -1.8988e-01,\n",
       "           -1.8883e-01, -6.8720e-02, -1.9515e-01, -6.6612e-02, -2.0147e-01,\n",
       "           -2.0884e-01, -2.0041e-01, -5.2916e-02, -1.9093e-01, -6.4505e-02,\n",
       "           -2.0252e-01, -9.5059e-02, -9.0844e-02, -7.0827e-02, -2.1200e-01,\n",
       "           -6.4505e-02, -6.8720e-02, -2.0884e-01, -2.0147e-01, -2.1727e-01,\n",
       "           -2.7631e-02, -6.5593e-03, -2.0884e-01, -1.8149e-02, -1.9409e-01,\n",
       "           -2.0568e-01, -8.6664e-03, -2.3778e-04, -2.0568e-01,  3.5583e-02,\n",
       "           -1.8250e-01,  4.4012e-02, -1.8567e-01,  7.3512e-02, -1.8040e-01,\n",
       "            7.7726e-02, -1.7513e-01,  1.0090e-01, -1.8250e-01, -1.6038e-01,\n",
       "            9.3529e-02, -1.6565e-01,  1.3673e-01, -1.4142e-01,  1.3883e-01,\n",
       "            1.3883e-01, -1.4563e-01, -1.2350e-01,  1.3883e-01, -9.9273e-02,\n",
       "            1.3883e-01, -7.2934e-02,  1.3883e-01,  1.3883e-01,  1.3883e-01,\n",
       "            1.3883e-01,  1.3883e-01,  1.3883e-01],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([-6.5872e-01,  1.6170e+00,  1.6170e+00,  1.3494e+00, -6.5872e-01,\n",
       "           -6.5872e-01,  1.8877e+00, -6.5872e-01,  1.0661e+01,  1.3498e+01,\n",
       "            1.4448e+01,  1.4448e+01, -6.5872e-01,  1.9109e+00,  6.4981e-01,\n",
       "            6.4981e-01,  1.9109e+00,  1.9109e+00,  6.4981e-01,  6.4981e-01,\n",
       "            6.4981e-01,  1.9109e+00,  6.4981e-01,  1.9109e+00,  1.9109e+00,\n",
       "           -6.4397e-01, -1.2877e-01, -5.8075e-01, -2.8049e-01,  1.0101e+00,\n",
       "            2.2133e+00,  3.0393e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "            1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "            1.7044e+00,  3.0393e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "            3.0393e+00,  1.7044e+00,  1.7044e+00,  1.7044e+00,  1.7044e+00,\n",
       "            3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "            3.0393e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "            3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,\n",
       "            3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "            1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,\n",
       "            3.0393e+00,  1.5538e+00,  3.2005e-01, -5.0068e-01, -5.6600e-01,\n",
       "           -2.7733e-01, -5.9972e-01, -5.4914e-01, -1.3299e-01, -2.3416e-02,\n",
       "           -4.3957e-01,  9.6690e-02, -2.6363e-01, -8.8737e-02, -9.7199e-03,\n",
       "            2.7685e-01,  1.6496e+00,  1.6496e+00,  1.7697e+00,  6.8036e-01,\n",
       "           -5.5336e-01,  1.0933e-01, -2.3940e-01,  2.9265e-01,  4.5490e-01,\n",
       "            1.8730e-01,  4.2856e-01,  9.9538e-01,  6.0978e-01,  9.9538e-01,\n",
       "            8.7527e-01,  8.7527e-01,  8.7527e-01,  3.0740e-01,  3.0740e-01,\n",
       "            8.7527e-01,  8.7527e-01,  3.0740e-01,  3.0740e-01,  8.7527e-01,\n",
       "            3.0740e-01,  3.0740e-01,  4.7492e-01,  3.8744e-02, -4.4273e-01,\n",
       "           -4.9857e-01, -3.5950e-01, -5.3756e-01, -5.5863e-01, -4.2798e-01,\n",
       "           -5.6073e-01, -5.4914e-01, -5.2702e-01, -4.9225e-01, -2.9208e-01,\n",
       "           -2.1095e-01, -4.4063e-01, -1.6670e-01, -2.6784e-01,  2.3681e-01,\n",
       "            5.4867e-01,  1.3146e-01,  6.9933e-01,  6.9933e-01,  4.0538e-01,\n",
       "            4.3383e-01,  6.9933e-01,  5.3813e-01,  6.9933e-01,  6.9933e-01,\n",
       "            5.3813e-01,  5.3813e-01,  6.9933e-01,  6.9933e-01,  6.9933e-01,\n",
       "            6.9933e-01,  6.9933e-01,  6.9933e-01,  5.3813e-01,  6.9933e-01,\n",
       "            6.9933e-01,  5.3813e-01,  5.3813e-01,  6.9933e-01,  5.3813e-01,\n",
       "            6.9933e-01,  6.9933e-01,  5.3813e-01,  5.3813e-01,  6.9933e-01,\n",
       "            5.3813e-01,  6.9933e-01,  5.3813e-01,  5.3813e-01, -4.2380e-02,\n",
       "            1.7992e-01,  1.7992e-01,  1.7992e-01, -4.2380e-02, -4.2380e-02,\n",
       "           -4.2380e-02,  1.7992e-01, -4.2380e-02,  1.7992e-01,  1.7992e-01,\n",
       "           -4.2380e-02, -2.6890e-01, -3.2263e-01, -1.8777e-01, -2.4045e-01,\n",
       "           -4.1640e-01, -4.6065e-01, -5.4493e-01, -5.5863e-01, -5.4493e-01,\n",
       "           -4.1956e-01, -3.9638e-01, -3.4897e-01, -3.2790e-01, -2.9418e-01,\n",
       "           -4.5854e-01, -4.3747e-01, -3.7004e-01, -3.2474e-01,  2.1996e-01,\n",
       "           -1.7618e-01, -1.4352e-01,  3.8431e-01, -9.4005e-02,  3.8431e-01,\n",
       "            1.4512e-02,  3.8431e-01,  3.8431e-01,  3.8431e-01,  1.5042e-01,\n",
       "            2.2312e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "            2.7158e-01,  3.8431e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,\n",
       "            2.7158e-01,  2.7158e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "            3.8431e-01,  3.8431e-01,  3.8431e-01,  3.8431e-01,  3.8431e-01,\n",
       "            3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,\n",
       "            2.7158e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "            3.8431e-01,  2.7158e-01,  2.7158e-01,  3.8431e-01,  3.8431e-01,\n",
       "            3.8431e-01,  3.8431e-01,  2.7158e-01,  2.7158e-01,  4.2119e-01,\n",
       "            2.3492e+00,  4.2646e-01,  2.9371e-01,  4.2646e-01,  1.6381e+00,\n",
       "            4.2646e-01,  1.2956e+00,  1.7676e-01,  3.0424e-01,  2.0731e-01,\n",
       "            1.7571e-01,  8.2994e-02, -9.4005e-02, -1.5722e-01, -2.7311e-01,\n",
       "           -2.0358e-01, -2.2149e-01, -2.2991e-01, -3.8374e-01, -2.2149e-01,\n",
       "           -3.7847e-01, -1.8461e-01, -3.7741e-01, -1.2140e-01, -3.5950e-01,\n",
       "           -3.2898e-02, -2.9840e-01,  1.8414e-01,  7.1371e-03,  4.2119e-01,\n",
       "            6.9297e-02,  4.2119e-01,  1.5358e-01,  4.2119e-01,  2.1047e-01,\n",
       "            4.2119e-01,  2.1047e-01,  2.1047e-01,  4.2119e-01,  1.3378e+00,\n",
       "            1.3378e+00,  1.3378e+00,  3.1478e-01,  7.5619e-02, -3.9220e-02,\n",
       "           -1.6143e-01, -3.3422e-01, -3.5634e-01, -2.5625e-01, -3.5740e-01,\n",
       "           -3.8268e-01, -3.9743e-01, -4.3957e-01, -4.4590e-01, -3.4581e-01,\n",
       "           -3.5529e-01, -4.9541e-01, -4.8909e-01, -4.6381e-01, -3.7636e-01,\n",
       "            1.2405e-02, -3.4370e-01, -3.1420e-01, -2.9629e-01,  2.9792e-01,\n",
       "            3.5692e-01,  3.5692e-01,  3.5692e-01,  3.5692e-01,  3.3476e-02,\n",
       "            3.5692e-01,  3.3476e-02,  3.5692e-01,  3.3476e-02,  3.5692e-01,\n",
       "            3.3476e-02,  3.5692e-01,  3.5692e-01,  3.3476e-02,  3.3476e-02,\n",
       "            3.3476e-02,  3.5692e-01,  3.5692e-01,  3.3476e-02,  3.3476e-02,\n",
       "            3.3476e-02,  3.3476e-02,  3.3476e-02,  3.5692e-01,  3.5692e-01,\n",
       "            3.5692e-01,  3.3476e-02,  3.3476e-02,  3.3476e-02,  2.4208e-01,\n",
       "            5.4548e-02,  5.4548e-02,  2.4208e-01,  5.4548e-02,  1.7887e-01,\n",
       "            1.2514e-01,  5.4548e-02, -1.1718e-01, -4.0691e-01, -3.5529e-01,\n",
       "           -5.0595e-01, -4.0059e-01, -3.6477e-01, -5.2175e-01, -3.1841e-01,\n",
       "           -3.0893e-01, -5.2175e-01, -2.9524e-01, -5.1543e-01, -4.8698e-01,\n",
       "           -4.7118e-01, -4.0797e-01,  1.5042e-01, -3.0577e-01, -1.8356e-01,\n",
       "           -1.8356e-01, -1.8356e-01,  1.5042e-01,  1.5042e-01,  1.5042e-01,\n",
       "           -1.8356e-01, -1.8356e-01,  1.5042e-01,  1.5042e-01,  1.5042e-01,\n",
       "           -1.8356e-01,  1.5042e-01, -1.8356e-01,  1.5042e-01, -1.8356e-01,\n",
       "            1.5042e-01,  1.5042e-01, -1.8356e-01,  1.5042e-01, -1.8356e-01,\n",
       "            1.5042e-01,  1.5042e-01, -1.8356e-01, -1.8356e-01,  2.7685e-01,\n",
       "            2.7685e-01,  2.6631e-01,  4.3172e-01,  1.8414e-01,  2.5048e-02,\n",
       "            1.0090e-01, -1.2915e-03, -2.1309e-02, -1.1613e-01, -2.3518e-01,\n",
       "           -2.6679e-01, -3.0050e-01, -2.2149e-01, -3.0682e-01, -4.1218e-01,\n",
       "           -3.2895e-01, -4.3431e-01, -3.5213e-01, -3.8163e-01, -5.0279e-01,\n",
       "           -5.1543e-01, -3.8163e-01, -5.2070e-01, -3.8268e-01, -3.8374e-01,\n",
       "           -3.5740e-01, -5.2807e-01, -3.5529e-01, -5.2491e-01, -5.3018e-01,\n",
       "           -3.0999e-01, -4.8698e-01, -4.8698e-01, -4.9225e-01, -1.2877e-01,\n",
       "           -6.0291e-02, -4.3957e-01, -7.2934e-02, -3.6688e-01, -7.2934e-02,\n",
       "           -2.8786e-01, -2.8786e-01, -2.8786e-01, -7.2934e-02, -7.2934e-02,\n",
       "           -2.8786e-01, -7.2934e-02,  2.7738e+00,  3.5587e-01,  1.7487e+00,\n",
       "            1.4726e+00,  2.9160e-01,  1.0691e+00,  2.3787e-01,  1.5358e-01,\n",
       "            1.3356e-01,  1.7149e-01, -5.1863e-02, -1.8777e-01, -1.9620e-01,\n",
       "           -2.2149e-01, -3.1315e-01, -2.3729e-01, -2.6258e-01, -3.7847e-01,\n",
       "           -2.8154e-01, -3.9849e-01, -4.0165e-01, -4.1745e-01, -3.0472e-01,\n",
       "           -4.2377e-01, -4.2904e-01, -4.3325e-01, -3.0156e-01, -4.4590e-01,\n",
       "           -2.8470e-01, -4.4800e-01, -2.8891e-01, -4.4379e-01, -4.2377e-01,\n",
       "           -4.0586e-01, -3.5529e-01,  3.6637e-02, -2.9313e-01,  3.6637e-02,\n",
       "            3.6637e-02, -2.9313e-01,  3.6637e-02, -2.9313e-01,  3.6637e-02,\n",
       "           -2.9313e-01, -2.9313e-01,  3.6637e-02,  3.6637e-02, -2.9313e-01,\n",
       "            3.6637e-02, -2.9313e-01, -2.9313e-01, -2.9313e-01,  3.6637e-02],\n",
       "          grad_fn=<SplitWithSizesBackward0>),\n",
       "   tensor([ 7.6044e-01,  1.8203e+00,  1.8203e+00,  1.8203e+00,  7.6044e-01,\n",
       "            7.6044e-01,  1.8203e+00,  7.6044e-01,  7.6044e-01,  1.8203e+00,\n",
       "            1.8203e+00,  7.6044e-01,  1.8203e+00,  1.8203e+00,  1.8203e+00,\n",
       "            7.6044e-01,  1.8203e+00,  7.6044e-01,  7.6044e-01,  7.6044e-01,\n",
       "            1.5232e+00,  1.2409e+00,  7.6044e-01,  9.8063e-01,  6.2874e-01,\n",
       "            7.4885e-01,  4.0012e-01,  3.1899e-01,  2.7474e-01,  3.0214e-01,\n",
       "            2.6315e-01,  2.7264e-01,  4.9915e-01,  4.2962e-01,  9.6693e-01,\n",
       "            7.6044e-01,  9.6693e-01,  6.4454e-01,  9.0688e-01,  9.0688e-01,\n",
       "            6.4454e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,  9.0688e-01,\n",
       "            6.4454e-01,  9.0688e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,\n",
       "            6.4454e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,  6.4454e-01,\n",
       "            9.0688e-01,  9.0688e-01,  6.4454e-01,  7.6149e-01,  6.0135e-01,\n",
       "            2.8844e-01,  1.4410e-01,  1.6619e-02, -2.7631e-02, -4.7648e-02,\n",
       "           -1.3299e-01, -1.2034e-01, -2.2359e-01, -2.1833e-01, -2.6995e-01,\n",
       "           -2.8575e-01, -2.5520e-01, -2.5309e-01, -2.8681e-01, -2.0568e-01,\n",
       "           -1.3615e-01, -7.8202e-02,  2.1574e-01,  6.8563e-01,  2.1574e-01,\n",
       "            2.1574e-01,  1.4484e+00,  1.2809e+00,  2.1574e-01,  1.1165e+00,\n",
       "            6.8563e-01,  2.1574e-01,  5.5920e-01,  4.3067e-01,  2.9371e-01,\n",
       "            3.1478e-01,  2.0310e-01,  1.2830e-01,  9.4583e-02,  5.9815e-02,\n",
       "           -4.1327e-02, -1.3615e-01, -2.0568e-01, -2.0779e-01, -3.3632e-01,\n",
       "           -3.6266e-01, -3.5950e-01, -3.7636e-01, -3.9322e-01, -3.7847e-01,\n",
       "           -3.7004e-01, -3.7847e-01, -3.7320e-01, -3.6056e-01, -3.9111e-01,\n",
       "           -3.3211e-01, -3.6266e-01, -2.9734e-01, -3.2895e-01,  2.3576e-01,\n",
       "            5.8028e-01,  2.3576e-01,  1.6813e+00,  1.3715e+00,  9.6272e-01,\n",
       "            6.9722e-01,  4.2646e-01,  2.3576e-01,  3.8115e-01,  2.3576e-01,\n",
       "            1.8624e-01,  2.0626e-01,  1.2724e-01,  8.8262e-02,  5.2440e-02,\n",
       "            7.1371e-03, -9.7199e-03, -3.7113e-02, -7.2934e-02, -8.9791e-02,\n",
       "           -1.2034e-01, -1.5195e-01, -2.0884e-01, -2.4572e-01, -2.9208e-01,\n",
       "           -3.0577e-01, -3.2052e-01, -3.2684e-01, -3.4897e-01, -3.5213e-01,\n",
       "           -3.7531e-01, -3.6266e-01, -3.6056e-01, -3.5213e-01, -3.7004e-01,\n",
       "           -3.4897e-01, -3.3843e-01, -3.1947e-01,  4.0749e-01,  3.9590e-01,\n",
       "            4.0749e-01,  3.9590e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,\n",
       "            3.9590e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,\n",
       "            3.9590e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,\n",
       "            3.9590e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,  3.9590e-01,\n",
       "            4.0749e-01,  3.9590e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,\n",
       "            3.9590e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,\n",
       "            3.9590e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,  4.0749e-01,\n",
       "            4.0749e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,\n",
       "            4.0749e-01,  3.9590e-01,  6.0556e-01,  4.1803e-01,  3.9590e-01,\n",
       "            4.0855e-01,  3.9590e-01,  2.5578e-01,  2.1469e-01,  1.8098e-01,\n",
       "            1.3356e-01,  2.9228e-03, -5.9237e-02, -9.7166e-02, -1.2350e-01,\n",
       "           -2.2465e-01, -2.6363e-01, -3.0050e-01, -3.0261e-01, -3.1736e-01,\n",
       "           -3.5950e-01, -3.8900e-01, -3.8584e-01, -4.0691e-01, -4.1429e-01,\n",
       "           -4.3431e-01, -4.4590e-01, -4.5748e-01, -4.7118e-01, -4.6275e-01,\n",
       "           -4.5854e-01, -4.7118e-01, -4.5854e-01, -4.5116e-01, -4.7856e-01,\n",
       "            2.4524e-01,  2.7474e-01,  2.4524e-01,  2.7474e-01,  2.7474e-01,\n",
       "            2.4524e-01,  2.7474e-01,  2.4524e-01,  2.4524e-01,  2.7474e-01,\n",
       "            2.4524e-01,  2.7474e-01,  2.4524e-01,  2.7474e-01,  2.4524e-01,\n",
       "            2.7474e-01,  2.4524e-01,  2.7474e-01,  2.4524e-01,  4.1908e-01,\n",
       "            2.7474e-01,  4.1065e-01,  2.7474e-01,  2.4524e-01,  2.1364e-01,\n",
       "            2.4946e-01,  1.3673e-01,  7.9833e-02,  1.0933e-01,  5.6655e-02,\n",
       "           -2.0256e-02, -1.1508e-01, -1.5617e-01, -1.5511e-01, -2.0147e-01,\n",
       "           -2.0252e-01, -2.3729e-01, -2.4993e-01, -2.7522e-01, -2.8470e-01,\n",
       "           -3.1315e-01, -3.1631e-01, -3.4370e-01, -3.6266e-01, -3.7004e-01,\n",
       "           -4.1745e-01, -4.2904e-01, -4.5222e-01, -4.5222e-01, -4.6381e-01,\n",
       "           -4.8488e-01, -4.9436e-01, -4.9225e-01, -5.0806e-01, -5.2386e-01,\n",
       "           -5.0595e-01, -5.1016e-01, -5.3123e-01,  3.2531e-01,  5.3076e-01,\n",
       "            3.2531e-01,  3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "            3.2531e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "            5.3076e-01,  3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "            5.3076e-01,  5.3076e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,\n",
       "            3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,\n",
       "            3.2531e-01,  4.8546e-01,  4.2856e-01,  2.2733e-01,  3.3585e-01,\n",
       "            1.5990e-01,  1.2303e-01,  7.9833e-02,  2.0837e-01,  1.6833e-01,\n",
       "            1.3251e-01,  9.7744e-02,  6.4030e-02, -7.8202e-02,  4.0851e-02,\n",
       "           -1.1718e-01,  9.2443e-03, -1.4247e-01, -7.6127e-03, -1.6143e-01,\n",
       "           -3.3952e-02, -5.9237e-02, -2.2991e-01, -2.6258e-01, -3.0577e-01,\n",
       "           -3.1736e-01, -1.1824e-01, -1.3193e-01, -3.5950e-01, -1.3615e-01,\n",
       "           -1.3299e-01, -3.8374e-01, -1.2667e-01, -1.2561e-01, -3.9638e-01,\n",
       "           -1.1192e-01, -1.0454e-01, -4.0691e-01, -9.1898e-02, -5.2916e-02,\n",
       "            3.8431e-01, -5.2916e-02,  1.8287e+00, -5.2916e-02, -5.2916e-02,\n",
       "            1.5738e+00, -5.2916e-02,  1.3736e+00, -5.2916e-02,  1.2714e+00,\n",
       "           -5.2916e-02, -5.2916e-02, -5.2916e-02,  1.0301e+00, -5.2916e-02,\n",
       "           -5.2916e-02,  8.0363e-01,  7.3515e-01, -5.2916e-02,  6.6561e-01,\n",
       "           -5.2916e-02,  6.0662e-01, -5.2916e-02,  5.4656e-01,  4.9072e-01,\n",
       "            9.5636e-02,  2.8844e-01, -6.0291e-02,  2.4314e-01,  2.0099e-01,\n",
       "           -8.6630e-02, -1.2983e-01, -2.0041e-01, -1.7513e-01,  5.2440e-02,\n",
       "           -2.4361e-01, -8.6664e-03, -2.9418e-01, -2.9629e-01, -3.3316e-01,\n",
       "           -1.1192e-01, -1.3088e-01, -3.7215e-01, -1.6881e-01, -1.8567e-01,\n",
       "           -2.0252e-01, -2.1200e-01, -2.2465e-01, -4.7434e-01, -4.7750e-01,\n",
       "           -2.4993e-01, -4.9752e-01, -4.9963e-01, -2.5836e-01, -5.1016e-01,\n",
       "           -2.6574e-01, -5.1332e-01, -2.6468e-01, -5.2070e-01, -5.2597e-01,\n",
       "           -5.2386e-01, -2.5099e-01, -5.2597e-01, -2.0568e-01,  4.2119e-01,\n",
       "           -2.0568e-01,  4.2119e-01, -2.0568e-01,  4.2119e-01,  4.2119e-01,\n",
       "            4.2119e-01, -2.0568e-01,  4.2119e-01, -2.0568e-01, -2.0568e-01,\n",
       "           -2.0568e-01, -2.0568e-01, -2.0568e-01,  4.2119e-01, -2.0568e-01,\n",
       "            4.2119e-01,  4.2119e-01, -2.0568e-01,  3.7483e-01, -2.0568e-01,\n",
       "            2.2101e-01, -2.0568e-01,  1.7992e-01, -2.0568e-01,  1.3778e-01,\n",
       "           -2.5625e-01,  5.9815e-02, -3.1631e-01, -8.6664e-03, -3.0577e-01,\n",
       "           -3.7109e-01, -6.2398e-02, -3.5424e-01, -8.9791e-02, -3.9638e-01,\n",
       "           -1.1508e-01, -1.6038e-01, -4.4484e-01, -1.8250e-01, -4.4379e-01,\n",
       "           -2.1306e-01, -4.8277e-01, -2.4256e-01, -2.7416e-01, -5.1332e-01,\n",
       "           -2.8470e-01, -2.9524e-01, -5.3018e-01, -2.9734e-01, -5.3229e-01,\n",
       "           -3.0156e-01, -5.4072e-01, -5.4177e-01, -3.1209e-01, -5.4598e-01,\n",
       "           -3.1315e-01, -5.5020e-01, -5.5125e-01, -3.0472e-01,  4.0749e-01,\n",
       "            4.0749e-01,  4.0749e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "            4.0749e-01,  4.0749e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "           -5.4072e-01,  4.0749e-01,  4.0749e-01, -5.4072e-01, -5.4072e-01,\n",
       "            4.0749e-01, -5.4072e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "            2.8633e-01, -5.4072e-01,  2.6315e-01,  2.3260e-01, -5.4072e-01,\n",
       "            1.9151e-01,  1.5253e-01, -5.9761e-01, -5.4072e-01, -5.7654e-01,\n",
       "            4.4012e-02, -5.9129e-01, -2.3778e-04, -5.7022e-01, -5.7022e-01,\n",
       "           -5.7759e-01, -7.2934e-02, -5.7864e-01, -5.5125e-01, -1.2034e-01,\n",
       "           -1.2983e-01, -5.7443e-01, -1.4458e-01, -5.7759e-01, -1.8356e-01,\n",
       "           -1.8040e-01, -5.9234e-01, -1.9831e-01, -5.7970e-01, -1.9515e-01,\n",
       "           -5.7759e-01, -1.9936e-01, -5.7654e-01, -5.7864e-01, -2.0358e-01,\n",
       "           -5.8602e-01, -2.0358e-01, -2.0568e-01, -5.7759e-01, -2.1095e-01,\n",
       "           -5.8075e-01, -1.9515e-01, -2.0252e-01, -5.7759e-01,  5.6447e-01,\n",
       "           -9.7689e-01,  5.2128e-01,  4.6860e-01,  4.7703e-01,  4.4753e-01,\n",
       "           -9.7689e-01,  4.1803e-01, -9.7689e-01, -9.7689e-01,  3.5271e-01,\n",
       "            2.9265e-01, -9.7689e-01,  2.6947e-01, -9.7689e-01,  2.2628e-01,\n",
       "           -9.7689e-01,  1.9467e-01, -9.7689e-01,  1.7571e-01, -9.7689e-01,\n",
       "            1.5569e-01,  1.3989e-01, -9.7689e-01, -9.7689e-01,  7.7726e-02,\n",
       "           -9.7689e-01,  6.1922e-02,  4.7173e-02, -9.7689e-01,  4.0851e-02,\n",
       "           -9.7689e-01,  2.5048e-02, -2.3449e-03, -9.7689e-01, -1.2881e-02,\n",
       "           -9.7689e-01, -4.4488e-02, -9.7689e-01, -4.8702e-02, -5.8184e-02,\n",
       "           -9.7689e-01, -6.5559e-02, -9.7689e-01, -9.7689e-01, -8.3469e-02,\n",
       "           -9.7689e-01, -8.0309e-02, -8.4523e-02, -9.7689e-01, -8.9791e-02,\n",
       "           -9.7166e-02, -1.0033e-01, -1.1192e-01, -9.7689e-01, -1.0243e-01,\n",
       "           -9.7689e-01, -9.7689e-01, -1.0454e-01, -9.7689e-01, -1.0033e-01,\n",
       "           -9.7689e-01, -9.9273e-02, -9.7689e-01, -9.7689e-01, -9.5059e-02,\n",
       "           -9.7689e-01, -8.8737e-02, -9.7689e-01],\n",
       "          grad_fn=<SplitWithSizesBackward0>)]},\n",
       " 'Query Point': {'Log Moneyness': tensor([-1.9007,  0.6870,  0.8618, -1.4475], grad_fn=<SliceBackward0>),\n",
       "  'Time to Maturity': tensor([-0.7412,  1.0536, -0.8894,  0.9511], grad_fn=<SliceBackward0>)},\n",
       " 'Target Volatility': tensor([0.3204, 0.2626, 0.5944, 0.3362])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SurfaceBatchNorm(nn.Module):\n",
    "    def __init__(self, num_features=1, momentum=0.1):\n",
    "        super(SurfaceBatchNorm, self).__init__()\n",
    "        self.log_moneyness_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.time_to_maturity_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.implied_volatility_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.market_return_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.market_volatility_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "        self.treasury_rate_bn = nn.BatchNorm1d(num_features, momentum=momentum)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Concatenate all tensors from the Input Surface into one tensor for each feature\n",
    "        input_surface_log_moneyness = torch.cat([x for x in batch['Input Surface']['Log Moneyness']])\n",
    "        input_surface_time_to_maturity = torch.cat([x for x in batch['Input Surface']['Time to Maturity']])\n",
    "        input_surface_implied_volatility = torch.cat([x for x in batch['Input Surface']['Implied Volatility']])\n",
    "\n",
    "        # Concatenate Input Surface tensors with Query Point tensors\n",
    "        total_log_moneyness = torch.cat([input_surface_log_moneyness, batch['Query Point']['Log Moneyness']])\n",
    "        total_time_to_maturity = torch.cat([input_surface_time_to_maturity, batch['Query Point']['Time to Maturity']])\n",
    "\n",
    "        # Normalize Log Moneyness and Time to Maturity\n",
    "        norm_log_moneyness = self.log_moneyness_bn(total_log_moneyness.unsqueeze(1)).squeeze(1)\n",
    "        norm_time_to_maturity = self.time_to_maturity_bn(total_time_to_maturity.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Normalize Implied Volatility (only from Input Surface)\n",
    "        norm_implied_volatility = self.implied_volatility_bn(input_surface_implied_volatility.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Split the normalized results back to corresponding structures\n",
    "        input_surface_sizes = [len(x) for x in batch['Input Surface']['Log Moneyness']]\n",
    "        total_input_size = sum(input_surface_sizes)\n",
    "\n",
    "        # Normalizing Market Features\n",
    "        market_features = batch['Market Features']\n",
    "        norm_market_return = self.market_return_bn(market_features['Market Return'].unsqueeze(1)).squeeze(1)\n",
    "        norm_market_volatility = self.market_volatility_bn(market_features['Market Volatility'].unsqueeze(1)).squeeze(1)\n",
    "        norm_treasury_rate = self.treasury_rate_bn(market_features['Treasury Rate'].unsqueeze(1)).squeeze(1)\n",
    "\n",
    "        # Reconstructing the batch with normalized data\n",
    "        output = {\n",
    "            'Datetime': batch['Datetime'],\n",
    "            'Symbol': batch['Symbol'],\n",
    "            'Market Features': {\n",
    "                'Market Return': norm_market_return,\n",
    "                'Market Volatility': norm_market_volatility,\n",
    "                'Treasury Rate': norm_treasury_rate\n",
    "            },\n",
    "            'Input Surface': {\n",
    "                'Log Moneyness': list(torch.split(norm_log_moneyness[:total_input_size], input_surface_sizes)),\n",
    "                'Time to Maturity': list(torch.split(norm_time_to_maturity[:total_input_size], input_surface_sizes)),\n",
    "                'Implied Volatility': list(torch.split(norm_implied_volatility, input_surface_sizes))\n",
    "            },\n",
    "            'Query Point': {\n",
    "                'Log Moneyness': norm_log_moneyness[total_input_size:],\n",
    "                'Time to Maturity': norm_time_to_maturity[total_input_size:]\n",
    "            },\n",
    "            'Target Volatility': batch['Target Volatility']\n",
    "        }\n",
    "\n",
    "        return output\n",
    "\n",
    "# Usage\n",
    "surfacebatchnorm = SurfaceBatchNorm()\n",
    "processed_batch = surfacebatchnorm(batch)\n",
    "processed_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6845,  0.7368,  1.5961],\n",
       "         [-1.2593, -0.9681,  0.5388],\n",
       "         [-1.1992, -0.8333,  0.7038]],\n",
       "\n",
       "        [[ 1.1950,  0.7473,  0.2984],\n",
       "         [ 0.8943, -0.0236, -0.9674],\n",
       "         [ 0.6300, -0.7003, -2.0739]],\n",
       "\n",
       "        [[ 0.0789, -0.4775, -1.1493],\n",
       "         [ 1.0084, -0.0040, -1.1368],\n",
       "         [ 1.9723,  0.6296, -0.9216]],\n",
       "\n",
       "        [[ 2.1026,  0.7422, -0.5977],\n",
       "         [ 0.8996, -0.2620, -1.1257],\n",
       "         [-0.0421, -0.7001, -1.0169]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# class ParametricContinuousKernel(nn.Module):\n",
    "#     def __init__(self, input_dim, hidden_dim, hidden_layers, output_dim=1, dropout_prob=0.1):\n",
    "#         super(ParametricContinuousKernel, self).__init__()\n",
    "#         layers = []\n",
    "#         current_dim = input_dim\n",
    "#         for _ in range(hidden_layers):\n",
    "#             layers.append(nn.Linear(current_dim, hidden_dim))\n",
    "#             layers.append(nn.GELU())\n",
    "#             layers.append(nn.Dropout(dropout_prob))\n",
    "#             current_dim = hidden_dim\n",
    "#         layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "#         self.net = nn.Sequential(*layers)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "class EllipticalRBFKernel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(EllipticalRBFKernel, self).__init__()\n",
    "        # Initialize the bandwidth parameters for each dimension\n",
    "        # We use log-space parameterization for stability in optimization (exp to ensure positivity)\n",
    "        self.log_bandwidth = nn.Parameter(torch.zeros(input_dim))  # Initialized to exp(0) = 1\n",
    "\n",
    "    def forward(self, distances):\n",
    "        # Scale the distances by the bandwidths\n",
    "        # torch.exp(self.log_bandwidth) converts log bandwidth back to the standard scale\n",
    "        scaled_distances = distances / torch.exp(self.log_bandwidth)\n",
    "\n",
    "        # Compute the RBF kernel output using the scaled distances\n",
    "        # The RBF kernel formula exp(-0.5 * (scaled distance)^2)\n",
    "        kernel_values = torch.exp(-0.5 * torch.sum(scaled_distances ** 2, dim=-1))\n",
    "\n",
    "        return kernel_values\n",
    "\n",
    "class SurfaceContinuousKernelEmbedding(nn.Module):\n",
    "    def __init__(self, grid_dim):\n",
    "        super(SurfaceContinuousKernelEmbedding, self).__init__()\n",
    "        self.grid_dim = grid_dim\n",
    "        self.kernel = EllipticalRBFKernel(input_dim=2)\n",
    "        self.layer_norm = nn.LayerNorm([self.grid_dim, self.grid_dim])  # Normalizing across each image's dimensions\n",
    "\n",
    "        # Create a regular grid in (0, 1)x(0, 1), excluding 0 and 1\n",
    "        grid_points = torch.linspace(1 / (grid_dim + 1), 1 - 1 / (grid_dim + 1), grid_dim)\n",
    "        mesh_x, mesh_y = torch.meshgrid(grid_points, grid_points, indexing='ij')\n",
    "        self.grid_points = torch.stack([mesh_x.flatten(), mesh_y.flatten()], dim=-1)\n",
    "        self.grid_points = torch.erfinv(2 * self.grid_points - 1) * np.sqrt(2)  # inverse CDF of normal\n",
    "\n",
    "    def forward(self, input_surface_batch):\n",
    "        batch_size = len(input_surface_batch['Log Moneyness'])\n",
    "        batch_embedded_surfaces = []\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            # Extract the coordinates and implied volatilities for each surface in the batch\n",
    "            surface_coords = torch.stack([\n",
    "                input_surface_batch['Log Moneyness'][i], \n",
    "                input_surface_batch['Time to Maturity'][i]\n",
    "            ], dim=-1)\n",
    "            surface_ivs = input_surface_batch['Implied Volatility'][i]\n",
    "\n",
    "            # Initialize the output grid for the current surface\n",
    "            embedded_surface = torch.zeros((self.grid_dim, self.grid_dim), dtype=torch.float32, device=surface_coords.device)\n",
    "\n",
    "            # Compute the convolution for each point on the output grid\n",
    "            for idx, grid_point in enumerate(self.grid_points):\n",
    "                # Calculate the distance from each input point to the current grid point\n",
    "                point_differences = surface_coords - grid_point\n",
    "\n",
    "                # Apply the parametric kernel to these differences\n",
    "                kernel_outputs = self.kernel(point_differences)\n",
    "\n",
    "                # Compute the weighted sum of IVs based on the kernel outputs\n",
    "                embedded_surface[idx // self.grid_dim, idx % self.grid_dim] = (kernel_outputs * surface_ivs).sum()\n",
    "\n",
    "            # Normalize the embedded surface\n",
    "            embedded_surface = self.layer_norm(embedded_surface)\n",
    "            # Append the encoded surface for this input surface to the batch list\n",
    "            batch_embedded_surfaces.append(embedded_surface)\n",
    "\n",
    "        # Stack all encoded surfaces to form a batch tensor\n",
    "        return torch.stack(batch_embedded_surfaces)\n",
    "\n",
    "\n",
    "# Example of initializing and using this module\n",
    "grid_dim = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Grid Dimension']\n",
    "# kernel_hidden_dim = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Kernel Hidden Layer Dimension']\n",
    "# kernel_hidden_layers = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Kernel Hidden Layer Count']\n",
    "# kernel_dropout_prob = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Kernel Dropout Probability']\n",
    "\n",
    "continuous_kernel_embedding = SurfaceContinuousKernelEmbedding(grid_dim=grid_dim)\n",
    "continuous_kernel_embedding_batch = continuous_kernel_embedding(processed_batch['Input Surface'])\n",
    "continuous_kernel_embedding_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2993,  0.2987,  0.2889],\n",
       "          [ 0.3216,  0.3182,  0.3010],\n",
       "          [ 0.3209,  0.3167,  0.2991]],\n",
       "\n",
       "         [[ 1.4097,  1.4527,  2.1581],\n",
       "          [-0.1859,  0.0532,  1.2902],\n",
       "          [-0.1366,  0.1638,  1.4256]],\n",
       "\n",
       "         [[-0.8816, -0.9475, -2.0297],\n",
       "          [ 1.5665,  1.1998, -0.6981],\n",
       "          [ 1.4909,  1.0300, -0.9060]],\n",
       "\n",
       "         [[-0.6286, -0.6876, -1.6553],\n",
       "          [ 1.5604,  1.2324, -0.4646],\n",
       "          [ 1.4927,  1.0806, -0.6505]],\n",
       "\n",
       "         [[-1.4224, -1.4532, -1.9597],\n",
       "          [-0.2768, -0.4484, -1.3365],\n",
       "          [-0.3122, -0.5278, -1.4338]],\n",
       "\n",
       "         [[-0.2896, -0.2682,  0.0844],\n",
       "          [-1.0873, -0.9677, -0.3494],\n",
       "          [-1.0626, -0.9124, -0.2817]],\n",
       "\n",
       "         [[-0.2086, -0.2102, -0.2362],\n",
       "          [-0.1497, -0.1585, -0.2042],\n",
       "          [-0.1515, -0.1626, -0.2092]],\n",
       "\n",
       "         [[ 1.3301,  1.3936,  2.4362],\n",
       "          [-1.0283, -0.6749,  1.1533],\n",
       "          [-0.9554, -0.5114,  1.3536]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2935,  0.2986,  0.3037],\n",
       "          [ 0.2969,  0.3074,  0.3182],\n",
       "          [ 0.2999,  0.3152,  0.3309]],\n",
       "\n",
       "         [[ 1.8289,  1.4613,  1.0928],\n",
       "          [ 1.5820,  0.8285,  0.0538],\n",
       "          [ 1.3651,  0.2730, -0.8546]],\n",
       "\n",
       "         [[-1.5246, -0.9607, -0.3954],\n",
       "          [-1.1459,  0.0102,  1.1989],\n",
       "          [-0.8130,  0.8624,  2.5925]],\n",
       "\n",
       "         [[-1.2036, -0.6994, -0.1939],\n",
       "          [-0.8650,  0.1687,  1.2316],\n",
       "          [-0.5674,  0.9308,  2.4777]],\n",
       "\n",
       "         [[-1.7233, -1.4594, -1.1949],\n",
       "          [-1.5461, -1.0051, -0.4488],\n",
       "          [-1.3903, -0.6063,  0.2033]],\n",
       "\n",
       "         [[-0.0801, -0.2639, -0.4480],\n",
       "          [-0.2035, -0.5802, -0.9675],\n",
       "          [-0.3120, -0.8578, -1.4215]],\n",
       "\n",
       "         [[-0.2241, -0.2105, -0.1969],\n",
       "          [-0.2150, -0.1871, -0.1585],\n",
       "          [-0.2070, -0.1666, -0.1250]],\n",
       "\n",
       "         [[ 1.9496,  1.4063,  0.8617],\n",
       "          [ 1.5847,  0.4710, -0.6741],\n",
       "          [ 1.2641, -0.3500, -2.0166]]],\n",
       "\n",
       "\n",
       "        [[[ 0.3062,  0.3126,  0.3203],\n",
       "          [ 0.2956,  0.3072,  0.3202],\n",
       "          [ 0.2846,  0.2999,  0.3177]],\n",
       "\n",
       "         [[ 0.9127,  0.4559, -0.0956],\n",
       "          [ 1.6757,  0.8446, -0.0853],\n",
       "          [ 2.4669,  1.3647,  0.0913]],\n",
       "\n",
       "         [[-0.1189,  0.5818,  1.4280],\n",
       "          [-1.2896, -0.0145,  1.4123],\n",
       "          [-2.5035, -0.8124,  1.1412]],\n",
       "\n",
       "         [[ 0.0533,  0.6798,  1.4365],\n",
       "          [-0.9935,  0.1466,  1.4224],\n",
       "          [-2.0790, -0.5668,  1.1801]],\n",
       "\n",
       "         [[-1.0655, -0.7376, -0.3416],\n",
       "          [-1.6133, -1.0166, -0.3489],\n",
       "          [-2.1814, -1.3900, -0.4758]],\n",
       "\n",
       "         [[-0.5381, -0.7664, -1.0421],\n",
       "          [-0.1567, -0.5721, -1.0370],\n",
       "          [ 0.2388, -0.3122, -0.9487]],\n",
       "\n",
       "         [[-0.1902, -0.1734, -0.1530],\n",
       "          [-0.2184, -0.1877, -0.1534],\n",
       "          [-0.2476, -0.2069, -0.1599]],\n",
       "\n",
       "         [[ 0.5954, -0.0797, -0.8949],\n",
       "          [ 1.7232,  0.4948, -0.8797],\n",
       "          [ 2.8926,  1.2635, -0.6186]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2831,  0.2986,  0.3140],\n",
       "          [ 0.2968,  0.3102,  0.3200],\n",
       "          [ 0.3076,  0.3152,  0.3188]],\n",
       "\n",
       "         [[ 2.5739,  1.4572,  0.3572],\n",
       "          [ 1.5863,  0.6328, -0.0762],\n",
       "          [ 0.8134,  0.2732,  0.0131]],\n",
       "\n",
       "         [[-2.6676, -0.9543,  0.7333],\n",
       "          [-1.1525,  0.3104,  1.3982],\n",
       "          [ 0.0335,  0.8622,  1.2613]],\n",
       "\n",
       "         [[-2.2257, -0.6937,  0.8153],\n",
       "          [-0.8709,  0.4372,  1.4099],\n",
       "          [ 0.1895,  0.9306,  1.2874]],\n",
       "\n",
       "         [[-2.2582, -1.4564, -0.6667],\n",
       "          [-1.5492, -0.8646, -0.3555],\n",
       "          [-0.9942, -0.6064, -0.4196]],\n",
       "\n",
       "         [[ 0.2923, -0.2659, -0.8158],\n",
       "          [-0.2014, -0.6780, -1.0324],\n",
       "          [-0.5878, -0.8578, -0.9878]],\n",
       "\n",
       "         [[-0.2516, -0.2104, -0.1697],\n",
       "          [-0.2151, -0.1799, -0.1537],\n",
       "          [-0.1866, -0.1666, -0.1570]],\n",
       "\n",
       "         [[ 3.0507,  1.4002, -0.2256],\n",
       "          [ 1.5911,  0.1818, -0.8662],\n",
       "          [ 0.4486, -0.3498, -0.7342]]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SurfaceProjectionEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels, d_embedding, grid_dim):\n",
    "        super(SurfaceProjectionEmbedding, self).__init__()\n",
    "        # Initialize the 1x1 convolution layer\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, d_embedding, kernel_size=1)\n",
    "        # Initialize layer normalization across the channel, height, and width dimensions\n",
    "        self.layer_norm = nn.LayerNorm([d_embedding, grid_dim, grid_dim])  # Normalizes across (channels, height, width)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure x has dimensions: (batch_size, channels, height, width)\n",
    "        # Add a channel dimension if necessary\n",
    "        if x.dim() == 3:  # assuming x has dimensions (batch_size, height, width)\n",
    "            x = x.unsqueeze(1)  # add channel dimension\n",
    "        # Apply the 1x1 convolution to project the input to a higher dimensional space\n",
    "        x = self.conv1x1(x)\n",
    "        # Normalize the features across each channel, maintaining the spatial dimensions\n",
    "        x = self.layer_norm(x)\n",
    "        return x\n",
    "    \n",
    "d_embedding = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Channels Dimension']  # Desired number of output channels\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "# Create the module\n",
    "projection_embedding = SurfaceProjectionEmbedding(1, d_embedding, grid_dim)   \n",
    "projection_embedding_batch = projection_embedding(continuous_kernel_embedding_batch)\n",
    "projection_embedding_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.2993,  0.2987,  0.2889],\n",
       "           [ 0.3216,  0.3182,  0.3010],\n",
       "           [ 0.3209,  0.3167,  0.2991]],\n",
       " \n",
       "          [[ 1.4097,  1.4527,  2.1581],\n",
       "           [-0.1859,  0.0532,  1.2902],\n",
       "           [-0.1366,  0.1638,  1.4256]],\n",
       " \n",
       "          [[-0.8816, -0.9475, -2.0297],\n",
       "           [ 1.5665,  1.1998, -0.6981],\n",
       "           [ 1.4909,  1.0300, -0.9060]],\n",
       " \n",
       "          [[-0.6286, -0.6876, -1.6553],\n",
       "           [ 1.5604,  1.2324, -0.4646],\n",
       "           [ 1.4927,  1.0806, -0.6505]],\n",
       " \n",
       "          [[-1.4224, -1.4532, -1.9597],\n",
       "           [-0.2768, -0.4484, -1.3365],\n",
       "           [-0.3122, -0.5278, -1.4338]],\n",
       " \n",
       "          [[-0.2896, -0.2682,  0.0844],\n",
       "           [-1.0873, -0.9677, -0.3494],\n",
       "           [-1.0626, -0.9124, -0.2817]],\n",
       " \n",
       "          [[-0.2086, -0.2102, -0.2362],\n",
       "           [-0.1497, -0.1585, -0.2042],\n",
       "           [-0.1515, -0.1626, -0.2092]],\n",
       " \n",
       "          [[ 1.3301,  1.3936,  2.4362],\n",
       "           [-1.0283, -0.6749,  1.1533],\n",
       "           [-0.9554, -0.5114,  1.3536]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2935,  0.2986,  0.3037],\n",
       "           [ 0.2969,  0.3074,  0.3182],\n",
       "           [ 0.2999,  0.3152,  0.3309]],\n",
       " \n",
       "          [[ 1.8289,  1.4613,  1.0928],\n",
       "           [ 1.5820,  0.8285,  0.0538],\n",
       "           [ 1.3651,  0.2730, -0.8546]],\n",
       " \n",
       "          [[-1.5246, -0.9607, -0.3954],\n",
       "           [-1.1459,  0.0102,  1.1989],\n",
       "           [-0.8130,  0.8624,  2.5925]],\n",
       " \n",
       "          [[-1.2036, -0.6994, -0.1939],\n",
       "           [-0.8650,  0.1687,  1.2316],\n",
       "           [-0.5674,  0.9308,  2.4777]],\n",
       " \n",
       "          [[-1.7233, -1.4594, -1.1949],\n",
       "           [-1.5461, -1.0051, -0.4488],\n",
       "           [-1.3903, -0.6063,  0.2033]],\n",
       " \n",
       "          [[-0.0801, -0.2639, -0.4480],\n",
       "           [-0.2035, -0.5802, -0.9675],\n",
       "           [-0.3120, -0.8578, -1.4215]],\n",
       " \n",
       "          [[-0.2241, -0.2105, -0.1969],\n",
       "           [-0.2150, -0.1871, -0.1585],\n",
       "           [-0.2070, -0.1666, -0.1250]],\n",
       " \n",
       "          [[ 1.9496,  1.4063,  0.8617],\n",
       "           [ 1.5847,  0.4710, -0.6741],\n",
       "           [ 1.2641, -0.3500, -2.0166]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3062,  0.3126,  0.3203],\n",
       "           [ 0.2956,  0.3072,  0.3202],\n",
       "           [ 0.2846,  0.2999,  0.3177]],\n",
       " \n",
       "          [[ 0.9127,  0.4559, -0.0956],\n",
       "           [ 1.6757,  0.8446, -0.0853],\n",
       "           [ 2.4669,  1.3647,  0.0913]],\n",
       " \n",
       "          [[-0.1189,  0.5818,  1.4280],\n",
       "           [-1.2896, -0.0145,  1.4123],\n",
       "           [-2.5035, -0.8124,  1.1412]],\n",
       " \n",
       "          [[ 0.0533,  0.6798,  1.4365],\n",
       "           [-0.9935,  0.1466,  1.4224],\n",
       "           [-2.0790, -0.5668,  1.1801]],\n",
       " \n",
       "          [[-1.0655, -0.7376, -0.3416],\n",
       "           [-1.6133, -1.0166, -0.3489],\n",
       "           [-2.1814, -1.3900, -0.4758]],\n",
       " \n",
       "          [[-0.5381, -0.7664, -1.0421],\n",
       "           [-0.1567, -0.5721, -1.0370],\n",
       "           [ 0.2388, -0.3122, -0.9487]],\n",
       " \n",
       "          [[-0.1902, -0.1734, -0.1530],\n",
       "           [-0.2184, -0.1877, -0.1534],\n",
       "           [-0.2476, -0.2069, -0.1599]],\n",
       " \n",
       "          [[ 0.5954, -0.0797, -0.8949],\n",
       "           [ 1.7232,  0.4948, -0.8797],\n",
       "           [ 2.8926,  1.2635, -0.6186]]],\n",
       " \n",
       " \n",
       "         [[[ 0.2831,  0.2986,  0.3140],\n",
       "           [ 0.2968,  0.3102,  0.3200],\n",
       "           [ 0.3076,  0.3152,  0.3188]],\n",
       " \n",
       "          [[ 2.5739,  1.4572,  0.3572],\n",
       "           [ 1.5863,  0.6328, -0.0762],\n",
       "           [ 0.8134,  0.2732,  0.0131]],\n",
       " \n",
       "          [[-2.6676, -0.9543,  0.7333],\n",
       "           [-1.1525,  0.3104,  1.3982],\n",
       "           [ 0.0335,  0.8622,  1.2613]],\n",
       " \n",
       "          [[-2.2257, -0.6937,  0.8153],\n",
       "           [-0.8709,  0.4372,  1.4099],\n",
       "           [ 0.1895,  0.9306,  1.2874]],\n",
       " \n",
       "          [[-2.2582, -1.4564, -0.6667],\n",
       "           [-1.5492, -0.8646, -0.3555],\n",
       "           [-0.9942, -0.6064, -0.4196]],\n",
       " \n",
       "          [[ 0.2923, -0.2659, -0.8158],\n",
       "           [-0.2014, -0.6780, -1.0324],\n",
       "           [-0.5878, -0.8578, -0.9878]],\n",
       " \n",
       "          [[-0.2516, -0.2104, -0.1697],\n",
       "           [-0.2151, -0.1799, -0.1537],\n",
       "           [-0.1866, -0.1666, -0.1570]],\n",
       " \n",
       "          [[ 3.0507,  1.4002, -0.2256],\n",
       "           [ 1.5911,  0.1818, -0.8662],\n",
       "           [ 0.4486, -0.3498, -0.7342]]]], grad_fn=<NativeLayerNormBackward0>),\n",
       " {'Datetime': [Timestamp('2013-03-14 00:00:00'),\n",
       "   Timestamp('2013-01-31 00:00:00'),\n",
       "   Timestamp('2013-02-05 00:00:00'),\n",
       "   Timestamp('2013-05-20 00:00:00')],\n",
       "  'Symbol': ['GOOGL', 'AAPL', 'AAPL', 'AAPL'],\n",
       "  'Market Features': {'Market Return': tensor([ 0.4010, -0.9509,  1.1927, -0.6427], grad_fn=<SqueezeBackward1>),\n",
       "   'Market Volatility': tensor([-1.5886,  1.0710,  0.5712, -0.0535], grad_fn=<SqueezeBackward1>),\n",
       "   'Treasury Rate': tensor([ 1.2539e+00, -1.0051e-07,  2.5078e-01, -1.5047e+00],\n",
       "          grad_fn=<SqueezeBackward1>)},\n",
       "  'Input Surface': {'Log Moneyness': [tensor([-2.2581e+00, -1.8348e+00, -1.7707e+00, -1.7081e+00, -1.6774e+00,\n",
       "            -1.6171e+00, -1.5582e+00, -1.4166e+00, -1.3353e+00, -1.1304e+00,\n",
       "            -1.1304e+00, -1.0576e+00, -9.6379e-01, -9.4085e-01, -8.7328e-01,\n",
       "            -8.2921e-01, -8.0746e-01, -7.8590e-01, -7.6452e-01, -7.0143e-01,\n",
       "            -5.4050e-01, -4.6371e-01, -3.8918e-01, -2.6380e-01, -2.2909e-01,\n",
       "            -2.1191e-01, -1.7790e-01, -1.4434e-01, -1.1122e-01, -6.2331e-02,\n",
       "             1.4165e-03,  1.7106e-02,  3.2699e-02,  3.2699e-02,  9.4129e-02,\n",
       "             1.9817e-01,  2.4149e-01,  2.6996e-01,  3.1207e-01,  3.6716e-01,\n",
       "             3.8074e-01,  4.0770e-01,  4.3437e-01,  4.6077e-01,  5.1274e-01,\n",
       "             6.2594e-01,  7.2248e-01,  8.1547e-01,  9.7043e-01, -3.5272e-01,\n",
       "            -3.5272e-01, -3.1678e-01, -2.8134e-01, -2.4639e-01, -1.1122e-01,\n",
       "            -3.0257e-02, -3.0257e-02,  3.2699e-02,  4.8197e-02,  9.4129e-02,\n",
       "             1.3924e-01,  1.3924e-01,  1.8357e-01,  2.8407e-01,  3.1207e-01,\n",
       "            -3.5272e-01, -3.1678e-01, -2.1191e-01, -1.4434e-01, -1.4434e-01,\n",
       "            -7.8522e-02, -4.6243e-02,  1.0926e-01,  1.9817e-01,  1.9817e-01,\n",
       "             2.5576e-01, -6.6023e-01, -5.7978e-01, -3.1678e-01, -2.1191e-01,\n",
       "            -2.1191e-01, -1.4434e-01, -1.4371e-02,  4.8197e-02,  1.0926e-01,\n",
       "             1.0926e-01,  2.2713e-01, -4.2617e-01, -4.2617e-01, -3.8918e-01,\n",
       "            -3.8918e-01, -2.4639e-01, -2.1191e-01, -1.7790e-01, -1.4434e-01,\n",
       "            -7.8522e-02, -4.6243e-02,  1.3924e-01,  2.2713e-01,  2.5576e-01,\n",
       "             2.8407e-01, -1.9007e+00, -1.7707e+00, -1.5582e+00, -1.4723e+00,\n",
       "            -1.4166e+00, -1.3892e+00, -1.2825e+00, -1.1059e+00, -1.0576e+00,\n",
       "            -1.0339e+00, -9.8693e-01, -9.1813e-01, -8.9561e-01, -8.0746e-01,\n",
       "            -7.8590e-01, -7.2228e-01, -7.0143e-01, -6.8075e-01, -6.3988e-01,\n",
       "            -5.9966e-01, -5.0181e-01, -4.6371e-01, -3.3468e-01, -2.8134e-01,\n",
       "            -2.6380e-01, -1.7790e-01, -1.4434e-01, -1.4434e-01, -1.2772e-01,\n",
       "            -1.1122e-01, -9.4817e-02, -9.4817e-02, -4.6243e-02, -4.6243e-02,\n",
       "             3.2699e-02,  4.8197e-02,  6.3600e-02,  9.4129e-02,  1.9817e-01,\n",
       "             2.8407e-01,  2.8407e-01,  3.3976e-01,  3.6716e-01,  3.8074e-01,\n",
       "             3.8074e-01,  3.9426e-01,  4.6077e-01,  4.9985e-01,  5.1274e-01,\n",
       "             5.3834e-01,  5.7625e-01,  6.3821e-01,  6.5042e-01,  7.2248e-01,\n",
       "             7.2248e-01,  7.6940e-01,  7.6940e-01,  7.9254e-01,  8.1547e-01,\n",
       "             9.0518e-01,  9.2711e-01,  9.9181e-01,  1.0130e+00, -1.9007e+00,\n",
       "            -1.8026e+00, -1.6471e+00, -1.5582e+00, -1.5006e+00, -1.4166e+00,\n",
       "            -1.3892e+00, -1.3353e+00, -1.2565e+00, -1.2308e+00, -1.0576e+00,\n",
       "            -1.0103e+00, -9.4085e-01, -8.9561e-01, -8.5115e-01, -7.8590e-01,\n",
       "            -7.6452e-01, -7.4331e-01, -6.8075e-01, -6.6023e-01, -6.1969e-01,\n",
       "            -5.6006e-01, -4.6371e-01, -3.8918e-01, -3.5272e-01, -3.3468e-01,\n",
       "            -3.1678e-01, -2.9900e-01, -2.8134e-01, -2.6380e-01, -2.6380e-01,\n",
       "            -2.4639e-01, -1.9485e-01, -1.7790e-01, -1.6107e-01, -1.6107e-01,\n",
       "            -1.1122e-01, -6.2331e-02, -6.2331e-02, -4.6243e-02, -1.4371e-02,\n",
       "             1.4165e-03,  9.4129e-02,  1.0926e-01,  1.0926e-01,  1.3924e-01,\n",
       "             1.5410e-01,  1.8357e-01,  1.9817e-01,  2.1269e-01,  2.2713e-01,\n",
       "             2.8407e-01,  3.2596e-01,  3.5350e-01,  3.8074e-01,  3.9426e-01,\n",
       "             4.9985e-01,  5.1274e-01,  5.7625e-01,  6.0122e-01,  8.3820e-01,\n",
       "             8.6072e-01,  8.8305e-01,  9.2711e-01,  1.0130e+00, -2.1825e+00,\n",
       "            -2.1455e+00, -2.1090e+00, -1.9007e+00, -1.8675e+00, -1.8348e+00,\n",
       "            -1.8026e+00, -1.8026e+00, -1.7707e+00, -1.4723e+00, -1.3621e+00,\n",
       "            -1.2308e+00, -1.2053e+00, -1.0817e+00, -1.0817e+00, -1.0339e+00,\n",
       "            -9.6379e-01, -9.1813e-01, -8.9561e-01, -8.7328e-01, -8.5115e-01,\n",
       "            -8.5115e-01, -8.2921e-01, -6.3988e-01, -6.3988e-01, -6.1969e-01,\n",
       "            -5.9966e-01, -5.7978e-01, -5.6006e-01, -4.0761e-01, -3.7088e-01,\n",
       "            -3.5272e-01, -3.1678e-01, -2.9900e-01, -2.1191e-01, -1.6107e-01,\n",
       "            -1.4434e-01, -1.2772e-01, -6.2331e-02,  1.7106e-02,  7.8910e-02,\n",
       "             9.4129e-02,  1.0926e-01,  1.0926e-01,  1.6888e-01,  1.8357e-01,\n",
       "             1.9817e-01,  2.5576e-01,  2.8407e-01,  3.1207e-01,  4.4760e-01,\n",
       "             4.8689e-01,  5.7625e-01,  6.5042e-01,  6.7467e-01,  8.1547e-01,\n",
       "             9.0518e-01, -1.9682e+00, -1.9682e+00, -1.9342e+00, -1.9007e+00,\n",
       "            -1.8348e+00, -1.8026e+00, -1.7081e+00, -1.6171e+00, -1.5874e+00,\n",
       "            -1.5874e+00, -1.5582e+00, -1.4166e+00, -1.3621e+00, -1.3353e+00,\n",
       "            -1.3087e+00, -1.2308e+00, -1.2053e+00, -1.1801e+00, -1.1801e+00,\n",
       "            -1.1551e+00, -1.0817e+00, -1.0339e+00, -8.9561e-01, -8.7328e-01,\n",
       "            -8.0746e-01, -7.8590e-01, -7.2228e-01, -6.8075e-01, -6.8075e-01,\n",
       "            -6.6023e-01, -6.3988e-01, -4.2617e-01, -4.0761e-01, -4.0761e-01,\n",
       "            -3.3468e-01, -2.4639e-01, -2.4639e-01, -1.6107e-01, -7.8522e-02,\n",
       "             1.7106e-02,  6.3600e-02,  1.0926e-01,  1.8357e-01,  1.9817e-01,\n",
       "             1.9817e-01,  2.8407e-01,  3.2596e-01,  3.8074e-01,  4.6077e-01,\n",
       "             4.7386e-01,  4.7386e-01,  4.9985e-01,  5.2557e-01,  6.9868e-01,\n",
       "             7.4605e-01,  7.4605e-01,  8.6072e-01,  8.8305e-01,  9.4886e-01,\n",
       "            -2.5855e+00, -2.5422e+00, -2.3760e+00, -2.3760e+00, -2.3361e+00,\n",
       "            -2.2581e+00, -2.2200e+00, -2.1455e+00, -2.1455e+00, -2.1090e+00,\n",
       "            -1.9682e+00, -1.8348e+00, -1.8348e+00, -1.6774e+00, -1.6171e+00,\n",
       "            -1.5292e+00, -1.5006e+00, -1.3087e+00, -1.2825e+00, -1.2308e+00,\n",
       "            -1.1801e+00, -1.1304e+00, -1.1304e+00, -1.1059e+00, -1.0339e+00,\n",
       "            -9.6379e-01, -8.9561e-01, -8.9561e-01, -8.7328e-01, -8.5115e-01,\n",
       "            -6.1969e-01, -5.7978e-01, -4.6371e-01, -4.2617e-01, -3.7088e-01,\n",
       "            -3.3468e-01, -2.9900e-01, -2.8134e-01, -2.6380e-01, -2.2909e-01,\n",
       "            -2.1191e-01, -1.9485e-01, -9.4817e-02, -6.2331e-02, -6.2331e-02,\n",
       "            -3.0257e-02, -1.4371e-02,  1.7106e-02,  7.8910e-02,  1.0926e-01,\n",
       "             1.8357e-01,  1.9817e-01,  1.9817e-01,  2.1269e-01,  2.4149e-01,\n",
       "             3.1207e-01,  3.6716e-01,  4.3437e-01,  4.8689e-01,  5.2557e-01,\n",
       "             5.5104e-01,  7.9254e-01,  8.6072e-01,  9.7043e-01,  9.9181e-01,\n",
       "             9.9181e-01], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([ 0.0502,  0.0779,  0.0779,  0.1053,  0.1053,  0.1324,  0.1592,  0.1592,\n",
       "             0.1858,  0.2380,  0.2637,  0.2892,  0.2892,  0.3144,  0.3144,  0.3641,\n",
       "             0.3886,  0.4368,  0.4368,  0.4606,  0.4842,  0.4842,  0.5076,  0.5307,\n",
       "             0.5307,  0.5536,  0.5536,  0.6212,  0.6433,  0.6433,  0.6653,  0.6653,\n",
       "             0.7086,  0.7086,  0.7300,  0.7512,  0.7512,  0.7722,  0.7930,  0.7930,\n",
       "             0.8137,  0.8137,  0.8343,  0.8546,  0.8546,  0.8748,  0.8948,  0.9147,\n",
       "             0.9344,  0.9344,  0.9540,  0.9734,  0.9734,  1.0118,  1.0308,  1.0496,\n",
       "             1.0869,  1.1053,  1.1053,  1.1236,  1.1236,  1.1418,  1.1418,  1.1598,\n",
       "             1.1598,  1.1955,  1.1955,  1.2131,  1.2307,  1.2481,  1.2654,  1.2826,\n",
       "             1.2826,  1.2996,  1.2996,  1.3166,  1.3334,  1.3334,  1.3501,  1.3501,\n",
       "             1.3668,  1.3997,  1.4160,  1.4160,  1.4321,  1.4321,  1.4482,  1.4482,\n",
       "             1.4642,  1.4801,  1.4801,  1.4959,  1.4959,  1.5116,  1.5272,  1.5427,\n",
       "             1.5886,  1.5886,  1.6037,  1.6188,  1.6188,  1.6337,  1.6486,  1.6634,\n",
       "             1.6780,  1.6927,  1.7072,  1.7216,  1.7216,  1.7502,  1.7786,  1.7786,\n",
       "             1.7926,  1.8066,  1.8204,  1.8204,  1.8342,  1.8480,  1.8480,  1.8616,\n",
       "             1.8616,  1.8752,  1.8887,  1.9156,  1.9289,  1.9289,  1.9421,  1.9421,\n",
       "             1.9552,  1.9683,  1.9814,  1.9943,  2.0072,  2.0201,  2.0201,  2.0328,\n",
       "             2.0455,  2.0957,  2.0957,  2.1204,  2.1204,  2.1449,  2.1449,  2.1691,\n",
       "            -1.6784, -1.6784, -1.5706, -1.5706, -1.4671, -1.3678, -1.2721, -1.1800,\n",
       "            -1.1800, -1.0911, -1.0052, -0.8416, -0.6880, -0.6880, -0.6146, -0.6146,\n",
       "            -0.5432, -0.5432, -0.4738, -0.4062, -0.3404, -0.2762, -0.2137, -0.2137,\n",
       "            -0.1526, -0.0930, -0.0930, -0.0347,  0.0222,  0.0222,  0.0779,  0.0779,\n",
       "             0.1324,  0.2380,  0.2892,  0.3394,  0.3886,  0.3886,  0.4368,  0.4368,\n",
       "             0.5307,  0.5763,  0.6653,  0.7086,  0.7512,  0.7512,  0.7930,  0.7930,\n",
       "             0.8343,  0.8748,  0.9540,  0.9540,  0.9927,  1.1053,  1.1418,  1.2131,\n",
       "             1.2131,  1.2481,  1.2826,  1.2826,  1.3166,  1.3501,  1.3501,  1.3833,\n",
       "             1.4160,  1.4482,  1.5734,  1.5734,  1.6037,  1.6037,  1.6337,  1.6337,\n",
       "             1.6634,  1.6634,  1.6927,  1.7216,  1.7216,  1.7502,  1.7786,  1.8342,\n",
       "             1.9156,  1.9421,  1.9683,  1.9943,  1.9943,  2.0201,  2.0201,  2.0455,\n",
       "             2.0455,  2.0707,  2.0957,  2.1204,  2.1449,  2.1691],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.4192, -0.3534, -0.3211, -0.1060, -0.0767,  0.0923,  0.0923,  0.2250,\n",
       "             0.3755,  0.4712,  0.5858,  0.7381,  0.7800, -1.3325, -1.3325, -1.2852,\n",
       "            -1.1930, -1.0182, -0.9351, -0.7011, -0.6276, -0.5562, -0.4528, -0.3534,\n",
       "            -0.2578,  0.0092,  0.0923,  0.1194,  0.2250,  0.2507,  0.3511,  0.5177,\n",
       "             0.5633,  0.5858,  0.5858,  0.7169,  0.7169,  0.7592,  0.7592,  0.8007,\n",
       "             0.9409,  0.9796,  1.1106,  1.2001,  1.2001,  1.2523,  1.2695,  1.3035,\n",
       "             1.3537,  1.3866,  1.3866,  1.4191,  1.4671,  1.4829,  1.5141,  1.5450,\n",
       "             1.6207,  1.6207,  1.6503,  1.6503,  1.6941,  1.7229,  1.7372,  1.7655,\n",
       "             1.7796,  1.8349,  1.8622,  1.9158,  1.9158,  1.9290,  1.9553,  1.9553,\n",
       "             1.9813,  1.9813,  2.1074,  2.1319, -0.2893, -0.2267, -0.0478,  0.0092,\n",
       "             0.0092,  0.0649,  0.1727,  0.1727,  0.1990,  0.2250,  0.2250,  0.2762,\n",
       "             0.3263,  0.3511,  0.3998,  0.5406,  0.6522, -0.4192, -0.4192,  0.1462,\n",
       "             0.2762,  0.3263,  0.3263,  0.3511,  0.4476,  0.5177,  0.5177,  0.5633,\n",
       "             0.5633, -1.4300, -1.1930, -1.1482, -1.0608, -1.0182, -0.9351, -0.8547,\n",
       "            -0.8154, -0.7386, -0.5213, -0.5213, -0.4868, -0.3534, -0.3534, -0.1356,\n",
       "            -0.0478, -0.0478,  0.0372,  0.0923,  0.1462,  0.1727,  0.2250,  0.2507,\n",
       "             0.2762,  0.2762,  0.3014,  0.3263,  0.3263,  0.4238,  0.4476,  0.5177,\n",
       "             0.5858,  0.6303,  0.6522,  0.6740,  0.6955,  0.7169,  0.7381,  0.7800,\n",
       "             0.8007,  0.8618,  0.8818,  0.9017,  0.9409,  0.9796,  1.0553,  1.0738,\n",
       "             1.0923,  1.1287,  1.1287,  1.2523,  1.3371,  1.3537,  1.3537,  1.4191,\n",
       "             1.4352,  1.4829,  1.4985,  1.5141,  1.6355,  1.6650,  1.6941,  1.7086,\n",
       "             1.7514, -1.3808, -1.1930, -1.1482, -1.1041, -1.0608, -0.9763, -0.9351,\n",
       "            -0.9351, -0.8946, -0.8946, -0.8547, -0.5213, -0.3534, -0.3211, -0.3211,\n",
       "            -0.2578, -0.0191,  0.0923,  0.1194,  0.2250,  0.2507,  0.3014,  0.3511,\n",
       "             0.3755,  0.3998,  0.4238,  0.4476,  0.4712,  0.5406,  0.5858,  0.6522,\n",
       "             0.6740,  0.6955,  0.6955,  0.7169,  0.7381,  0.7592,  0.7592,  0.7800,\n",
       "             0.8007,  0.8416,  0.8818,  0.9796,  1.0177,  1.0177,  1.0553,  1.2176,\n",
       "             1.2176,  1.2523,  1.3537,  1.3537,  1.3702,  1.3866,  1.4352,  1.4352,\n",
       "             1.4512,  1.4671,  1.4829,  1.5141,  1.5296,  1.5450,  1.5604,  1.5756,\n",
       "             1.5756,  1.5907,  1.6941,  1.7086,  1.7372,  1.7655,  1.8212,  1.8622,\n",
       "             1.8757,  1.8891,  1.9422,  1.9422,  1.9683,  2.0198,  2.0577,  2.0827,\n",
       "             2.1319, -1.1482, -1.0608, -1.0182, -0.9763, -0.9351, -0.8946, -0.8547,\n",
       "            -0.8154, -0.5917, -0.5562, -0.5213, -0.4868, -0.4868, -0.2578, -0.1356,\n",
       "            -0.0478, -0.0191,  0.0372,  0.1194,  0.2250,  0.2250,  0.2507,  0.3014,\n",
       "             0.3263,  0.3998,  0.4476,  0.4712,  0.5633,  0.5858,  0.8618,  0.8618,\n",
       "             0.9017,  0.9214,  0.9409,  1.0177,  1.0553,  1.1647,  1.2176,  1.2351,\n",
       "             1.2523, -1.2387, -1.1041, -0.9763, -0.8946, -0.6641, -0.5562, -0.3534,\n",
       "            -0.2267, -0.1960, -0.1960, -0.1656, -0.1356, -0.1060, -0.0191,  0.0092,\n",
       "             0.0372,  0.0649,  0.1727,  0.4476,  0.5177,  0.6522,  0.6522,  0.7169,\n",
       "             0.7381,  0.7800,  0.8212,  0.9796,  1.0366,  1.0738,  1.1106,  1.1287,\n",
       "             1.1468,  1.2001,  1.2176,  1.2695,  1.2866,  1.3035,  1.3035,  1.3204,\n",
       "             1.3371,  1.4029,  1.4191,  1.4191,  1.4352,  1.4829,  1.5141,  1.5756,\n",
       "             1.6057,  1.6503,  1.6503,  1.6650,  1.7655,  1.8074,  1.9025,  1.9290,\n",
       "            -1.3325, -1.2387, -1.1930, -1.0608, -0.9763, -0.8946, -0.8154, -0.7386,\n",
       "            -0.4868, -0.1356, -0.0191,  0.1194,  0.1990,  0.4238,  0.4476,  0.4712,\n",
       "             0.4945,  0.5177,  0.5177,  0.5406,  0.6303,  0.6522,  0.8007,  0.9409,\n",
       "             0.9604,  1.1287,  1.2001,  1.2351,  1.3702,  1.4352,  1.4671,  1.4985,\n",
       "             1.5450,  1.5450,  1.5756,  1.6207,  1.6355,  1.6355,  1.6650,  1.6796,\n",
       "             1.7372,  1.8074,  1.8212,  1.8891,  1.8891,  1.9025,  1.9813,  2.0198,\n",
       "             2.0577,  2.1074, -1.2852, -1.2387, -1.1930, -0.9351, -0.8154, -0.8154,\n",
       "            -0.7767, -0.7767, -0.6641, -0.5562, -0.4192, -0.3534, -0.3211, -0.3211,\n",
       "            -0.1060, -0.0191, -0.0191,  0.0372,  0.0649,  0.1990,  0.3014,  0.4238,\n",
       "             0.4238,  0.4712,  0.4712,  0.4945,  0.5177,  0.5858,  0.5858,  0.6082,\n",
       "             0.6522,  0.6522,  0.8212,  0.8416,  0.9214,  0.9214,  0.9604,  1.0177,\n",
       "             1.1824,  1.2001,  1.2695,  1.3537,  1.3702,  1.4191,  1.5141,  1.5450,\n",
       "             1.6207,  1.6796, -1.8623, -1.5314, -1.4802, -1.3808, -1.2852, -1.2387,\n",
       "            -1.1930, -1.0182, -0.9763, -0.8547, -0.5917, -0.3861, -0.1960, -0.1060,\n",
       "            -0.0767, -0.0478,  0.0649,  0.1727,  0.1727,  0.2250,  0.2507,  0.3263,\n",
       "             0.3263,  0.3755,  0.3998,  0.4238,  0.4945,  0.5858,  0.6082,  0.6740,\n",
       "             0.6740,  0.8416,  0.9017,  1.0177,  1.2001,  1.2176,  1.4191,  1.4512,\n",
       "             1.5296,  1.5604,  1.5756,  1.5907,  1.6207,  1.6796,  1.7229,  1.7514,\n",
       "             1.7655,  1.8074,  1.8486,  1.9025,  1.9290,  1.9422,  2.0198],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.9343, -0.8512, -0.8107, -0.7708, -0.7315, -0.6928, -0.6928, -0.6547,\n",
       "            -0.6172, -0.6172, -0.5802, -0.4374, -0.3689, -0.3353, -0.3022, -0.2695,\n",
       "            -0.2695, -0.2054, -0.1739, -0.1428, -0.1428, -0.1121, -0.0817, -0.0817,\n",
       "            -0.0518, -0.0518,  0.0072,  0.0361,  0.0648,  0.0648,  0.0931,  0.1211,\n",
       "             0.1488,  0.1762,  0.2301,  0.2566,  0.2566, -0.9343, -0.9343, -0.8924,\n",
       "            -0.8512, -0.8107, -0.7708, -0.7315, -0.7315, -0.6928, -0.6928, -0.6547,\n",
       "            -0.6172, -0.5437, -0.4723, -0.4374, -0.4029, -0.3689, -0.3353, -0.3353,\n",
       "            -0.3022, -0.2695, -0.2372, -0.2054, -0.1428, -0.1121, -0.0817, -0.0518,\n",
       "            -0.0518, -0.0221, -0.0221,  0.0361,  0.0361,  0.0648,  0.1488,  0.1488,\n",
       "             0.1762,  0.1762,  0.2033,  0.2301,  0.2566, -0.6928, -0.6928, -0.6172,\n",
       "            -0.5078, -0.5078, -0.4723, -0.4374, -0.4374, -0.3353, -0.3022, -0.3022,\n",
       "            -0.2695, -0.2372, -0.2372, -0.2054, -0.1739, -0.1739, -0.1428, -0.1121,\n",
       "            -0.0817, -0.0518, -0.0518,  0.0361,  0.0648,  0.0648,  0.0931,  0.1211,\n",
       "             0.1488,  0.1488,  0.1762,  0.1762,  0.2033,  0.2033,  0.2301,  0.2301,\n",
       "             0.2566,  0.2566, -0.7708, -0.7708, -0.6928, -0.6928, -0.6172, -0.5437,\n",
       "            -0.4374, -0.4029, -0.3353, -0.3353, -0.3022, -0.2695, -0.2695, -0.2372,\n",
       "            -0.2054, -0.2054, -0.1739, -0.1739, -0.1428, -0.1428, -0.1121, -0.1121,\n",
       "            -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,  0.0361,  0.0648,  0.0931,\n",
       "             0.1211,  0.1211,  0.1488,  0.1488,  0.1762,  0.1762,  0.2033,  0.2301,\n",
       "             0.2566, -1.9617, -1.8991, -1.8381, -1.8381, -1.7784, -1.7784, -1.7202,\n",
       "            -1.7202, -1.6633, -1.6633, -1.6076, -1.5531, -1.5531, -1.4997, -1.4997,\n",
       "            -1.4475, -1.3963, -1.3963, -1.3461, -1.2969, -1.2486, -1.2486, -1.2013,\n",
       "            -1.2013, -1.1548, -1.1091, -1.1091, -1.0643, -1.0202, -0.9769, -0.9343,\n",
       "            -0.8924, -0.8924, -0.8107, -0.8107, -0.7708, -0.7315, -0.6928, -0.6547,\n",
       "            -0.6172, -0.6172, -0.5802, -0.5437, -0.5437, -0.5078, -0.4723, -0.4723,\n",
       "            -0.4374, -0.4374, -0.3689, -0.3689, -0.3353, -0.3353, -0.2695, -0.2372,\n",
       "            -0.2054, -0.2054, -0.1428, -0.1121, -0.0817, -0.0817, -0.0518, -0.0221,\n",
       "             0.0072,  0.0072,  0.0361,  0.0361,  0.0648,  0.0931,  0.1211,  0.1762,\n",
       "             0.1762,  0.2033,  0.2033,  0.2301,  0.2566,  0.2566, -1.6076, -1.6076,\n",
       "            -1.4475, -1.4475, -1.3963, -1.3461, -1.3461, -1.2969, -1.2486, -1.2486,\n",
       "            -1.1548, -1.1548, -1.1091, -0.9769, -0.9343, -0.9343, -0.8107, -0.8107,\n",
       "            -0.7708, -0.6547, -0.6547, -0.6172, -0.6172, -0.5437, -0.5437, -0.5078,\n",
       "            -0.4723, -0.4723, -0.4374, -0.4029, -0.4029, -0.3353, -0.3022, -0.2695,\n",
       "            -0.2695, -0.2372, -0.2372, -0.2054, -0.2054, -0.1739, -0.1739, -0.1428,\n",
       "            -0.1121, -0.1121, -0.0817, -0.0221, -0.0221,  0.0072,  0.0361,  0.0648,\n",
       "             0.0648,  0.0931,  0.1211,  0.1211,  0.1488,  0.2033,  0.2301,  0.2301,\n",
       "            -1.8991, -1.8991, -1.8381, -1.7202, -1.6633, -1.6633, -1.6076, -1.5531,\n",
       "            -1.5531, -1.4997, -1.4997, -1.4475, -1.3963, -1.3461, -1.2969, -1.2486,\n",
       "            -1.2013, -1.2013, -1.0643, -1.0202, -0.9343, -0.9343, -0.8924, -0.8512,\n",
       "            -0.8512, -0.8107, -0.8107, -0.7315, -0.7315, -0.6928, -0.6172, -0.6172,\n",
       "            -0.5802, -0.5437, -0.5078, -0.5078, -0.4723, -0.4374, -0.4029, -0.3689,\n",
       "            -0.3353, -0.3353, -0.3022, -0.3022, -0.2695, -0.2695, -0.2372, -0.2372,\n",
       "            -0.2054, -0.1739, -0.1428, -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,\n",
       "             0.0361,  0.0931,  0.1211,  0.1211,  0.1488,  0.1762,  0.1762,  0.2033,\n",
       "             0.2301,  0.2301, -1.8381, -1.8381, -1.7784, -1.7784, -1.6633, -1.6076,\n",
       "            -1.6076, -1.5531, -1.4997, -1.4475, -1.4475, -1.3963, -1.3461, -1.2969,\n",
       "            -1.2969, -1.2486, -1.2013, -1.1548, -1.1091, -1.0643, -1.0643, -1.0202,\n",
       "            -1.0202, -0.9769, -0.9769, -0.9343, -0.8107, -0.7708, -0.7315, -0.7315,\n",
       "            -0.6928, -0.6547, -0.6172, -0.5802, -0.5437, -0.5437, -0.5078, -0.4723,\n",
       "            -0.4374, -0.4029, -0.3353, -0.3353, -0.3022, -0.2695, -0.2372, -0.2054,\n",
       "            -0.1739, -0.1428, -0.1121, -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,\n",
       "             0.0361,  0.0648,  0.0648,  0.0931,  0.0931,  0.1488,  0.1762,  0.2033,\n",
       "             0.2033,  0.2301, -1.7202, -1.7202, -1.6633, -1.6633, -1.6076, -1.6076,\n",
       "            -1.5531, -1.4997, -1.4475, -1.4475, -1.3963, -1.3461, -1.2486, -1.2013,\n",
       "            -1.1091, -1.1091, -1.0643, -1.0202, -0.9769, -0.9343, -0.9343, -0.8107,\n",
       "            -0.8107, -0.7708, -0.7708, -0.7315, -0.7315, -0.6547, -0.6547, -0.6172,\n",
       "            -0.5802, -0.5437, -0.5078, -0.5078, -0.4723, -0.4723, -0.4374, -0.4374,\n",
       "            -0.3689, -0.3353, -0.3353, -0.3022, -0.2695, -0.2372, -0.2054, -0.1428,\n",
       "            -0.1121, -0.0817, -0.0518, -0.0221, -0.0221,  0.0072,  0.0072,  0.0361,\n",
       "             0.0648,  0.0648,  0.0931,  0.1488,  0.2033,  0.2301,  0.2301, -2.0258,\n",
       "            -1.9617, -1.8991, -1.7784, -1.7784, -1.7202, -1.7202, -1.6633, -1.6076,\n",
       "            -1.6076, -1.5531, -1.4997, -1.4997, -1.4475, -1.3963, -1.3461, -1.3461,\n",
       "            -1.2969, -1.2013, -1.2013, -1.1548, -1.0643, -1.0202, -1.0202, -0.9769,\n",
       "            -0.9343, -0.9343, -0.8924, -0.8512, -0.8107, -0.7315, -0.7315, -0.6928,\n",
       "            -0.6547, -0.6172, -0.5802, -0.5078, -0.5078, -0.4723, -0.4374, -0.4029,\n",
       "            -0.3689, -0.3353, -0.3022, -0.2372, -0.2054, -0.1739, -0.1428, -0.1428,\n",
       "            -0.1121, -0.1121, -0.0817, -0.0817, -0.0518, -0.0221, -0.0221,  0.0072,\n",
       "             0.0072,  0.0648,  0.0931,  0.1211,  0.1488,  0.1488,  0.1762,  0.2033,\n",
       "            -1.9617, -1.8381, -1.8381, -1.7784, -1.7202, -1.6633, -1.6076, -1.6076,\n",
       "            -1.5531, -1.4997, -1.4997, -1.3963, -1.3461, -1.3461, -1.2969, -1.2486,\n",
       "            -1.2013, -1.2013, -1.1548, -1.1548, -1.1091, -1.1091, -1.0643, -0.9769,\n",
       "            -0.9343, -0.9343, -0.8924, -0.8924, -0.8512, -0.8107, -0.8107, -0.7708,\n",
       "            -0.7708, -0.6928, -0.6547, -0.6547, -0.5437, -0.5437, -0.5078, -0.5078,\n",
       "            -0.4723, -0.4374, -0.4374, -0.4029, -0.3689, -0.3689, -0.3353, -0.3353,\n",
       "            -0.3022, -0.2695, -0.2695, -0.2054, -0.1739, -0.1428, -0.1121, -0.1121,\n",
       "            -0.0518, -0.0221, -0.0221,  0.0072,  0.0072,  0.0361,  0.0361,  0.0648,\n",
       "             0.0931,  0.0931,  0.1211,  0.1211,  0.1488],\n",
       "           grad_fn=<SplitWithSizesBackward0>)],\n",
       "   'Time to Maturity': [tensor([-0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065,\n",
       "            -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065,\n",
       "            -0.9065, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723,\n",
       "            -0.8723, -0.8723, -0.8723, -0.8723, -0.8267, -0.8267, -0.8267, -0.8267,\n",
       "            -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.7868,\n",
       "            -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868,\n",
       "            -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350,\n",
       "            -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8552, -0.8552, -0.8552, -0.8552,\n",
       "            -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552,\n",
       "            -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8153, -0.8153, -0.8153,\n",
       "            -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153,\n",
       "            -0.8153, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511],\n",
       "           grad_fn=<SplitWithSizesBackward0>)],\n",
       "   'Implied Volatility': [tensor([ 0.9100,  0.9100, -1.3298,  0.9100,  0.9100, -1.3298,  0.9100, -1.3298,\n",
       "            -1.3298, -1.3298,  0.9100,  0.9100, -1.3298, -1.3298, -1.3298, -1.3298,\n",
       "            -1.3298,  0.9100,  0.9100, -1.3298,  0.9100,  0.9100, -1.3298,  0.9100,\n",
       "            -1.3298, -1.3298,  0.9100,  0.9100,  0.9100,  0.9100, -0.9126, -1.3298,\n",
       "            -1.5479, -1.5047, -1.4436, -1.9325, -1.3298, -1.9325, -1.9325, -1.3298,\n",
       "            -1.3298, -1.9325, -1.9325, -1.9325, -1.9325, -1.9325, -1.3298, -1.3298,\n",
       "            -1.9325, -0.4111,  2.1227, -0.4111,  1.7898,  1.4895, -0.4111, -0.9537,\n",
       "            -0.9832, -1.5300, -1.6080, -1.6080, -1.4468, -1.3562, -1.1571, -1.0306,\n",
       "            -1.3593,  1.5875,  1.2577,  0.5666, -0.0961, -0.0287, -0.7725, -1.0443,\n",
       "            -1.6786, -1.4952, -1.7365, -1.7365,  0.7984,  0.7984,  0.5181, -0.1762,\n",
       "            -0.0993, -0.5649, -1.3973, -1.6617, -1.7049, -1.7144, -1.5395,  0.7278,\n",
       "             0.4349,  0.5666,  0.3443, -0.2268, -0.3595, -0.5786, -0.7146, -1.0391,\n",
       "            -1.1170, -1.5300, -1.6059, -1.3657, -1.2909,  0.0250,  0.1525,  4.8915,\n",
       "             0.0250,  4.2288,  0.0250,  0.0250,  2.7675,  0.1525,  0.0250,  2.2038,\n",
       "             1.8762,  1.7687,  0.0250,  0.1525,  0.1525,  0.0250,  0.1525,  0.0250,\n",
       "             0.0250,  0.0250,  0.1525, -0.1562, -0.2436, -0.2605, -0.4554, -0.4975,\n",
       "            -0.5112, -0.5218, -0.5302, -0.5260, -0.5776, -0.6313, -0.6471, -0.7198,\n",
       "            -0.7335, -0.7493, -0.7736, -0.8663, -0.8852, -0.9084, -0.9959, -1.2213,\n",
       "            -0.8189, -0.9959, -0.9959, -0.8136, -0.9959, -0.7746, -0.7746, -0.9959,\n",
       "            -0.7746, -0.7746, -0.7746, -0.9959, -0.7746, -0.9959, -0.9959, -0.9959,\n",
       "            -0.9959, -0.7746, -0.9959, -0.9959, -0.2584, -0.1383, -0.2584, -0.2584,\n",
       "            -0.2584,  2.6379,  2.5367, -0.2584,  2.0511,  1.9562, -0.2584,  1.2988,\n",
       "            -0.1383, -0.2584, -0.2584, -0.1383, -0.1383, -0.1383, -0.2584, -0.1383,\n",
       "            -0.1383, -0.2584, -0.2584, -0.3964, -0.4638, -0.4944, -0.5102, -0.5513,\n",
       "            -0.5786, -0.5976, -0.5966, -0.5818, -0.6735, -0.6851, -0.7230, -0.7346,\n",
       "            -0.7936, -0.8357, -0.8473, -0.8452, -0.8884, -0.8894, -0.9600, -0.9685,\n",
       "            -0.9853, -0.9959, -0.9980, -1.0085, -1.0517, -1.0464, -1.0443, -1.0664,\n",
       "            -1.0422, -1.0928, -1.0443, -1.0443, -1.0011, -1.1117, -1.1117, -1.1117,\n",
       "            -0.8810, -0.8810, -0.8810, -0.8810, -0.8810, -0.3384, -0.3384,  3.2405,\n",
       "            -0.3384,  2.5599, -0.3384, -0.3384,  2.3766,  2.2871, -0.2847, -0.2847,\n",
       "            -0.3384, -0.3384, -0.3384, -0.2847, -0.3384, -0.2847, -0.2847, -0.2847,\n",
       "            -0.2847, -0.3384, -0.2847, -0.2847, -0.3384, -0.2847, -0.2847, -0.3026,\n",
       "            -0.3384, -0.3574, -0.5997, -0.6229, -0.6387, -0.7293, -0.7082, -0.8125,\n",
       "            -0.9021, -0.9168, -0.9305, -0.9916, -1.0327, -1.0949, -1.1044, -1.0949,\n",
       "            -1.1075, -1.1507, -1.1539, -1.1560, -1.1592, -1.1866, -1.2024, -1.1929,\n",
       "            -1.3003, -1.1634, -1.2845, -1.2845, -0.8304, -1.2845, -0.1024, -0.0287,\n",
       "            -0.1024, -0.1024, -0.1024, -0.1024, -0.0287, -0.1024, -0.1024, -0.0287,\n",
       "            -0.0287, -0.1024, -0.1024, -0.0287, -0.1024, -0.0287, -0.1024, -0.1024,\n",
       "            -0.0287, -0.1024, -0.1024, -0.1024, -0.1024, -0.1014, -0.1730, -0.1867,\n",
       "            -0.2657, -0.3142, -0.3247, -0.3416, -0.3606, -0.6008, -0.6081, -0.6050,\n",
       "            -0.6798, -0.7441, -0.7398, -0.8083, -0.8599, -0.9390, -0.9527, -0.9980,\n",
       "            -1.0369, -1.0275, -1.0454, -1.0612, -1.0875, -1.1012, -1.1107, -1.1307,\n",
       "            -1.1149, -1.1328, -1.1149, -1.0854, -1.1128, -1.1412, -1.1412, -1.1412,\n",
       "            -1.1054, -0.1899, -0.0803, -0.0803, -0.1899, -0.1899, -0.1899, -0.1899,\n",
       "            -0.0803, -0.1899, -0.0803, -0.0803, -0.0803, -0.1899, -0.0803, -0.1899,\n",
       "            -0.1899, -0.1899, -0.0803, -0.0803, -0.1899, -0.0803, -0.0803, -0.1899,\n",
       "            -0.0803, -0.1256, -0.2004, -0.2531, -0.2426, -0.2531, -0.2868, -0.4743,\n",
       "            -0.5218, -0.5776, -0.5976, -0.6355, -0.6577, -0.6777, -0.7103, -0.7135,\n",
       "            -0.7430, -0.7409, -0.7567, -0.8115, -0.8431, -0.8336, -0.8673, -0.8631,\n",
       "            -0.8757, -0.9010, -0.9221, -0.9537, -0.9758, -0.9664, -0.9737, -0.9790,\n",
       "            -1.0159, -1.0401, -1.0580, -1.0759, -1.0896, -1.0896, -1.0812, -1.0728,\n",
       "            -1.0169, -1.0517, -1.0759], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-2.9208e-01, -3.7741e-01, -2.9313e-01, -3.8268e-01, -3.0261e-01,\n",
       "            -3.0682e-01, -3.9111e-01, -3.1209e-01, -3.1104e-01, -4.1640e-01,\n",
       "            -3.2474e-01, -4.2166e-01, -3.2790e-01, -4.2798e-01, -3.3000e-01,\n",
       "            -4.3641e-01, -3.3000e-01, -4.4695e-01, -3.3632e-01, -4.4695e-01,\n",
       "            -4.5011e-01, -3.3422e-01, -4.5222e-01, -4.5011e-01, -3.4897e-01,\n",
       "            -4.5432e-01, -3.3422e-01, -4.5959e-01, -4.6065e-01, -3.1736e-01,\n",
       "            -4.5643e-01, -3.0682e-01, -4.5643e-01, -2.9418e-01, -2.9524e-01,\n",
       "            -4.5959e-01, -2.8891e-01, -4.5222e-01, -4.4590e-01, -2.7943e-01,\n",
       "            -4.4168e-01, -2.4993e-01, -2.7206e-01, -4.4800e-01, -2.3518e-01,\n",
       "            -4.4379e-01, -4.3957e-01, -4.2693e-01, -4.2588e-01, -2.0358e-01,\n",
       "            -4.2377e-01, -4.2693e-01, -2.5625e-01, -2.5625e-01, -4.0270e-01,\n",
       "            -3.9111e-01, -2.5625e-01, -3.7531e-01, -2.5625e-01, -3.8690e-01,\n",
       "            -2.5625e-01, -3.8374e-01, -2.5625e-01, -3.8057e-01, -2.5625e-01,\n",
       "            -3.6477e-01, -2.5625e-01, -2.5625e-01, -2.5625e-01, -2.5625e-01,\n",
       "            -3.4159e-01, -3.3843e-01, -2.5625e-01, -3.1947e-01, -2.5625e-01,\n",
       "            -2.9102e-01, -3.0050e-01, -2.5625e-01, -2.8786e-01, -2.5625e-01,\n",
       "            -2.7943e-01, -2.5625e-01, -2.6047e-01, -2.5625e-01, -2.3518e-01,\n",
       "            -2.5625e-01, -2.4045e-01, -2.5625e-01, -2.5625e-01, -2.4256e-01,\n",
       "            -2.5625e-01, -2.4045e-01, -2.5625e-01, -2.1306e-01, -2.1200e-01,\n",
       "            -2.1727e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.1727e-01, -2.5625e-01,\n",
       "            -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01,\n",
       "            -2.1727e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01,\n",
       "            -2.5625e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01,\n",
       "            -2.1727e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01,  1.5201e+00,\n",
       "             2.6315e-01,  1.2609e+00,  2.6947e-01,  2.0942e-01,  8.0152e-01,\n",
       "             5.7501e-01,  4.6333e-01,  1.3989e-01,  1.3883e-01,  1.0512e-01,\n",
       "             9.2476e-02,  5.8762e-02,  6.4030e-02,  3.3476e-02,  4.4012e-02,\n",
       "            -9.7199e-03,  3.7691e-02,  2.6101e-02,  7.1371e-03, -8.3469e-02,\n",
       "            -1.9202e-02, -9.5059e-02, -9.7199e-03, -1.1613e-01, -1.2561e-01,\n",
       "            -2.1309e-02, -1.3825e-01, -1.3088e-01, -3.5006e-02, -1.4352e-01,\n",
       "            -5.2916e-02, -3.9220e-02, -1.7618e-01, -1.5827e-01, -1.8988e-01,\n",
       "            -1.8883e-01, -6.8720e-02, -1.9515e-01, -6.6612e-02, -2.0147e-01,\n",
       "            -2.0884e-01, -2.0041e-01, -5.2916e-02, -1.9093e-01, -6.4505e-02,\n",
       "            -2.0252e-01, -9.5059e-02, -9.0844e-02, -7.0827e-02, -2.1200e-01,\n",
       "            -6.4505e-02, -6.8720e-02, -2.0884e-01, -2.0147e-01, -2.1727e-01,\n",
       "            -2.7631e-02, -6.5593e-03, -2.0884e-01, -1.8149e-02, -1.9409e-01,\n",
       "            -2.0568e-01, -8.6664e-03, -2.3778e-04, -2.0568e-01,  3.5583e-02,\n",
       "            -1.8250e-01,  4.4012e-02, -1.8567e-01,  7.3512e-02, -1.8040e-01,\n",
       "             7.7726e-02, -1.7513e-01,  1.0090e-01, -1.8250e-01, -1.6038e-01,\n",
       "             9.3529e-02, -1.6565e-01,  1.3673e-01, -1.4142e-01,  1.3883e-01,\n",
       "             1.3883e-01, -1.4563e-01, -1.2350e-01,  1.3883e-01, -9.9273e-02,\n",
       "             1.3883e-01, -7.2934e-02,  1.3883e-01,  1.3883e-01,  1.3883e-01,\n",
       "             1.3883e-01,  1.3883e-01,  1.3883e-01],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-6.5872e-01,  1.6170e+00,  1.6170e+00,  1.3494e+00, -6.5872e-01,\n",
       "            -6.5872e-01,  1.8877e+00, -6.5872e-01,  1.0661e+01,  1.3498e+01,\n",
       "             1.4448e+01,  1.4448e+01, -6.5872e-01,  1.9109e+00,  6.4981e-01,\n",
       "             6.4981e-01,  1.9109e+00,  1.9109e+00,  6.4981e-01,  6.4981e-01,\n",
       "             6.4981e-01,  1.9109e+00,  6.4981e-01,  1.9109e+00,  1.9109e+00,\n",
       "            -6.4397e-01, -1.2877e-01, -5.8075e-01, -2.8049e-01,  1.0101e+00,\n",
       "             2.2133e+00,  3.0393e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "             1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "             1.7044e+00,  3.0393e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  1.7044e+00,  1.7044e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "             3.0393e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "             1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,\n",
       "             3.0393e+00,  1.5538e+00,  3.2005e-01, -5.0068e-01, -5.6600e-01,\n",
       "            -2.7733e-01, -5.9972e-01, -5.4914e-01, -1.3299e-01, -2.3416e-02,\n",
       "            -4.3957e-01,  9.6690e-02, -2.6363e-01, -8.8737e-02, -9.7199e-03,\n",
       "             2.7685e-01,  1.6496e+00,  1.6496e+00,  1.7697e+00,  6.8036e-01,\n",
       "            -5.5336e-01,  1.0933e-01, -2.3940e-01,  2.9265e-01,  4.5490e-01,\n",
       "             1.8730e-01,  4.2856e-01,  9.9538e-01,  6.0978e-01,  9.9538e-01,\n",
       "             8.7527e-01,  8.7527e-01,  8.7527e-01,  3.0740e-01,  3.0740e-01,\n",
       "             8.7527e-01,  8.7527e-01,  3.0740e-01,  3.0740e-01,  8.7527e-01,\n",
       "             3.0740e-01,  3.0740e-01,  4.7492e-01,  3.8744e-02, -4.4273e-01,\n",
       "            -4.9857e-01, -3.5950e-01, -5.3756e-01, -5.5863e-01, -4.2798e-01,\n",
       "            -5.6073e-01, -5.4914e-01, -5.2702e-01, -4.9225e-01, -2.9208e-01,\n",
       "            -2.1095e-01, -4.4063e-01, -1.6670e-01, -2.6784e-01,  2.3681e-01,\n",
       "             5.4867e-01,  1.3146e-01,  6.9933e-01,  6.9933e-01,  4.0538e-01,\n",
       "             4.3383e-01,  6.9933e-01,  5.3813e-01,  6.9933e-01,  6.9933e-01,\n",
       "             5.3813e-01,  5.3813e-01,  6.9933e-01,  6.9933e-01,  6.9933e-01,\n",
       "             6.9933e-01,  6.9933e-01,  6.9933e-01,  5.3813e-01,  6.9933e-01,\n",
       "             6.9933e-01,  5.3813e-01,  5.3813e-01,  6.9933e-01,  5.3813e-01,\n",
       "             6.9933e-01,  6.9933e-01,  5.3813e-01,  5.3813e-01,  6.9933e-01,\n",
       "             5.3813e-01,  6.9933e-01,  5.3813e-01,  5.3813e-01, -4.2380e-02,\n",
       "             1.7992e-01,  1.7992e-01,  1.7992e-01, -4.2380e-02, -4.2380e-02,\n",
       "            -4.2380e-02,  1.7992e-01, -4.2380e-02,  1.7992e-01,  1.7992e-01,\n",
       "            -4.2380e-02, -2.6890e-01, -3.2263e-01, -1.8777e-01, -2.4045e-01,\n",
       "            -4.1640e-01, -4.6065e-01, -5.4493e-01, -5.5863e-01, -5.4493e-01,\n",
       "            -4.1956e-01, -3.9638e-01, -3.4897e-01, -3.2790e-01, -2.9418e-01,\n",
       "            -4.5854e-01, -4.3747e-01, -3.7004e-01, -3.2474e-01,  2.1996e-01,\n",
       "            -1.7618e-01, -1.4352e-01,  3.8431e-01, -9.4005e-02,  3.8431e-01,\n",
       "             1.4512e-02,  3.8431e-01,  3.8431e-01,  3.8431e-01,  1.5042e-01,\n",
       "             2.2312e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "             2.7158e-01,  3.8431e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,\n",
       "             2.7158e-01,  2.7158e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "             3.8431e-01,  3.8431e-01,  3.8431e-01,  3.8431e-01,  3.8431e-01,\n",
       "             3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,\n",
       "             2.7158e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "             3.8431e-01,  2.7158e-01,  2.7158e-01,  3.8431e-01,  3.8431e-01,\n",
       "             3.8431e-01,  3.8431e-01,  2.7158e-01,  2.7158e-01,  4.2119e-01,\n",
       "             2.3492e+00,  4.2646e-01,  2.9371e-01,  4.2646e-01,  1.6381e+00,\n",
       "             4.2646e-01,  1.2956e+00,  1.7676e-01,  3.0424e-01,  2.0731e-01,\n",
       "             1.7571e-01,  8.2994e-02, -9.4005e-02, -1.5722e-01, -2.7311e-01,\n",
       "            -2.0358e-01, -2.2149e-01, -2.2991e-01, -3.8374e-01, -2.2149e-01,\n",
       "            -3.7847e-01, -1.8461e-01, -3.7741e-01, -1.2140e-01, -3.5950e-01,\n",
       "            -3.2898e-02, -2.9840e-01,  1.8414e-01,  7.1371e-03,  4.2119e-01,\n",
       "             6.9297e-02,  4.2119e-01,  1.5358e-01,  4.2119e-01,  2.1047e-01,\n",
       "             4.2119e-01,  2.1047e-01,  2.1047e-01,  4.2119e-01,  1.3378e+00,\n",
       "             1.3378e+00,  1.3378e+00,  3.1478e-01,  7.5619e-02, -3.9220e-02,\n",
       "            -1.6143e-01, -3.3422e-01, -3.5634e-01, -2.5625e-01, -3.5740e-01,\n",
       "            -3.8268e-01, -3.9743e-01, -4.3957e-01, -4.4590e-01, -3.4581e-01,\n",
       "            -3.5529e-01, -4.9541e-01, -4.8909e-01, -4.6381e-01, -3.7636e-01,\n",
       "             1.2405e-02, -3.4370e-01, -3.1420e-01, -2.9629e-01,  2.9792e-01,\n",
       "             3.5692e-01,  3.5692e-01,  3.5692e-01,  3.5692e-01,  3.3476e-02,\n",
       "             3.5692e-01,  3.3476e-02,  3.5692e-01,  3.3476e-02,  3.5692e-01,\n",
       "             3.3476e-02,  3.5692e-01,  3.5692e-01,  3.3476e-02,  3.3476e-02,\n",
       "             3.3476e-02,  3.5692e-01,  3.5692e-01,  3.3476e-02,  3.3476e-02,\n",
       "             3.3476e-02,  3.3476e-02,  3.3476e-02,  3.5692e-01,  3.5692e-01,\n",
       "             3.5692e-01,  3.3476e-02,  3.3476e-02,  3.3476e-02,  2.4208e-01,\n",
       "             5.4548e-02,  5.4548e-02,  2.4208e-01,  5.4548e-02,  1.7887e-01,\n",
       "             1.2514e-01,  5.4548e-02, -1.1718e-01, -4.0691e-01, -3.5529e-01,\n",
       "            -5.0595e-01, -4.0059e-01, -3.6477e-01, -5.2175e-01, -3.1841e-01,\n",
       "            -3.0893e-01, -5.2175e-01, -2.9524e-01, -5.1543e-01, -4.8698e-01,\n",
       "            -4.7118e-01, -4.0797e-01,  1.5042e-01, -3.0577e-01, -1.8356e-01,\n",
       "            -1.8356e-01, -1.8356e-01,  1.5042e-01,  1.5042e-01,  1.5042e-01,\n",
       "            -1.8356e-01, -1.8356e-01,  1.5042e-01,  1.5042e-01,  1.5042e-01,\n",
       "            -1.8356e-01,  1.5042e-01, -1.8356e-01,  1.5042e-01, -1.8356e-01,\n",
       "             1.5042e-01,  1.5042e-01, -1.8356e-01,  1.5042e-01, -1.8356e-01,\n",
       "             1.5042e-01,  1.5042e-01, -1.8356e-01, -1.8356e-01,  2.7685e-01,\n",
       "             2.7685e-01,  2.6631e-01,  4.3172e-01,  1.8414e-01,  2.5048e-02,\n",
       "             1.0090e-01, -1.2915e-03, -2.1309e-02, -1.1613e-01, -2.3518e-01,\n",
       "            -2.6679e-01, -3.0050e-01, -2.2149e-01, -3.0682e-01, -4.1218e-01,\n",
       "            -3.2895e-01, -4.3431e-01, -3.5213e-01, -3.8163e-01, -5.0279e-01,\n",
       "            -5.1543e-01, -3.8163e-01, -5.2070e-01, -3.8268e-01, -3.8374e-01,\n",
       "            -3.5740e-01, -5.2807e-01, -3.5529e-01, -5.2491e-01, -5.3018e-01,\n",
       "            -3.0999e-01, -4.8698e-01, -4.8698e-01, -4.9225e-01, -1.2877e-01,\n",
       "            -6.0291e-02, -4.3957e-01, -7.2934e-02, -3.6688e-01, -7.2934e-02,\n",
       "            -2.8786e-01, -2.8786e-01, -2.8786e-01, -7.2934e-02, -7.2934e-02,\n",
       "            -2.8786e-01, -7.2934e-02,  2.7738e+00,  3.5587e-01,  1.7487e+00,\n",
       "             1.4726e+00,  2.9160e-01,  1.0691e+00,  2.3787e-01,  1.5358e-01,\n",
       "             1.3356e-01,  1.7149e-01, -5.1863e-02, -1.8777e-01, -1.9620e-01,\n",
       "            -2.2149e-01, -3.1315e-01, -2.3729e-01, -2.6258e-01, -3.7847e-01,\n",
       "            -2.8154e-01, -3.9849e-01, -4.0165e-01, -4.1745e-01, -3.0472e-01,\n",
       "            -4.2377e-01, -4.2904e-01, -4.3325e-01, -3.0156e-01, -4.4590e-01,\n",
       "            -2.8470e-01, -4.4800e-01, -2.8891e-01, -4.4379e-01, -4.2377e-01,\n",
       "            -4.0586e-01, -3.5529e-01,  3.6637e-02, -2.9313e-01,  3.6637e-02,\n",
       "             3.6637e-02, -2.9313e-01,  3.6637e-02, -2.9313e-01,  3.6637e-02,\n",
       "            -2.9313e-01, -2.9313e-01,  3.6637e-02,  3.6637e-02, -2.9313e-01,\n",
       "             3.6637e-02, -2.9313e-01, -2.9313e-01, -2.9313e-01,  3.6637e-02],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([ 7.6044e-01,  1.8203e+00,  1.8203e+00,  1.8203e+00,  7.6044e-01,\n",
       "             7.6044e-01,  1.8203e+00,  7.6044e-01,  7.6044e-01,  1.8203e+00,\n",
       "             1.8203e+00,  7.6044e-01,  1.8203e+00,  1.8203e+00,  1.8203e+00,\n",
       "             7.6044e-01,  1.8203e+00,  7.6044e-01,  7.6044e-01,  7.6044e-01,\n",
       "             1.5232e+00,  1.2409e+00,  7.6044e-01,  9.8063e-01,  6.2874e-01,\n",
       "             7.4885e-01,  4.0012e-01,  3.1899e-01,  2.7474e-01,  3.0214e-01,\n",
       "             2.6315e-01,  2.7264e-01,  4.9915e-01,  4.2962e-01,  9.6693e-01,\n",
       "             7.6044e-01,  9.6693e-01,  6.4454e-01,  9.0688e-01,  9.0688e-01,\n",
       "             6.4454e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,  9.0688e-01,\n",
       "             6.4454e-01,  9.0688e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,\n",
       "             6.4454e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,  6.4454e-01,\n",
       "             9.0688e-01,  9.0688e-01,  6.4454e-01,  7.6149e-01,  6.0135e-01,\n",
       "             2.8844e-01,  1.4410e-01,  1.6619e-02, -2.7631e-02, -4.7648e-02,\n",
       "            -1.3299e-01, -1.2034e-01, -2.2359e-01, -2.1833e-01, -2.6995e-01,\n",
       "            -2.8575e-01, -2.5520e-01, -2.5309e-01, -2.8681e-01, -2.0568e-01,\n",
       "            -1.3615e-01, -7.8202e-02,  2.1574e-01,  6.8563e-01,  2.1574e-01,\n",
       "             2.1574e-01,  1.4484e+00,  1.2809e+00,  2.1574e-01,  1.1165e+00,\n",
       "             6.8563e-01,  2.1574e-01,  5.5920e-01,  4.3067e-01,  2.9371e-01,\n",
       "             3.1478e-01,  2.0310e-01,  1.2830e-01,  9.4583e-02,  5.9815e-02,\n",
       "            -4.1327e-02, -1.3615e-01, -2.0568e-01, -2.0779e-01, -3.3632e-01,\n",
       "            -3.6266e-01, -3.5950e-01, -3.7636e-01, -3.9322e-01, -3.7847e-01,\n",
       "            -3.7004e-01, -3.7847e-01, -3.7320e-01, -3.6056e-01, -3.9111e-01,\n",
       "            -3.3211e-01, -3.6266e-01, -2.9734e-01, -3.2895e-01,  2.3576e-01,\n",
       "             5.8028e-01,  2.3576e-01,  1.6813e+00,  1.3715e+00,  9.6272e-01,\n",
       "             6.9722e-01,  4.2646e-01,  2.3576e-01,  3.8115e-01,  2.3576e-01,\n",
       "             1.8624e-01,  2.0626e-01,  1.2724e-01,  8.8262e-02,  5.2440e-02,\n",
       "             7.1371e-03, -9.7199e-03, -3.7113e-02, -7.2934e-02, -8.9791e-02,\n",
       "            -1.2034e-01, -1.5195e-01, -2.0884e-01, -2.4572e-01, -2.9208e-01,\n",
       "            -3.0577e-01, -3.2052e-01, -3.2684e-01, -3.4897e-01, -3.5213e-01,\n",
       "            -3.7531e-01, -3.6266e-01, -3.6056e-01, -3.5213e-01, -3.7004e-01,\n",
       "            -3.4897e-01, -3.3843e-01, -3.1947e-01,  4.0749e-01,  3.9590e-01,\n",
       "             4.0749e-01,  3.9590e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,  3.9590e-01,\n",
       "             4.0749e-01,  3.9590e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,\n",
       "             3.9590e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,  4.0749e-01,\n",
       "             4.0749e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,\n",
       "             4.0749e-01,  3.9590e-01,  6.0556e-01,  4.1803e-01,  3.9590e-01,\n",
       "             4.0855e-01,  3.9590e-01,  2.5578e-01,  2.1469e-01,  1.8098e-01,\n",
       "             1.3356e-01,  2.9228e-03, -5.9237e-02, -9.7166e-02, -1.2350e-01,\n",
       "            -2.2465e-01, -2.6363e-01, -3.0050e-01, -3.0261e-01, -3.1736e-01,\n",
       "            -3.5950e-01, -3.8900e-01, -3.8584e-01, -4.0691e-01, -4.1429e-01,\n",
       "            -4.3431e-01, -4.4590e-01, -4.5748e-01, -4.7118e-01, -4.6275e-01,\n",
       "            -4.5854e-01, -4.7118e-01, -4.5854e-01, -4.5116e-01, -4.7856e-01,\n",
       "             2.4524e-01,  2.7474e-01,  2.4524e-01,  2.7474e-01,  2.7474e-01,\n",
       "             2.4524e-01,  2.7474e-01,  2.4524e-01,  2.4524e-01,  2.7474e-01,\n",
       "             2.4524e-01,  2.7474e-01,  2.4524e-01,  2.7474e-01,  2.4524e-01,\n",
       "             2.7474e-01,  2.4524e-01,  2.7474e-01,  2.4524e-01,  4.1908e-01,\n",
       "             2.7474e-01,  4.1065e-01,  2.7474e-01,  2.4524e-01,  2.1364e-01,\n",
       "             2.4946e-01,  1.3673e-01,  7.9833e-02,  1.0933e-01,  5.6655e-02,\n",
       "            -2.0256e-02, -1.1508e-01, -1.5617e-01, -1.5511e-01, -2.0147e-01,\n",
       "            -2.0252e-01, -2.3729e-01, -2.4993e-01, -2.7522e-01, -2.8470e-01,\n",
       "            -3.1315e-01, -3.1631e-01, -3.4370e-01, -3.6266e-01, -3.7004e-01,\n",
       "            -4.1745e-01, -4.2904e-01, -4.5222e-01, -4.5222e-01, -4.6381e-01,\n",
       "            -4.8488e-01, -4.9436e-01, -4.9225e-01, -5.0806e-01, -5.2386e-01,\n",
       "            -5.0595e-01, -5.1016e-01, -5.3123e-01,  3.2531e-01,  5.3076e-01,\n",
       "             3.2531e-01,  3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "             3.2531e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "             5.3076e-01,  3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "             5.3076e-01,  5.3076e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,\n",
       "             3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,\n",
       "             3.2531e-01,  4.8546e-01,  4.2856e-01,  2.2733e-01,  3.3585e-01,\n",
       "             1.5990e-01,  1.2303e-01,  7.9833e-02,  2.0837e-01,  1.6833e-01,\n",
       "             1.3251e-01,  9.7744e-02,  6.4030e-02, -7.8202e-02,  4.0851e-02,\n",
       "            -1.1718e-01,  9.2443e-03, -1.4247e-01, -7.6127e-03, -1.6143e-01,\n",
       "            -3.3952e-02, -5.9237e-02, -2.2991e-01, -2.6258e-01, -3.0577e-01,\n",
       "            -3.1736e-01, -1.1824e-01, -1.3193e-01, -3.5950e-01, -1.3615e-01,\n",
       "            -1.3299e-01, -3.8374e-01, -1.2667e-01, -1.2561e-01, -3.9638e-01,\n",
       "            -1.1192e-01, -1.0454e-01, -4.0691e-01, -9.1898e-02, -5.2916e-02,\n",
       "             3.8431e-01, -5.2916e-02,  1.8287e+00, -5.2916e-02, -5.2916e-02,\n",
       "             1.5738e+00, -5.2916e-02,  1.3736e+00, -5.2916e-02,  1.2714e+00,\n",
       "            -5.2916e-02, -5.2916e-02, -5.2916e-02,  1.0301e+00, -5.2916e-02,\n",
       "            -5.2916e-02,  8.0363e-01,  7.3515e-01, -5.2916e-02,  6.6561e-01,\n",
       "            -5.2916e-02,  6.0662e-01, -5.2916e-02,  5.4656e-01,  4.9072e-01,\n",
       "             9.5636e-02,  2.8844e-01, -6.0291e-02,  2.4314e-01,  2.0099e-01,\n",
       "            -8.6630e-02, -1.2983e-01, -2.0041e-01, -1.7513e-01,  5.2440e-02,\n",
       "            -2.4361e-01, -8.6664e-03, -2.9418e-01, -2.9629e-01, -3.3316e-01,\n",
       "            -1.1192e-01, -1.3088e-01, -3.7215e-01, -1.6881e-01, -1.8567e-01,\n",
       "            -2.0252e-01, -2.1200e-01, -2.2465e-01, -4.7434e-01, -4.7750e-01,\n",
       "            -2.4993e-01, -4.9752e-01, -4.9963e-01, -2.5836e-01, -5.1016e-01,\n",
       "            -2.6574e-01, -5.1332e-01, -2.6468e-01, -5.2070e-01, -5.2597e-01,\n",
       "            -5.2386e-01, -2.5099e-01, -5.2597e-01, -2.0568e-01,  4.2119e-01,\n",
       "            -2.0568e-01,  4.2119e-01, -2.0568e-01,  4.2119e-01,  4.2119e-01,\n",
       "             4.2119e-01, -2.0568e-01,  4.2119e-01, -2.0568e-01, -2.0568e-01,\n",
       "            -2.0568e-01, -2.0568e-01, -2.0568e-01,  4.2119e-01, -2.0568e-01,\n",
       "             4.2119e-01,  4.2119e-01, -2.0568e-01,  3.7483e-01, -2.0568e-01,\n",
       "             2.2101e-01, -2.0568e-01,  1.7992e-01, -2.0568e-01,  1.3778e-01,\n",
       "            -2.5625e-01,  5.9815e-02, -3.1631e-01, -8.6664e-03, -3.0577e-01,\n",
       "            -3.7109e-01, -6.2398e-02, -3.5424e-01, -8.9791e-02, -3.9638e-01,\n",
       "            -1.1508e-01, -1.6038e-01, -4.4484e-01, -1.8250e-01, -4.4379e-01,\n",
       "            -2.1306e-01, -4.8277e-01, -2.4256e-01, -2.7416e-01, -5.1332e-01,\n",
       "            -2.8470e-01, -2.9524e-01, -5.3018e-01, -2.9734e-01, -5.3229e-01,\n",
       "            -3.0156e-01, -5.4072e-01, -5.4177e-01, -3.1209e-01, -5.4598e-01,\n",
       "            -3.1315e-01, -5.5020e-01, -5.5125e-01, -3.0472e-01,  4.0749e-01,\n",
       "             4.0749e-01,  4.0749e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "             4.0749e-01,  4.0749e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "            -5.4072e-01,  4.0749e-01,  4.0749e-01, -5.4072e-01, -5.4072e-01,\n",
       "             4.0749e-01, -5.4072e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "             2.8633e-01, -5.4072e-01,  2.6315e-01,  2.3260e-01, -5.4072e-01,\n",
       "             1.9151e-01,  1.5253e-01, -5.9761e-01, -5.4072e-01, -5.7654e-01,\n",
       "             4.4012e-02, -5.9129e-01, -2.3778e-04, -5.7022e-01, -5.7022e-01,\n",
       "            -5.7759e-01, -7.2934e-02, -5.7864e-01, -5.5125e-01, -1.2034e-01,\n",
       "            -1.2983e-01, -5.7443e-01, -1.4458e-01, -5.7759e-01, -1.8356e-01,\n",
       "            -1.8040e-01, -5.9234e-01, -1.9831e-01, -5.7970e-01, -1.9515e-01,\n",
       "            -5.7759e-01, -1.9936e-01, -5.7654e-01, -5.7864e-01, -2.0358e-01,\n",
       "            -5.8602e-01, -2.0358e-01, -2.0568e-01, -5.7759e-01, -2.1095e-01,\n",
       "            -5.8075e-01, -1.9515e-01, -2.0252e-01, -5.7759e-01,  5.6447e-01,\n",
       "            -9.7689e-01,  5.2128e-01,  4.6860e-01,  4.7703e-01,  4.4753e-01,\n",
       "            -9.7689e-01,  4.1803e-01, -9.7689e-01, -9.7689e-01,  3.5271e-01,\n",
       "             2.9265e-01, -9.7689e-01,  2.6947e-01, -9.7689e-01,  2.2628e-01,\n",
       "            -9.7689e-01,  1.9467e-01, -9.7689e-01,  1.7571e-01, -9.7689e-01,\n",
       "             1.5569e-01,  1.3989e-01, -9.7689e-01, -9.7689e-01,  7.7726e-02,\n",
       "            -9.7689e-01,  6.1922e-02,  4.7173e-02, -9.7689e-01,  4.0851e-02,\n",
       "            -9.7689e-01,  2.5048e-02, -2.3449e-03, -9.7689e-01, -1.2881e-02,\n",
       "            -9.7689e-01, -4.4488e-02, -9.7689e-01, -4.8702e-02, -5.8184e-02,\n",
       "            -9.7689e-01, -6.5559e-02, -9.7689e-01, -9.7689e-01, -8.3469e-02,\n",
       "            -9.7689e-01, -8.0309e-02, -8.4523e-02, -9.7689e-01, -8.9791e-02,\n",
       "            -9.7166e-02, -1.0033e-01, -1.1192e-01, -9.7689e-01, -1.0243e-01,\n",
       "            -9.7689e-01, -9.7689e-01, -1.0454e-01, -9.7689e-01, -1.0033e-01,\n",
       "            -9.7689e-01, -9.9273e-02, -9.7689e-01, -9.7689e-01, -9.5059e-02,\n",
       "            -9.7689e-01, -8.8737e-02, -9.7689e-01],\n",
       "           grad_fn=<SplitWithSizesBackward0>)]},\n",
       "  'Query Point': {'Log Moneyness': tensor([-1.9007,  0.6870,  0.8618, -1.4475], grad_fn=<SliceBackward0>),\n",
       "   'Time to Maturity': tensor([-0.7412,  1.0536, -0.8894,  0.9511], grad_fn=<SliceBackward0>)},\n",
       "  'Target Volatility': tensor([0.3204, 0.2626, 0.5944, 0.3362])})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class InputEmbedding(nn.Module):\n",
    "    def __init__(self, grid_dim, d_embedding, momentum=0.1):\n",
    "        super(InputEmbedding, self).__init__()\n",
    "        # Initialize all sub-modules\n",
    "        self.surface_batchnorm = SurfaceBatchNorm(1, momentum)\n",
    "        self.surface_continuous_kernel_embedding = SurfaceContinuousKernelEmbedding(grid_dim)\n",
    "        self.surface_projection_embedding = SurfaceProjectionEmbedding(1, d_embedding, grid_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Process the batch with SurfaceBatchNorm\n",
    "        processed_batch = self.surface_batchnorm(batch)\n",
    "        \n",
    "        # Generate continuous kernel embeddings from the processed 'Input Surface'\n",
    "        continuous_kernel_embedding_batch = self.surface_continuous_kernel_embedding(processed_batch['Input Surface'])\n",
    "        \n",
    "        # Project the embeddings using 1x1 convolution\n",
    "        projection_embedding_batch = self.surface_projection_embedding(continuous_kernel_embedding_batch)\n",
    "\n",
    "        # Return both the positionally encoded embeddings and the processed batch\n",
    "        return projection_embedding_batch, processed_batch\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "grid_dim = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Grid Dimension']\n",
    "d_embedding = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Channels Dimension']  # Desired number of output channels\n",
    "input_embedding = InputEmbedding(grid_dim, d_embedding)\n",
    "projection_embedding_batch, processed_batch = input_embedding(batch)\n",
    "projection_embedding_batch, processed_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-6.0837e-01,  1.8441e-01,  1.8344e+00],\n",
       "          [ 9.6723e-01, -5.8042e-01, -4.7301e-02],\n",
       "          [-7.0156e-01, -6.5279e-01, -7.5022e-01]],\n",
       "\n",
       "         [[ 6.6131e-01,  2.8394e+00,  1.9287e+00],\n",
       "          [-7.4843e-01, -7.4947e-01, -6.5527e-01],\n",
       "          [ 3.4987e-01,  2.6305e-01, -3.6582e-01]],\n",
       "\n",
       "         [[-7.3371e-01, -7.4444e-01, -5.6426e-01],\n",
       "          [ 1.8031e+00,  6.6916e-01, -7.3786e-01],\n",
       "          [ 1.8068e+00, -7.1917e-01, -7.4583e-01]],\n",
       "\n",
       "         [[-7.2106e-01, -4.9608e-01, -6.5116e-01],\n",
       "          [ 2.5162e+00,  2.6079e+00, -5.0983e-01],\n",
       "          [-7.5009e-01, -7.4023e-01, -6.4303e-01]],\n",
       "\n",
       "         [[-6.3948e-01, -5.6314e-01, -5.5121e-01],\n",
       "          [-5.7120e-01, -7.5185e-01, -6.3542e-01],\n",
       "          [ 2.4126e+00,  9.0394e-02, -7.0332e-01]],\n",
       "\n",
       "         [[-7.5103e-01, -6.4380e-01, -6.7763e-01],\n",
       "          [-7.5164e-01, -6.3369e-01, -5.7734e-01],\n",
       "          [ 4.5396e-01,  1.3636e-02, -7.1074e-01]],\n",
       "\n",
       "         [[-6.9868e-01, -6.6248e-01, -6.6785e-01],\n",
       "          [ 6.6948e-01,  1.2328e+00, -2.8029e-01],\n",
       "          [-7.5113e-01,  9.5412e-01, -4.9054e-01]],\n",
       "\n",
       "         [[ 5.3490e-01,  1.1825e+00,  1.7192e+00],\n",
       "          [-6.3950e-01,  1.5526e-01,  1.4909e+00],\n",
       "          [-5.5162e-01, -6.4467e-01, -1.7664e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 4.2653e-01, -1.8110e-01, -7.9540e-01],\n",
       "          [ 9.9995e-01, -5.3242e-01,  6.5007e-01],\n",
       "          [-5.7834e-01, -5.4179e-02,  1.0313e+00]],\n",
       "\n",
       "         [[-3.4735e-01, -2.8339e-02,  6.1283e-01],\n",
       "          [ 7.6731e-01,  2.2838e+00, -3.7754e-01],\n",
       "          [ 6.5545e-01,  4.8093e-01, -4.0699e-01]],\n",
       "\n",
       "         [[-6.9810e-01, -7.9286e-01, -7.0439e-01],\n",
       "          [-3.2212e-01,  3.3634e-01,  7.4871e-01],\n",
       "          [-7.8153e-01, -1.9144e-01,  4.7659e+00]],\n",
       "\n",
       "         [[-6.9612e-01, -7.9734e-01, -7.3277e-01],\n",
       "          [-7.6032e-01, -3.0184e-01,  2.3306e+00],\n",
       "          [-7.9305e-01,  1.4784e+00,  2.6179e-03]],\n",
       "\n",
       "         [[-7.1077e-01, -6.8501e-01, -7.1708e-01],\n",
       "          [-6.2108e-01, -7.9450e-01, -7.3173e-01],\n",
       "          [-6.7191e-01, -7.1166e-01,  2.0649e+00]],\n",
       "\n",
       "         [[-7.9615e-01, -7.9141e-01, -7.4398e-01],\n",
       "          [-7.9471e-01, -7.5821e-01, -7.6622e-01],\n",
       "          [-7.6705e-01, -7.8101e-01,  1.3595e+00]],\n",
       "\n",
       "         [[-7.9734e-01, -7.3979e-01, -6.1736e-01],\n",
       "          [-7.8829e-01,  5.7955e-02,  1.4132e+00],\n",
       "          [-7.9471e-01,  9.6249e-01,  3.9380e-02]],\n",
       "\n",
       "         [[ 8.9967e-01,  9.9808e-01, -2.1743e-01],\n",
       "          [ 4.7012e-01,  1.0971e+00,  1.1434e-01],\n",
       "          [-8.9401e-02,  3.3032e-01, -6.1739e-01]]],\n",
       "\n",
       "\n",
       "        [[[-3.0592e-01, -3.4943e-02, -6.9767e-01],\n",
       "          [ 1.3791e+00, -6.6317e-01, -6.7653e-01],\n",
       "          [ 8.4471e-01,  5.2716e-01, -6.8583e-01]],\n",
       "\n",
       "         [[ 6.8942e-01, -3.7799e-01, -2.8045e-01],\n",
       "          [-4.1860e-01,  1.7183e+00,  1.1778e+00],\n",
       "          [ 4.0372e-01,  7.7327e-01,  9.9763e-02]],\n",
       "\n",
       "         [[-5.9896e-01,  2.5536e-01,  2.3267e+00],\n",
       "          [-5.4409e-01, -7.3409e-01, -7.1992e-01],\n",
       "          [-4.7299e-01, -7.3468e-01, -6.9258e-01]],\n",
       "\n",
       "         [[ 9.6449e-03,  1.7350e+00,  1.3207e+00],\n",
       "          [-7.0200e-01,  5.9639e-01, -1.2859e-01],\n",
       "          [-4.7373e-01, -1.0876e-01,  6.0568e-01]],\n",
       "\n",
       "         [[-7.1668e-01, -7.3466e-01,  2.5517e-01],\n",
       "          [-5.6453e-01, -7.3287e-01, -3.8926e-01],\n",
       "          [-4.7320e-01, -5.5184e-01, -6.5967e-01]],\n",
       "\n",
       "         [[-7.0775e-01, -7.2932e-01, -6.9035e-01],\n",
       "          [ 3.9988e-01, -7.2956e-01, -7.3105e-01],\n",
       "          [-7.2566e-01, -1.7637e-01, -6.9972e-01]],\n",
       "\n",
       "         [[-7.3380e-01, -6.1277e-01, -6.3604e-01],\n",
       "          [-5.9815e-01, -5.9761e-01, -1.2740e-01],\n",
       "          [-1.8456e-01, -4.9184e-01, -7.2954e-01]],\n",
       "\n",
       "         [[-1.1560e-01,  9.5437e-02, -5.5518e-01],\n",
       "          [ 2.9874e+00,  1.6474e+00, -5.5790e-01],\n",
       "          [ 2.9138e+00,  3.9404e+00, -6.9805e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.9642e+00, -7.3715e-01, -7.7071e-01],\n",
       "          [ 1.7145e+00, -4.7808e-02, -4.5658e-01],\n",
       "          [-7.9693e-01,  1.7406e-01, -7.7680e-01]],\n",
       "\n",
       "         [[-1.4553e-01,  1.3613e+00,  8.7342e-01],\n",
       "          [ 3.1880e+00,  6.0292e-01, -7.9488e-01],\n",
       "          [-1.5509e-01, -7.1241e-01,  1.0993e+00]],\n",
       "\n",
       "         [[-5.9549e-01, -7.9818e-01, -7.5675e-01],\n",
       "          [ 1.1103e+00,  1.4185e+00,  8.0730e-01],\n",
       "          [-5.6424e-01,  1.4052e-01,  1.5753e+00]],\n",
       "\n",
       "         [[-5.9331e-01, -7.6561e-01,  6.7870e-01],\n",
       "          [-1.8067e-01,  1.2664e+00,  2.0045e+00],\n",
       "          [-4.1157e-01,  9.6672e-01, -7.9836e-01]],\n",
       "\n",
       "         [[-5.9359e-01, -6.6124e-01, -7.8668e-01],\n",
       "          [-5.9164e-01, -7.9011e-01, -7.2260e-01],\n",
       "          [-7.8995e-01, -7.1941e-01,  1.5127e+00]],\n",
       "\n",
       "         [[-6.3795e-01, -7.8702e-01, -6.9508e-01],\n",
       "          [-7.4204e-01, -4.9126e-01, -7.3400e-01],\n",
       "          [-7.8340e-01,  1.9963e-02,  3.8917e-03]],\n",
       "\n",
       "         [[-2.4362e-01, -7.0869e-01, -7.1132e-01],\n",
       "          [-6.2764e-01, -7.9647e-01, -1.9553e-01],\n",
       "          [-7.9361e-01, -6.8163e-01, -7.0595e-01]],\n",
       "\n",
       "         [[ 2.5898e+00,  2.2161e+00, -7.8337e-01],\n",
       "          [ 4.7208e-01,  1.7084e+00, -7.6254e-01],\n",
       "          [-3.6769e-01, -1.1067e-01, -5.9598e-01]]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PreEncoder(nn.Module):\n",
    "    def __init__(self, d_embedding, branch_channels, grid_dim):\n",
    "        super(PreEncoder, self).__init__()\n",
    "        # Initial channel configuration is common to all branches\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Conv2d(d_embedding, branch_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(d_embedding, branch_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(branch_channels, branch_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(d_embedding, branch_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(branch_channels, branch_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(branch_channels, branch_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            nn.Conv2d(d_embedding, branch_channels, kernel_size=1),\n",
    "            nn.BatchNorm2d(branch_channels),\n",
    "            nn.GELU()\n",
    "        )\n",
    "        \n",
    "        # Reduce the concatenated channels back to the original number of channels\n",
    "        self.conv_reduce = nn.Conv2d(branch_channels * 4, d_embedding, kernel_size=1)\n",
    "        self.bn_reduce = nn.BatchNorm2d(d_embedding)\n",
    "        self.scale = nn.Parameter(torch.tensor(1.0))  # Learnable scale for residual connection\n",
    "        self.layer_norm = nn.LayerNorm([d_embedding, grid_dim, grid_dim])  # Normalize across (C, H, W)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply each branch to the input\n",
    "        out1 = self.branch1(x)\n",
    "        out2 = self.branch2(x)\n",
    "        out3 = self.branch3(x)\n",
    "        out4 = self.branch4(x)\n",
    "        \n",
    "        # Concatenate the outputs from each branch\n",
    "        concatenated = torch.cat([out1, out2, out3, out4], dim=1)\n",
    "        \n",
    "        # Reduce back to the initial number of channels\n",
    "        reduced = self.conv_reduce(concatenated)\n",
    "        reduced = self.bn_reduce(reduced)\n",
    "        \n",
    "        # Add the residual connection with scale\n",
    "        residual = x + self.scale * reduced\n",
    "        residual = F.gelu(residual)  # Apply GELU after adding the residual\n",
    "        \n",
    "        # Normalize the output\n",
    "        output = self.layer_norm(residual)\n",
    "        \n",
    "        return output\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "branch_channels = HYPERPARAMETERS['Input Embedding']['Pre-Encoder']['Branch Channels Dimension']\n",
    "pre_encoder = PreEncoder(d_embedding, branch_channels, grid_dim)\n",
    "pre_encoded_batch = pre_encoder(projection_embedding_batch)\n",
    "pre_encoded_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.5546, -0.8281,  0.6840],\n",
       "          [ 0.4616, -0.9567, -0.4681],\n",
       "          [-0.4954, -0.4507, -0.5400]],\n",
       "\n",
       "         [[ 0.8970,  2.8930,  2.0585],\n",
       "          [-0.1942, -0.1952, -0.1088],\n",
       "          [ 0.6116,  0.5320, -0.0443]],\n",
       "\n",
       "         [[-1.6694, -1.1070, -0.3696],\n",
       "          [ 0.6553,  0.1885, -0.5286],\n",
       "          [ 0.6587, -1.0838, -0.5359]],\n",
       "\n",
       "         [[-0.3698,  0.0370, -0.3058],\n",
       "          [ 2.5969,  2.8815, -0.1762],\n",
       "          [-0.3964, -0.1867, -0.2983]],\n",
       "\n",
       "         [[-1.0170, -0.9470, -0.9361],\n",
       "          [-0.9482, -1.1138, -1.0071],\n",
       "          [ 1.7924, -0.3357, -1.0631]],\n",
       "\n",
       "         [[-0.1966, -0.0983, -0.1294],\n",
       "          [-0.1972, -0.0891, -0.0374],\n",
       "          [ 0.9077,  0.5041, -0.1597]],\n",
       "\n",
       "         [[-1.0712, -1.0319, -1.0306],\n",
       "          [ 0.1826,  0.7050, -0.6754],\n",
       "          [-1.1193,  0.4496, -0.8681]],\n",
       "\n",
       "         [[ 0.9818,  1.5753,  2.0672],\n",
       "          [-0.0944,  0.6339,  1.8580],\n",
       "          [-0.0139, -0.0991,  0.3298]]],\n",
       "\n",
       "\n",
       "        [[[-0.5479, -1.0512, -1.5600],\n",
       "          [ 0.4443, -0.8249,  0.1545],\n",
       "          [-0.3457,  0.0885,  0.9875]],\n",
       "\n",
       "         [[-0.0247,  0.2395,  0.7706],\n",
       "          [ 1.0799,  2.3360,  0.1317],\n",
       "          [ 0.8059,  0.6613, -0.0741]],\n",
       "\n",
       "         [[-1.4794, -1.0406, -0.4501],\n",
       "          [-1.1680, -0.1053,  0.7535],\n",
       "          [-1.5485, -0.5425,  4.0808]],\n",
       "\n",
       "         [[-0.3136, -0.2160, -0.3439],\n",
       "          [-0.3668,  0.1944,  2.1934],\n",
       "          [-0.3939,  1.6689,  0.2652]],\n",
       "\n",
       "         [[-0.9782, -0.9569, -0.9834],\n",
       "          [-0.8983, -1.0420, -0.9900],\n",
       "          [-0.9348, -0.9678,  1.3320]],\n",
       "\n",
       "         [[-0.2151, -0.2112, -0.1719],\n",
       "          [-0.2139, -0.1836, -0.1903],\n",
       "          [-0.1910, -0.2025,  1.5704]],\n",
       "\n",
       "         [[-1.0499, -0.9967, -0.8897],\n",
       "          [-1.0424, -0.3359,  0.7922],\n",
       "          [-1.0477,  0.4133, -0.3457]],\n",
       "\n",
       "         [[ 1.1895,  1.2711,  0.2643],\n",
       "          [ 0.8337,  1.3531,  0.5391],\n",
       "          [ 0.3703,  0.7180, -0.0670]]],\n",
       "\n",
       "\n",
       "        [[[-1.0797, -0.8698, -1.3831],\n",
       "          [ 0.7092, -0.8727, -0.8830],\n",
       "          [ 0.7790,  0.5330, -0.4065]],\n",
       "\n",
       "         [[ 0.7800, -0.0468,  0.0287],\n",
       "          [ 0.0913,  1.7466,  1.3279],\n",
       "          [ 0.5587,  0.8449,  0.3232]],\n",
       "\n",
       "         [[-1.3067, -0.1612,  1.9269],\n",
       "          [-1.2642, -0.9276, -0.4329],\n",
       "          [-1.2091, -0.9281, -0.4118]],\n",
       "\n",
       "         [[ 0.2534,  1.7594,  1.2690],\n",
       "          [-0.2978,  0.8775,  0.1463],\n",
       "          [-0.1210,  0.3313,  0.7151]],\n",
       "\n",
       "         [[-0.9194, -0.9333, -0.1666],\n",
       "          [-0.7963, -0.9267, -0.6605],\n",
       "          [-0.7203, -0.7812, -0.8648]],\n",
       "\n",
       "         [[-0.1327, -0.1494, -0.1192],\n",
       "          [ 0.7253, -0.1495, -0.1507],\n",
       "          [-0.1465,  0.2789, -0.1264]],\n",
       "\n",
       "         [[-0.9326, -0.8337, -0.8465],\n",
       "          [-0.8276, -0.8219, -0.4525],\n",
       "          [-0.5072, -0.7400, -0.9189]],\n",
       "\n",
       "         [[ 0.3260,  0.4895, -0.0145],\n",
       "          [ 2.7296,  1.6916, -0.0166],\n",
       "          [ 2.6725,  3.4678, -0.1251]]],\n",
       "\n",
       "\n",
       "        [[[ 0.7255, -1.5112, -1.5390],\n",
       "          [ 1.0359, -0.4234, -0.7618],\n",
       "          [-0.5266,  0.2774, -0.5099]],\n",
       "\n",
       "         [[ 0.1424,  1.3901,  0.9861],\n",
       "          [ 3.0839,  0.9434, -0.2139],\n",
       "          [ 0.1345, -0.3270,  1.1731]],\n",
       "\n",
       "         [[-1.3939, -1.0447, -0.4933],\n",
       "          [ 0.0185,  0.7907,  0.8018],\n",
       "          [-1.3681, -0.2674,  1.4377]],\n",
       "\n",
       "         [[-0.2284, -0.1897,  0.8249],\n",
       "          [ 0.1133,  1.4928,  1.9226],\n",
       "          [-0.0779,  1.2447, -0.3981]],\n",
       "\n",
       "         [[-0.8809, -0.9369, -1.0407],\n",
       "          [-0.8737, -1.0380, -0.9821],\n",
       "          [-1.0323, -0.9739,  0.8743]],\n",
       "\n",
       "         [[-0.0840, -0.2075, -0.1313],\n",
       "          [-0.1702,  0.0375, -0.1635],\n",
       "          [-0.2045,  0.4607,  0.4474]],\n",
       "\n",
       "         [[-0.5911, -0.9706, -0.9672],\n",
       "          [-0.9091, -1.0433, -0.5401],\n",
       "          [-1.0465, -0.9482, -0.9627]],\n",
       "\n",
       "         [[ 2.5886,  2.2791, -0.2044],\n",
       "          [ 0.8351,  1.8588, -0.1872],\n",
       "          [ 0.1398,  0.3526, -0.0493]]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class SurfacePositionalEmbedding(nn.Module):\n",
    "    def __init__(self, grid_dim, d_embedding):\n",
    "        super(SurfacePositionalEmbedding, self).__init__()\n",
    "        self.grid_dim = grid_dim\n",
    "        self.d_embedding = d_embedding\n",
    "        \n",
    "        # Create a regular grid in (0, 1)x(0, 1), excluding 0 and 1\n",
    "        grid_points = torch.linspace(1 / (grid_dim + 1), 1 - 1 / (grid_dim + 1), grid_dim)\n",
    "        mesh_x, mesh_y = torch.meshgrid(grid_points, grid_points, indexing='ij')\n",
    "        self.grid_points = torch.stack([mesh_x.flatten(), mesh_y.flatten()], dim=-1)\n",
    "        self.grid_points = torch.erfinv(2 * self.grid_points - 1) * np.sqrt(2)  # inverse CDF of normal\n",
    "\n",
    "        # Initialize learnable scaling parameter (the base for positional embedding)\n",
    "        self.log_scale = nn.Parameter(torch.log(torch.tensor(10000.0)))\n",
    "        self.factor = nn.Parameter(torch.tensor(1.0))  # Learnable scale for the positional embedding contribution\n",
    "\n",
    "        # Layer normalization for final output\n",
    "        self.layer_norm = nn.LayerNorm([d_embedding, grid_dim, grid_dim])  # Normalizes across (channels, height, width)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is the output from the 1x1 convolution layer with shape (batch_size, d_embedding, grid_dim, grid_dim)\n",
    "        scale = torch.exp(self.log_scale)\n",
    "        pos_enc = torch.zeros_like(x)\n",
    "\n",
    "        # Repeat grid_points to match the batch size and reshape for broadcasting\n",
    "        batch_grid_points = self.grid_points.repeat(x.shape[0], 1, 1).view(x.shape[0], self.grid_dim*self.grid_dim, 2)\n",
    "        \n",
    "        for i in range(self.d_embedding // 4):\n",
    "            # Calculate positional embeddings for both dimensions\n",
    "            div_factor = scale ** (4 * i / self.d_embedding)\n",
    "            pos_enc[:, 4 * i, :, :] = torch.sin(batch_grid_points[:, :, 0].view(x.shape[0], self.grid_dim, self.grid_dim) / div_factor)\n",
    "            pos_enc[:, 4 * i + 1, :, :] = torch.cos(batch_grid_points[:, :, 0].view(x.shape[0], self.grid_dim, self.grid_dim) / div_factor)\n",
    "            pos_enc[:, 4 * i + 2, :, :] = torch.sin(batch_grid_points[:, :, 1].view(x.shape[0], self.grid_dim, self.grid_dim) / div_factor)\n",
    "            pos_enc[:, 4 * i + 3, :, :] = torch.cos(batch_grid_points[:, :, 1].view(x.shape[0], self.grid_dim, self.grid_dim) / div_factor)\n",
    "\n",
    "        # Apply the learned scale to positional embedding and add to the input\n",
    "        x = x + self.factor * pos_enc\n",
    "        # Normalize the final output\n",
    "        x = self.layer_norm(x) \n",
    "\n",
    "        return x\n",
    "\n",
    "# Create the SurfacePositionalEmbedding module\n",
    "positional_encoder = SurfacePositionalEmbedding(grid_dim, d_embedding)\n",
    "\n",
    "# Apply positional embedding\n",
    "positional_embedded_batch = positional_encoder(pre_encoded_batch)\n",
    "positional_embedded_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.2322e+00, -2.5396e-01, -1.4235e+00, -2.5456e-01, -9.4066e-01,\n",
       "            4.5215e-03, -4.7360e-01,  1.2686e-01],\n",
       "          [-1.4282e+00,  1.9080e+00, -9.0447e-01, -4.0972e-02, -9.2368e-01,\n",
       "            1.9135e-01, -7.2363e-01,  3.4015e+00],\n",
       "          [-1.3488e+00,  1.7327e+00,  2.1020e-01, -2.5321e-01, -2.9440e-01,\n",
       "            4.5288e-01, -4.4926e-01,  2.9342e+00],\n",
       "          [-5.6752e-01, -2.8359e-02,  1.0675e+00,  1.8990e+00, -8.9341e-01,\n",
       "            5.5186e-01, -9.4258e-01, -2.1595e-02],\n",
       "          [-3.5609e-01,  4.7226e-03, -6.7726e-01, -4.0126e-02, -8.9248e-01,\n",
       "           -5.6153e-02, -9.1099e-01, -6.2356e-02],\n",
       "          [-8.9268e-01, -1.9122e-02, -3.8458e-01,  1.9130e-01, -7.3351e-01,\n",
       "            4.7243e-01, -5.4017e-01,  1.5274e+00],\n",
       "          [ 1.1287e-01, -2.4079e-01,  1.2245e+00,  3.4947e+00, -9.2896e-01,\n",
       "           -5.3189e-02, -9.3156e-02,  8.7661e-02],\n",
       "          [-2.1814e-01, -1.3761e-01,  1.0871e+00,  8.8387e-01, -9.1330e-01,\n",
       "           -4.6758e-02, -6.8705e-01,  7.4230e-02],\n",
       "          [-3.8151e-01, -2.5352e-01, -3.7708e-01, -2.5443e-01, -5.9911e-01,\n",
       "            8.5849e-01, -6.5090e-01,  2.9978e-01]],\n",
       " \n",
       "         [[-1.2626e+00,  1.0033e+00, -1.2966e+00, -9.9716e-02, -8.2400e-01,\n",
       "           -2.5538e-02, -8.0744e-01,  1.7311e+00],\n",
       "          [-1.2802e+00,  1.6870e+00, -7.4783e-01,  2.7399e-02, -7.7253e-01,\n",
       "            4.8340e-03, -8.1755e-01,  1.4128e+00],\n",
       "          [-1.3139e+00,  1.2199e+00, -3.1876e-01, -1.8612e-01, -8.2258e-01,\n",
       "           -9.5242e-03, -5.3791e-01,  6.7383e-01],\n",
       "          [-7.8787e-01,  9.3125e-01, -1.1897e+00, -1.9939e-01, -7.7017e-01,\n",
       "            1.5941e-02, -7.4180e-01,  5.5127e-01],\n",
       "          [-1.6224e-01,  5.7408e-01, -8.0030e-01,  1.5655e+00, -7.3855e-01,\n",
       "            8.2318e-02, -8.1740e-01,  6.0547e-02],\n",
       "          [ 5.3014e-01,  1.1272e-01,  2.9379e-01,  2.6321e+00, -7.1431e-01,\n",
       "            7.9987e-02, -7.7921e-01,  6.6578e-02],\n",
       "          [-2.4544e-01, -1.1946e-01, -1.2003e+00, -1.9316e-01, -7.7684e-01,\n",
       "            2.4400e-04, -3.4853e-01,  4.4843e-01],\n",
       "          [ 4.3009e-01, -1.7980e-01, -6.3282e-01,  2.6379e+00, -7.2723e-01,\n",
       "            7.0031e-02, -7.8177e-01, -2.0306e-03],\n",
       "          [ 8.1792e-01, -1.4394e-01,  1.6611e+00,  4.1354e+00, -7.0919e-01,\n",
       "            8.2135e-02, -7.3353e-01,  7.8409e-02]],\n",
       " \n",
       "         [[-1.4119e+00, -3.0083e-01, -1.4686e+00, -2.1709e-01, -9.8224e-01,\n",
       "           -1.0552e-01, -8.1289e-01,  9.5477e-02],\n",
       "          [-2.8347e-01, -1.5116e-01,  5.0868e-01,  1.2541e-01, -7.7811e-01,\n",
       "            1.0434e-01, -9.1332e-01,  1.3919e-01],\n",
       "          [-6.0654e-01, -3.0958e-01,  8.7747e-01,  1.2833e+00, -9.6927e-01,\n",
       "           -1.3299e-01, -7.0575e-01, -7.1220e-02],\n",
       "          [-9.1405e-01,  1.3007e+00, -9.2564e-01, -3.0834e-01, -8.9099e-01,\n",
       "           -5.4101e-02, -9.5997e-01,  4.3510e-01],\n",
       "          [ 1.4812e+00,  1.6832e+00, -3.3613e-01, -1.2896e-01, -8.5551e-01,\n",
       "            5.0151e-01, -8.6657e-01,  2.1804e+00],\n",
       "          [-7.9062e-01, -1.3598e-01,  1.9911e+00, -3.0659e-01, -6.1535e-01,\n",
       "            1.0533e-02, -8.8640e-01, -1.3283e-01],\n",
       "          [-4.5060e-01,  2.5479e+00, -1.3923e+00, -3.1853e-01,  4.9667e-02,\n",
       "            1.5450e+00, -1.1505e-01,  3.1944e+00],\n",
       "          [-4.0104e-01,  1.4751e+00, -9.7285e-01,  5.9578e-03, -3.4301e-02,\n",
       "           -9.1902e-03, -9.3116e-01,  2.2475e+00],\n",
       "          [-4.4493e-01, -2.2079e-01,  2.2685e+00, -1.6305e-01, -3.9622e-01,\n",
       "            1.3545e-01, -8.9971e-01, -1.0892e-01]],\n",
       " \n",
       "         [[-1.2634e+00,  2.9183e+00, -1.2563e+00, -1.4306e-01, -6.3756e-01,\n",
       "            1.5474e+00, -6.5776e-01,  3.3028e+00],\n",
       "          [-1.1786e+00,  1.6187e+00, -7.5078e-01,  7.4453e-02, -5.7649e-01,\n",
       "            2.0991e-01, -7.6829e-01,  4.0154e+00],\n",
       "          [-1.0483e+00, -5.5172e-02,  1.1369e+00, -1.0950e-01, -7.5891e-01,\n",
       "            1.6553e-01, -6.8614e-01,  4.0394e-02],\n",
       "          [-7.0672e-01,  2.6903e-01, -1.2682e+00, -1.0554e-01, -6.7294e-01,\n",
       "            1.9791e-01, -5.4834e-01,  2.0348e+00],\n",
       "          [ 1.3815e+00,  2.7246e-01, -6.2175e-01,  4.1186e-02, -7.4760e-01,\n",
       "            3.4289e-02, -7.5496e-01,  4.6768e-01],\n",
       "          [-7.6592e-01,  1.0329e-01,  1.4049e+00, -2.3000e-02, -7.5314e-01,\n",
       "            2.2004e-01, -6.5058e-01,  4.3175e-02],\n",
       "          [-2.6765e-01, -9.7094e-02, -1.2529e+00, -1.3588e-01, -7.6298e-01,\n",
       "            4.0010e-01, -4.9971e-01,  1.1623e-01],\n",
       "          [-2.6744e-01, -6.2880e-02, -1.0776e-01,  5.6207e-02, -7.6718e-01,\n",
       "            6.6814e-02, -7.1866e-01,  3.8547e-02],\n",
       "          [-2.1489e-01, -1.4304e-01,  1.0387e+00,  6.9814e-01, -7.4534e-01,\n",
       "            1.8268e-01, -6.5456e-01,  1.0957e-01]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " {'Datetime': [Timestamp('2013-03-14 00:00:00'),\n",
       "   Timestamp('2013-01-31 00:00:00'),\n",
       "   Timestamp('2013-02-05 00:00:00'),\n",
       "   Timestamp('2013-05-20 00:00:00')],\n",
       "  'Symbol': ['GOOGL', 'AAPL', 'AAPL', 'AAPL'],\n",
       "  'Market Features': {'Market Return': tensor([ 0.4010, -0.9509,  1.1927, -0.6427], grad_fn=<SqueezeBackward1>),\n",
       "   'Market Volatility': tensor([-1.5886,  1.0710,  0.5712, -0.0535], grad_fn=<SqueezeBackward1>),\n",
       "   'Treasury Rate': tensor([ 1.2539e+00, -1.0051e-07,  2.5078e-01, -1.5047e+00],\n",
       "          grad_fn=<SqueezeBackward1>)},\n",
       "  'Input Surface': {'Log Moneyness': [tensor([-2.2581e+00, -1.8348e+00, -1.7707e+00, -1.7081e+00, -1.6774e+00,\n",
       "            -1.6171e+00, -1.5582e+00, -1.4166e+00, -1.3353e+00, -1.1304e+00,\n",
       "            -1.1304e+00, -1.0576e+00, -9.6379e-01, -9.4085e-01, -8.7328e-01,\n",
       "            -8.2921e-01, -8.0746e-01, -7.8590e-01, -7.6452e-01, -7.0143e-01,\n",
       "            -5.4050e-01, -4.6371e-01, -3.8918e-01, -2.6380e-01, -2.2909e-01,\n",
       "            -2.1191e-01, -1.7790e-01, -1.4434e-01, -1.1122e-01, -6.2331e-02,\n",
       "             1.4165e-03,  1.7106e-02,  3.2699e-02,  3.2699e-02,  9.4129e-02,\n",
       "             1.9817e-01,  2.4149e-01,  2.6996e-01,  3.1207e-01,  3.6716e-01,\n",
       "             3.8074e-01,  4.0770e-01,  4.3437e-01,  4.6077e-01,  5.1274e-01,\n",
       "             6.2594e-01,  7.2248e-01,  8.1547e-01,  9.7043e-01, -3.5272e-01,\n",
       "            -3.5272e-01, -3.1678e-01, -2.8134e-01, -2.4639e-01, -1.1122e-01,\n",
       "            -3.0257e-02, -3.0257e-02,  3.2699e-02,  4.8197e-02,  9.4129e-02,\n",
       "             1.3924e-01,  1.3924e-01,  1.8357e-01,  2.8407e-01,  3.1207e-01,\n",
       "            -3.5272e-01, -3.1678e-01, -2.1191e-01, -1.4434e-01, -1.4434e-01,\n",
       "            -7.8522e-02, -4.6243e-02,  1.0926e-01,  1.9817e-01,  1.9817e-01,\n",
       "             2.5576e-01, -6.6023e-01, -5.7978e-01, -3.1678e-01, -2.1191e-01,\n",
       "            -2.1191e-01, -1.4434e-01, -1.4371e-02,  4.8197e-02,  1.0926e-01,\n",
       "             1.0926e-01,  2.2713e-01, -4.2617e-01, -4.2617e-01, -3.8918e-01,\n",
       "            -3.8918e-01, -2.4639e-01, -2.1191e-01, -1.7790e-01, -1.4434e-01,\n",
       "            -7.8522e-02, -4.6243e-02,  1.3924e-01,  2.2713e-01,  2.5576e-01,\n",
       "             2.8407e-01, -1.9007e+00, -1.7707e+00, -1.5582e+00, -1.4723e+00,\n",
       "            -1.4166e+00, -1.3892e+00, -1.2825e+00, -1.1059e+00, -1.0576e+00,\n",
       "            -1.0339e+00, -9.8693e-01, -9.1813e-01, -8.9561e-01, -8.0746e-01,\n",
       "            -7.8590e-01, -7.2228e-01, -7.0143e-01, -6.8075e-01, -6.3988e-01,\n",
       "            -5.9966e-01, -5.0181e-01, -4.6371e-01, -3.3468e-01, -2.8134e-01,\n",
       "            -2.6380e-01, -1.7790e-01, -1.4434e-01, -1.4434e-01, -1.2772e-01,\n",
       "            -1.1122e-01, -9.4817e-02, -9.4817e-02, -4.6243e-02, -4.6243e-02,\n",
       "             3.2699e-02,  4.8197e-02,  6.3600e-02,  9.4129e-02,  1.9817e-01,\n",
       "             2.8407e-01,  2.8407e-01,  3.3976e-01,  3.6716e-01,  3.8074e-01,\n",
       "             3.8074e-01,  3.9426e-01,  4.6077e-01,  4.9985e-01,  5.1274e-01,\n",
       "             5.3834e-01,  5.7625e-01,  6.3821e-01,  6.5042e-01,  7.2248e-01,\n",
       "             7.2248e-01,  7.6940e-01,  7.6940e-01,  7.9254e-01,  8.1547e-01,\n",
       "             9.0518e-01,  9.2711e-01,  9.9181e-01,  1.0130e+00, -1.9007e+00,\n",
       "            -1.8026e+00, -1.6471e+00, -1.5582e+00, -1.5006e+00, -1.4166e+00,\n",
       "            -1.3892e+00, -1.3353e+00, -1.2565e+00, -1.2308e+00, -1.0576e+00,\n",
       "            -1.0103e+00, -9.4085e-01, -8.9561e-01, -8.5115e-01, -7.8590e-01,\n",
       "            -7.6452e-01, -7.4331e-01, -6.8075e-01, -6.6023e-01, -6.1969e-01,\n",
       "            -5.6006e-01, -4.6371e-01, -3.8918e-01, -3.5272e-01, -3.3468e-01,\n",
       "            -3.1678e-01, -2.9900e-01, -2.8134e-01, -2.6380e-01, -2.6380e-01,\n",
       "            -2.4639e-01, -1.9485e-01, -1.7790e-01, -1.6107e-01, -1.6107e-01,\n",
       "            -1.1122e-01, -6.2331e-02, -6.2331e-02, -4.6243e-02, -1.4371e-02,\n",
       "             1.4165e-03,  9.4129e-02,  1.0926e-01,  1.0926e-01,  1.3924e-01,\n",
       "             1.5410e-01,  1.8357e-01,  1.9817e-01,  2.1269e-01,  2.2713e-01,\n",
       "             2.8407e-01,  3.2596e-01,  3.5350e-01,  3.8074e-01,  3.9426e-01,\n",
       "             4.9985e-01,  5.1274e-01,  5.7625e-01,  6.0122e-01,  8.3820e-01,\n",
       "             8.6072e-01,  8.8305e-01,  9.2711e-01,  1.0130e+00, -2.1825e+00,\n",
       "            -2.1455e+00, -2.1090e+00, -1.9007e+00, -1.8675e+00, -1.8348e+00,\n",
       "            -1.8026e+00, -1.8026e+00, -1.7707e+00, -1.4723e+00, -1.3621e+00,\n",
       "            -1.2308e+00, -1.2053e+00, -1.0817e+00, -1.0817e+00, -1.0339e+00,\n",
       "            -9.6379e-01, -9.1813e-01, -8.9561e-01, -8.7328e-01, -8.5115e-01,\n",
       "            -8.5115e-01, -8.2921e-01, -6.3988e-01, -6.3988e-01, -6.1969e-01,\n",
       "            -5.9966e-01, -5.7978e-01, -5.6006e-01, -4.0761e-01, -3.7088e-01,\n",
       "            -3.5272e-01, -3.1678e-01, -2.9900e-01, -2.1191e-01, -1.6107e-01,\n",
       "            -1.4434e-01, -1.2772e-01, -6.2331e-02,  1.7106e-02,  7.8910e-02,\n",
       "             9.4129e-02,  1.0926e-01,  1.0926e-01,  1.6888e-01,  1.8357e-01,\n",
       "             1.9817e-01,  2.5576e-01,  2.8407e-01,  3.1207e-01,  4.4760e-01,\n",
       "             4.8689e-01,  5.7625e-01,  6.5042e-01,  6.7467e-01,  8.1547e-01,\n",
       "             9.0518e-01, -1.9682e+00, -1.9682e+00, -1.9342e+00, -1.9007e+00,\n",
       "            -1.8348e+00, -1.8026e+00, -1.7081e+00, -1.6171e+00, -1.5874e+00,\n",
       "            -1.5874e+00, -1.5582e+00, -1.4166e+00, -1.3621e+00, -1.3353e+00,\n",
       "            -1.3087e+00, -1.2308e+00, -1.2053e+00, -1.1801e+00, -1.1801e+00,\n",
       "            -1.1551e+00, -1.0817e+00, -1.0339e+00, -8.9561e-01, -8.7328e-01,\n",
       "            -8.0746e-01, -7.8590e-01, -7.2228e-01, -6.8075e-01, -6.8075e-01,\n",
       "            -6.6023e-01, -6.3988e-01, -4.2617e-01, -4.0761e-01, -4.0761e-01,\n",
       "            -3.3468e-01, -2.4639e-01, -2.4639e-01, -1.6107e-01, -7.8522e-02,\n",
       "             1.7106e-02,  6.3600e-02,  1.0926e-01,  1.8357e-01,  1.9817e-01,\n",
       "             1.9817e-01,  2.8407e-01,  3.2596e-01,  3.8074e-01,  4.6077e-01,\n",
       "             4.7386e-01,  4.7386e-01,  4.9985e-01,  5.2557e-01,  6.9868e-01,\n",
       "             7.4605e-01,  7.4605e-01,  8.6072e-01,  8.8305e-01,  9.4886e-01,\n",
       "            -2.5855e+00, -2.5422e+00, -2.3760e+00, -2.3760e+00, -2.3361e+00,\n",
       "            -2.2581e+00, -2.2200e+00, -2.1455e+00, -2.1455e+00, -2.1090e+00,\n",
       "            -1.9682e+00, -1.8348e+00, -1.8348e+00, -1.6774e+00, -1.6171e+00,\n",
       "            -1.5292e+00, -1.5006e+00, -1.3087e+00, -1.2825e+00, -1.2308e+00,\n",
       "            -1.1801e+00, -1.1304e+00, -1.1304e+00, -1.1059e+00, -1.0339e+00,\n",
       "            -9.6379e-01, -8.9561e-01, -8.9561e-01, -8.7328e-01, -8.5115e-01,\n",
       "            -6.1969e-01, -5.7978e-01, -4.6371e-01, -4.2617e-01, -3.7088e-01,\n",
       "            -3.3468e-01, -2.9900e-01, -2.8134e-01, -2.6380e-01, -2.2909e-01,\n",
       "            -2.1191e-01, -1.9485e-01, -9.4817e-02, -6.2331e-02, -6.2331e-02,\n",
       "            -3.0257e-02, -1.4371e-02,  1.7106e-02,  7.8910e-02,  1.0926e-01,\n",
       "             1.8357e-01,  1.9817e-01,  1.9817e-01,  2.1269e-01,  2.4149e-01,\n",
       "             3.1207e-01,  3.6716e-01,  4.3437e-01,  4.8689e-01,  5.2557e-01,\n",
       "             5.5104e-01,  7.9254e-01,  8.6072e-01,  9.7043e-01,  9.9181e-01,\n",
       "             9.9181e-01], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([ 0.0502,  0.0779,  0.0779,  0.1053,  0.1053,  0.1324,  0.1592,  0.1592,\n",
       "             0.1858,  0.2380,  0.2637,  0.2892,  0.2892,  0.3144,  0.3144,  0.3641,\n",
       "             0.3886,  0.4368,  0.4368,  0.4606,  0.4842,  0.4842,  0.5076,  0.5307,\n",
       "             0.5307,  0.5536,  0.5536,  0.6212,  0.6433,  0.6433,  0.6653,  0.6653,\n",
       "             0.7086,  0.7086,  0.7300,  0.7512,  0.7512,  0.7722,  0.7930,  0.7930,\n",
       "             0.8137,  0.8137,  0.8343,  0.8546,  0.8546,  0.8748,  0.8948,  0.9147,\n",
       "             0.9344,  0.9344,  0.9540,  0.9734,  0.9734,  1.0118,  1.0308,  1.0496,\n",
       "             1.0869,  1.1053,  1.1053,  1.1236,  1.1236,  1.1418,  1.1418,  1.1598,\n",
       "             1.1598,  1.1955,  1.1955,  1.2131,  1.2307,  1.2481,  1.2654,  1.2826,\n",
       "             1.2826,  1.2996,  1.2996,  1.3166,  1.3334,  1.3334,  1.3501,  1.3501,\n",
       "             1.3668,  1.3997,  1.4160,  1.4160,  1.4321,  1.4321,  1.4482,  1.4482,\n",
       "             1.4642,  1.4801,  1.4801,  1.4959,  1.4959,  1.5116,  1.5272,  1.5427,\n",
       "             1.5886,  1.5886,  1.6037,  1.6188,  1.6188,  1.6337,  1.6486,  1.6634,\n",
       "             1.6780,  1.6927,  1.7072,  1.7216,  1.7216,  1.7502,  1.7786,  1.7786,\n",
       "             1.7926,  1.8066,  1.8204,  1.8204,  1.8342,  1.8480,  1.8480,  1.8616,\n",
       "             1.8616,  1.8752,  1.8887,  1.9156,  1.9289,  1.9289,  1.9421,  1.9421,\n",
       "             1.9552,  1.9683,  1.9814,  1.9943,  2.0072,  2.0201,  2.0201,  2.0328,\n",
       "             2.0455,  2.0957,  2.0957,  2.1204,  2.1204,  2.1449,  2.1449,  2.1691,\n",
       "            -1.6784, -1.6784, -1.5706, -1.5706, -1.4671, -1.3678, -1.2721, -1.1800,\n",
       "            -1.1800, -1.0911, -1.0052, -0.8416, -0.6880, -0.6880, -0.6146, -0.6146,\n",
       "            -0.5432, -0.5432, -0.4738, -0.4062, -0.3404, -0.2762, -0.2137, -0.2137,\n",
       "            -0.1526, -0.0930, -0.0930, -0.0347,  0.0222,  0.0222,  0.0779,  0.0779,\n",
       "             0.1324,  0.2380,  0.2892,  0.3394,  0.3886,  0.3886,  0.4368,  0.4368,\n",
       "             0.5307,  0.5763,  0.6653,  0.7086,  0.7512,  0.7512,  0.7930,  0.7930,\n",
       "             0.8343,  0.8748,  0.9540,  0.9540,  0.9927,  1.1053,  1.1418,  1.2131,\n",
       "             1.2131,  1.2481,  1.2826,  1.2826,  1.3166,  1.3501,  1.3501,  1.3833,\n",
       "             1.4160,  1.4482,  1.5734,  1.5734,  1.6037,  1.6037,  1.6337,  1.6337,\n",
       "             1.6634,  1.6634,  1.6927,  1.7216,  1.7216,  1.7502,  1.7786,  1.8342,\n",
       "             1.9156,  1.9421,  1.9683,  1.9943,  1.9943,  2.0201,  2.0201,  2.0455,\n",
       "             2.0455,  2.0707,  2.0957,  2.1204,  2.1449,  2.1691],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.4192, -0.3534, -0.3211, -0.1060, -0.0767,  0.0923,  0.0923,  0.2250,\n",
       "             0.3755,  0.4712,  0.5858,  0.7381,  0.7800, -1.3325, -1.3325, -1.2852,\n",
       "            -1.1930, -1.0182, -0.9351, -0.7011, -0.6276, -0.5562, -0.4528, -0.3534,\n",
       "            -0.2578,  0.0092,  0.0923,  0.1194,  0.2250,  0.2507,  0.3511,  0.5177,\n",
       "             0.5633,  0.5858,  0.5858,  0.7169,  0.7169,  0.7592,  0.7592,  0.8007,\n",
       "             0.9409,  0.9796,  1.1106,  1.2001,  1.2001,  1.2523,  1.2695,  1.3035,\n",
       "             1.3537,  1.3866,  1.3866,  1.4191,  1.4671,  1.4829,  1.5141,  1.5450,\n",
       "             1.6207,  1.6207,  1.6503,  1.6503,  1.6941,  1.7229,  1.7372,  1.7655,\n",
       "             1.7796,  1.8349,  1.8622,  1.9158,  1.9158,  1.9290,  1.9553,  1.9553,\n",
       "             1.9813,  1.9813,  2.1074,  2.1319, -0.2893, -0.2267, -0.0478,  0.0092,\n",
       "             0.0092,  0.0649,  0.1727,  0.1727,  0.1990,  0.2250,  0.2250,  0.2762,\n",
       "             0.3263,  0.3511,  0.3998,  0.5406,  0.6522, -0.4192, -0.4192,  0.1462,\n",
       "             0.2762,  0.3263,  0.3263,  0.3511,  0.4476,  0.5177,  0.5177,  0.5633,\n",
       "             0.5633, -1.4300, -1.1930, -1.1482, -1.0608, -1.0182, -0.9351, -0.8547,\n",
       "            -0.8154, -0.7386, -0.5213, -0.5213, -0.4868, -0.3534, -0.3534, -0.1356,\n",
       "            -0.0478, -0.0478,  0.0372,  0.0923,  0.1462,  0.1727,  0.2250,  0.2507,\n",
       "             0.2762,  0.2762,  0.3014,  0.3263,  0.3263,  0.4238,  0.4476,  0.5177,\n",
       "             0.5858,  0.6303,  0.6522,  0.6740,  0.6955,  0.7169,  0.7381,  0.7800,\n",
       "             0.8007,  0.8618,  0.8818,  0.9017,  0.9409,  0.9796,  1.0553,  1.0738,\n",
       "             1.0923,  1.1287,  1.1287,  1.2523,  1.3371,  1.3537,  1.3537,  1.4191,\n",
       "             1.4352,  1.4829,  1.4985,  1.5141,  1.6355,  1.6650,  1.6941,  1.7086,\n",
       "             1.7514, -1.3808, -1.1930, -1.1482, -1.1041, -1.0608, -0.9763, -0.9351,\n",
       "            -0.9351, -0.8946, -0.8946, -0.8547, -0.5213, -0.3534, -0.3211, -0.3211,\n",
       "            -0.2578, -0.0191,  0.0923,  0.1194,  0.2250,  0.2507,  0.3014,  0.3511,\n",
       "             0.3755,  0.3998,  0.4238,  0.4476,  0.4712,  0.5406,  0.5858,  0.6522,\n",
       "             0.6740,  0.6955,  0.6955,  0.7169,  0.7381,  0.7592,  0.7592,  0.7800,\n",
       "             0.8007,  0.8416,  0.8818,  0.9796,  1.0177,  1.0177,  1.0553,  1.2176,\n",
       "             1.2176,  1.2523,  1.3537,  1.3537,  1.3702,  1.3866,  1.4352,  1.4352,\n",
       "             1.4512,  1.4671,  1.4829,  1.5141,  1.5296,  1.5450,  1.5604,  1.5756,\n",
       "             1.5756,  1.5907,  1.6941,  1.7086,  1.7372,  1.7655,  1.8212,  1.8622,\n",
       "             1.8757,  1.8891,  1.9422,  1.9422,  1.9683,  2.0198,  2.0577,  2.0827,\n",
       "             2.1319, -1.1482, -1.0608, -1.0182, -0.9763, -0.9351, -0.8946, -0.8547,\n",
       "            -0.8154, -0.5917, -0.5562, -0.5213, -0.4868, -0.4868, -0.2578, -0.1356,\n",
       "            -0.0478, -0.0191,  0.0372,  0.1194,  0.2250,  0.2250,  0.2507,  0.3014,\n",
       "             0.3263,  0.3998,  0.4476,  0.4712,  0.5633,  0.5858,  0.8618,  0.8618,\n",
       "             0.9017,  0.9214,  0.9409,  1.0177,  1.0553,  1.1647,  1.2176,  1.2351,\n",
       "             1.2523, -1.2387, -1.1041, -0.9763, -0.8946, -0.6641, -0.5562, -0.3534,\n",
       "            -0.2267, -0.1960, -0.1960, -0.1656, -0.1356, -0.1060, -0.0191,  0.0092,\n",
       "             0.0372,  0.0649,  0.1727,  0.4476,  0.5177,  0.6522,  0.6522,  0.7169,\n",
       "             0.7381,  0.7800,  0.8212,  0.9796,  1.0366,  1.0738,  1.1106,  1.1287,\n",
       "             1.1468,  1.2001,  1.2176,  1.2695,  1.2866,  1.3035,  1.3035,  1.3204,\n",
       "             1.3371,  1.4029,  1.4191,  1.4191,  1.4352,  1.4829,  1.5141,  1.5756,\n",
       "             1.6057,  1.6503,  1.6503,  1.6650,  1.7655,  1.8074,  1.9025,  1.9290,\n",
       "            -1.3325, -1.2387, -1.1930, -1.0608, -0.9763, -0.8946, -0.8154, -0.7386,\n",
       "            -0.4868, -0.1356, -0.0191,  0.1194,  0.1990,  0.4238,  0.4476,  0.4712,\n",
       "             0.4945,  0.5177,  0.5177,  0.5406,  0.6303,  0.6522,  0.8007,  0.9409,\n",
       "             0.9604,  1.1287,  1.2001,  1.2351,  1.3702,  1.4352,  1.4671,  1.4985,\n",
       "             1.5450,  1.5450,  1.5756,  1.6207,  1.6355,  1.6355,  1.6650,  1.6796,\n",
       "             1.7372,  1.8074,  1.8212,  1.8891,  1.8891,  1.9025,  1.9813,  2.0198,\n",
       "             2.0577,  2.1074, -1.2852, -1.2387, -1.1930, -0.9351, -0.8154, -0.8154,\n",
       "            -0.7767, -0.7767, -0.6641, -0.5562, -0.4192, -0.3534, -0.3211, -0.3211,\n",
       "            -0.1060, -0.0191, -0.0191,  0.0372,  0.0649,  0.1990,  0.3014,  0.4238,\n",
       "             0.4238,  0.4712,  0.4712,  0.4945,  0.5177,  0.5858,  0.5858,  0.6082,\n",
       "             0.6522,  0.6522,  0.8212,  0.8416,  0.9214,  0.9214,  0.9604,  1.0177,\n",
       "             1.1824,  1.2001,  1.2695,  1.3537,  1.3702,  1.4191,  1.5141,  1.5450,\n",
       "             1.6207,  1.6796, -1.8623, -1.5314, -1.4802, -1.3808, -1.2852, -1.2387,\n",
       "            -1.1930, -1.0182, -0.9763, -0.8547, -0.5917, -0.3861, -0.1960, -0.1060,\n",
       "            -0.0767, -0.0478,  0.0649,  0.1727,  0.1727,  0.2250,  0.2507,  0.3263,\n",
       "             0.3263,  0.3755,  0.3998,  0.4238,  0.4945,  0.5858,  0.6082,  0.6740,\n",
       "             0.6740,  0.8416,  0.9017,  1.0177,  1.2001,  1.2176,  1.4191,  1.4512,\n",
       "             1.5296,  1.5604,  1.5756,  1.5907,  1.6207,  1.6796,  1.7229,  1.7514,\n",
       "             1.7655,  1.8074,  1.8486,  1.9025,  1.9290,  1.9422,  2.0198],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.9343, -0.8512, -0.8107, -0.7708, -0.7315, -0.6928, -0.6928, -0.6547,\n",
       "            -0.6172, -0.6172, -0.5802, -0.4374, -0.3689, -0.3353, -0.3022, -0.2695,\n",
       "            -0.2695, -0.2054, -0.1739, -0.1428, -0.1428, -0.1121, -0.0817, -0.0817,\n",
       "            -0.0518, -0.0518,  0.0072,  0.0361,  0.0648,  0.0648,  0.0931,  0.1211,\n",
       "             0.1488,  0.1762,  0.2301,  0.2566,  0.2566, -0.9343, -0.9343, -0.8924,\n",
       "            -0.8512, -0.8107, -0.7708, -0.7315, -0.7315, -0.6928, -0.6928, -0.6547,\n",
       "            -0.6172, -0.5437, -0.4723, -0.4374, -0.4029, -0.3689, -0.3353, -0.3353,\n",
       "            -0.3022, -0.2695, -0.2372, -0.2054, -0.1428, -0.1121, -0.0817, -0.0518,\n",
       "            -0.0518, -0.0221, -0.0221,  0.0361,  0.0361,  0.0648,  0.1488,  0.1488,\n",
       "             0.1762,  0.1762,  0.2033,  0.2301,  0.2566, -0.6928, -0.6928, -0.6172,\n",
       "            -0.5078, -0.5078, -0.4723, -0.4374, -0.4374, -0.3353, -0.3022, -0.3022,\n",
       "            -0.2695, -0.2372, -0.2372, -0.2054, -0.1739, -0.1739, -0.1428, -0.1121,\n",
       "            -0.0817, -0.0518, -0.0518,  0.0361,  0.0648,  0.0648,  0.0931,  0.1211,\n",
       "             0.1488,  0.1488,  0.1762,  0.1762,  0.2033,  0.2033,  0.2301,  0.2301,\n",
       "             0.2566,  0.2566, -0.7708, -0.7708, -0.6928, -0.6928, -0.6172, -0.5437,\n",
       "            -0.4374, -0.4029, -0.3353, -0.3353, -0.3022, -0.2695, -0.2695, -0.2372,\n",
       "            -0.2054, -0.2054, -0.1739, -0.1739, -0.1428, -0.1428, -0.1121, -0.1121,\n",
       "            -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,  0.0361,  0.0648,  0.0931,\n",
       "             0.1211,  0.1211,  0.1488,  0.1488,  0.1762,  0.1762,  0.2033,  0.2301,\n",
       "             0.2566, -1.9617, -1.8991, -1.8381, -1.8381, -1.7784, -1.7784, -1.7202,\n",
       "            -1.7202, -1.6633, -1.6633, -1.6076, -1.5531, -1.5531, -1.4997, -1.4997,\n",
       "            -1.4475, -1.3963, -1.3963, -1.3461, -1.2969, -1.2486, -1.2486, -1.2013,\n",
       "            -1.2013, -1.1548, -1.1091, -1.1091, -1.0643, -1.0202, -0.9769, -0.9343,\n",
       "            -0.8924, -0.8924, -0.8107, -0.8107, -0.7708, -0.7315, -0.6928, -0.6547,\n",
       "            -0.6172, -0.6172, -0.5802, -0.5437, -0.5437, -0.5078, -0.4723, -0.4723,\n",
       "            -0.4374, -0.4374, -0.3689, -0.3689, -0.3353, -0.3353, -0.2695, -0.2372,\n",
       "            -0.2054, -0.2054, -0.1428, -0.1121, -0.0817, -0.0817, -0.0518, -0.0221,\n",
       "             0.0072,  0.0072,  0.0361,  0.0361,  0.0648,  0.0931,  0.1211,  0.1762,\n",
       "             0.1762,  0.2033,  0.2033,  0.2301,  0.2566,  0.2566, -1.6076, -1.6076,\n",
       "            -1.4475, -1.4475, -1.3963, -1.3461, -1.3461, -1.2969, -1.2486, -1.2486,\n",
       "            -1.1548, -1.1548, -1.1091, -0.9769, -0.9343, -0.9343, -0.8107, -0.8107,\n",
       "            -0.7708, -0.6547, -0.6547, -0.6172, -0.6172, -0.5437, -0.5437, -0.5078,\n",
       "            -0.4723, -0.4723, -0.4374, -0.4029, -0.4029, -0.3353, -0.3022, -0.2695,\n",
       "            -0.2695, -0.2372, -0.2372, -0.2054, -0.2054, -0.1739, -0.1739, -0.1428,\n",
       "            -0.1121, -0.1121, -0.0817, -0.0221, -0.0221,  0.0072,  0.0361,  0.0648,\n",
       "             0.0648,  0.0931,  0.1211,  0.1211,  0.1488,  0.2033,  0.2301,  0.2301,\n",
       "            -1.8991, -1.8991, -1.8381, -1.7202, -1.6633, -1.6633, -1.6076, -1.5531,\n",
       "            -1.5531, -1.4997, -1.4997, -1.4475, -1.3963, -1.3461, -1.2969, -1.2486,\n",
       "            -1.2013, -1.2013, -1.0643, -1.0202, -0.9343, -0.9343, -0.8924, -0.8512,\n",
       "            -0.8512, -0.8107, -0.8107, -0.7315, -0.7315, -0.6928, -0.6172, -0.6172,\n",
       "            -0.5802, -0.5437, -0.5078, -0.5078, -0.4723, -0.4374, -0.4029, -0.3689,\n",
       "            -0.3353, -0.3353, -0.3022, -0.3022, -0.2695, -0.2695, -0.2372, -0.2372,\n",
       "            -0.2054, -0.1739, -0.1428, -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,\n",
       "             0.0361,  0.0931,  0.1211,  0.1211,  0.1488,  0.1762,  0.1762,  0.2033,\n",
       "             0.2301,  0.2301, -1.8381, -1.8381, -1.7784, -1.7784, -1.6633, -1.6076,\n",
       "            -1.6076, -1.5531, -1.4997, -1.4475, -1.4475, -1.3963, -1.3461, -1.2969,\n",
       "            -1.2969, -1.2486, -1.2013, -1.1548, -1.1091, -1.0643, -1.0643, -1.0202,\n",
       "            -1.0202, -0.9769, -0.9769, -0.9343, -0.8107, -0.7708, -0.7315, -0.7315,\n",
       "            -0.6928, -0.6547, -0.6172, -0.5802, -0.5437, -0.5437, -0.5078, -0.4723,\n",
       "            -0.4374, -0.4029, -0.3353, -0.3353, -0.3022, -0.2695, -0.2372, -0.2054,\n",
       "            -0.1739, -0.1428, -0.1121, -0.0817, -0.0518, -0.0221,  0.0072,  0.0361,\n",
       "             0.0361,  0.0648,  0.0648,  0.0931,  0.0931,  0.1488,  0.1762,  0.2033,\n",
       "             0.2033,  0.2301, -1.7202, -1.7202, -1.6633, -1.6633, -1.6076, -1.6076,\n",
       "            -1.5531, -1.4997, -1.4475, -1.4475, -1.3963, -1.3461, -1.2486, -1.2013,\n",
       "            -1.1091, -1.1091, -1.0643, -1.0202, -0.9769, -0.9343, -0.9343, -0.8107,\n",
       "            -0.8107, -0.7708, -0.7708, -0.7315, -0.7315, -0.6547, -0.6547, -0.6172,\n",
       "            -0.5802, -0.5437, -0.5078, -0.5078, -0.4723, -0.4723, -0.4374, -0.4374,\n",
       "            -0.3689, -0.3353, -0.3353, -0.3022, -0.2695, -0.2372, -0.2054, -0.1428,\n",
       "            -0.1121, -0.0817, -0.0518, -0.0221, -0.0221,  0.0072,  0.0072,  0.0361,\n",
       "             0.0648,  0.0648,  0.0931,  0.1488,  0.2033,  0.2301,  0.2301, -2.0258,\n",
       "            -1.9617, -1.8991, -1.7784, -1.7784, -1.7202, -1.7202, -1.6633, -1.6076,\n",
       "            -1.6076, -1.5531, -1.4997, -1.4997, -1.4475, -1.3963, -1.3461, -1.3461,\n",
       "            -1.2969, -1.2013, -1.2013, -1.1548, -1.0643, -1.0202, -1.0202, -0.9769,\n",
       "            -0.9343, -0.9343, -0.8924, -0.8512, -0.8107, -0.7315, -0.7315, -0.6928,\n",
       "            -0.6547, -0.6172, -0.5802, -0.5078, -0.5078, -0.4723, -0.4374, -0.4029,\n",
       "            -0.3689, -0.3353, -0.3022, -0.2372, -0.2054, -0.1739, -0.1428, -0.1428,\n",
       "            -0.1121, -0.1121, -0.0817, -0.0817, -0.0518, -0.0221, -0.0221,  0.0072,\n",
       "             0.0072,  0.0648,  0.0931,  0.1211,  0.1488,  0.1488,  0.1762,  0.2033,\n",
       "            -1.9617, -1.8381, -1.8381, -1.7784, -1.7202, -1.6633, -1.6076, -1.6076,\n",
       "            -1.5531, -1.4997, -1.4997, -1.3963, -1.3461, -1.3461, -1.2969, -1.2486,\n",
       "            -1.2013, -1.2013, -1.1548, -1.1548, -1.1091, -1.1091, -1.0643, -0.9769,\n",
       "            -0.9343, -0.9343, -0.8924, -0.8924, -0.8512, -0.8107, -0.8107, -0.7708,\n",
       "            -0.7708, -0.6928, -0.6547, -0.6547, -0.5437, -0.5437, -0.5078, -0.5078,\n",
       "            -0.4723, -0.4374, -0.4374, -0.4029, -0.3689, -0.3689, -0.3353, -0.3353,\n",
       "            -0.3022, -0.2695, -0.2695, -0.2054, -0.1739, -0.1428, -0.1121, -0.1121,\n",
       "            -0.0518, -0.0221, -0.0221,  0.0072,  0.0072,  0.0361,  0.0361,  0.0648,\n",
       "             0.0931,  0.0931,  0.1211,  0.1211,  0.1488],\n",
       "           grad_fn=<SplitWithSizesBackward0>)],\n",
       "   'Time to Maturity': [tensor([-0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407, -0.9407,\n",
       "            -0.9407, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065,\n",
       "            -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065, -0.9065,\n",
       "            -0.9065, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723, -0.8723,\n",
       "            -0.8723, -0.8723, -0.8723, -0.8723, -0.8267, -0.8267, -0.8267, -0.8267,\n",
       "            -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.8267, -0.7868,\n",
       "            -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7868,\n",
       "            -0.7868, -0.7868, -0.7868, -0.7868, -0.7868, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412, -0.7412,\n",
       "            -0.7412, -0.7412, -0.7412, -0.7412, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.5817,\n",
       "            -0.5817, -0.5817, -0.5817, -0.5817, -0.5817, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,\n",
       "            -0.3823, -0.3823, -0.3823, -0.3823, -0.3823, -0.3823,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,  0.1363,\n",
       "             0.1363,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,  0.8143,\n",
       "             0.8143,  0.8143,  0.8143], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536, 1.0536,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277, 3.1277,\n",
       "            3.1277, 3.1277, 3.1277, 3.1277], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.9350,\n",
       "            -0.9350, -0.9350, -0.9350, -0.9350, -0.9350, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8552, -0.8552, -0.8552, -0.8552,\n",
       "            -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8552,\n",
       "            -0.8552, -0.8552, -0.8552, -0.8552, -0.8552, -0.8153, -0.8153, -0.8153,\n",
       "            -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153, -0.8153,\n",
       "            -0.8153, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298, -0.7298,\n",
       "            -0.7298, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304, -0.5304,\n",
       "            -0.5304, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709, -0.3709,\n",
       "            -0.3709, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714, -0.1714,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119, -0.0119,\n",
       "            -0.0119, -0.0119,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,  0.5066,\n",
       "             0.5066,  0.5066,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,\n",
       "             1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252,  1.0252],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.9293,\n",
       "            -0.9293, -0.9293, -0.9293, -0.9293, -0.9293, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8894,\n",
       "            -0.8894, -0.8894, -0.8894, -0.8894, -0.8894, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495, -0.8495,\n",
       "            -0.8495, -0.8495, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096, -0.8096,\n",
       "            -0.8096, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640,\n",
       "            -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.7640, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045, -0.6045,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449, -0.4449,\n",
       "            -0.4449, -0.4449, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455, -0.2455,\n",
       "            -0.2455, -0.2455, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,\n",
       "            -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860, -0.0860,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,  0.4326,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,  0.9511,\n",
       "             0.9511,  0.9511,  0.9511,  0.9511,  0.9511],\n",
       "           grad_fn=<SplitWithSizesBackward0>)],\n",
       "   'Implied Volatility': [tensor([ 0.9100,  0.9100, -1.3298,  0.9100,  0.9100, -1.3298,  0.9100, -1.3298,\n",
       "            -1.3298, -1.3298,  0.9100,  0.9100, -1.3298, -1.3298, -1.3298, -1.3298,\n",
       "            -1.3298,  0.9100,  0.9100, -1.3298,  0.9100,  0.9100, -1.3298,  0.9100,\n",
       "            -1.3298, -1.3298,  0.9100,  0.9100,  0.9100,  0.9100, -0.9126, -1.3298,\n",
       "            -1.5479, -1.5047, -1.4436, -1.9325, -1.3298, -1.9325, -1.9325, -1.3298,\n",
       "            -1.3298, -1.9325, -1.9325, -1.9325, -1.9325, -1.9325, -1.3298, -1.3298,\n",
       "            -1.9325, -0.4111,  2.1227, -0.4111,  1.7898,  1.4895, -0.4111, -0.9537,\n",
       "            -0.9832, -1.5300, -1.6080, -1.6080, -1.4468, -1.3562, -1.1571, -1.0306,\n",
       "            -1.3593,  1.5875,  1.2577,  0.5666, -0.0961, -0.0287, -0.7725, -1.0443,\n",
       "            -1.6786, -1.4952, -1.7365, -1.7365,  0.7984,  0.7984,  0.5181, -0.1762,\n",
       "            -0.0993, -0.5649, -1.3973, -1.6617, -1.7049, -1.7144, -1.5395,  0.7278,\n",
       "             0.4349,  0.5666,  0.3443, -0.2268, -0.3595, -0.5786, -0.7146, -1.0391,\n",
       "            -1.1170, -1.5300, -1.6059, -1.3657, -1.2909,  0.0250,  0.1525,  4.8915,\n",
       "             0.0250,  4.2288,  0.0250,  0.0250,  2.7675,  0.1525,  0.0250,  2.2038,\n",
       "             1.8762,  1.7687,  0.0250,  0.1525,  0.1525,  0.0250,  0.1525,  0.0250,\n",
       "             0.0250,  0.0250,  0.1525, -0.1562, -0.2436, -0.2605, -0.4554, -0.4975,\n",
       "            -0.5112, -0.5218, -0.5302, -0.5260, -0.5776, -0.6313, -0.6471, -0.7198,\n",
       "            -0.7335, -0.7493, -0.7736, -0.8663, -0.8852, -0.9084, -0.9959, -1.2213,\n",
       "            -0.8189, -0.9959, -0.9959, -0.8136, -0.9959, -0.7746, -0.7746, -0.9959,\n",
       "            -0.7746, -0.7746, -0.7746, -0.9959, -0.7746, -0.9959, -0.9959, -0.9959,\n",
       "            -0.9959, -0.7746, -0.9959, -0.9959, -0.2584, -0.1383, -0.2584, -0.2584,\n",
       "            -0.2584,  2.6379,  2.5367, -0.2584,  2.0511,  1.9562, -0.2584,  1.2988,\n",
       "            -0.1383, -0.2584, -0.2584, -0.1383, -0.1383, -0.1383, -0.2584, -0.1383,\n",
       "            -0.1383, -0.2584, -0.2584, -0.3964, -0.4638, -0.4944, -0.5102, -0.5513,\n",
       "            -0.5786, -0.5976, -0.5966, -0.5818, -0.6735, -0.6851, -0.7230, -0.7346,\n",
       "            -0.7936, -0.8357, -0.8473, -0.8452, -0.8884, -0.8894, -0.9600, -0.9685,\n",
       "            -0.9853, -0.9959, -0.9980, -1.0085, -1.0517, -1.0464, -1.0443, -1.0664,\n",
       "            -1.0422, -1.0928, -1.0443, -1.0443, -1.0011, -1.1117, -1.1117, -1.1117,\n",
       "            -0.8810, -0.8810, -0.8810, -0.8810, -0.8810, -0.3384, -0.3384,  3.2405,\n",
       "            -0.3384,  2.5599, -0.3384, -0.3384,  2.3766,  2.2871, -0.2847, -0.2847,\n",
       "            -0.3384, -0.3384, -0.3384, -0.2847, -0.3384, -0.2847, -0.2847, -0.2847,\n",
       "            -0.2847, -0.3384, -0.2847, -0.2847, -0.3384, -0.2847, -0.2847, -0.3026,\n",
       "            -0.3384, -0.3574, -0.5997, -0.6229, -0.6387, -0.7293, -0.7082, -0.8125,\n",
       "            -0.9021, -0.9168, -0.9305, -0.9916, -1.0327, -1.0949, -1.1044, -1.0949,\n",
       "            -1.1075, -1.1507, -1.1539, -1.1560, -1.1592, -1.1866, -1.2024, -1.1929,\n",
       "            -1.3003, -1.1634, -1.2845, -1.2845, -0.8304, -1.2845, -0.1024, -0.0287,\n",
       "            -0.1024, -0.1024, -0.1024, -0.1024, -0.0287, -0.1024, -0.1024, -0.0287,\n",
       "            -0.0287, -0.1024, -0.1024, -0.0287, -0.1024, -0.0287, -0.1024, -0.1024,\n",
       "            -0.0287, -0.1024, -0.1024, -0.1024, -0.1024, -0.1014, -0.1730, -0.1867,\n",
       "            -0.2657, -0.3142, -0.3247, -0.3416, -0.3606, -0.6008, -0.6081, -0.6050,\n",
       "            -0.6798, -0.7441, -0.7398, -0.8083, -0.8599, -0.9390, -0.9527, -0.9980,\n",
       "            -1.0369, -1.0275, -1.0454, -1.0612, -1.0875, -1.1012, -1.1107, -1.1307,\n",
       "            -1.1149, -1.1328, -1.1149, -1.0854, -1.1128, -1.1412, -1.1412, -1.1412,\n",
       "            -1.1054, -0.1899, -0.0803, -0.0803, -0.1899, -0.1899, -0.1899, -0.1899,\n",
       "            -0.0803, -0.1899, -0.0803, -0.0803, -0.0803, -0.1899, -0.0803, -0.1899,\n",
       "            -0.1899, -0.1899, -0.0803, -0.0803, -0.1899, -0.0803, -0.0803, -0.1899,\n",
       "            -0.0803, -0.1256, -0.2004, -0.2531, -0.2426, -0.2531, -0.2868, -0.4743,\n",
       "            -0.5218, -0.5776, -0.5976, -0.6355, -0.6577, -0.6777, -0.7103, -0.7135,\n",
       "            -0.7430, -0.7409, -0.7567, -0.8115, -0.8431, -0.8336, -0.8673, -0.8631,\n",
       "            -0.8757, -0.9010, -0.9221, -0.9537, -0.9758, -0.9664, -0.9737, -0.9790,\n",
       "            -1.0159, -1.0401, -1.0580, -1.0759, -1.0896, -1.0896, -1.0812, -1.0728,\n",
       "            -1.0169, -1.0517, -1.0759], grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-2.9208e-01, -3.7741e-01, -2.9313e-01, -3.8268e-01, -3.0261e-01,\n",
       "            -3.0682e-01, -3.9111e-01, -3.1209e-01, -3.1104e-01, -4.1640e-01,\n",
       "            -3.2474e-01, -4.2166e-01, -3.2790e-01, -4.2798e-01, -3.3000e-01,\n",
       "            -4.3641e-01, -3.3000e-01, -4.4695e-01, -3.3632e-01, -4.4695e-01,\n",
       "            -4.5011e-01, -3.3422e-01, -4.5222e-01, -4.5011e-01, -3.4897e-01,\n",
       "            -4.5432e-01, -3.3422e-01, -4.5959e-01, -4.6065e-01, -3.1736e-01,\n",
       "            -4.5643e-01, -3.0682e-01, -4.5643e-01, -2.9418e-01, -2.9524e-01,\n",
       "            -4.5959e-01, -2.8891e-01, -4.5222e-01, -4.4590e-01, -2.7943e-01,\n",
       "            -4.4168e-01, -2.4993e-01, -2.7206e-01, -4.4800e-01, -2.3518e-01,\n",
       "            -4.4379e-01, -4.3957e-01, -4.2693e-01, -4.2588e-01, -2.0358e-01,\n",
       "            -4.2377e-01, -4.2693e-01, -2.5625e-01, -2.5625e-01, -4.0270e-01,\n",
       "            -3.9111e-01, -2.5625e-01, -3.7531e-01, -2.5625e-01, -3.8690e-01,\n",
       "            -2.5625e-01, -3.8374e-01, -2.5625e-01, -3.8057e-01, -2.5625e-01,\n",
       "            -3.6477e-01, -2.5625e-01, -2.5625e-01, -2.5625e-01, -2.5625e-01,\n",
       "            -3.4159e-01, -3.3843e-01, -2.5625e-01, -3.1947e-01, -2.5625e-01,\n",
       "            -2.9102e-01, -3.0050e-01, -2.5625e-01, -2.8786e-01, -2.5625e-01,\n",
       "            -2.7943e-01, -2.5625e-01, -2.6047e-01, -2.5625e-01, -2.3518e-01,\n",
       "            -2.5625e-01, -2.4045e-01, -2.5625e-01, -2.5625e-01, -2.4256e-01,\n",
       "            -2.5625e-01, -2.4045e-01, -2.5625e-01, -2.1306e-01, -2.1200e-01,\n",
       "            -2.1727e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.1727e-01, -2.5625e-01,\n",
       "            -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01,\n",
       "            -2.1727e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.1727e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01,\n",
       "            -2.5625e-01, -2.5625e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01,\n",
       "            -2.1727e-01, -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.1727e-01,\n",
       "            -2.5625e-01, -2.1727e-01, -2.5625e-01, -2.5625e-01,  1.5201e+00,\n",
       "             2.6315e-01,  1.2609e+00,  2.6947e-01,  2.0942e-01,  8.0152e-01,\n",
       "             5.7501e-01,  4.6333e-01,  1.3989e-01,  1.3883e-01,  1.0512e-01,\n",
       "             9.2476e-02,  5.8762e-02,  6.4030e-02,  3.3476e-02,  4.4012e-02,\n",
       "            -9.7199e-03,  3.7691e-02,  2.6101e-02,  7.1371e-03, -8.3469e-02,\n",
       "            -1.9202e-02, -9.5059e-02, -9.7199e-03, -1.1613e-01, -1.2561e-01,\n",
       "            -2.1309e-02, -1.3825e-01, -1.3088e-01, -3.5006e-02, -1.4352e-01,\n",
       "            -5.2916e-02, -3.9220e-02, -1.7618e-01, -1.5827e-01, -1.8988e-01,\n",
       "            -1.8883e-01, -6.8720e-02, -1.9515e-01, -6.6612e-02, -2.0147e-01,\n",
       "            -2.0884e-01, -2.0041e-01, -5.2916e-02, -1.9093e-01, -6.4505e-02,\n",
       "            -2.0252e-01, -9.5059e-02, -9.0844e-02, -7.0827e-02, -2.1200e-01,\n",
       "            -6.4505e-02, -6.8720e-02, -2.0884e-01, -2.0147e-01, -2.1727e-01,\n",
       "            -2.7631e-02, -6.5593e-03, -2.0884e-01, -1.8149e-02, -1.9409e-01,\n",
       "            -2.0568e-01, -8.6664e-03, -2.3778e-04, -2.0568e-01,  3.5583e-02,\n",
       "            -1.8250e-01,  4.4012e-02, -1.8567e-01,  7.3512e-02, -1.8040e-01,\n",
       "             7.7726e-02, -1.7513e-01,  1.0090e-01, -1.8250e-01, -1.6038e-01,\n",
       "             9.3529e-02, -1.6565e-01,  1.3673e-01, -1.4142e-01,  1.3883e-01,\n",
       "             1.3883e-01, -1.4563e-01, -1.2350e-01,  1.3883e-01, -9.9273e-02,\n",
       "             1.3883e-01, -7.2934e-02,  1.3883e-01,  1.3883e-01,  1.3883e-01,\n",
       "             1.3883e-01,  1.3883e-01,  1.3883e-01],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([-6.5872e-01,  1.6170e+00,  1.6170e+00,  1.3494e+00, -6.5872e-01,\n",
       "            -6.5872e-01,  1.8877e+00, -6.5872e-01,  1.0661e+01,  1.3498e+01,\n",
       "             1.4448e+01,  1.4448e+01, -6.5872e-01,  1.9109e+00,  6.4981e-01,\n",
       "             6.4981e-01,  1.9109e+00,  1.9109e+00,  6.4981e-01,  6.4981e-01,\n",
       "             6.4981e-01,  1.9109e+00,  6.4981e-01,  1.9109e+00,  1.9109e+00,\n",
       "            -6.4397e-01, -1.2877e-01, -5.8075e-01, -2.8049e-01,  1.0101e+00,\n",
       "             2.2133e+00,  3.0393e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "             1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "             1.7044e+00,  3.0393e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  1.7044e+00,  1.7044e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "             3.0393e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,\n",
       "             3.0393e+00,  1.7044e+00,  1.7044e+00,  3.0393e+00,  3.0393e+00,\n",
       "             1.7044e+00,  3.0393e+00,  1.7044e+00,  3.0393e+00,  1.7044e+00,\n",
       "             3.0393e+00,  1.5538e+00,  3.2005e-01, -5.0068e-01, -5.6600e-01,\n",
       "            -2.7733e-01, -5.9972e-01, -5.4914e-01, -1.3299e-01, -2.3416e-02,\n",
       "            -4.3957e-01,  9.6690e-02, -2.6363e-01, -8.8737e-02, -9.7199e-03,\n",
       "             2.7685e-01,  1.6496e+00,  1.6496e+00,  1.7697e+00,  6.8036e-01,\n",
       "            -5.5336e-01,  1.0933e-01, -2.3940e-01,  2.9265e-01,  4.5490e-01,\n",
       "             1.8730e-01,  4.2856e-01,  9.9538e-01,  6.0978e-01,  9.9538e-01,\n",
       "             8.7527e-01,  8.7527e-01,  8.7527e-01,  3.0740e-01,  3.0740e-01,\n",
       "             8.7527e-01,  8.7527e-01,  3.0740e-01,  3.0740e-01,  8.7527e-01,\n",
       "             3.0740e-01,  3.0740e-01,  4.7492e-01,  3.8744e-02, -4.4273e-01,\n",
       "            -4.9857e-01, -3.5950e-01, -5.3756e-01, -5.5863e-01, -4.2798e-01,\n",
       "            -5.6073e-01, -5.4914e-01, -5.2702e-01, -4.9225e-01, -2.9208e-01,\n",
       "            -2.1095e-01, -4.4063e-01, -1.6670e-01, -2.6784e-01,  2.3681e-01,\n",
       "             5.4867e-01,  1.3146e-01,  6.9933e-01,  6.9933e-01,  4.0538e-01,\n",
       "             4.3383e-01,  6.9933e-01,  5.3813e-01,  6.9933e-01,  6.9933e-01,\n",
       "             5.3813e-01,  5.3813e-01,  6.9933e-01,  6.9933e-01,  6.9933e-01,\n",
       "             6.9933e-01,  6.9933e-01,  6.9933e-01,  5.3813e-01,  6.9933e-01,\n",
       "             6.9933e-01,  5.3813e-01,  5.3813e-01,  6.9933e-01,  5.3813e-01,\n",
       "             6.9933e-01,  6.9933e-01,  5.3813e-01,  5.3813e-01,  6.9933e-01,\n",
       "             5.3813e-01,  6.9933e-01,  5.3813e-01,  5.3813e-01, -4.2380e-02,\n",
       "             1.7992e-01,  1.7992e-01,  1.7992e-01, -4.2380e-02, -4.2380e-02,\n",
       "            -4.2380e-02,  1.7992e-01, -4.2380e-02,  1.7992e-01,  1.7992e-01,\n",
       "            -4.2380e-02, -2.6890e-01, -3.2263e-01, -1.8777e-01, -2.4045e-01,\n",
       "            -4.1640e-01, -4.6065e-01, -5.4493e-01, -5.5863e-01, -5.4493e-01,\n",
       "            -4.1956e-01, -3.9638e-01, -3.4897e-01, -3.2790e-01, -2.9418e-01,\n",
       "            -4.5854e-01, -4.3747e-01, -3.7004e-01, -3.2474e-01,  2.1996e-01,\n",
       "            -1.7618e-01, -1.4352e-01,  3.8431e-01, -9.4005e-02,  3.8431e-01,\n",
       "             1.4512e-02,  3.8431e-01,  3.8431e-01,  3.8431e-01,  1.5042e-01,\n",
       "             2.2312e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "             2.7158e-01,  3.8431e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,\n",
       "             2.7158e-01,  2.7158e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "             3.8431e-01,  3.8431e-01,  3.8431e-01,  3.8431e-01,  3.8431e-01,\n",
       "             3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,\n",
       "             2.7158e-01,  3.8431e-01,  2.7158e-01,  3.8431e-01,  2.7158e-01,\n",
       "             3.8431e-01,  2.7158e-01,  2.7158e-01,  3.8431e-01,  3.8431e-01,\n",
       "             3.8431e-01,  3.8431e-01,  2.7158e-01,  2.7158e-01,  4.2119e-01,\n",
       "             2.3492e+00,  4.2646e-01,  2.9371e-01,  4.2646e-01,  1.6381e+00,\n",
       "             4.2646e-01,  1.2956e+00,  1.7676e-01,  3.0424e-01,  2.0731e-01,\n",
       "             1.7571e-01,  8.2994e-02, -9.4005e-02, -1.5722e-01, -2.7311e-01,\n",
       "            -2.0358e-01, -2.2149e-01, -2.2991e-01, -3.8374e-01, -2.2149e-01,\n",
       "            -3.7847e-01, -1.8461e-01, -3.7741e-01, -1.2140e-01, -3.5950e-01,\n",
       "            -3.2898e-02, -2.9840e-01,  1.8414e-01,  7.1371e-03,  4.2119e-01,\n",
       "             6.9297e-02,  4.2119e-01,  1.5358e-01,  4.2119e-01,  2.1047e-01,\n",
       "             4.2119e-01,  2.1047e-01,  2.1047e-01,  4.2119e-01,  1.3378e+00,\n",
       "             1.3378e+00,  1.3378e+00,  3.1478e-01,  7.5619e-02, -3.9220e-02,\n",
       "            -1.6143e-01, -3.3422e-01, -3.5634e-01, -2.5625e-01, -3.5740e-01,\n",
       "            -3.8268e-01, -3.9743e-01, -4.3957e-01, -4.4590e-01, -3.4581e-01,\n",
       "            -3.5529e-01, -4.9541e-01, -4.8909e-01, -4.6381e-01, -3.7636e-01,\n",
       "             1.2405e-02, -3.4370e-01, -3.1420e-01, -2.9629e-01,  2.9792e-01,\n",
       "             3.5692e-01,  3.5692e-01,  3.5692e-01,  3.5692e-01,  3.3476e-02,\n",
       "             3.5692e-01,  3.3476e-02,  3.5692e-01,  3.3476e-02,  3.5692e-01,\n",
       "             3.3476e-02,  3.5692e-01,  3.5692e-01,  3.3476e-02,  3.3476e-02,\n",
       "             3.3476e-02,  3.5692e-01,  3.5692e-01,  3.3476e-02,  3.3476e-02,\n",
       "             3.3476e-02,  3.3476e-02,  3.3476e-02,  3.5692e-01,  3.5692e-01,\n",
       "             3.5692e-01,  3.3476e-02,  3.3476e-02,  3.3476e-02,  2.4208e-01,\n",
       "             5.4548e-02,  5.4548e-02,  2.4208e-01,  5.4548e-02,  1.7887e-01,\n",
       "             1.2514e-01,  5.4548e-02, -1.1718e-01, -4.0691e-01, -3.5529e-01,\n",
       "            -5.0595e-01, -4.0059e-01, -3.6477e-01, -5.2175e-01, -3.1841e-01,\n",
       "            -3.0893e-01, -5.2175e-01, -2.9524e-01, -5.1543e-01, -4.8698e-01,\n",
       "            -4.7118e-01, -4.0797e-01,  1.5042e-01, -3.0577e-01, -1.8356e-01,\n",
       "            -1.8356e-01, -1.8356e-01,  1.5042e-01,  1.5042e-01,  1.5042e-01,\n",
       "            -1.8356e-01, -1.8356e-01,  1.5042e-01,  1.5042e-01,  1.5042e-01,\n",
       "            -1.8356e-01,  1.5042e-01, -1.8356e-01,  1.5042e-01, -1.8356e-01,\n",
       "             1.5042e-01,  1.5042e-01, -1.8356e-01,  1.5042e-01, -1.8356e-01,\n",
       "             1.5042e-01,  1.5042e-01, -1.8356e-01, -1.8356e-01,  2.7685e-01,\n",
       "             2.7685e-01,  2.6631e-01,  4.3172e-01,  1.8414e-01,  2.5048e-02,\n",
       "             1.0090e-01, -1.2915e-03, -2.1309e-02, -1.1613e-01, -2.3518e-01,\n",
       "            -2.6679e-01, -3.0050e-01, -2.2149e-01, -3.0682e-01, -4.1218e-01,\n",
       "            -3.2895e-01, -4.3431e-01, -3.5213e-01, -3.8163e-01, -5.0279e-01,\n",
       "            -5.1543e-01, -3.8163e-01, -5.2070e-01, -3.8268e-01, -3.8374e-01,\n",
       "            -3.5740e-01, -5.2807e-01, -3.5529e-01, -5.2491e-01, -5.3018e-01,\n",
       "            -3.0999e-01, -4.8698e-01, -4.8698e-01, -4.9225e-01, -1.2877e-01,\n",
       "            -6.0291e-02, -4.3957e-01, -7.2934e-02, -3.6688e-01, -7.2934e-02,\n",
       "            -2.8786e-01, -2.8786e-01, -2.8786e-01, -7.2934e-02, -7.2934e-02,\n",
       "            -2.8786e-01, -7.2934e-02,  2.7738e+00,  3.5587e-01,  1.7487e+00,\n",
       "             1.4726e+00,  2.9160e-01,  1.0691e+00,  2.3787e-01,  1.5358e-01,\n",
       "             1.3356e-01,  1.7149e-01, -5.1863e-02, -1.8777e-01, -1.9620e-01,\n",
       "            -2.2149e-01, -3.1315e-01, -2.3729e-01, -2.6258e-01, -3.7847e-01,\n",
       "            -2.8154e-01, -3.9849e-01, -4.0165e-01, -4.1745e-01, -3.0472e-01,\n",
       "            -4.2377e-01, -4.2904e-01, -4.3325e-01, -3.0156e-01, -4.4590e-01,\n",
       "            -2.8470e-01, -4.4800e-01, -2.8891e-01, -4.4379e-01, -4.2377e-01,\n",
       "            -4.0586e-01, -3.5529e-01,  3.6637e-02, -2.9313e-01,  3.6637e-02,\n",
       "             3.6637e-02, -2.9313e-01,  3.6637e-02, -2.9313e-01,  3.6637e-02,\n",
       "            -2.9313e-01, -2.9313e-01,  3.6637e-02,  3.6637e-02, -2.9313e-01,\n",
       "             3.6637e-02, -2.9313e-01, -2.9313e-01, -2.9313e-01,  3.6637e-02],\n",
       "           grad_fn=<SplitWithSizesBackward0>),\n",
       "    tensor([ 7.6044e-01,  1.8203e+00,  1.8203e+00,  1.8203e+00,  7.6044e-01,\n",
       "             7.6044e-01,  1.8203e+00,  7.6044e-01,  7.6044e-01,  1.8203e+00,\n",
       "             1.8203e+00,  7.6044e-01,  1.8203e+00,  1.8203e+00,  1.8203e+00,\n",
       "             7.6044e-01,  1.8203e+00,  7.6044e-01,  7.6044e-01,  7.6044e-01,\n",
       "             1.5232e+00,  1.2409e+00,  7.6044e-01,  9.8063e-01,  6.2874e-01,\n",
       "             7.4885e-01,  4.0012e-01,  3.1899e-01,  2.7474e-01,  3.0214e-01,\n",
       "             2.6315e-01,  2.7264e-01,  4.9915e-01,  4.2962e-01,  9.6693e-01,\n",
       "             7.6044e-01,  9.6693e-01,  6.4454e-01,  9.0688e-01,  9.0688e-01,\n",
       "             6.4454e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,  9.0688e-01,\n",
       "             6.4454e-01,  9.0688e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,\n",
       "             6.4454e-01,  9.0688e-01,  6.4454e-01,  6.4454e-01,  6.4454e-01,\n",
       "             9.0688e-01,  9.0688e-01,  6.4454e-01,  7.6149e-01,  6.0135e-01,\n",
       "             2.8844e-01,  1.4410e-01,  1.6619e-02, -2.7631e-02, -4.7648e-02,\n",
       "            -1.3299e-01, -1.2034e-01, -2.2359e-01, -2.1833e-01, -2.6995e-01,\n",
       "            -2.8575e-01, -2.5520e-01, -2.5309e-01, -2.8681e-01, -2.0568e-01,\n",
       "            -1.3615e-01, -7.8202e-02,  2.1574e-01,  6.8563e-01,  2.1574e-01,\n",
       "             2.1574e-01,  1.4484e+00,  1.2809e+00,  2.1574e-01,  1.1165e+00,\n",
       "             6.8563e-01,  2.1574e-01,  5.5920e-01,  4.3067e-01,  2.9371e-01,\n",
       "             3.1478e-01,  2.0310e-01,  1.2830e-01,  9.4583e-02,  5.9815e-02,\n",
       "            -4.1327e-02, -1.3615e-01, -2.0568e-01, -2.0779e-01, -3.3632e-01,\n",
       "            -3.6266e-01, -3.5950e-01, -3.7636e-01, -3.9322e-01, -3.7847e-01,\n",
       "            -3.7004e-01, -3.7847e-01, -3.7320e-01, -3.6056e-01, -3.9111e-01,\n",
       "            -3.3211e-01, -3.6266e-01, -2.9734e-01, -3.2895e-01,  2.3576e-01,\n",
       "             5.8028e-01,  2.3576e-01,  1.6813e+00,  1.3715e+00,  9.6272e-01,\n",
       "             6.9722e-01,  4.2646e-01,  2.3576e-01,  3.8115e-01,  2.3576e-01,\n",
       "             1.8624e-01,  2.0626e-01,  1.2724e-01,  8.8262e-02,  5.2440e-02,\n",
       "             7.1371e-03, -9.7199e-03, -3.7113e-02, -7.2934e-02, -8.9791e-02,\n",
       "            -1.2034e-01, -1.5195e-01, -2.0884e-01, -2.4572e-01, -2.9208e-01,\n",
       "            -3.0577e-01, -3.2052e-01, -3.2684e-01, -3.4897e-01, -3.5213e-01,\n",
       "            -3.7531e-01, -3.6266e-01, -3.6056e-01, -3.5213e-01, -3.7004e-01,\n",
       "            -3.4897e-01, -3.3843e-01, -3.1947e-01,  4.0749e-01,  3.9590e-01,\n",
       "             4.0749e-01,  3.9590e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  3.9590e-01,  3.9590e-01,  4.0749e-01,  3.9590e-01,\n",
       "             4.0749e-01,  3.9590e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,\n",
       "             3.9590e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,\n",
       "             3.9590e-01,  4.0749e-01,  3.9590e-01,  4.0749e-01,  4.0749e-01,\n",
       "             4.0749e-01,  4.0749e-01,  4.0749e-01,  3.9590e-01,  3.9590e-01,\n",
       "             4.0749e-01,  3.9590e-01,  6.0556e-01,  4.1803e-01,  3.9590e-01,\n",
       "             4.0855e-01,  3.9590e-01,  2.5578e-01,  2.1469e-01,  1.8098e-01,\n",
       "             1.3356e-01,  2.9228e-03, -5.9237e-02, -9.7166e-02, -1.2350e-01,\n",
       "            -2.2465e-01, -2.6363e-01, -3.0050e-01, -3.0261e-01, -3.1736e-01,\n",
       "            -3.5950e-01, -3.8900e-01, -3.8584e-01, -4.0691e-01, -4.1429e-01,\n",
       "            -4.3431e-01, -4.4590e-01, -4.5748e-01, -4.7118e-01, -4.6275e-01,\n",
       "            -4.5854e-01, -4.7118e-01, -4.5854e-01, -4.5116e-01, -4.7856e-01,\n",
       "             2.4524e-01,  2.7474e-01,  2.4524e-01,  2.7474e-01,  2.7474e-01,\n",
       "             2.4524e-01,  2.7474e-01,  2.4524e-01,  2.4524e-01,  2.7474e-01,\n",
       "             2.4524e-01,  2.7474e-01,  2.4524e-01,  2.7474e-01,  2.4524e-01,\n",
       "             2.7474e-01,  2.4524e-01,  2.7474e-01,  2.4524e-01,  4.1908e-01,\n",
       "             2.7474e-01,  4.1065e-01,  2.7474e-01,  2.4524e-01,  2.1364e-01,\n",
       "             2.4946e-01,  1.3673e-01,  7.9833e-02,  1.0933e-01,  5.6655e-02,\n",
       "            -2.0256e-02, -1.1508e-01, -1.5617e-01, -1.5511e-01, -2.0147e-01,\n",
       "            -2.0252e-01, -2.3729e-01, -2.4993e-01, -2.7522e-01, -2.8470e-01,\n",
       "            -3.1315e-01, -3.1631e-01, -3.4370e-01, -3.6266e-01, -3.7004e-01,\n",
       "            -4.1745e-01, -4.2904e-01, -4.5222e-01, -4.5222e-01, -4.6381e-01,\n",
       "            -4.8488e-01, -4.9436e-01, -4.9225e-01, -5.0806e-01, -5.2386e-01,\n",
       "            -5.0595e-01, -5.1016e-01, -5.3123e-01,  3.2531e-01,  5.3076e-01,\n",
       "             3.2531e-01,  3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "             3.2531e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "             5.3076e-01,  3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,\n",
       "             5.3076e-01,  5.3076e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,\n",
       "             3.2531e-01,  3.2531e-01,  5.3076e-01,  3.2531e-01,  5.3076e-01,\n",
       "             3.2531e-01,  4.8546e-01,  4.2856e-01,  2.2733e-01,  3.3585e-01,\n",
       "             1.5990e-01,  1.2303e-01,  7.9833e-02,  2.0837e-01,  1.6833e-01,\n",
       "             1.3251e-01,  9.7744e-02,  6.4030e-02, -7.8202e-02,  4.0851e-02,\n",
       "            -1.1718e-01,  9.2443e-03, -1.4247e-01, -7.6127e-03, -1.6143e-01,\n",
       "            -3.3952e-02, -5.9237e-02, -2.2991e-01, -2.6258e-01, -3.0577e-01,\n",
       "            -3.1736e-01, -1.1824e-01, -1.3193e-01, -3.5950e-01, -1.3615e-01,\n",
       "            -1.3299e-01, -3.8374e-01, -1.2667e-01, -1.2561e-01, -3.9638e-01,\n",
       "            -1.1192e-01, -1.0454e-01, -4.0691e-01, -9.1898e-02, -5.2916e-02,\n",
       "             3.8431e-01, -5.2916e-02,  1.8287e+00, -5.2916e-02, -5.2916e-02,\n",
       "             1.5738e+00, -5.2916e-02,  1.3736e+00, -5.2916e-02,  1.2714e+00,\n",
       "            -5.2916e-02, -5.2916e-02, -5.2916e-02,  1.0301e+00, -5.2916e-02,\n",
       "            -5.2916e-02,  8.0363e-01,  7.3515e-01, -5.2916e-02,  6.6561e-01,\n",
       "            -5.2916e-02,  6.0662e-01, -5.2916e-02,  5.4656e-01,  4.9072e-01,\n",
       "             9.5636e-02,  2.8844e-01, -6.0291e-02,  2.4314e-01,  2.0099e-01,\n",
       "            -8.6630e-02, -1.2983e-01, -2.0041e-01, -1.7513e-01,  5.2440e-02,\n",
       "            -2.4361e-01, -8.6664e-03, -2.9418e-01, -2.9629e-01, -3.3316e-01,\n",
       "            -1.1192e-01, -1.3088e-01, -3.7215e-01, -1.6881e-01, -1.8567e-01,\n",
       "            -2.0252e-01, -2.1200e-01, -2.2465e-01, -4.7434e-01, -4.7750e-01,\n",
       "            -2.4993e-01, -4.9752e-01, -4.9963e-01, -2.5836e-01, -5.1016e-01,\n",
       "            -2.6574e-01, -5.1332e-01, -2.6468e-01, -5.2070e-01, -5.2597e-01,\n",
       "            -5.2386e-01, -2.5099e-01, -5.2597e-01, -2.0568e-01,  4.2119e-01,\n",
       "            -2.0568e-01,  4.2119e-01, -2.0568e-01,  4.2119e-01,  4.2119e-01,\n",
       "             4.2119e-01, -2.0568e-01,  4.2119e-01, -2.0568e-01, -2.0568e-01,\n",
       "            -2.0568e-01, -2.0568e-01, -2.0568e-01,  4.2119e-01, -2.0568e-01,\n",
       "             4.2119e-01,  4.2119e-01, -2.0568e-01,  3.7483e-01, -2.0568e-01,\n",
       "             2.2101e-01, -2.0568e-01,  1.7992e-01, -2.0568e-01,  1.3778e-01,\n",
       "            -2.5625e-01,  5.9815e-02, -3.1631e-01, -8.6664e-03, -3.0577e-01,\n",
       "            -3.7109e-01, -6.2398e-02, -3.5424e-01, -8.9791e-02, -3.9638e-01,\n",
       "            -1.1508e-01, -1.6038e-01, -4.4484e-01, -1.8250e-01, -4.4379e-01,\n",
       "            -2.1306e-01, -4.8277e-01, -2.4256e-01, -2.7416e-01, -5.1332e-01,\n",
       "            -2.8470e-01, -2.9524e-01, -5.3018e-01, -2.9734e-01, -5.3229e-01,\n",
       "            -3.0156e-01, -5.4072e-01, -5.4177e-01, -3.1209e-01, -5.4598e-01,\n",
       "            -3.1315e-01, -5.5020e-01, -5.5125e-01, -3.0472e-01,  4.0749e-01,\n",
       "             4.0749e-01,  4.0749e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "             4.0749e-01,  4.0749e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "            -5.4072e-01,  4.0749e-01,  4.0749e-01, -5.4072e-01, -5.4072e-01,\n",
       "             4.0749e-01, -5.4072e-01, -5.4072e-01,  4.0749e-01, -5.4072e-01,\n",
       "             2.8633e-01, -5.4072e-01,  2.6315e-01,  2.3260e-01, -5.4072e-01,\n",
       "             1.9151e-01,  1.5253e-01, -5.9761e-01, -5.4072e-01, -5.7654e-01,\n",
       "             4.4012e-02, -5.9129e-01, -2.3778e-04, -5.7022e-01, -5.7022e-01,\n",
       "            -5.7759e-01, -7.2934e-02, -5.7864e-01, -5.5125e-01, -1.2034e-01,\n",
       "            -1.2983e-01, -5.7443e-01, -1.4458e-01, -5.7759e-01, -1.8356e-01,\n",
       "            -1.8040e-01, -5.9234e-01, -1.9831e-01, -5.7970e-01, -1.9515e-01,\n",
       "            -5.7759e-01, -1.9936e-01, -5.7654e-01, -5.7864e-01, -2.0358e-01,\n",
       "            -5.8602e-01, -2.0358e-01, -2.0568e-01, -5.7759e-01, -2.1095e-01,\n",
       "            -5.8075e-01, -1.9515e-01, -2.0252e-01, -5.7759e-01,  5.6447e-01,\n",
       "            -9.7689e-01,  5.2128e-01,  4.6860e-01,  4.7703e-01,  4.4753e-01,\n",
       "            -9.7689e-01,  4.1803e-01, -9.7689e-01, -9.7689e-01,  3.5271e-01,\n",
       "             2.9265e-01, -9.7689e-01,  2.6947e-01, -9.7689e-01,  2.2628e-01,\n",
       "            -9.7689e-01,  1.9467e-01, -9.7689e-01,  1.7571e-01, -9.7689e-01,\n",
       "             1.5569e-01,  1.3989e-01, -9.7689e-01, -9.7689e-01,  7.7726e-02,\n",
       "            -9.7689e-01,  6.1922e-02,  4.7173e-02, -9.7689e-01,  4.0851e-02,\n",
       "            -9.7689e-01,  2.5048e-02, -2.3449e-03, -9.7689e-01, -1.2881e-02,\n",
       "            -9.7689e-01, -4.4488e-02, -9.7689e-01, -4.8702e-02, -5.8184e-02,\n",
       "            -9.7689e-01, -6.5559e-02, -9.7689e-01, -9.7689e-01, -8.3469e-02,\n",
       "            -9.7689e-01, -8.0309e-02, -8.4523e-02, -9.7689e-01, -8.9791e-02,\n",
       "            -9.7166e-02, -1.0033e-01, -1.1192e-01, -9.7689e-01, -1.0243e-01,\n",
       "            -9.7689e-01, -9.7689e-01, -1.0454e-01, -9.7689e-01, -1.0033e-01,\n",
       "            -9.7689e-01, -9.9273e-02, -9.7689e-01, -9.7689e-01, -9.5059e-02,\n",
       "            -9.7689e-01, -8.8737e-02, -9.7689e-01],\n",
       "           grad_fn=<SplitWithSizesBackward0>)]},\n",
       "  'Query Point': {'Log Moneyness': tensor([-1.9007,  0.6870,  0.8618, -1.4475], grad_fn=<SliceBackward0>),\n",
       "   'Time to Maturity': tensor([-0.7412,  1.0536, -0.8894,  0.9511], grad_fn=<SliceBackward0>)},\n",
       "  'Target Volatility': tensor([0.3204, 0.2626, 0.5944, 0.3362])})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SurfaceEmbedding(nn.Module):\n",
    "    def __init__(self, grid_dim, d_embedding, branch_channels, num_pre_encoder_blocks, momentum=0.1):\n",
    "        super(SurfaceEmbedding, self).__init__()\n",
    "        # Initialize the InputEmbedding module\n",
    "        self.input_embedding = InputEmbedding(grid_dim, d_embedding, momentum)\n",
    "        \n",
    "        # Initialize multiple PreEncoder blocks\n",
    "        self.pre_encoders = nn.ModuleList([\n",
    "            PreEncoder(d_embedding, branch_channels, grid_dim) for _ in range(num_pre_encoder_blocks)\n",
    "        ])\n",
    "        \n",
    "        # Initialize positional embedding, adjusted to apply before flattening\n",
    "        self.positional_embedding = SurfacePositionalEmbedding(grid_dim, d_embedding)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Process batch through InputEmbedding to get initial embeddings and the processed batch\n",
    "        embedding_batch, processed_batch = self.input_embedding(batch)\n",
    "        \n",
    "        # Sequentially pass the output through each PreEncoder block\n",
    "        pre_encoded_batch = embedding_batch\n",
    "        for pre_encoder in self.pre_encoders:\n",
    "            pre_encoded_batch = pre_encoder(pre_encoded_batch)\n",
    "        \n",
    "        # Apply positional embedding to the output of the last PreEncoder block\n",
    "        positional_embedded_batch = self.positional_embedding(pre_encoded_batch)\n",
    "        \n",
    "        # Flatten the 2D spatial structure into a sequence of tokens\n",
    "        batch_size, num_channels, height, width = positional_embedded_batch.shape\n",
    "        tokenized_positional_embedded_batch = positional_embedded_batch.view(batch_size, num_channels, height * width).transpose(1, 2)\n",
    "        \n",
    "        # The final output is now suitable for processing by transformer encoders\n",
    "        return tokenized_positional_embedded_batch, processed_batch\n",
    "\n",
    "\n",
    "# Example usage\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "grid_dim = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Grid Dimension']\n",
    "d_embedding = HYPERPARAMETERS['Input Embedding']['Surface Embedding']['Channels Dimension']\n",
    "branch_channels = HYPERPARAMETERS['Input Embedding']['Pre-Encoder']['Branch Channels Dimension']\n",
    "num_pre_encoder_blocks = HYPERPARAMETERS['Input Embedding']['Pre-Encoder']['Number of Blocks']\n",
    "\n",
    "surface_embedding = SurfaceEmbedding(grid_dim, d_embedding, branch_channels, num_pre_encoder_blocks)\n",
    "tokenized_positional_embedded_batch, processed_batch = surface_embedding(batch)\n",
    "tokenized_positional_embedded_batch, processed_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2469, -0.3497, -1.4286,  1.3753, -0.9483,  1.2850, -0.9019,\n",
       "           0.7213],\n",
       "         [-0.1632,  0.3022, -1.6315,  0.8646, -0.4627,  0.6740, -1.1551,\n",
       "           1.5716],\n",
       "         [-0.3699,  0.1405, -1.2775,  0.3203, -0.4004,  0.9784, -1.2458,\n",
       "           1.8545],\n",
       "         [ 0.6897, -0.1253, -0.3942,  1.4151, -1.2410,  1.0470, -1.6302,\n",
       "           0.2389],\n",
       "         [ 0.3982, -0.3709, -1.0674,  1.4139, -1.0317,  1.2783, -1.2252,\n",
       "           0.6049],\n",
       "         [ 0.6897, -0.4072, -1.0200,  1.2286, -1.2428,  0.6611, -1.1428,\n",
       "           1.2333],\n",
       "         [ 1.0847, -0.7412, -0.2555,  1.7976, -1.0018,  0.4697, -1.3238,\n",
       "          -0.0297],\n",
       "         [ 0.6992, -0.6551,  0.4165,  1.2582, -1.3620,  0.9885, -1.5638,\n",
       "           0.2185],\n",
       "         [ 0.6872, -0.4694, -0.9725,  1.0512, -1.1934,  1.3166, -1.2126,\n",
       "           0.7928]],\n",
       "\n",
       "        [[-1.4550,  0.5706, -0.7268, -0.1802,  0.6716,  0.4818, -1.1145,\n",
       "           1.7525],\n",
       "         [-1.4392,  0.8674, -0.5820, -0.2491,  0.5831,  0.4650, -1.2642,\n",
       "           1.6190],\n",
       "         [-1.2970,  1.1358, -0.3747, -0.5670,  0.4052,  0.9636, -1.4441,\n",
       "           1.1782],\n",
       "         [-1.4109,  0.9829, -0.8179, -0.1247,  0.0695,  0.9421, -1.1247,\n",
       "           1.4837],\n",
       "         [-0.8403,  0.2662, -0.7749,  1.4573,  0.1030,  0.6948, -1.7937,\n",
       "           0.8876],\n",
       "         [-0.6679, -0.1744,  0.4363,  1.9704, -0.3684,  0.5878, -1.7220,\n",
       "          -0.0618],\n",
       "         [-0.9869,  0.4513, -1.3399,  0.4725,  0.1806,  0.5598, -1.1244,\n",
       "           1.7870],\n",
       "         [-0.3319, -0.3850, -0.4032,  1.8695,  0.0470,  0.9655, -1.7747,\n",
       "           0.0129],\n",
       "         [-0.2816, -0.4557,  0.9092,  1.5975, -0.1586,  0.6649, -1.9370,\n",
       "          -0.3388]],\n",
       "\n",
       "        [[-1.2719, -1.2480,  0.1443,  0.5464, -0.8874,  0.7552,  0.1985,\n",
       "           1.7630],\n",
       "         [-0.0869, -1.3321,  1.6306, -0.4642, -1.2642,  1.0996, -0.2652,\n",
       "           0.6824],\n",
       "         [-0.5187, -1.0991,  1.9357,  0.4991, -1.4554,  0.3876, -0.2115,\n",
       "           0.4622],\n",
       "         [-0.6537,  0.0753,  0.2875, -0.4616, -1.6389,  1.1301, -0.4902,\n",
       "           1.7515],\n",
       "         [ 0.1195, -1.4088,  1.1551,  0.1467, -1.5120,  0.3722, -0.3265,\n",
       "           1.4539],\n",
       "         [-0.4025, -1.0836,  1.9892, -0.3202, -1.2996,  0.8226, -0.1654,\n",
       "           0.4596],\n",
       "         [-1.0663, -0.5908, -0.1330, -0.4022, -0.7267,  0.9971, -0.2568,\n",
       "           2.1786],\n",
       "         [-1.1889, -0.4350, -0.2438, -0.0085, -0.5405,  0.2408, -0.2574,\n",
       "           2.4333],\n",
       "         [ 0.0290, -1.2664,  2.0464, -0.5003, -1.1735,  0.7510, -0.0130,\n",
       "           0.1268]],\n",
       "\n",
       "        [[-1.4620,  0.5585, -0.6269,  0.0778, -0.2257,  0.5330, -0.8696,\n",
       "           2.0150],\n",
       "         [-1.5548,  0.3134, -0.3994,  0.2360, -0.0096,  0.1755, -0.8757,\n",
       "           2.1145],\n",
       "         [-1.1746, -0.4055,  1.5299,  0.2818, -0.9825,  0.6377, -1.0961,\n",
       "           1.2093],\n",
       "         [-1.4726, -0.0205, -0.4787,  0.4514, -0.1326,  0.2490, -0.7699,\n",
       "           2.1739],\n",
       "         [ 0.3890, -0.1720, -0.2124,  1.4282, -1.4537,  0.0548, -1.3619,\n",
       "           1.3279],\n",
       "         [-0.7821, -0.6571,  1.5669,  0.4984, -1.2364,  0.6794, -1.0976,\n",
       "           1.0286],\n",
       "         [-0.6939, -0.1006, -0.6373,  0.7174, -1.2281,  1.0047, -0.8784,\n",
       "           1.8161],\n",
       "         [-0.6472, -0.6394,  0.8514,  1.0599, -1.4136,  0.7640, -1.1584,\n",
       "           1.1833],\n",
       "         [-1.1798, -0.2777,  0.9397,  1.4665, -1.0273,  0.5276, -1.2400,\n",
       "           0.7911]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ScaledResidualNorm(nn.Module):\n",
    "    def __init__(self, d_embedding):\n",
    "        super(ScaledResidualNorm, self).__init__()\n",
    "        self.scale = nn.Parameter(torch.tensor(1.0))\n",
    "        self.norm = nn.LayerNorm(d_embedding)\n",
    "\n",
    "    def forward(self, x, sublayer_output):\n",
    "        return self.norm(x + self.scale * sublayer_output)\n",
    "\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, d_embedding, hidden_dim, dropout):\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(d_embedding, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, d_embedding),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.feedforward(x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_embedding, n_heads, hidden_dim, dropout, external_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.self_attention = nn.MultiheadAttention(embed_dim=d_embedding, num_heads=n_heads, batch_first=True)\n",
    "        self.scaled_residual_norm1 = ScaledResidualNorm(d_embedding)\n",
    "        self.feedforward1 = FeedForwardNetwork(d_embedding, hidden_dim, dropout)\n",
    "        self.scaled_residual_norm2 = ScaledResidualNorm(d_embedding)\n",
    "        \n",
    "        self.external_attention = nn.MultiheadAttention(embed_dim=d_embedding, num_heads=n_heads, kdim=external_dim, vdim=external_dim, batch_first=True)\n",
    "        self.scaled_residual_norm3 = ScaledResidualNorm(d_embedding)\n",
    "        self.feedforward2 = FeedForwardNetwork(d_embedding, hidden_dim, dropout)\n",
    "        self.scaled_residual_norm4 = ScaledResidualNorm(d_embedding)\n",
    "\n",
    "    def forward(self, surface_tokens, external_features):\n",
    "        # Self-attention block\n",
    "        self_attn_output, _ = self.self_attention(surface_tokens, surface_tokens, surface_tokens)\n",
    "        x = self.scaled_residual_norm1(surface_tokens, self_attn_output)\n",
    "        \n",
    "        # Feedforward network block 1\n",
    "        ff_output = self.feedforward1(x)\n",
    "        x = self.scaled_residual_norm2(x, ff_output)\n",
    "        \n",
    "        # External attention block\n",
    "        ext_attn_output, _ = self.external_attention(x, external_features, external_features)\n",
    "        x = self.scaled_residual_norm3(x, ext_attn_output)\n",
    "        \n",
    "        # Feedforward network block 2\n",
    "        ff_output = self.feedforward2(x)\n",
    "        x = self.scaled_residual_norm4(x, ff_output)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class SurfaceEncoding(nn.Module):\n",
    "    def __init__(self, d_embedding, n_heads, hidden_dim, dropout, external_dim, num_encoder_blocks):\n",
    "        super(SurfaceEncoding, self).__init__()\n",
    "        self.encoders = nn.ModuleList([\n",
    "            Encoder(d_embedding, n_heads, hidden_dim, dropout, external_dim) for _ in range(num_encoder_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, tokenized_positional_embedded_batch, processed_batch):\n",
    "        # Extract market features from processed batch and create external_features tensor\n",
    "        market_features = processed_batch['Market Features']\n",
    "        external_features = torch.stack([\n",
    "            market_features['Market Return'],\n",
    "            market_features['Market Volatility'],\n",
    "            market_features['Treasury Rate']\n",
    "        ], dim=-1).unsqueeze(1)  # (batch, 1, features)\n",
    "        \n",
    "        # Pass the tokenized positional embeddings and external features through each encoder block\n",
    "        x = tokenized_positional_embedded_batch\n",
    "        for encoder in self.encoders:\n",
    "            x = encoder(x, external_features)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# Example usage\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "n_heads = HYPERPARAMETERS['Surface Encoding']['Encoder']['Number of Heads']\n",
    "hidden_dim = HYPERPARAMETERS['Surface Encoding']['Encoder']['Hidden Dimension']\n",
    "dropout = HYPERPARAMETERS['Surface Encoding']['Encoder']['Dropout']\n",
    "num_encoder_blocks = HYPERPARAMETERS['Surface Encoding']['Encoder']['Number of Blocks']\n",
    "external_dim = 3  # Assuming 3 market features\n",
    "\n",
    "surface_encoding = SurfaceEncoding(d_embedding, n_heads, hidden_dim, dropout, external_dim, num_encoder_blocks)\n",
    "encoded_surface = surface_encoding(tokenized_positional_embedded_batch, processed_batch)    \n",
    "encoded_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5042, -0.3693, -1.9808,  1.0166, -0.7196, -0.2118,  0.3608,  1.3998],\n",
       "        [ 1.4882,  0.0684, -1.4299,  0.5567, -1.2357, -0.6671,  0.0133,  1.2058],\n",
       "        [ 1.3204,  0.0949, -1.9956,  0.6253, -0.8096, -0.3823,  0.1181,  1.0289],\n",
       "        [ 0.4256, -0.2793, -1.4502,  1.0144, -1.1896, -0.5031,  0.2925,  1.6896]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "class PointEmbedding(nn.Module):\n",
    "    def __init__(self, d_embedding, surface_embedding):\n",
    "        super(PointEmbedding, self).__init__()\n",
    "        self.d_embedding = d_embedding\n",
    "        self.log_scale = surface_embedding.positional_embedding.log_scale  # Shared log_scale parameter from SurfacePositionalEmbedding\n",
    "        self.factor = nn.Parameter(torch.tensor(1.0))  # Learnable scale for the positional embedding contribution\n",
    "        self.learnable_embedding = nn.Parameter(torch.randn(d_embedding))  # Learnable embedding vector\n",
    "        self.layer_norm = nn.LayerNorm(d_embedding)  # Normalize across the embedding dimension\n",
    "        self.scaled_residual_norm = ScaledResidualNorm(d_embedding)  # Scaled residual normalization\n",
    "\n",
    "    def forward(self, query_point_batch):\n",
    "        log_moneyness = query_point_batch['Log Moneyness']\n",
    "        time_to_maturity = query_point_batch['Time to Maturity']\n",
    "\n",
    "        # Stack the query point coordinates\n",
    "        query_coords = torch.stack([log_moneyness, time_to_maturity], dim=-1)  # Shape: (batch_size, 2)\n",
    "\n",
    "        # Positional embedding calculation\n",
    "        scale = torch.exp(self.log_scale)\n",
    "        pos_enc = torch.zeros(query_coords.size(0), self.d_embedding, device=query_coords.device)\n",
    "\n",
    "        for i in range(self.d_embedding // 4):\n",
    "            div_factor = scale ** (4 * i / self.d_embedding)\n",
    "            pos_enc[:, 4 * i] = torch.sin(query_coords[:, 0] / div_factor)\n",
    "            pos_enc[:, 4 * i + 1] = torch.cos(query_coords[:, 0] / div_factor)\n",
    "            pos_enc[:, 4 * i + 2] = torch.sin(query_coords[:, 1] / div_factor)\n",
    "            pos_enc[:, 4 * i + 3] = torch.cos(query_coords[:, 1] / div_factor)\n",
    "\n",
    "        # Use ScaledResidualNorm to combine learnable embedding and positional encoding\n",
    "        point_embedded = self.scaled_residual_norm(self.learnable_embedding, pos_enc)\n",
    "\n",
    "        return point_embedded\n",
    "\n",
    "# Example usage:\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "point_embedding = PointEmbedding(d_embedding, surface_embedding)\n",
    "point_embedded = point_embedding(processed_batch['Query Point'])\n",
    "point_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.6697e-02, -1.0196e-01, -2.0467e+00,  9.5017e-01, -1.8322e-01,\n",
       "         -5.6851e-01,  3.3655e-01,  1.5570e+00],\n",
       "        [ 1.1735e+00,  3.5872e-01, -1.5941e+00,  5.4041e-01, -9.4090e-01,\n",
       "         -9.1696e-01, -1.1575e-02,  1.3909e+00],\n",
       "        [ 1.0623e+00,  1.8758e-01, -2.1339e+00,  5.3964e-01, -3.6191e-01,\n",
       "         -6.4388e-01,  1.5799e-01,  1.1921e+00],\n",
       "        [ 5.5675e-04, -4.4207e-02, -1.5026e+00,  1.0834e+00, -7.7097e-01,\n",
       "         -7.5784e-01,  1.5493e-01,  1.8367e+00]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PreDecoder(nn.Module):\n",
    "    def __init__(self, d_embedding, hidden_dim, dropout):\n",
    "        super(PreDecoder, self).__init__()\n",
    "        # Initialize the feedforward network\n",
    "        self.feedforward = FeedForwardNetwork(d_embedding, hidden_dim, dropout)\n",
    "        # Initialize the scaled residual normalization module\n",
    "        self.scaled_residual_norm = ScaledResidualNorm(d_embedding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Process the input through the feedforward network\n",
    "        feedforward_output = self.feedforward(x)\n",
    "        # Apply the scaled residual connection\n",
    "        output = self.scaled_residual_norm(x, feedforward_output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Example usage\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "hidden_dim = HYPERPARAMETERS['Query Embedding']['Pre-Decoder']['Hidden Dimension']\n",
    "dropout = HYPERPARAMETERS['Query Embedding']['Pre-Decoder']['Dropout']\n",
    "\n",
    "pre_decoder = PreDecoder(d_embedding, hidden_dim, dropout)\n",
    "pre_decoded_output = pre_decoder(point_embedded)  # Example input\n",
    "pre_decoded_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final BLock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7447, -0.0774, -1.7717,  1.0139, -1.1276, -0.3336,  0.1905,\n",
       "           1.3613]],\n",
       "\n",
       "        [[ 1.2842, -0.0804, -0.9078,  0.8424, -1.2601, -1.2203,  0.0255,\n",
       "           1.3164]],\n",
       "\n",
       "        [[ 1.4975, -0.0342, -1.5508,  0.7655, -0.8453, -0.9524,  0.0515,\n",
       "           1.0682]],\n",
       "\n",
       "        [[ 0.8848, -0.1789, -1.0814,  1.0093, -1.3445, -0.9847,  0.2222,\n",
       "           1.4732]]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class QueryEmbedding(nn.Module):\n",
    "    def __init__(self, d_embedding, surface_embedding, num_pre_decoder_blocks, hidden_dim, dropout):\n",
    "        super(QueryEmbedding, self).__init__()\n",
    "        # Initialize the PointEmbedding\n",
    "        self.point_embedding = PointEmbedding(d_embedding, surface_embedding)\n",
    "\n",
    "        # Initialize the PreDecoder blocks\n",
    "        self.pre_decoders = nn.ModuleList([\n",
    "            PreDecoder(d_embedding, hidden_dim, dropout) for _ in range(num_pre_decoder_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, processed_batch):\n",
    "        query_point_batch = processed_batch['Query Point']\n",
    "\n",
    "        # First apply the point embedding\n",
    "        query_embedded = self.point_embedding(query_point_batch)\n",
    "        \n",
    "        # Sequentially apply each PreDecoder block\n",
    "        for pre_decoder in self.pre_decoders:\n",
    "            query_embedded = pre_decoder(query_embedded)\n",
    "        \n",
    "        # Reshape the output to (batch, 1, embedding) to make it a sequence of length 1\n",
    "        query_embedded = query_embedded.unsqueeze(1)  # Add the sequence length dimension\n",
    "        \n",
    "        return query_embedded\n",
    "    \n",
    "# Example usage\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "hidden_dim = HYPERPARAMETERS['Query Embedding']['Pre-Decoder']['Hidden Dimension']\n",
    "dropout = HYPERPARAMETERS['Query Embedding']['Pre-Decoder']['Dropout']\n",
    "num_pre_decoder_blocks = HYPERPARAMETERS['Query Embedding']['Pre-Decoder']['Number of Blocks']    \n",
    "\n",
    "query_embedding = QueryEmbedding(d_embedding, surface_embedding, num_pre_decoder_blocks, hidden_dim, dropout)\n",
    "query_embedded = query_embedding(processed_batch)\n",
    "query_embedded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0483, -0.2380, -1.5907,  0.8196, -1.4996,  0.9765, -0.1599,\n",
       "           0.6439]],\n",
       "\n",
       "        [[ 1.7490, -0.2841, -0.9002,  0.8834, -1.4725,  0.1600, -0.7979,\n",
       "           0.6623]],\n",
       "\n",
       "        [[ 1.3270, -0.5674, -1.4404,  0.9870, -1.2326,  0.9964, -0.4555,\n",
       "           0.3855]],\n",
       "\n",
       "        [[ 0.9850,  0.2246, -0.9211,  1.0486, -1.9522,  0.0174, -0.4226,\n",
       "           1.0204]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, d_embedding, n_heads, hidden_dim, dropout):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=d_embedding, num_heads=n_heads, batch_first=True)\n",
    "        self.scaled_residual_norm1 = ScaledResidualNorm(d_embedding)\n",
    "        self.feedforward = FeedForwardNetwork(d_embedding, hidden_dim, dropout)\n",
    "        self.scaled_residual_norm2 = ScaledResidualNorm(d_embedding)\n",
    "\n",
    "    def forward(self, query, encoded_surface):\n",
    "        # Cross-attention\n",
    "        cross_attn_output, _ = self.cross_attention(query, encoded_surface, encoded_surface)\n",
    "        x = self.scaled_residual_norm1(query, cross_attn_output)\n",
    "\n",
    "        # Feedforward network\n",
    "        ff_output = self.feedforward(x)\n",
    "        x = self.scaled_residual_norm2(x, ff_output)\n",
    "\n",
    "        return x\n",
    "\n",
    "class SurfaceDecoder(nn.Module):\n",
    "    def __init__(self, d_embedding, n_heads, hidden_dim, dropout, num_decoder_blocks):\n",
    "        super(SurfaceDecoder, self).__init__()\n",
    "        self.decoder_blocks = nn.ModuleList([\n",
    "            DecoderBlock(d_embedding, n_heads, hidden_dim, dropout) for _ in range(num_decoder_blocks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, query_embedded, encoded_surface):\n",
    "        x = query_embedded\n",
    "\n",
    "        for decoder_block in self.decoder_blocks:\n",
    "            x = decoder_block(x, encoded_surface)\n",
    "\n",
    "        return x\n",
    "    \n",
    "# Example usage:\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "n_heads = HYPERPARAMETERS['Surface Decoding']['Decoder']['Number of Heads']\n",
    "hidden_dim = HYPERPARAMETERS['Surface Decoding']['Decoder']['Hidden Dimension']\n",
    "dropout = HYPERPARAMETERS['Surface Decoding']['Decoder']['Dropout']\n",
    "num_decoder_blocks = HYPERPARAMETERS['Surface Decoding']['Decoder']['Number of Blocks']\n",
    "\n",
    "surface_decoder = SurfaceDecoder(d_embedding, n_heads, hidden_dim, dropout, num_decoder_blocks)\n",
    "decoded_surface = surface_decoder(query_embedded, encoded_surface)\n",
    "decoded_surface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IvySPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0161,  0.1768,  0.0644,  0.0999], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class IvySPT(nn.Module):\n",
    "    def __init__(self, hyperparameters):\n",
    "        super(IvySPT, self).__init__()\n",
    "        # Extract hyperparameters for each component\n",
    "        input_embedding_hp = hyperparameters['Input Embedding']\n",
    "        surface_encoding_hp = hyperparameters['Surface Encoding']['Encoder']\n",
    "        query_embedding_hp = hyperparameters['Query Embedding']['Pre-Decoder']\n",
    "        surface_decoding_hp = hyperparameters['Surface Decoding']['Decoder']\n",
    "\n",
    "        # Initialize modules\n",
    "        self.surface_embedding = SurfaceEmbedding(\n",
    "            grid_dim=input_embedding_hp['Surface Embedding']['Grid Dimension'],\n",
    "            d_embedding=input_embedding_hp['Surface Embedding']['Channels Dimension'],\n",
    "            branch_channels=input_embedding_hp['Pre-Encoder']['Branch Channels Dimension'],\n",
    "            num_pre_encoder_blocks=input_embedding_hp['Pre-Encoder']['Number of Blocks']\n",
    "        )\n",
    "\n",
    "        self.surface_encoding = SurfaceEncoding(\n",
    "            d_embedding=input_embedding_hp['Surface Embedding']['Channels Dimension'],\n",
    "            n_heads=surface_encoding_hp['Number of Heads'],\n",
    "            hidden_dim=surface_encoding_hp['Hidden Dimension'],\n",
    "            dropout=surface_encoding_hp['Dropout'],\n",
    "            external_dim=surface_encoding_hp['External Feature Dimension'],\n",
    "            num_encoder_blocks=surface_encoding_hp['Number of Blocks']\n",
    "        )\n",
    "\n",
    "        self.query_embedding = QueryEmbedding(\n",
    "            d_embedding=input_embedding_hp['Surface Embedding']['Channels Dimension'],\n",
    "            surface_embedding=self.surface_embedding,\n",
    "            num_pre_decoder_blocks=query_embedding_hp['Number of Blocks'],\n",
    "            hidden_dim=query_embedding_hp['Hidden Dimension'],\n",
    "            dropout=query_embedding_hp['Dropout']\n",
    "        )\n",
    "\n",
    "        self.surface_decoder = SurfaceDecoder(\n",
    "            d_embedding=input_embedding_hp['Surface Embedding']['Channels Dimension'],\n",
    "            n_heads=surface_decoding_hp['Number of Heads'],\n",
    "            hidden_dim=surface_decoding_hp['Hidden Dimension'],\n",
    "            dropout=surface_decoding_hp['Dropout'],\n",
    "            num_decoder_blocks=surface_decoding_hp['Number of Blocks']\n",
    "        )\n",
    "\n",
    "        # Final fully connected layer to predict implied volatility\n",
    "        self.final_layer = nn.Linear(input_embedding_hp['Surface Embedding']['Channels Dimension'], 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # Pass batch through Surface Embedding\n",
    "        tokenized_positional_embedded_batch, processed_batch = self.surface_embedding(batch)\n",
    "\n",
    "        # Pass tokenized embeddings and market features to Surface Encoding\n",
    "        encoded_output = self.surface_encoding(tokenized_positional_embedded_batch, processed_batch)\n",
    "\n",
    "        # Pass query points through Query Embedding\n",
    "        query_embedded = self.query_embedding(processed_batch)\n",
    "\n",
    "        # Decode the query embeddings with the encoded surface data\n",
    "        decoded_output = self.surface_decoder(query_embedded, encoded_output)\n",
    "\n",
    "        # Apply the final fully connected layer\n",
    "        final_output = self.final_layer(decoded_output.squeeze(1)).squeeze(1)  # Removing sequence length dimension and flattening\n",
    "\n",
    "        return final_output\n",
    "\n",
    "torch.manual_seed(RANDOM_STATE)    \n",
    "ivy_spt = IvySPT(HYPERPARAMETERS)\n",
    "iv_estimates = ivy_spt(batch)  \n",
    "iv_estimates  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surface Arbitrage Free Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.9122, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SurfaceArbitrageFreeLoss(nn.Module):\n",
    "    def __init__(self, hyperparameters):\n",
    "        super(SurfaceArbitrageFreeLoss, self).__init__()\n",
    "        self.calendar_coeff = hyperparameters['No-Arbitrage']['Calendar']\n",
    "        self.butterfly_coeff = hyperparameters['No-Arbitrage']['Butterfly']\n",
    "\n",
    "    def forward(self, iv_estimates, batch):\n",
    "        target_volatility = batch['Target Volatility']\n",
    "\n",
    "        # Calculate mean squared error between model estimates and target volatilities\n",
    "        mse_loss = F.mse_loss(iv_estimates, target_volatility)\n",
    "\n",
    "        # Calculate the total implied variance\n",
    "        time_to_maturity = batch['Query Point']['Time to Maturity']\n",
    "        log_moneyness = batch['Query Point']['Log Moneyness']\n",
    "        total_implied_variance = time_to_maturity * iv_estimates.pow(2)\n",
    "\n",
    "        # Compute gradients needed for arbitrage conditions\n",
    "        w_t = torch.autograd.grad(total_implied_variance.sum(), time_to_maturity, create_graph=True)[0] \n",
    "        w_x = torch.autograd.grad(total_implied_variance.sum(), log_moneyness, create_graph=True)[0]\n",
    "        w_xx = torch.autograd.grad(w_x.sum(), log_moneyness, create_graph=True)[0]\n",
    "\n",
    "        # Calculate Calendar Arbitrage Loss\n",
    "        calendar_arbitrage_loss = torch.mean(torch.clamp(-w_t, min=0) ** 2)\n",
    "\n",
    "        # Calculate Butterfly Arbitrage Loss\n",
    "        w = total_implied_variance\n",
    "        g = (1 - log_moneyness * w_x / (2 * w)) ** 2 - w_x / 4 * (1 / w + 1 / 4) + w_xx / 2\n",
    "        butterfly_arbitrage_loss = torch.mean(torch.clamp(-g, min=0) ** 2)\n",
    "\n",
    "        # Combine all losses with coefficients\n",
    "        total_loss = mse_loss + self.calendar_coeff * calendar_arbitrage_loss + self.butterfly_coeff * butterfly_arbitrage_loss\n",
    "\n",
    "        return total_loss\n",
    "    \n",
    "surface_arbitrage_free_loss = SurfaceArbitrageFreeLoss(HYPERPARAMETERS)    \n",
    "total_loss = surface_arbitrage_free_loss(iv_estimates, batch)\n",
    "total_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
