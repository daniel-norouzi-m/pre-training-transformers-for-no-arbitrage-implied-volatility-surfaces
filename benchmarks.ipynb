{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.interpolate import griddata\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tracemalloc  # For memory usage\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "from ivyspt.input_processing import split_surfaces, IVSurfaceDataset\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "RANDOM_STATE = 0\n",
    "N_JOBS = 8\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "np.random.seed(RANDOM_STATE)\n",
    "random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    'Input Preprocessing' : {\n",
    "        'Mask Proportions' : [0.1, 0.3, 0.5, 0.7],\n",
    "        'Number of Query Points' : None,\n",
    "        'Batch Size' : 1\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_data = pd.read_csv('data/pre_train_data.csv', parse_dates=True, index_col=[0, 1], date_format=\"ISO8601\")\n",
    "fine_tune_data = pd.read_csv('data/fine_tune_data.csv', parse_dates=True, index_col=[0, 1], date_format=\"ISO8601\")\n",
    "pre_train_surfaces_train, pre_train_surfaces_validation, pre_train_surfaces_test = split_surfaces(\n",
    "    pre_train_data,\n",
    "    toy_sample=True,\n",
    "    max_points=50,\n",
    "    max_surfaces=50,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "fine_tune_surfaces_train, fine_tune_surfaces_validation, fine_tune_surfaces_test = split_surfaces(\n",
    "    fine_tune_data,\n",
    "    toy_sample=True,\n",
    "    max_points=50,\n",
    "    max_surfaces=50,\n",
    "    random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_dataset_test = IVSurfaceDataset(\n",
    "    pre_train_surfaces_test, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "pre_train_data_loader_test = DataLoader(\n",
    "    pre_train_dataset_test, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")\n",
    "fine_tune_dataset_test = IVSurfaceDataset(\n",
    "    fine_tune_surfaces_test, \n",
    "    hyperparameters['Input Preprocessing']['Mask Proportions'], \n",
    "    RANDOM_STATE, \n",
    "    hyperparameters['Input Preprocessing']['Number of Query Points'] \n",
    ")\n",
    "fine_tune_data_loader_test = DataLoader(\n",
    "    fine_tune_dataset_test, \n",
    "    batch_size=hyperparameters['Input Preprocessing']['Batch Size'], \n",
    "    shuffle=True, \n",
    "    num_workers=0, \n",
    "    collate_fn=IVSurfaceDataset.collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU Information:\n",
      "Model Name: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz\n",
      "\n",
      "\n",
      "GPU Information:\n",
      "Number of GPUs available: 1\n",
      "GPU 0: NVIDIA GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import torch\n",
    "\n",
    "def get_cpu_info():\n",
    "    # Run the lscpu command\n",
    "    result = subprocess.run(['lscpu'], stdout=subprocess.PIPE)\n",
    "    # Decode the output from bytes to string\n",
    "    lscpu_output = result.stdout.decode('utf-8')\n",
    "    \n",
    "    # Parse the lscpu output\n",
    "    cpu_info = {}\n",
    "    for line in lscpu_output.split('\\n'):\n",
    "        if line.strip():\n",
    "            parts = line.split(':', 1)\n",
    "            if len(parts) == 2:\n",
    "                key, value = parts\n",
    "                cpu_info[key.strip()] = value.strip()\n",
    "\n",
    "    # Extract useful information\n",
    "    useful_info = {\n",
    "        \"Model name\": cpu_info.get(\"Model name\"),\n",
    "    }\n",
    "\n",
    "    return useful_info\n",
    "\n",
    "def format_cpu_info(cpu_info):\n",
    "    report = (\n",
    "        f\"Model Name: {cpu_info['Model name']}\\n\"\n",
    "    )\n",
    "    return report\n",
    "\n",
    "def print_device_info():\n",
    "    # Print CPU info\n",
    "    cpu_info = get_cpu_info()\n",
    "    print(\"CPU Information:\")\n",
    "    print(format_cpu_info(cpu_info))\n",
    "\n",
    "    # Check if CUDA (GPU) is available\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"\\nGPU Information:\")\n",
    "        print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"\\nNo GPU available. Running on CPU.\")\n",
    "\n",
    "# Call the function\n",
    "print_device_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_models(\n",
    "    data_loader, \n",
    "    model_type='mlp',\n",
    "    random_state=0\n",
    "):\n",
    "    mse_list = []\n",
    "    total_time = 0\n",
    "    max_memory_usage = 0\n",
    "\n",
    "    for batch in data_loader:\n",
    "        # Extract the data from the batch\n",
    "        input_surface = batch['Input Surface']\n",
    "        query_points = batch['Query Points']\n",
    "\n",
    "        X_train = np.column_stack((\n",
    "            input_surface['Log Moneyness'][0].numpy(), \n",
    "            input_surface['Time to Maturity'][0].numpy()\n",
    "        ))\n",
    "        y_train = input_surface['Total Variance'][0].numpy()\n",
    "\n",
    "        X_test = np.column_stack((\n",
    "            query_points['Log Moneyness'][0].detach().clone().numpy(), \n",
    "            query_points['Time to Maturity'][0].detach().clone().numpy()\n",
    "        ))\n",
    "        y_test = query_points['Total Variance'][0].numpy()\n",
    "\n",
    "        # Start memory and time tracking\n",
    "        tracemalloc.start()\n",
    "        start_time = time.time()\n",
    "\n",
    "        if model_type == 'mlp':\n",
    "            model = MLPRegressor(max_iter=500, random_state=random_state)\n",
    "\n",
    "        elif model_type == 'gpr':\n",
    "            model = GaussianProcessRegressor(random_state=random_state)\n",
    "\n",
    "        elif model_type == 'quadratic':\n",
    "            poly = PolynomialFeatures(degree=2)\n",
    "            X_train_poly = poly.fit_transform(X_train)\n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train_poly, y_train)\n",
    "            X_test_poly = poly.transform(X_test)\n",
    "            y_pred = model.predict(X_test_poly)\n",
    "\n",
    "        elif model_type == 'cubic_spline':\n",
    "            y_pred = griddata(X_train, y_train, X_test, method='cubic')    \n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model type.\")\n",
    "\n",
    "        if model_type in ['mlp', 'gpr']:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "        # Calculate the MSE\n",
    "        if not np.isnan(y_pred).any():\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            mse_list.append(mse)\n",
    "\n",
    "        # End memory and time tracking\n",
    "        current_memory, peak_memory = tracemalloc.get_traced_memory()\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        tracemalloc.stop()\n",
    "\n",
    "        total_time += elapsed_time\n",
    "        max_memory_usage = max(max_memory_usage, peak_memory)\n",
    "\n",
    "    # Aggregate results\n",
    "    avg_mse = np.mean(mse_list)\n",
    "    print(f\"Model: {model_type.upper()}\")\n",
    "    print(f\"Average MSE: {avg_mse:.6f}\")\n",
    "    print(f\"Total Computation Time: {total_time:.2f} seconds\")\n",
    "    print(f\"Max Memory Usage: {max_memory_usage / 1024:.2f} KB\")\n",
    "\n",
    "    return avg_mse, total_time, max_memory_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MLP\n",
      "Average MSE: 0.006071\n",
      "Total Computation Time: 0.75 seconds\n",
      "Max Memory Usage: 71.62 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.006071134, 0.7473068237304688, 73334)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP\n",
    "benchmark_models(pre_train_data_loader_test, model_type='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GPR\n",
      "Average MSE: 59.368100\n",
      "Total Computation Time: 0.19 seconds\n",
      "Max Memory Usage: 62.33 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(59.36810031723222, 0.18669891357421875, 63822)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Process Regression\n",
    "benchmark_models(pre_train_data_loader_test, model_type='gpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: QUADRATIC\n",
      "Average MSE: 0.005918\n",
      "Total Computation Time: 0.12 seconds\n",
      "Max Memory Usage: 21.42 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0059176637, 0.11544299125671387, 21938)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quadratic Regression\n",
    "benchmark_models(pre_train_data_loader_test, model_type='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CUBIC_SPLINE\n",
      "Average MSE: nan\n",
      "Total Computation Time: 0.03 seconds\n",
      "Max Memory Usage: 22.59 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hermes/anaconda3/envs/Apache/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/hermes/anaconda3/envs/Apache/lib/python3.10/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nan, 0.025411128997802734, 23135)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cubic Spline\n",
    "benchmark_models(pre_train_data_loader_test, model_type='cubic_spline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hermes/anaconda3/envs/Apache/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/hermes/anaconda3/envs/Apache/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/hermes/anaconda3/envs/Apache/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: MLP\n",
      "Average MSE: 0.170223\n",
      "Total Computation Time: 1.84 seconds\n",
      "Max Memory Usage: 199.20 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.17022325, 1.842632532119751, 203984)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP\n",
    "benchmark_models(fine_tune_data_loader_test, model_type='mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GPR\n",
      "Average MSE: 0.394979\n",
      "Total Computation Time: 0.22 seconds\n",
      "Max Memory Usage: 44.51 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3949791406405574, 0.21772193908691406, 45581)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Gaussian Process Regression\n",
    "benchmark_models(fine_tune_data_loader_test, model_type='gpr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: QUADRATIC\n",
      "Average MSE: 0.170043\n",
      "Total Computation Time: 0.11 seconds\n",
      "Max Memory Usage: 10.79 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.17004265, 0.10647821426391602, 11048)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quadratic Regression\n",
    "benchmark_models(fine_tune_data_loader_test, model_type='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: CUBIC_SPLINE\n",
      "Average MSE: 0.364371\n",
      "Total Computation Time: 0.03 seconds\n",
      "Max Memory Usage: 15.00 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.36437131553383834, 0.03224349021911621, 15356)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cubic Spline\n",
    "benchmark_models(fine_tune_data_loader_test, model_type='cubic_spline')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
